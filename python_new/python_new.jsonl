{"message": "> Do we know if Oracle is affected as well?\r\n\r\nIt works on Oracle.", "timestamp": "2023-01-16T18:26:37Z", "file_name": "tests/aggregation/tests.py", "range": {"start_line": 1630, "end_line": 1630, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1071502713", "html_url": "https://github.com/django/django/pull/16460#discussion_r1071502713", "attention_area": "        self.assertCountEqual(books_qs, [300, 946, 1132])", "file_path": "files/41/00/00000041.py", "old_file_path": "files/40/00/00000040.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1614,6 +1615,20 @@ def test_group_by_exists_annotation(self):\n         ).annotate(total=Count(\"*\"))\n         self.assertEqual(dict(has_long_books_breakdown), {True: 2, False: 3})\n \n+    def test_group_by_nested_expression_with_params(self):\n+        books_qs = (\n+            Book.objects.annotate(greatest_pages=Greatest(\"pages\", Value(600)))\n+            .values(\n+                \"greatest_pages\",\n+            )\n+            .annotate(\n+                min_pages=Min(\"pages\"),\n+                least=Least(\"min_pages\", \"greatest_pages\"),\n+            )\n+            .values_list(\"least\", flat=True)\n+        )\n+        self.assertCountEqual(books_qs, [300, 946, 1132])", "source": "def test_group_by_nested_expression_with_params(self):\n        books_qs = (\n            Book.objects.annotate(greatest_pages=Greatest(\"pages\", Value(600)))\n            .values(\n                \"greatest_pages\",\n            )\n            .annotate(\n                min_pages=Min(\"pages\"),\n                least=Least(\"min_pages\", \"greatest_pages\"),\n            )\n            .values_list(\"least\", flat=True)\n        )\n        self.assertCountEqual(books_qs, [300, 946, 1132])", "source_start_line": 1618, "tokens": ["def", "test_group_by_nested_expression_with_params", "(", "self", ")", ":", "books_qs", "=", "(", "Book", ".", "objects", ".", "annotate", "(", "greatest_pages", "=", "Greatest", "(", "\"pages\"", ",", "Value", "(", "600", ")", ")", ")", ".", "values", "(", "\"greatest_pages\"", ",", ")", ".", "annotate", "(", "min_pages", "=", "Min", "(", "\"pages\"", ")", ",", "least", "=", "Least", "(", "\"min_pages\"", ",", "\"greatest_pages\"", ")", ",", ")", ".", "values_list", "(", "\"least\"", ",", "flat", "=", "True", ")", ")", "self", ".", "assertCountEqual", "(", "books_qs", ",", "[", "300", ",", "946", ",", "1132", "]", ")"], "to_mask": {"VAR": ["books_qs", "self"], "METHOD": ["Greatest", "Least", "Min", "Value", "annotate", "assertCountEqual", "values", "values_list"]}, "attention_idx_tokens": [63, 76], "patch": "@@ -1614,6 +1615,20 @@\n         ).annotate(total=Count(\"*\"))\n         self.assertEqual(dict(has_long_books_breakdown), {True: 2, False: 3})\n \n+    def test_group_by_nested_expression_with_params(self):\n+        books_qs = (\n+            Book.objects.annotate(greatest_pages=Greatest(\"pages\", Value(600)))\n+            .values(\n+                \"greatest_pages\",\n+            )\n+            .annotate(\n+                min_pages=Min(\"pages\"),\n+                least=Least(\"min_pages\", \"greatest_pages\"),\n+            )\n+            .values_list(\"least\", flat=True)\n+        )\n+        self.assertCountEqual(books_qs, [300, 946, 1132])", "ext_attention_idx_tokens": [0, 76], "uid": "d094c694", "question": "> Do we know if Oracle is affected as well?    It works on Oracle.", "code": "def test group by nested expression with params self books qs Book objects annotate greatest pages Greatest \"pages\" Value 600 values \"greatest pages\" annotate min pages Min \"pages\" least Least \"min pages\" \"greatest pages\" values list \"least\" flat True self assertCountEqual books qs [300 946 1132]"}
{"message": "This change is backward compatible I'm afraid, what about tables were created before we attempt to change the naming conventions?", "timestamp": "2023-02-10T06:56:15Z", "file_name": "django/db/models/fields/related.py", "range": {"start_line": 1266, "end_line": 1266, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1102347746", "html_url": "https://github.com/django/django/pull/16532#discussion_r1102347746", "attention_area": "", "file_path": "files/89/00/00000089.py", "old_file_path": "files/90/00/00000090.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1252,11 +1252,18 @@ def set_managed(model, related, through):\n     lazy_related_operation(set_managed, klass, to_model, name)\n \n     to = make_model_tuple(to_model)[1]\n+    to_app = make_model_tuple(to_model)[0]\n     from_ = klass._meta.model_name\n-    if to == from_:\n+    has_conflicting_m2m_field = False\n+\n+    if to == from_ and to_app == klass._meta.app_label:\n         to = \"to_%s\" % to\n         from_ = \"from_%s\" % from_\n \n+    if to == from_ and to_app != klass._meta.app_label:\n+        to = \"%s_%s\" % (to_app, to)\n+        has_conflicting_m2m_field = True\n+", "source": "def create_many_to_many_intermediary_model(field, klass):\n    from django.db import models\n\n    def set_managed(model, related, through):\n        through._meta.managed = model._meta.managed or related._meta.managed\n\n    to_model = resolve_relation(klass, field.remote_field.model)\n    name = \"%s_%s\" % (klass._meta.object_name, field.name)\n    lazy_related_operation(set_managed, klass, to_model, name)\n\n    to = make_model_tuple(to_model)[1]\n    to_app = make_model_tuple(to_model)[0]\n    from_ = klass._meta.model_name\n    has_conflicting_m2m_field = False\n\n    if to == from_ and to_app == klass._meta.app_label:\n        to = \"to_%s\" % to\n        from_ = \"from_%s\" % from_\n\n    if to == from_ and to_app != klass._meta.app_label:\n        to = \"%s_%s\" % (to_app, to)\n        has_conflicting_m2m_field = True\n\n    meta = type(\n        \"Meta\",\n        (),\n        {\n            \"db_table\": field._get_m2m_db_table(klass._meta),\n            \"auto_created\": klass,\n            \"app_label\": klass._meta.app_label,\n            \"db_tablespace\": klass._meta.db_tablespace,\n            \"unique_together\": (from_, to),\n            \"verbose_name\": _(\"%(from)s-%(to)s relationship\")\n            % {\"from\": from_, \"to\": to},\n            \"verbose_name_plural\": _(\"%(from)s-%(to)s relationships\")\n            % {\"from\": from_, \"to\": to},\n            \"apps\": field.model._meta.apps,\n            \"has_conflicting_m2m_field\": has_conflicting_m2m_field,\n        },\n    )\n    # Construct and return the new class.\n    return type(\n        name,\n        (models.Model,),\n        {\n            \"Meta\": meta,\n            \"__module__\": klass.__module__,\n            from_: models.ForeignKey(\n                klass,\n                related_name=\"%s+\" % name,\n                db_tablespace=field.db_tablespace,\n                db_constraint=field.remote_field.db_constraint,\n                on_delete=CASCADE,\n            ),\n            to: models.ForeignKey(\n                to_model,\n                related_name=\"%s+\" % name,\n                db_tablespace=field.db_tablespace,\n                db_constraint=field.remote_field.db_constraint,\n                on_delete=CASCADE,\n            ),\n        },\n    )", "source_start_line": 1244, "tokens": ["def", "create_many_to_many_intermediary_model", "(", "field", ",", "klass", ")", ":", "from", "django", ".", "db", "import", "models", "def", "set_managed", "(", "model", ",", "related", ",", "through", ")", ":", "through", ".", "_meta", ".", "managed", "=", "model", ".", "_meta", ".", "managed", "or", "related", ".", "_meta", ".", "managed", "to_model", "=", "resolve_relation", "(", "klass", ",", "field", ".", "remote_field", ".", "model", ")", "name", "=", "\"%s_%s\"", "%", "(", "klass", ".", "_meta", ".", "object_name", ",", "field", ".", "name", ")", "lazy_related_operation", "(", "set_managed", ",", "klass", ",", "to_model", ",", "name", ")", "to", "=", "make_model_tuple", "(", "to_model", ")", "[", "1", "]", "to_app", "=", "make_model_tuple", "(", "to_model", ")", "[", "0", "]", "from_", "=", "klass", ".", "_meta", ".", "model_name", "has_conflicting_m2m_field", "=", "False", "if", "to", "==", "from_", "and", "to_app", "==", "klass", ".", "_meta", ".", "app_label", ":", "to", "=", "\"to_%s\"", "%", "to", "from_", "=", "\"from_%s\"", "%", "from_", "if", "to", "==", "from_", "and", "to_app", "!=", "klass", ".", "_meta", ".", "app_label", ":", "to", "=", "\"%s_%s\"", "%", "(", "to_app", ",", "to", ")", "has_conflicting_m2m_field", "=", "True", "meta", "=", "type", "(", "\"Meta\"", ",", "(", ")", ",", "{", "\"db_table\"", ":", "field", ".", "_get_m2m_db_table", "(", "klass", ".", "_meta", ")", ",", "\"auto_created\"", ":", "klass", ",", "\"app_label\"", ":", "klass", ".", "_meta", ".", "app_label", ",", "\"db_tablespace\"", ":", "klass", ".", "_meta", ".", "db_tablespace", ",", "\"unique_together\"", ":", "(", "from_", ",", "to", ")", ",", "\"verbose_name\"", ":", "_", "(", "\"%(from)s-%(to)s relationship\"", ")", "%", "{", "\"from\"", ":", "from_", ",", "\"to\"", ":", "to", "}", ",", "\"verbose_name_plural\"", ":", "_", "(", "\"%(from)s-%(to)s relationships\"", ")", "%", "{", "\"from\"", ":", "from_", ",", "\"to\"", ":", "to", "}", ",", "\"apps\"", ":", "field", ".", "model", ".", "_meta", ".", "apps", ",", "\"has_conflicting_m2m_field\"", ":", "has_conflicting_m2m_field", ",", "}", ",", ")", "return", "type", "(", "name", ",", "(", "models", ".", "Model", ",", ")", ",", "{", "\"Meta\"", ":", "meta", ",", "\"__module__\"", ":", "klass", ".", "__module__", ",", "from_", ":", "models", ".", "ForeignKey", "(", "klass", ",", "related_name", "=", "\"%s+\"", "%", "name", ",", "db_tablespace", "=", "field", ".", "db_tablespace", ",", "db_constraint", "=", "field", ".", "remote_field", ".", "db_constraint", ",", "on_delete", "=", "CASCADE", ",", ")", ",", "to", ":", "models", ".", "ForeignKey", "(", "to_model", ",", "related_name", "=", "\"%s+\"", "%", "name", ",", "db_tablespace", "=", "field", ".", "db_tablespace", ",", "db_constraint", "=", "field", ".", "remote_field", ".", "db_constraint", ",", "on_delete", "=", "CASCADE", ",", ")", ",", "}", ",", ")"], "to_mask": {"VAR": ["field", "from_", "has_conflicting_m2m_field", "klass", "managed", "meta", "model", "name", "related", "through", "to", "to_app", "to_model"], "METHOD": ["ForeignKey", "_", "_get_m2m_db_table", "lazy_related_operation", "make_model_tuple", "resolve_relation", "type"]}, "attention_idx_tokens": [null, null], "patch": "@@ -1252,11 +1252,18 @@\n     lazy_related_operation(set_managed, klass, to_model, name)\n \n     to = make_model_tuple(to_model)[1]\n+    to_app = make_model_tuple(to_model)[0]\n     from_ = klass._meta.model_name\n-    if to == from_:\n+    has_conflicting_m2m_field = False\n+\n+    if to == from_ and to_app == klass._meta.app_label:\n         to = \"to_%s\" % to\n         from_ = \"from_%s\" % from_\n \n+    if to == from_ and to_app != klass._meta.app_label:\n+        to = \"%s_%s\" % (to_app, to)\n+        has_conflicting_m2m_field = True\n+", "ext_attention_idx_tokens": [87, 157], "uid": "5acbdd61", "question": "This change is backward compatible I'm afraid, what about tables were created before we attempt to change the naming conventions?", "code": "def create many to many intermediary model field klass from django db import models def set managed model related through through meta managed model meta managed or related meta managed to model resolve relation klass field remote field model name \"%s %s\" % klass meta object name field name lazy related operation set managed klass to model name to make model tuple to model [1] to app make model tuple to model [0] from klass meta model name has conflicting m2m field False if to from and to app klass meta app label to \"to %s\" % to from \"from %s\" % from if to from and to app ! klass meta app label to \"%s %s\" % to app to has conflicting m2m field True meta type \"Meta\" { \"db table\" field get m2m db table klass meta \"auto created\" klass \"app label\" klass meta app label \"db tablespace\" klass meta db tablespace \"unique together\" from to \"verbose name\" \"% from s-% to s relationship\" % {\"from\" from \"to\" to} \"verbose name plural\" \"% from s-% to s relationships\" % {\"from\" from \"to\" to} \"apps\" field model meta apps \"has conflicting m2m field\" has conflicting m2m field } # Construct and return the new class return type name models Model { \"Meta\" meta \" module \" klass module from models ForeignKey klass related name \"%s+\" % name db tablespace field db tablespace db constraint field remote field db constraint on delete CASCADE to models ForeignKey to model related name \"%s+\" % name db tablespace field db tablespace db constraint field remote field db constraint on delete CASCADE }"}
{"message": "> `test_union_multiple_models_with_values_list_and_annotations` still works when reverting other changes\r\n\r\nIt does? \ud83e\udd14 \r\nUsing Python 3.10.4 and 3.11.1, it fails if we keep the `set` in `self.annotation_select_mask`.\r\nBut I guess the order could be correct in the `set` by \"chance\".\r\n\r\n`aggregation_regress.tests.AggregationTests.test_values_list_annotation_args_ordering` also fails locally when reverting other changes.", "timestamp": "2023-03-18T22:00:05Z", "file_name": "django/db/models/sql/query.py", "range": {"start_line": 2433, "end_line": 2433, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1141177453", "html_url": "https://github.com/django/django/pull/16649#discussion_r1141177453", "attention_area": "                if k in self.annotations", "file_path": "files/85/01/00000185.py", "old_file_path": "files/84/01/00000184.py", "filters": {"comment_message": false, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -2423,9 +2428,9 @@ def annotation_select(self):\n             return {}\n         elif self.annotation_select_mask is not None:\n             self._annotation_select_cache = {\n-                k: v\n-                for k, v in self.annotations.items()\n-                if k in self.annotation_select_mask\n+                k: self.annotations[k]\n+                for k in self.annotation_select_mask\n+                if k in self.annotations", "source": "def annotation_select(self):\n        \"\"\"\n        Return the dictionary of aggregate columns that are not masked and\n        should be used in the SELECT clause. Cache this result for performance.\n        \"\"\"\n        if self._annotation_select_cache is not None:\n            return self._annotation_select_cache\n        elif not self.annotations:\n            return {}\n        elif self.annotation_select_mask is not None:\n            self._annotation_select_cache = {\n                k: self.annotations[k]\n                for k in self.annotation_select_mask\n                if k in self.annotations\n            }\n            return self._annotation_select_cache\n        else:\n            return self.annotations", "source_start_line": 2420, "tokens": ["def", "annotation_select", "(", "self", ")", ":", "\"\"\"        Return the dictionary of aggregate columns that are not masked and        should be used in the SELECT clause. Cache this result for performance.        \"\"\"", "if", "self", ".", "_annotation_select_cache", "is", "not", "None", ":", "return", "self", ".", "_annotation_select_cache", "elif", "not", "self", ".", "annotations", ":", "return", "{", "}", "elif", "self", ".", "annotation_select_mask", "is", "not", "None", ":", "self", ".", "_annotation_select_cache", "=", "{", "k", ":", "self", ".", "annotations", "[", "k", "]", "for", "k", "in", "self", ".", "annotation_select_mask", "if", "k", "in", "self", ".", "annotations", "}", "return", "self", ".", "_annotation_select_cache", "else", ":", "return", "self", ".", "annotations"], "to_mask": {"VAR": ["_annotation_select_cache", "self"], "METHOD": []}, "attention_idx_tokens": [55, 60], "patch": "@@ -2423,9 +2428,9 @@\n             return {}\n         elif self.annotation_select_mask is not None:\n             self._annotation_select_cache = {\n-                k: v\n-                for k, v in self.annotations.items()\n-                if k in self.annotation_select_mask\n+                k: self.annotations[k]\n+                for k in self.annotation_select_mask\n+                if k in self.annotations", "ext_attention_idx_tokens": [41, 61], "uid": "6dc2c374", "question": "> `test_union_multiple_models_with_values_list_and_annotations` still works when reverting other changes    It does? \ud83e\udd14   Using Python 3.10.4 and 3.11.1, it fails if we keep the `set` in `self.annotation_select_mask`.  But I guess the order could be correct in the `set` by \"chance\".    `aggregation_regress.tests.AggregationTests.test_values_list_annotation_args_ordering` also fails locally when reverting other changes.", "code": "def annotation select self \"\"\" Return the dictionary of aggregate columns that are not masked and should be used in the SELECT clause Cache this result for performance \"\"\" if self annotation select cache is not None return self annotation select cache elif not self annotations return {} elif self annotation select mask is not None self annotation select cache { k self annotations[k] for k in self annotation select mask if k in self annotations } return self annotation select cache else return self annotations"}
{"message": "@adamchainz You're probably more familiar with chaining than me but isn't the implicit version slightly different? \ud83e\udd14  At least that's how I'm reading it in the docs:\r\n\r\nhttps://docs.python.org/3/tutorial/errors.html#exception-chaining\r\n\r\nMore specifically: https://docs.python.org/3/reference/simple_stmts.html#raise\r\n\r\nUsing `from` attaches the parent to the `__cause__` as opposed to the `__context__` with the implicit variety \ud83e\udd14\r\n", "timestamp": "2023-03-29T08:10:30Z", "file_name": "django/template/context.py", "range": {"start_line": 261, "end_line": 261, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1151550745", "html_url": "https://github.com/django/django/pull/16693#discussion_r1151550745", "attention_area": "                ) from e", "file_path": "files/26/02/00000226.py", "old_file_path": "files/21/02/00000221.py", "filters": {"comment_message": false, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -251,7 +251,15 @@ def bind_template(self, template):\n         processors = template.engine.template_context_processors + self._processors\n         updates = {}\n         for processor in processors:\n-            updates.update(processor(self.request))\n+            context = processor(self.request)\n+            try:\n+                updates.update(context)\n+            except TypeError as e:\n+                raise TypeError(\n+                    f\"Context processor {processor.__qualname__} didn't return a \"\n+                    \"dictionary.\"\n+                ) from e", "source": "def bind_template(self, template):\n        if self.template is not None:\n            raise RuntimeError(\"Context is already bound to a template\")\n\n        self.template = template\n        # Set context processors according to the template engine's settings.\n        processors = template.engine.template_context_processors + self._processors\n        updates = {}\n        for processor in processors:\n            context = processor(self.request)\n            try:\n                updates.update(context)\n            except TypeError as e:\n                raise TypeError(\n                    f\"Context processor {processor.__qualname__} didn't return a \"\n                    \"dictionary.\"\n                ) from e\n\n        self.dicts[self._processors_index] = updates\n\n        try:\n            yield\n        finally:\n            self.template = None\n            # Unset context processors.\n            self.dicts[self._processors_index] = {}", "source_start_line": 245, "tokens": ["def", "bind_template", "(", "self", ",", "template", ")", ":", "if", "self", ".", "template", "is", "not", "None", ":", "raise", "RuntimeError", "(", "\"Context is already bound to a template\"", ")", "self", ".", "template", "=", "template", "processors", "=", "template", ".", "engine", ".", "template_context_processors", "+", "self", ".", "_processors", "updates", "=", "{", "}", "for", "processor", "in", "processors", ":", "context", "=", "processor", "(", "self", ".", "request", ")", "try", ":", "updates", ".", "update", "(", "context", ")", "except", "TypeError", "as", "e", ":", "raise", "TypeError", "(", "f\"", "{", "processor", ".", "__qualname__", "}", "\"", "\"dictionary.\"", ")", "from", "e", "self", ".", "dicts", "[", "self", ".", "_processors_index", "]", "=", "updates", "try", ":", "yield", "finally", ":", "self", ".", "template", "=", "None", "self", ".", "dicts", "[", "self", ".", "_processors_index", "]", "=", "{", "}"], "to_mask": {"VAR": ["context", "e", "processor", "processors", "self", "template", "updates"], "METHOD": ["RuntimeError", "TypeError", "processor", "update"]}, "attention_idx_tokens": [78, 80], "patch": "@@ -251,7 +251,15 @@\n         processors = template.engine.template_context_processors + self._processors\n         updates = {}\n         for processor in processors:\n-            updates.update(processor(self.request))\n+            context = processor(self.request)\n+            try:\n+                updates.update(context)\n+            except TypeError as e:\n+                raise TypeError(\n+                    f\"Context processor {processor.__qualname__} didn't return a \"\n+                    \"dictionary.\"\n+                ) from e", "ext_attention_idx_tokens": [46, 90], "uid": "8af67a63", "question": "@adamchainz You're probably more familiar with chaining than me but isn't the implicit version slightly different? \ud83e\udd14  At least that's how I'm reading it in the docs:    https://docs.python.org/3/tutorial/errors.html#exception-chaining    More specifically: https://docs.python.org/3/reference/simple_stmts.html#raise    Using `from` attaches the parent to the `__cause__` as opposed to the `__context__` with the implicit variety \ud83e\udd14  ", "code": "def bind template self template if self template is not None raise RuntimeError \"Context is already bound to a template\" self template template # Set context processors according to the template engine s settings processors template engine template context processors + self processors updates {} for processor in processors context processor self request try updates update context except TypeError as e raise TypeError f\"Context processor {processor qualname } didn t return a \" \"dictionary \" from e self dicts[self processors index] updates try yield finally self template None # Unset context processors self dicts[self processors index] {}"}
{"message": "This change is due to the fact that we're currently activating a fallback language not `settings.LANGUAGE_CODE`:\r\n\r\nhttps://github.com/django/django/blob/5b8a043bf51ab8bcf4a758d0b4646f30a84be183/django/middleware/locale.py#L40-L41\r\n\r\n@claudep What do you think?", "timestamp": "2023-04-07T08:50:04Z", "file_name": "django/urls/resolvers.py", "range": {"start_line": 355, "end_line": 355, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1160552460", "html_url": "https://github.com/django/django/pull/16735#discussion_r1160552460", "attention_area": "        if language_code == default_language and not self.prefix_default_language:", "file_path": "files/39/02/00000239.py", "old_file_path": "files/38/02/00000238.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -351,7 +351,8 @@ def regex(self):\n     @property\n     def language_prefix(self):\n         language_code = get_language() or settings.LANGUAGE_CODE\n-        if language_code == settings.LANGUAGE_CODE and not self.prefix_default_language:\n+        default_language = get_supported_language_variant(settings.LANGUAGE_CODE)\n+        if language_code == default_language and not self.prefix_default_language:", "source": "def language_prefix(self):\n        language_code = get_language() or settings.LANGUAGE_CODE\n        default_language = get_supported_language_variant(settings.LANGUAGE_CODE)\n        if language_code == default_language and not self.prefix_default_language:\n            return \"\"\n        else:\n            return \"%s/\" % language_code", "source_start_line": 352, "tokens": ["def", "language_prefix", "(", "self", ")", ":", "language_code", "=", "get_language", "(", ")", "or", "settings", ".", "LANGUAGE_CODE", "default_language", "=", "get_supported_language_variant", "(", "settings", ".", "LANGUAGE_CODE", ")", "if", "language_code", "==", "default_language", "and", "not", "self", ".", "prefix_default_language", ":", "return", "\"\"", "else", ":", "return", "\"%s/\"", "%", "language_code"], "to_mask": {"VAR": ["default_language", "language_code", "self"], "METHOD": ["get_language", "get_supported_language_variant"]}, "attention_idx_tokens": [23, 32], "patch": "@@ -351,7 +351,8 @@\n     @property\n     def language_prefix(self):\n         language_code = get_language() or settings.LANGUAGE_CODE\n-        if language_code == settings.LANGUAGE_CODE and not self.prefix_default_language:\n+        default_language = get_supported_language_variant(settings.LANGUAGE_CODE)\n+        if language_code == default_language and not self.prefix_default_language:", "ext_attention_idx_tokens": [15, 34], "uid": "d50292e0", "question": "This change is due to the fact that we're currently activating a fallback language not `settings.LANGUAGE_CODE`:    https://github.com/django/django/blob/5b8a043bf51ab8bcf4a758d0b4646f30a84be183/django/middleware/locale.py#L40-L41    @claudep What do you think?", "code": "def language prefix self language code get language or settings LANGUAGE CODE default language get supported language variant settings LANGUAGE CODE if language code default language and not self prefix default language return \"\" else return \"%s \" % language code"}
{"message": "What is your question exactly?", "timestamp": "2023-04-07T11:39:05Z", "file_name": "django/urls/resolvers.py", "range": {"start_line": 355, "end_line": 355, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1160645096", "html_url": "https://github.com/django/django/pull/16735#discussion_r1160645096", "attention_area": "        if language_code == default_language and not self.prefix_default_language:", "file_path": "files/39/02/00000239.py", "old_file_path": "files/38/02/00000238.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -351,7 +351,8 @@ def regex(self):\n     @property\n     def language_prefix(self):\n         language_code = get_language() or settings.LANGUAGE_CODE\n-        if language_code == settings.LANGUAGE_CODE and not self.prefix_default_language:\n+        default_language = get_supported_language_variant(settings.LANGUAGE_CODE)\n+        if language_code == default_language and not self.prefix_default_language:", "source": "def language_prefix(self):\n        language_code = get_language() or settings.LANGUAGE_CODE\n        default_language = get_supported_language_variant(settings.LANGUAGE_CODE)\n        if language_code == default_language and not self.prefix_default_language:\n            return \"\"\n        else:\n            return \"%s/\" % language_code", "source_start_line": 352, "tokens": ["def", "language_prefix", "(", "self", ")", ":", "language_code", "=", "get_language", "(", ")", "or", "settings", ".", "LANGUAGE_CODE", "default_language", "=", "get_supported_language_variant", "(", "settings", ".", "LANGUAGE_CODE", ")", "if", "language_code", "==", "default_language", "and", "not", "self", ".", "prefix_default_language", ":", "return", "\"\"", "else", ":", "return", "\"%s/\"", "%", "language_code"], "to_mask": {"VAR": ["default_language", "language_code", "self"], "METHOD": ["get_language", "get_supported_language_variant"]}, "attention_idx_tokens": [23, 32], "patch": "@@ -351,7 +351,8 @@\n     @property\n     def language_prefix(self):\n         language_code = get_language() or settings.LANGUAGE_CODE\n-        if language_code == settings.LANGUAGE_CODE and not self.prefix_default_language:\n+        default_language = get_supported_language_variant(settings.LANGUAGE_CODE)\n+        if language_code == default_language and not self.prefix_default_language:", "ext_attention_idx_tokens": [15, 34], "uid": "fdd06258", "question": "What is your question exactly?", "code": "def language prefix self language code get language or settings LANGUAGE CODE default language get supported language variant settings LANGUAGE CODE if language code default language and not self prefix default language return \"\" else return \"%s \" % language code"}
{"message": "\ud83d\udc4d This looks correct though am wondering why it was only failing with Value() \ud83e\udd14", "timestamp": "2023-05-10T08:40:06Z", "file_name": "django/db/models/functions/text.py", "range": {"start_line": 271, "end_line": 271, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1189554788", "html_url": "https://github.com/django/django/pull/16842#discussion_r1189554788", "attention_area": "        return sql, params * 3", "file_path": "files/45/03/00000345.py", "old_file_path": "files/46/03/00000346.py", "filters": {"comment_message": false, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -268,6 +268,7 @@ def as_oracle(self, compiler, connection, **extra_context):\n             ),\n             **extra_context,\n         )\n+        return sql, params * 3", "source": "def as_oracle(self, compiler, connection, **extra_context):\n        # REVERSE in Oracle is undocumented and doesn't support multi-byte\n        # strings. Use a special subquery instead.\n        sql, params = super().as_sql(\n            compiler,\n            connection,\n            template=(\n                \"(SELECT LISTAGG(s) WITHIN GROUP (ORDER BY n DESC) FROM \"\n                \"(SELECT LEVEL n, SUBSTR(%(expressions)s, LEVEL, 1) s \"\n                \"FROM DUAL CONNECT BY LEVEL <= LENGTH(%(expressions)s)) \"\n                \"GROUP BY %(expressions)s)\"\n            ),\n            **extra_context,\n        )\n        return sql, params * 3", "source_start_line": 257, "tokens": ["def", "as_oracle", "(", "self", ",", "compiler", ",", "connection", ",", "**", "extra_context", ")", ":", "sql", ",", "params", "=", "super", "(", ")", ".", "as_sql", "(", "compiler", ",", "connection", ",", "template", "=", "(", "\"(SELECT LISTAGG(s) WITHIN GROUP (ORDER BY n DESC) FROM \"", "\"(SELECT LEVEL n, SUBSTR(%(expressions)s, LEVEL, 1) s \"", "\"FROM DUAL CONNECT BY LEVEL <= LENGTH(%(expressions)s)) \"", "\"GROUP BY %(expressions)s)\"", ")", ",", "**", "extra_context", ",", ")", "return", "sql", ",", "params", "*", "3"], "to_mask": {"VAR": ["compiler", "connection", "params", "self", "sql"], "METHOD": ["as_sql", "super"]}, "attention_idx_tokens": [40, 45], "patch": "@@ -268,6 +268,7 @@\n             ),\n             **extra_context,\n         )\n+        return sql, params * 3", "ext_attention_idx_tokens": [40, 45], "uid": "4acc0ca3", "question": "\ud83d\udc4d This looks correct though am wondering why it was only failing with Value() \ud83e\udd14", "code": "def as oracle self compiler connection **extra context # REVERSE in Oracle is undocumented and doesn t support multi-byte # strings Use a special subquery instead sql params super as sql compiler connection template \" SELECT LISTAGG s WITHIN GROUP ORDER BY n DESC FROM \" \" SELECT LEVEL n SUBSTR % expressions s LEVEL 1 s \" \"FROM DUAL CONNECT BY LEVEL < LENGTH % expressions s \" \"GROUP BY % expressions s \" **extra context return sql params * 3"}
{"message": "I couldn't get this working for some reason with 3.12.0a7 but I wanted to see whether this message was in this PEP-678 \"note\" \ud83e\udd14\r\n\r\nDid you see any \"notes\"?", "timestamp": "2023-05-23T10:23:29Z", "file_name": "tests/utils_tests/test_functional.py", "range": {"start_line": 137, "end_line": 137, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1202018208", "html_url": "https://github.com/django/django/pull/16887#discussion_r1202018208", "attention_area": "        )", "file_path": "files/80/03/00000380.py", "old_file_path": "files/81/03/00000381.py", "filters": {"comment_message": false, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -130,7 +131,18 @@ def other_value(self):\n \n     def test_cached_property_reuse_different_names(self):\n         \"\"\"Disallow this case because the decorated function wouldn't be cached.\"\"\"\n-        with self.assertRaises(RuntimeError) as ctx:\n+        type_msg = (\n+            \"Cannot assign the same cached_property to two different names ('a' and \"\n+            \"'b').\"\n+        )", "source": "def test_cached_property_reuse_different_names(self):\n        \"\"\"Disallow this case because the decorated function wouldn't be cached.\"\"\"\n        type_msg = (\n            \"Cannot assign the same cached_property to two different names ('a' and \"\n            \"'b').\"\n        )\n        if PY312:\n            error_type = TypeError\n            msg = type_msg\n        else:\n            error_type = RuntimeError\n            msg = \"Error calling __set_name__\"\n\n        with self.assertRaisesMessage(error_type, msg) as ctx:\n\n            class ReusedCachedProperty:\n                @cached_property\n                def a(self):\n                    pass\n\n                b = a\n\n        if not PY312:\n            self.assertEqual(str(ctx.exception.__context__), str(TypeError(type_msg)))", "source_start_line": 132, "tokens": ["def", "test_cached_property_reuse_different_names", "(", "self", ")", ":", "\"\"\"Disallow this case because the decorated function wouldn't be cached.\"\"\"", "type_msg", "=", "(", "\"Cannot assign the same cached_property to two different names ('a' and \"", "\"'b').\"", ")", "if", "PY312", ":", "error_type", "=", "TypeError", "msg", "=", "type_msg", "else", ":", "error_type", "=", "RuntimeError", "msg", "=", "\"Error calling __set_name__\"", "with", "self", ".", "assertRaisesMessage", "(", "error_type", ",", "msg", ")", "as", "ctx", ":", "class", "ReusedCachedProperty", ":", "@", "cached_property", "def", "a", "(", "self", ")", ":", "pass", "b", "=", "a", "if", "not", "PY312", ":", "self", ".", "assertEqual", "(", "str", "(", "ctx", ".", "exception", ".", "__context__", ")", ",", "str", "(", "TypeError", "(", "type_msg", ")", ")", ")"], "to_mask": {"VAR": ["b", "ctx", "error_type", "msg", "self", "type_msg"], "METHOD": ["TypeError", "assertEqual", "assertRaisesMessage", "str"]}, "attention_idx_tokens": [12, 12], "patch": "@@ -130,7 +131,18 @@\n \n     def test_cached_property_reuse_different_names(self):\n         \"\"\"Disallow this case because the decorated function wouldn't be cached.\"\"\"\n-        with self.assertRaises(RuntimeError) as ctx:\n+        type_msg = (\n+            \"Cannot assign the same cached_property to two different names ('a' and \"\n+            \"'b').\"\n+        )", "ext_attention_idx_tokens": [7, 41], "uid": "14d730a0", "question": "I couldn't get this working for some reason with 3.12.0a7 but I wanted to see whether this message was in this PEP-678 \"note\" \ud83e\udd14    Did you see any \"notes\"?", "code": "def test cached property reuse different names self \"\"\"Disallow this case because the decorated function wouldn t be cached \"\"\" type msg \"Cannot assign the same cached property to two different names a and \" \" b \" if PY312 error type TypeError msg type msg else error type RuntimeError msg \"Error calling set name \" with self assertRaisesMessage error type msg as ctx class ReusedCachedProperty @cached property def a self pass b a if not PY312 self assertEqual str ctx exception context str TypeError type msg"}
{"message": "iirc it was to deal with problematic backends like Oracle", "timestamp": "2023-09-16T13:10:10Z", "file_name": "django/db/models/query_utils.py", "range": {"start_line": 139, "end_line": 139, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1327959505", "html_url": "https://github.com/django/django/pull/15659#discussion_r1327959505", "attention_area": "            logger.warning(\"Got a database error calling check() on %r: %s\", self, e)", "file_path": "files/51/06/00000651.py", "old_file_path": "files/52/06/00000652.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -110,6 +114,31 @@ def flatten(self):\n             else:\n                 yield child\n \n+    def check(self, against, using=DEFAULT_DB_ALIAS):\n+        \"\"\"\n+        Do a database query to check if the expressions of the Q instance\n+        matches against the expressions.\n+        \"\"\"\n+        # Avoid circular imports.\n+        from django.db.models import Value\n+        from django.db.models.sql import Query\n+        from django.db.models.sql.constants import SINGLE\n+\n+        query = Query(None)\n+        for name, value in against.items():\n+            if not hasattr(value, \"resolve_expression\"):\n+                value = Value(value)\n+            query.add_annotation(value, name, select=False)\n+        query.add_annotation(Value(1), \"_check\")\n+        # This will raise a FieldError if a field is missing in \"against\".\n+        query.add_q(self)\n+        compiler = query.get_compiler(using=using)\n+        try:\n+            return compiler.execute_sql(SINGLE) is not None\n+        except DatabaseError as e:\n+            logger.warning(\"Got a database error calling check() on %r: %s\", self, e)", "source": "def check(self, against, using=DEFAULT_DB_ALIAS):\n        \"\"\"\n        Do a database query to check if the expressions of the Q instance\n        matches against the expressions.\n        \"\"\"\n        # Avoid circular imports.\n        from django.db.models import Value\n        from django.db.models.sql import Query\n        from django.db.models.sql.constants import SINGLE\n\n        query = Query(None)\n        for name, value in against.items():\n            if not hasattr(value, \"resolve_expression\"):\n                value = Value(value)\n            query.add_annotation(value, name, select=False)\n        query.add_annotation(Value(1), \"_check\")\n        # This will raise a FieldError if a field is missing in \"against\".\n        query.add_q(self)\n        compiler = query.get_compiler(using=using)\n        try:\n            return compiler.execute_sql(SINGLE) is not None\n        except DatabaseError as e:\n            logger.warning(\"Got a database error calling check() on %r: %s\", self, e)\n            return True", "source_start_line": 117, "tokens": ["def", "check", "(", "self", ",", "against", ",", "using", "=", "DEFAULT_DB_ALIAS", ")", ":", "\"\"\"        Do a database query to check if the expressions of the Q instance        matches against the expressions.        \"\"\"", "from", "django", ".", "db", ".", "models", "import", "Value", "from", "django", ".", "db", ".", "models", ".", "sql", "import", "Query", "from", "django", ".", "db", ".", "models", ".", "sql", ".", "constants", "import", "SINGLE", "query", "=", "Query", "(", "None", ")", "for", "name", ",", "value", "in", "against", ".", "items", "(", ")", ":", "if", "not", "hasattr", "(", "value", ",", "\"resolve_expression\"", ")", ":", "value", "=", "Value", "(", "value", ")", "query", ".", "add_annotation", "(", "value", ",", "name", ",", "select", "=", "False", ")", "query", ".", "add_annotation", "(", "Value", "(", "1", ")", ",", "\"_check\"", ")", "query", ".", "add_q", "(", "self", ")", "compiler", "=", "query", ".", "get_compiler", "(", "using", "=", "using", ")", "try", ":", "return", "compiler", ".", "execute_sql", "(", "SINGLE", ")", "is", "not", "None", "except", "DatabaseError", "as", "e", ":", "logger", ".", "warning", "(", "\"Got a database error calling check() on %r: %s\"", ",", "self", ",", "e", ")", "return", "True"], "to_mask": {"VAR": ["against", "compiler", "e", "name", "query", "self", "using", "value"], "METHOD": ["Query", "Value", "add_annotation", "add_q", "execute_sql", "get_compiler", "hasattr", "items", "warning"]}, "attention_idx_tokens": [131, 140], "patch": "@@ -110,6 +114,31 @@\n             else:\n                 yield child\n \n+    def check(self, against, using=DEFAULT_DB_ALIAS):\n+        \"\"\"\n+        Do a database query to check if the expressions of the Q instance\n+        matches against the expressions.\n+        \"\"\"\n+        # Avoid circular imports.\n+        from django.db.models import Value\n+        from django.db.models.sql import Query\n+        from django.db.models.sql.constants import SINGLE\n+\n+        query = Query(None)\n+        for name, value in against.items():\n+            if not hasattr(value, \"resolve_expression\"):\n+                value = Value(value)\n+            query.add_annotation(value, name, select=False)\n+        query.add_annotation(Value(1), \"_check\")\n+        # This will raise a FieldError if a field is missing in \"against\".\n+        query.add_q(self)\n+        compiler = query.get_compiler(using=using)\n+        try:\n+            return compiler.execute_sql(SINGLE) is not None\n+        except DatabaseError as e:\n+            logger.warning(\"Got a database error calling check() on %r: %s\", self, e)", "ext_attention_idx_tokens": [0, 142], "uid": "cea1045c", "question": "iirc it was to deal with problematic backends like Oracle", "code": "def check self against using DEFAULT DB ALIAS \"\"\" Do a database query to check if the expressions of the Q instance matches against the expressions \"\"\" # Avoid circular imports from django db models import Value from django db models sql import Query from django db models sql constants import SINGLE query Query None for name value in against items if not hasattr value \"resolve expression\" value Value value query add annotation value name select False query add annotation Value 1 \" check\" # This will raise a FieldError if a field is missing in \"against\" query add q self compiler query get compiler using using try return compiler execute sql SINGLE is not None except DatabaseError as e logger warning \"Got a database error calling check on %r %s\" self e return True"}
{"message": "where's kezabelle when you need a linguistic expert lol", "timestamp": "2023-11-13T10:44:43Z", "file_name": "django/db/backends/base/operations.py", "range": {"start_line": 234, "end_line": 234, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1390942364", "html_url": "https://github.com/django/django/pull/17468#discussion_r1390942364", "attention_area": "    def force_group_by(self):", "file_path": "files/62/07/00000762.py", "old_file_path": "files/61/07/00000761.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -231,6 +231,13 @@ def field_cast_sql(self, db_type, internal_type):\n         )\n         return \"%s\"\n \n+    def force_group_by(self):", "source": "def force_group_by(self):\n        \"\"\"\n        Return a GROUP BY clause to use with a HAVING clause when no grouping\n        is specified.\n        \"\"\"\n        return []", "source_start_line": 234, "tokens": ["def", "force_group_by", "(", "self", ")", ":", "\"\"\"        Return a GROUP BY clause to use with a HAVING clause when no grouping        is specified.        \"\"\"", "return", "[", "]"], "to_mask": {"VAR": ["self"], "METHOD": []}, "attention_idx_tokens": [0, 5], "patch": "@@ -231,6 +231,13 @@\n         )\n         return \"%s\"\n \n+    def force_group_by(self):", "ext_attention_idx_tokens": [0, 9], "uid": "43e9d7d4", "question": "where's kezabelle when you need a linguistic expert lol", "code": "def force group by self \"\"\" Return a GROUP BY clause to use with a HAVING clause when no grouping is specified \"\"\" return []"}
{"message": "I don\u2019t understand what you\u2019re proposing. An HTTP setting that defaults to True, but if set to False opts in to the future? Why would that mean no warning when opting in?", "timestamp": "2023-11-28T15:38:24Z", "file_name": "django/forms/fields.py", "range": {"start_line": 778, "end_line": 778, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1407975432", "html_url": "https://github.com/django/django/pull/17538#discussion_r1407975432", "attention_area": "                assume_scheme = \"http\"", "file_path": "files/93/07/00000793.py", "old_file_path": "files/90/07/00000790.py", "filters": {"comment_message": false, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -762,14 +763,19 @@ class URLField(CharField):\n \n     def __init__(self, *, assume_scheme=None, **kwargs):\n         if assume_scheme is None:\n-            warnings.warn(\n-                \"The default scheme will be changed from 'http' to 'https' in Django \"\n-                \"6.0. Pass the forms.URLField.assume_scheme argument to silence this \"\n-                \"warning.\",\n-                RemovedInDjango60Warning,\n-                stacklevel=2,\n-            )\n-            assume_scheme = \"http\"\n+            if settings.FORMS_URLFIELD_ASSUME_HTTPS:\n+                assume_scheme = \"https\"\n+            else:\n+                warnings.warn(\n+                    \"The default scheme will be changed from 'http' to 'https' in \"\n+                    \"Django 6.0. Pass the forms.URLField.assume_scheme argument to \"\n+                    \"silence this warning, or set the FORMS_URLFIELD_ASSUME_HTTPS \"\n+                    \"transitional setting to True to opt into using 'https' as the new \"\n+                    \"default scheme.\",\n+                    RemovedInDjango60Warning,\n+                    stacklevel=2,\n+                )\n+                assume_scheme = \"http\"", "source": "def __init__(self, *, assume_scheme=None, **kwargs):\n        if assume_scheme is None:\n            if settings.FORMS_URLFIELD_ASSUME_HTTPS:\n                assume_scheme = \"https\"\n            else:\n                warnings.warn(\n                    \"The default scheme will be changed from 'http' to 'https' in \"\n                    \"Django 6.0. Pass the forms.URLField.assume_scheme argument to \"\n                    \"silence this warning, or set the FORMS_URLFIELD_ASSUME_HTTPS \"\n                    \"transitional setting to True to opt into using 'https' as the new \"\n                    \"default scheme.\",\n                    RemovedInDjango60Warning,\n                    stacklevel=2,\n                )\n                assume_scheme = \"http\"\n        # RemovedInDjango60Warning: When the deprecation ends, replace with:\n        # self.assume_scheme = assume_scheme or \"https\"\n        self.assume_scheme = assume_scheme\n        super().__init__(strip=True, **kwargs)", "source_start_line": 764, "tokens": ["def", "__init__", "(", "self", ",", "*", ",", "assume_scheme", "=", "None", ",", "**", "kwargs", ")", ":", "if", "assume_scheme", "is", "None", ":", "if", "settings", ".", "FORMS_URLFIELD_ASSUME_HTTPS", ":", "assume_scheme", "=", "\"https\"", "else", ":", "warnings", ".", "warn", "(", "\"The default scheme will be changed from 'http' to 'https' in \"", "\"Django 6.0. Pass the forms.URLField.assume_scheme argument to \"", "\"silence this warning, or set the FORMS_URLFIELD_ASSUME_HTTPS \"", "\"transitional setting to True to opt into using 'https' as the new \"", "\"default scheme.\"", ",", "RemovedInDjango60Warning", ",", "stacklevel", "=", "2", ",", ")", "assume_scheme", "=", "\"http\"", "self", ".", "assume_scheme", "=", "assume_scheme", "super", "(", ")", ".", "__init__", "(", "strip", "=", "True", ",", "**", "kwargs", ")"], "to_mask": {"VAR": ["assume_scheme", "self"], "METHOD": ["__init__", "super", "warn"]}, "attention_idx_tokens": [47, 49], "patch": "@@ -762,14 +763,19 @@\n \n     def __init__(self, *, assume_scheme=None, **kwargs):\n         if assume_scheme is None:\n-            warnings.warn(\n-                \"The default scheme will be changed from 'http' to 'https' in Django \"\n-                \"6.0. Pass the forms.URLField.assume_scheme argument to silence this \"\n-                \"warning.\",\n-                RemovedInDjango60Warning,\n-                stacklevel=2,\n-            )\n-            assume_scheme = \"http\"\n+            if settings.FORMS_URLFIELD_ASSUME_HTTPS:\n+                assume_scheme = \"https\"\n+            else:\n+                warnings.warn(\n+                    \"The default scheme will be changed from 'http' to 'https' in \"\n+                    \"Django 6.0. Pass the forms.URLField.assume_scheme argument to \"\n+                    \"silence this warning, or set the FORMS_URLFIELD_ASSUME_HTTPS \"\n+                    \"transitional setting to True to opt into using 'https' as the new \"\n+                    \"default scheme.\",\n+                    RemovedInDjango60Warning,\n+                    stacklevel=2,\n+                )\n+                assume_scheme = \"http\"", "ext_attention_idx_tokens": [20, 49], "uid": "13ff2835", "question": "I don\u2019t understand what you\u2019re proposing. An HTTP setting that defaults to True, but if set to False opts in to the future? Why would that mean no warning when opting in?", "code": "def init self * assume scheme None **kwargs if assume scheme is None if settings FORMS URLFIELD ASSUME HTTPS assume scheme \"https\" else warnings warn \"The default scheme will be changed from http to https in \" \"Django 6 0 Pass the forms URLField assume scheme argument to \" \"silence this warning or set the FORMS URLFIELD ASSUME HTTPS \" \"transitional setting to True to opt into using https as the new \" \"default scheme \" RemovedInDjango60Warning stacklevel 2 assume scheme \"http\" # RemovedInDjango60Warning When the deprecation ends replace with # self assume scheme assume scheme or \"https\" self assume scheme assume scheme super init strip True **kwargs"}
{"message": "> Make sense? (It might not: I've been at the computer all day, so may well be hallucinating by this point \ud83d\ude1c)\r\n\r\n@carltongibson I'm against your idea, as it would mean that we're making a backward incompatible change that user will probably not notice. ", "timestamp": "2023-11-28T16:31:07Z", "file_name": "django/forms/fields.py", "range": {"start_line": 778, "end_line": 778, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1408055020", "html_url": "https://github.com/django/django/pull/17538#discussion_r1408055020", "attention_area": "                assume_scheme = \"http\"", "file_path": "files/93/07/00000793.py", "old_file_path": "files/90/07/00000790.py", "filters": {"comment_message": false, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -762,14 +763,19 @@ class URLField(CharField):\n \n     def __init__(self, *, assume_scheme=None, **kwargs):\n         if assume_scheme is None:\n-            warnings.warn(\n-                \"The default scheme will be changed from 'http' to 'https' in Django \"\n-                \"6.0. Pass the forms.URLField.assume_scheme argument to silence this \"\n-                \"warning.\",\n-                RemovedInDjango60Warning,\n-                stacklevel=2,\n-            )\n-            assume_scheme = \"http\"\n+            if settings.FORMS_URLFIELD_ASSUME_HTTPS:\n+                assume_scheme = \"https\"\n+            else:\n+                warnings.warn(\n+                    \"The default scheme will be changed from 'http' to 'https' in \"\n+                    \"Django 6.0. Pass the forms.URLField.assume_scheme argument to \"\n+                    \"silence this warning, or set the FORMS_URLFIELD_ASSUME_HTTPS \"\n+                    \"transitional setting to True to opt into using 'https' as the new \"\n+                    \"default scheme.\",\n+                    RemovedInDjango60Warning,\n+                    stacklevel=2,\n+                )\n+                assume_scheme = \"http\"", "source": "def __init__(self, *, assume_scheme=None, **kwargs):\n        if assume_scheme is None:\n            if settings.FORMS_URLFIELD_ASSUME_HTTPS:\n                assume_scheme = \"https\"\n            else:\n                warnings.warn(\n                    \"The default scheme will be changed from 'http' to 'https' in \"\n                    \"Django 6.0. Pass the forms.URLField.assume_scheme argument to \"\n                    \"silence this warning, or set the FORMS_URLFIELD_ASSUME_HTTPS \"\n                    \"transitional setting to True to opt into using 'https' as the new \"\n                    \"default scheme.\",\n                    RemovedInDjango60Warning,\n                    stacklevel=2,\n                )\n                assume_scheme = \"http\"\n        # RemovedInDjango60Warning: When the deprecation ends, replace with:\n        # self.assume_scheme = assume_scheme or \"https\"\n        self.assume_scheme = assume_scheme\n        super().__init__(strip=True, **kwargs)", "source_start_line": 764, "tokens": ["def", "__init__", "(", "self", ",", "*", ",", "assume_scheme", "=", "None", ",", "**", "kwargs", ")", ":", "if", "assume_scheme", "is", "None", ":", "if", "settings", ".", "FORMS_URLFIELD_ASSUME_HTTPS", ":", "assume_scheme", "=", "\"https\"", "else", ":", "warnings", ".", "warn", "(", "\"The default scheme will be changed from 'http' to 'https' in \"", "\"Django 6.0. Pass the forms.URLField.assume_scheme argument to \"", "\"silence this warning, or set the FORMS_URLFIELD_ASSUME_HTTPS \"", "\"transitional setting to True to opt into using 'https' as the new \"", "\"default scheme.\"", ",", "RemovedInDjango60Warning", ",", "stacklevel", "=", "2", ",", ")", "assume_scheme", "=", "\"http\"", "self", ".", "assume_scheme", "=", "assume_scheme", "super", "(", ")", ".", "__init__", "(", "strip", "=", "True", ",", "**", "kwargs", ")"], "to_mask": {"VAR": ["assume_scheme", "self"], "METHOD": ["__init__", "super", "warn"]}, "attention_idx_tokens": [47, 49], "patch": "@@ -762,14 +763,19 @@\n \n     def __init__(self, *, assume_scheme=None, **kwargs):\n         if assume_scheme is None:\n-            warnings.warn(\n-                \"The default scheme will be changed from 'http' to 'https' in Django \"\n-                \"6.0. Pass the forms.URLField.assume_scheme argument to silence this \"\n-                \"warning.\",\n-                RemovedInDjango60Warning,\n-                stacklevel=2,\n-            )\n-            assume_scheme = \"http\"\n+            if settings.FORMS_URLFIELD_ASSUME_HTTPS:\n+                assume_scheme = \"https\"\n+            else:\n+                warnings.warn(\n+                    \"The default scheme will be changed from 'http' to 'https' in \"\n+                    \"Django 6.0. Pass the forms.URLField.assume_scheme argument to \"\n+                    \"silence this warning, or set the FORMS_URLFIELD_ASSUME_HTTPS \"\n+                    \"transitional setting to True to opt into using 'https' as the new \"\n+                    \"default scheme.\",\n+                    RemovedInDjango60Warning,\n+                    stacklevel=2,\n+                )\n+                assume_scheme = \"http\"", "ext_attention_idx_tokens": [20, 49], "uid": "998db27a", "question": "> Make sense? (It might not: I've been at the computer all day, so may well be hallucinating by this point \ud83d\ude1c)    @carltongibson I'm against your idea, as it would mean that we're making a backward incompatible change that user will probably not notice. ", "code": "def init self * assume scheme None **kwargs if assume scheme is None if settings FORMS URLFIELD ASSUME HTTPS assume scheme \"https\" else warnings warn \"The default scheme will be changed from http to https in \" \"Django 6 0 Pass the forms URLField assume scheme argument to \" \"silence this warning or set the FORMS URLFIELD ASSUME HTTPS \" \"transitional setting to True to opt into using https as the new \" \"default scheme \" RemovedInDjango60Warning stacklevel 2 assume scheme \"http\" # RemovedInDjango60Warning When the deprecation ends replace with # self assume scheme assume scheme or \"https\" self assume scheme assume scheme super init strip True **kwargs"}
{"message": "Is this always a vector? ", "timestamp": "2023-12-17T17:01:44Z", "file_name": "django/contrib/gis/gdal/datasource.py", "range": {"start_line": 67, "end_line": 67, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1429212773", "html_url": "https://github.com/django/django/pull/16650#discussion_r1429212773", "attention_area": "                    self._write | capi.GDAL_OF_VECTOR,", "file_path": "files/30/08/00000830.py", "old_file_path": "files/29/08/00000829.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -54,21 +53,22 @@ class DataSource(GDALBase):\n \n     def __init__(self, ds_input, ds_driver=False, write=False, encoding=\"utf-8\"):\n         # The write flag.\n-        if write:\n-            self._write = 1\n-        else:\n-            self._write = 0\n+        self._write = capi.GDAL_OF_UPDATE if write else capi.GDAL_OF_READONLY\n         # See also https://gdal.org/development/rfc/rfc23_ogr_unicode.html\n         self.encoding = encoding\n \n         Driver.ensure_registered()\n \n         if isinstance(ds_input, (str, Path)):\n-            # The data source driver is a void pointer.\n-            ds_driver = Driver.ptr_type()\n             try:\n-                # OGROpen will auto-detect the data source type.\n-                ds = capi.open_ds(force_bytes(ds_input), self._write, byref(ds_driver))\n+                # GDALOpenEx will auto-detect the data source type.\n+                ds = capi.open_ds(\n+                    force_bytes(ds_input),\n+                    self._write | capi.GDAL_OF_VECTOR,", "source": "def __init__(self, ds_input, ds_driver=False, write=False, encoding=\"utf-8\"):\n        # The write flag.\n        self._write = capi.GDAL_OF_UPDATE if write else capi.GDAL_OF_READONLY\n        # See also https://gdal.org/development/rfc/rfc23_ogr_unicode.html\n        self.encoding = encoding\n\n        Driver.ensure_registered()\n\n        if isinstance(ds_input, (str, Path)):\n            try:\n                # GDALOpenEx will auto-detect the data source type.\n                ds = capi.open_ds(\n                    force_bytes(ds_input),\n                    self._write | capi.GDAL_OF_VECTOR,\n                    None,\n                    None,\n                    None,\n                )\n            except GDALException:\n                # Making the error message more clear rather than something\n                # like \"Invalid pointer returned from OGROpen\".\n                raise GDALException('Could not open the datasource at \"%s\"' % ds_input)\n        elif isinstance(ds_input, self.ptr_type) and isinstance(\n            ds_driver, Driver.ptr_type\n        ):\n            ds = ds_input\n        else:\n            raise GDALException(\"Invalid data source input type: %s\" % type(ds_input))\n\n        if ds:\n            self.ptr = ds\n            driver = capi.get_dataset_driver(ds)\n            self.driver = Driver(driver)\n        else:\n            # Raise an exception if the returned pointer is NULL\n            raise GDALException('Invalid data source file \"%s\"' % ds_input)", "source_start_line": 54, "tokens": ["def", "__init__", "(", "self", ",", "ds_input", ",", "ds_driver", "=", "False", ",", "write", "=", "False", ",", "encoding", "=", "\"utf-8\"", ")", ":", "self", ".", "_write", "=", "capi", ".", "GDAL_OF_UPDATE", "if", "write", "else", "capi", ".", "GDAL_OF_READONLY", "self", ".", "encoding", "=", "encoding", "Driver", ".", "ensure_registered", "(", ")", "if", "isinstance", "(", "ds_input", ",", "(", "str", ",", "Path", ")", ")", ":", "try", ":", "ds", "=", "capi", ".", "open_ds", "(", "force_bytes", "(", "ds_input", ")", ",", "self", ".", "_write", "|", "capi", ".", "GDAL_OF_VECTOR", ",", "None", ",", "None", ",", "None", ",", ")", "except", "GDALException", ":", "raise", "GDALException", "(", "'Could not open the datasource at \"%s\"'", "%", "ds_input", ")", "elif", "isinstance", "(", "ds_input", ",", "self", ".", "ptr_type", ")", "and", "isinstance", "(", "ds_driver", ",", "Driver", ".", "ptr_type", ")", ":", "ds", "=", "ds_input", "else", ":", "raise", "GDALException", "(", "\"Invalid data source input type: %s\"", "%", "type", "(", "ds_input", ")", ")", "if", "ds", ":", "self", ".", "ptr", "=", "ds", "driver", "=", "capi", ".", "get_dataset_driver", "(", "ds", ")", "self", ".", "driver", "=", "Driver", "(", "driver", ")", "else", ":", "raise", "GDALException", "(", "'Invalid data source file \"%s\"'", "%", "ds_input", ")"], "to_mask": {"VAR": ["_write", "driver", "ds", "ds_driver", "ds_input", "encoding", "ptr", "self", "write"], "METHOD": ["Driver", "GDALException", "ensure_registered", "force_bytes", "get_dataset_driver", "isinstance", "open_ds", "type"]}, "attention_idx_tokens": [68, 75], "patch": "@@ -54,21 +53,22 @@\n \n     def __init__(self, ds_input, ds_driver=False, write=False, encoding=\"utf-8\"):\n         # The write flag.\n-        if write:\n-            self._write = 1\n-        else:\n-            self._write = 0\n+        self._write = capi.GDAL_OF_UPDATE if write else capi.GDAL_OF_READONLY\n         # See also https://gdal.org/development/rfc/rfc23_ogr_unicode.html\n         self.encoding = encoding\n \n         Driver.ensure_registered()\n \n         if isinstance(ds_input, (str, Path)):\n-            # The data source driver is a void pointer.\n-            ds_driver = Driver.ptr_type()\n             try:\n-                # OGROpen will auto-detect the data source type.\n-                ds = capi.open_ds(force_bytes(ds_input), self._write, byref(ds_driver))\n+                # GDALOpenEx will auto-detect the data source type.\n+                ds = capi.open_ds(\n+                    force_bytes(ds_input),\n+                    self._write | capi.GDAL_OF_VECTOR,", "ext_attention_idx_tokens": [20, 85], "uid": "dac32385", "question": "Is this always a vector? ", "code": "def init self ds input ds driver False write False encoding \"utf-8\" # The write flag self write capi GDAL OF UPDATE if write else capi GDAL OF READONLY # See also https gdal org development rfc rfc23 ogr unicode html self encoding encoding Driver ensure registered if isinstance ds input str Path try # GDALOpenEx will auto-detect the data source type ds capi open ds force bytes ds input self write | capi GDAL OF VECTOR None None None except GDALException # Making the error message more clear rather than something # like \"Invalid pointer returned from OGROpen\" raise GDALException Could not open the datasource at \"%s\" % ds input elif isinstance ds input self ptr type and isinstance ds driver Driver ptr type ds ds input else raise GDALException \"Invalid data source input type %s\" % type ds input if ds self ptr ds driver capi get dataset driver ds self driver Driver driver else # Raise an exception if the returned pointer is NULL raise GDALException Invalid data source file \"%s\" % ds input"}
{"message": "What is CE here?", "timestamp": "2023-03-23T18:39:41Z", "file_name": "keras/backend.py", "range": {"start_line": 5602, "end_line": 5602, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1146664531", "html_url": "https://github.com/keras-team/keras/pull/17651#discussion_r1146664531", "attention_area": "    negative log-likelihood and included in CE.", "file_path": "files/53/00/00000053.py", "old_file_path": "files/43/00/00000043.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -5574,6 +5574,88 @@ def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n     return -tf.reduce_sum(target * tf.math.log(output), axis)\n \n \n+@keras_export(\"keras.backend.categorical_focal_crossentropy\")\n+@tf.__internal__.dispatch.add_dispatch_support\n+@doc_controls.do_not_generate_docs\n+def categorical_focal_crossentropy(\n+    target,\n+    output,\n+    alpha=0.25,\n+    gamma=2.0,\n+    from_logits=False,\n+    axis=-1,\n+):\n+    \"\"\"Computes the alpha balanced focal crossentropy loss.\n+\n+    According to [Lin et al., 2018](https://arxiv.org/pdf/1708.02002.pdf), it\n+    helps to apply a focal factor to down-weight easy examples and focus more on\n+    hard examples. By default, the focal tensor is computed as follows:\n+\n+    It has pt defined as:\n+    pt = p, if y = 1 else 1 - p\n+\n+    The authors use alpha-balanced variant of focal loss in the paper:\n+    FL(pt) = \u2212\u03b1_t * (1 \u2212 pt)^gamma * log(pt)\n+\n+    Extending this to multi-class case is straightforward:\n+    FL(pt) = \u03b1_t * (1 \u2212 pt)^gamma * CE, where minus comes from\n+    negative log-likelihood and included in CE.", "source": "def categorical_focal_crossentropy(\n    target,\n    output,\n    alpha=0.25,\n    gamma=2.0,\n    from_logits=False,\n    axis=-1,\n):\n    \"\"\"Computes the alpha balanced focal crossentropy loss.\n\n    According to [Lin et al., 2018](https://arxiv.org/pdf/1708.02002.pdf), it\n    helps to apply a focal factor to down-weight easy examples and focus more on\n    hard examples. By default, the focal tensor is computed as follows:\n\n    It has pt defined as:\n    pt = p, if y = 1 else 1 - p\n\n    The authors use alpha-balanced variant of focal loss in the paper:\n    FL(pt) = \u2212\u03b1_t * (1 \u2212 pt)^gamma * log(pt)\n\n    Extending this to multi-class case is straightforward:\n    FL(pt) = \u03b1_t * (1 \u2212 pt)^gamma * CE, where minus comes from\n    negative log-likelihood and included in CE.\n\n    `modulating_factor` is (1 \u2212 pt)^gamma, where `gamma` is a focusing\n    parameter. When `gamma` = 0, there is no focal effect on the categorical\n    crossentropy. And if alpha = 1, at the same time the loss is equivalent\n    to the categorical crossentropy.\n\n    Args:\n        target: A tensor with the same shape as `output`.\n        output: A tensor.\n        alpha: A weight balancing factor for all classes, default is `0.25` as\n            mentioned in the reference. It can be a list of floats or a scalar.\n            In the multi-class case, alpha may be set by inverse class\n            frequency by using `compute_class_weight` from `sklearn.utils`.\n        gamma: A focusing parameter, default is `2.0` as mentioned in the\n            reference. It helps to gradually reduce the importance given to\n            simple examples in a smooth manner.\n        from_logits: Whether `output` is expected to be a logits tensor. By\n            default, we consider that `output` encodes a probability\n            distribution.\n\n    Returns:\n        A tensor.\n    \"\"\"\n    target = tf.convert_to_tensor(target)\n    output = tf.convert_to_tensor(output)\n    target.shape.assert_is_compatible_with(output.shape)\n\n    output, from_logits = _get_logits(\n        output, from_logits, \"Softmax\", \"categorical_focal_crossentropy\"\n    )\n\n    output = tf.__internal__.smart_cond.smart_cond(\n        from_logits,\n        lambda: softmax(output),\n        lambda: output,\n    )\n\n    # scale preds so that the class probas of each sample sum to 1\n    output = output / tf.reduce_sum(output, axis=axis, keepdims=True)\n\n    epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\n    output = tf.clip_by_value(output, epsilon_, 1.0 - epsilon_)\n\n    # Calculate cross entropy\n    cce = -target * tf.math.log(output)\n\n    # Calculate factors\n    modulating_factor = tf.pow(1.0 - output, gamma)\n    weighting_factor = tf.multiply(modulating_factor, alpha)\n\n    # Apply weighting factor\n    focal_cce = tf.multiply(weighting_factor, cce)\n    focal_cce = tf.reduce_sum(focal_cce, axis=axis)\n    return focal_cce", "source_start_line": 5580, "tokens": ["def", "categorical_focal_crossentropy", "(", "target", ",", "output", ",", "alpha", "=", "0.25", ",", "gamma", "=", "2.0", ",", "from_logits", "=", "False", ",", "axis", "=", "-", "1", ",", ")", ":", "\"\"\"Computes the alpha balanced focal crossentropy loss.    According to [Lin et al., 2018](https://arxiv.org/pdf/1708.02002.pdf), it    helps to apply a focal factor to down-weight easy examples and focus more on    hard examples. By default, the focal tensor is computed as follows:    It has pt defined as:    pt = p, if y = 1 else 1 - p    The authors use alpha-balanced variant of focal loss in the paper:    FL(pt) = \u2212\u03b1_t * (1 \u2212 pt)^gamma * log(pt)    Extending this to multi-class case is straightforward:    FL(pt) = \u03b1_t * (1 \u2212 pt)^gamma * CE, where minus comes from    negative log-likelihood and included in CE.    `modulating_factor` is (1 \u2212 pt)^gamma, where `gamma` is a focusing    parameter. When `gamma` = 0, there is no focal effect on the categorical    crossentropy. And if alpha = 1, at the same time the loss is equivalent    to the categorical crossentropy.    Args:        target: A tensor with the same shape as `output`.        output: A tensor.        alpha: A weight balancing factor for all classes, default is `0.25` as            mentioned in the reference. It can be a list of floats or a scalar.            In the multi-class case, alpha may be set by inverse class            frequency by using `compute_class_weight` from `sklearn.utils`.        gamma: A focusing parameter, default is `2.0` as mentioned in the            reference. It helps to gradually reduce the importance given to            simple examples in a smooth manner.        from_logits: Whether `output` is expected to be a logits tensor. By            default, we consider that `output` encodes a probability            distribution.    Returns:        A tensor.    \"\"\"", "target", "=", "tf", ".", "convert_to_tensor", "(", "target", ")", "output", "=", "tf", ".", "convert_to_tensor", "(", "output", ")", "target", ".", "shape", ".", "assert_is_compatible_with", "(", "output", ".", "shape", ")", "output", ",", "from_logits", "=", "_get_logits", "(", "output", ",", "from_logits", ",", "\"Softmax\"", ",", "\"categorical_focal_crossentropy\"", ")", "output", "=", "tf", ".", "__internal__", ".", "smart_cond", ".", "smart_cond", "(", "from_logits", ",", "lambda", ":", "softmax", "(", "output", ")", ",", "lambda", ":", "output", ",", ")", "output", "=", "output", "/", "tf", ".", "reduce_sum", "(", "output", ",", "axis", "=", "axis", ",", "keepdims", "=", "True", ")", "epsilon_", "=", "_constant_to_tensor", "(", "epsilon", "(", ")", ",", "output", ".", "dtype", ".", "base_dtype", ")", "output", "=", "tf", ".", "clip_by_value", "(", "output", ",", "epsilon_", ",", "1.0", "-", "epsilon_", ")", "cce", "=", "-", "target", "*", "tf", ".", "math", ".", "log", "(", "output", ")", "modulating_factor", "=", "tf", ".", "pow", "(", "1.0", "-", "output", ",", "gamma", ")", "weighting_factor", "=", "tf", ".", "multiply", "(", "modulating_factor", ",", "alpha", ")", "focal_cce", "=", "tf", ".", "multiply", "(", "weighting_factor", ",", "cce", ")", "focal_cce", "=", "tf", ".", "reduce_sum", "(", "focal_cce", ",", "axis", "=", "axis", ")", "return", "focal_cce"], "to_mask": {"VAR": ["alpha", "axis", "cce", "epsilon_", "focal_cce", "from_logits", "gamma", "modulating_factor", "output", "target", "weighting_factor"], "METHOD": ["_constant_to_tensor", "_get_logits", "assert_is_compatible_with", "clip_by_value", "convert_to_tensor", "epsilon", "log", "multiply", "pow", "reduce_sum", "smart_cond", "softmax"]}, "attention_idx_tokens": [null, null], "patch": "@@ -5574,6 +5574,88 @@\n     return -tf.reduce_sum(target * tf.math.log(output), axis)\n \n \n+@keras_export(\"keras.backend.categorical_focal_crossentropy\")\n+@tf.__internal__.dispatch.add_dispatch_support\n+@doc_controls.do_not_generate_docs\n+def categorical_focal_crossentropy(\n+    target,\n+    output,\n+    alpha=0.25,\n+    gamma=2.0,\n+    from_logits=False,\n+    axis=-1,\n+):\n+    \"\"\"Computes the alpha balanced focal crossentropy loss.\n+\n+    According to [Lin et al., 2018](https://arxiv.org/pdf/1708.02002.pdf), it\n+    helps to apply a focal factor to down-weight easy examples and focus more on\n+    hard examples. By default, the focal tensor is computed as follows:\n+\n+    It has pt defined as:\n+    pt = p, if y = 1 else 1 - p\n+\n+    The authors use alpha-balanced variant of focal loss in the paper:\n+    FL(pt) = \u2212\u03b1_t * (1 \u2212 pt)^gamma * log(pt)\n+\n+    Extending this to multi-class case is straightforward:\n+    FL(pt) = \u03b1_t * (1 \u2212 pt)^gamma * CE, where minus comes from\n+    negative log-likelihood and included in CE.", "ext_attention_idx_tokens": [0, 195], "uid": "52330360", "question": "What is CE here?", "code": "def categorical focal crossentropy target output alpha 0 25 gamma 2 0 from logits False axis -1 \"\"\"Computes the alpha balanced focal crossentropy loss According to [Lin et al 2018] https arxiv org pdf 1708 02002 pdf it helps to apply a focal factor to down-weight easy examples and focus more on hard examples By default the focal tensor is computed as follows It has pt defined as pt p if y 1 else 1 - p The authors use alpha-balanced variant of focal loss in the paper FL pt \u2212\u03b1 t * 1 \u2212 pt ^gamma * log pt Extending this to multi-class case is straightforward FL pt \u03b1 t * 1 \u2212 pt ^gamma * CE where minus comes from negative log-likelihood and included in CE `modulating factor` is 1 \u2212 pt ^gamma where `gamma` is a focusing parameter When `gamma` 0 there is no focal effect on the categorical crossentropy And if alpha 1 at the same time the loss is equivalent to the categorical crossentropy Args target A tensor with the same shape as `output` output A tensor alpha A weight balancing factor for all classes default is `0 25` as mentioned in the reference It can be a list of floats or a scalar In the multi-class case alpha may be set by inverse class frequency by using `compute class weight` from `sklearn utils` gamma A focusing parameter default is `2 0` as mentioned in the reference It helps to gradually reduce the importance given to simple examples in a smooth manner from logits Whether `output` is expected to be a logits tensor By default we consider that `output` encodes a probability distribution Returns A tensor \"\"\" target tf convert to tensor target output tf convert to tensor output target shape assert is compatible with output shape output from logits get logits output from logits \"Softmax\" \"categorical focal crossentropy\" output tf internal smart cond smart cond from logits lambda softmax output lambda output # scale preds so that the class probas of each sample sum to 1 output output tf reduce sum output axis axis keepdims True epsilon constant to tensor epsilon output dtype base dtype output tf clip by value output epsilon 1 0 - epsilon # Calculate cross entropy cce -target * tf math log output # Calculate factors modulating factor tf pow 1 0 - output gamma weighting factor tf multiply modulating factor alpha # Apply weighting factor focal cce tf multiply weighting factor cce focal cce tf reduce sum focal cce axis axis return focal cce"}
{"message": "What is `probas`?", "timestamp": "2023-03-23T18:47:59Z", "file_name": "keras/backend.py", "range": {"start_line": 5640, "end_line": 5640, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1146678656", "html_url": "https://github.com/keras-team/keras/pull/17651#discussion_r1146678656", "attention_area": "    # scale preds so that the class probas of each sample sum to 1", "file_path": "files/53/00/00000053.py", "old_file_path": "files/43/00/00000043.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -5574,6 +5574,88 @@ def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n     return -tf.reduce_sum(target * tf.math.log(output), axis)\n \n \n+@keras_export(\"keras.backend.categorical_focal_crossentropy\")\n+@tf.__internal__.dispatch.add_dispatch_support\n+@doc_controls.do_not_generate_docs\n+def categorical_focal_crossentropy(\n+    target,\n+    output,\n+    alpha=0.25,\n+    gamma=2.0,\n+    from_logits=False,\n+    axis=-1,\n+):\n+    \"\"\"Computes the alpha balanced focal crossentropy loss.\n+\n+    According to [Lin et al., 2018](https://arxiv.org/pdf/1708.02002.pdf), it\n+    helps to apply a focal factor to down-weight easy examples and focus more on\n+    hard examples. By default, the focal tensor is computed as follows:\n+\n+    It has pt defined as:\n+    pt = p, if y = 1 else 1 - p\n+\n+    The authors use alpha-balanced variant of focal loss in the paper:\n+    FL(pt) = \u2212\u03b1_t * (1 \u2212 pt)^gamma * log(pt)\n+\n+    Extending this to multi-class case is straightforward:\n+    FL(pt) = \u03b1_t * (1 \u2212 pt)^gamma * CE, where minus comes from\n+    negative log-likelihood and included in CE.\n+\n+    `modulating_factor` is (1 \u2212 pt)^gamma, where `gamma` is a focusing\n+    parameter. When `gamma` = 0, there is no focal effect on the categorical\n+    crossentropy. And if alpha = 1, at the same time the loss is equivalent\n+    to the categorical crossentropy.\n+\n+    Args:\n+        target: A tensor with the same shape as `output`.\n+        output: A tensor.\n+        alpha: A weight balancing factor for all classes, default is `0.25` as\n+            mentioned in the reference. It can be a list of floats or a scalar.\n+            In the multi-class case, alpha may be set by inverse class\n+            frequency by using `compute_class_weight` from `sklearn.utils`.\n+        gamma: A focusing parameter, default is `2.0` as mentioned in the\n+            reference. It helps to gradually reduce the importance given to\n+            simple examples in a smooth manner.\n+        from_logits: Whether `output` is expected to be a logits tensor. By\n+            default, we consider that `output` encodes a probability\n+            distribution.\n+\n+    Returns:\n+        A tensor.\n+    \"\"\"\n+    target = tf.convert_to_tensor(target)\n+    output = tf.convert_to_tensor(output)\n+    target.shape.assert_is_compatible_with(output.shape)\n+\n+    output, from_logits = _get_logits(\n+        output, from_logits, \"Softmax\", \"categorical_focal_crossentropy\"\n+    )\n+\n+    output = tf.__internal__.smart_cond.smart_cond(\n+        from_logits,\n+        lambda: softmax(output),\n+        lambda: output,\n+    )\n+\n+    # scale preds so that the class probas of each sample sum to 1", "source": "def categorical_focal_crossentropy(\n    target,\n    output,\n    alpha=0.25,\n    gamma=2.0,\n    from_logits=False,\n    axis=-1,\n):\n    \"\"\"Computes the alpha balanced focal crossentropy loss.\n\n    According to [Lin et al., 2018](https://arxiv.org/pdf/1708.02002.pdf), it\n    helps to apply a focal factor to down-weight easy examples and focus more on\n    hard examples. By default, the focal tensor is computed as follows:\n\n    It has pt defined as:\n    pt = p, if y = 1 else 1 - p\n\n    The authors use alpha-balanced variant of focal loss in the paper:\n    FL(pt) = \u2212\u03b1_t * (1 \u2212 pt)^gamma * log(pt)\n\n    Extending this to multi-class case is straightforward:\n    FL(pt) = \u03b1_t * (1 \u2212 pt)^gamma * CE, where minus comes from\n    negative log-likelihood and included in CE.\n\n    `modulating_factor` is (1 \u2212 pt)^gamma, where `gamma` is a focusing\n    parameter. When `gamma` = 0, there is no focal effect on the categorical\n    crossentropy. And if alpha = 1, at the same time the loss is equivalent\n    to the categorical crossentropy.\n\n    Args:\n        target: A tensor with the same shape as `output`.\n        output: A tensor.\n        alpha: A weight balancing factor for all classes, default is `0.25` as\n            mentioned in the reference. It can be a list of floats or a scalar.\n            In the multi-class case, alpha may be set by inverse class\n            frequency by using `compute_class_weight` from `sklearn.utils`.\n        gamma: A focusing parameter, default is `2.0` as mentioned in the\n            reference. It helps to gradually reduce the importance given to\n            simple examples in a smooth manner.\n        from_logits: Whether `output` is expected to be a logits tensor. By\n            default, we consider that `output` encodes a probability\n            distribution.\n\n    Returns:\n        A tensor.\n    \"\"\"\n    target = tf.convert_to_tensor(target)\n    output = tf.convert_to_tensor(output)\n    target.shape.assert_is_compatible_with(output.shape)\n\n    output, from_logits = _get_logits(\n        output, from_logits, \"Softmax\", \"categorical_focal_crossentropy\"\n    )\n\n    output = tf.__internal__.smart_cond.smart_cond(\n        from_logits,\n        lambda: softmax(output),\n        lambda: output,\n    )\n\n    # scale preds so that the class probas of each sample sum to 1\n    output = output / tf.reduce_sum(output, axis=axis, keepdims=True)\n\n    epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\n    output = tf.clip_by_value(output, epsilon_, 1.0 - epsilon_)\n\n    # Calculate cross entropy\n    cce = -target * tf.math.log(output)\n\n    # Calculate factors\n    modulating_factor = tf.pow(1.0 - output, gamma)\n    weighting_factor = tf.multiply(modulating_factor, alpha)\n\n    # Apply weighting factor\n    focal_cce = tf.multiply(weighting_factor, cce)\n    focal_cce = tf.reduce_sum(focal_cce, axis=axis)\n    return focal_cce", "source_start_line": 5580, "tokens": ["def", "categorical_focal_crossentropy", "(", "target", ",", "output", ",", "alpha", "=", "0.25", ",", "gamma", "=", "2.0", ",", "from_logits", "=", "False", ",", "axis", "=", "-", "1", ",", ")", ":", "\"\"\"Computes the alpha balanced focal crossentropy loss.    According to [Lin et al., 2018](https://arxiv.org/pdf/1708.02002.pdf), it    helps to apply a focal factor to down-weight easy examples and focus more on    hard examples. By default, the focal tensor is computed as follows:    It has pt defined as:    pt = p, if y = 1 else 1 - p    The authors use alpha-balanced variant of focal loss in the paper:    FL(pt) = \u2212\u03b1_t * (1 \u2212 pt)^gamma * log(pt)    Extending this to multi-class case is straightforward:    FL(pt) = \u03b1_t * (1 \u2212 pt)^gamma * CE, where minus comes from    negative log-likelihood and included in CE.    `modulating_factor` is (1 \u2212 pt)^gamma, where `gamma` is a focusing    parameter. When `gamma` = 0, there is no focal effect on the categorical    crossentropy. And if alpha = 1, at the same time the loss is equivalent    to the categorical crossentropy.    Args:        target: A tensor with the same shape as `output`.        output: A tensor.        alpha: A weight balancing factor for all classes, default is `0.25` as            mentioned in the reference. It can be a list of floats or a scalar.            In the multi-class case, alpha may be set by inverse class            frequency by using `compute_class_weight` from `sklearn.utils`.        gamma: A focusing parameter, default is `2.0` as mentioned in the            reference. It helps to gradually reduce the importance given to            simple examples in a smooth manner.        from_logits: Whether `output` is expected to be a logits tensor. By            default, we consider that `output` encodes a probability            distribution.    Returns:        A tensor.    \"\"\"", "target", "=", "tf", ".", "convert_to_tensor", "(", "target", ")", "output", "=", "tf", ".", "convert_to_tensor", "(", "output", ")", "target", ".", "shape", ".", "assert_is_compatible_with", "(", "output", ".", "shape", ")", "output", ",", "from_logits", "=", "_get_logits", "(", "output", ",", "from_logits", ",", "\"Softmax\"", ",", "\"categorical_focal_crossentropy\"", ")", "output", "=", "tf", ".", "__internal__", ".", "smart_cond", ".", "smart_cond", "(", "from_logits", ",", "lambda", ":", "softmax", "(", "output", ")", ",", "lambda", ":", "output", ",", ")", "output", "=", "output", "/", "tf", ".", "reduce_sum", "(", "output", ",", "axis", "=", "axis", ",", "keepdims", "=", "True", ")", "epsilon_", "=", "_constant_to_tensor", "(", "epsilon", "(", ")", ",", "output", ".", "dtype", ".", "base_dtype", ")", "output", "=", "tf", ".", "clip_by_value", "(", "output", ",", "epsilon_", ",", "1.0", "-", "epsilon_", ")", "cce", "=", "-", "target", "*", "tf", ".", "math", ".", "log", "(", "output", ")", "modulating_factor", "=", "tf", ".", "pow", "(", "1.0", "-", "output", ",", "gamma", ")", "weighting_factor", "=", "tf", ".", "multiply", "(", "modulating_factor", ",", "alpha", ")", "focal_cce", "=", "tf", ".", "multiply", "(", "weighting_factor", ",", "cce", ")", "focal_cce", "=", "tf", ".", "reduce_sum", "(", "focal_cce", ",", "axis", "=", "axis", ")", "return", "focal_cce"], "to_mask": {"VAR": ["alpha", "axis", "cce", "epsilon_", "focal_cce", "from_logits", "gamma", "modulating_factor", "output", "target", "weighting_factor"], "METHOD": ["_constant_to_tensor", "_get_logits", "assert_is_compatible_with", "clip_by_value", "convert_to_tensor", "epsilon", "log", "multiply", "pow", "reduce_sum", "smart_cond", "softmax"]}, "attention_idx_tokens": [null, null], "patch": "@@ -5574,6 +5574,88 @@\n     return -tf.reduce_sum(target * tf.math.log(output), axis)\n \n \n+@keras_export(\"keras.backend.categorical_focal_crossentropy\")\n+@tf.__internal__.dispatch.add_dispatch_support\n+@doc_controls.do_not_generate_docs\n+def categorical_focal_crossentropy(\n+    target,\n+    output,\n+    alpha=0.25,\n+    gamma=2.0,\n+    from_logits=False,\n+    axis=-1,\n+):\n+    \"\"\"Computes the alpha balanced focal crossentropy loss.\n+\n+    According to [Lin et al., 2018](https://arxiv.org/pdf/1708.02002.pdf), it\n+    helps to apply a focal factor to down-weight easy examples and focus more on\n+    hard examples. By default, the focal tensor is computed as follows:\n+\n+    It has pt defined as:\n+    pt = p, if y = 1 else 1 - p\n+\n+    The authors use alpha-balanced variant of focal loss in the paper:\n+    FL(pt) = \u2212\u03b1_t * (1 \u2212 pt)^gamma * log(pt)\n+\n+    Extending this to multi-class case is straightforward:\n+    FL(pt) = \u03b1_t * (1 \u2212 pt)^gamma * CE, where minus comes from\n+    negative log-likelihood and included in CE.\n+\n+    `modulating_factor` is (1 \u2212 pt)^gamma, where `gamma` is a focusing\n+    parameter. When `gamma` = 0, there is no focal effect on the categorical\n+    crossentropy. And if alpha = 1, at the same time the loss is equivalent\n+    to the categorical crossentropy.\n+\n+    Args:\n+        target: A tensor with the same shape as `output`.\n+        output: A tensor.\n+        alpha: A weight balancing factor for all classes, default is `0.25` as\n+            mentioned in the reference. It can be a list of floats or a scalar.\n+            In the multi-class case, alpha may be set by inverse class\n+            frequency by using `compute_class_weight` from `sklearn.utils`.\n+        gamma: A focusing parameter, default is `2.0` as mentioned in the\n+            reference. It helps to gradually reduce the importance given to\n+            simple examples in a smooth manner.\n+        from_logits: Whether `output` is expected to be a logits tensor. By\n+            default, we consider that `output` encodes a probability\n+            distribution.\n+\n+    Returns:\n+        A tensor.\n+    \"\"\"\n+    target = tf.convert_to_tensor(target)\n+    output = tf.convert_to_tensor(output)\n+    target.shape.assert_is_compatible_with(output.shape)\n+\n+    output, from_logits = _get_logits(\n+        output, from_logits, \"Softmax\", \"categorical_focal_crossentropy\"\n+    )\n+\n+    output = tf.__internal__.smart_cond.smart_cond(\n+        from_logits,\n+        lambda: softmax(output),\n+        lambda: output,\n+    )\n+\n+    # scale preds so that the class probas of each sample sum to 1", "ext_attention_idx_tokens": [0, 195], "uid": "ff5ece5d", "question": "What is `probas`?", "code": "def categorical focal crossentropy target output alpha 0 25 gamma 2 0 from logits False axis -1 \"\"\"Computes the alpha balanced focal crossentropy loss According to [Lin et al 2018] https arxiv org pdf 1708 02002 pdf it helps to apply a focal factor to down-weight easy examples and focus more on hard examples By default the focal tensor is computed as follows It has pt defined as pt p if y 1 else 1 - p The authors use alpha-balanced variant of focal loss in the paper FL pt \u2212\u03b1 t * 1 \u2212 pt ^gamma * log pt Extending this to multi-class case is straightforward FL pt \u03b1 t * 1 \u2212 pt ^gamma * CE where minus comes from negative log-likelihood and included in CE `modulating factor` is 1 \u2212 pt ^gamma where `gamma` is a focusing parameter When `gamma` 0 there is no focal effect on the categorical crossentropy And if alpha 1 at the same time the loss is equivalent to the categorical crossentropy Args target A tensor with the same shape as `output` output A tensor alpha A weight balancing factor for all classes default is `0 25` as mentioned in the reference It can be a list of floats or a scalar In the multi-class case alpha may be set by inverse class frequency by using `compute class weight` from `sklearn utils` gamma A focusing parameter default is `2 0` as mentioned in the reference It helps to gradually reduce the importance given to simple examples in a smooth manner from logits Whether `output` is expected to be a logits tensor By default we consider that `output` encodes a probability distribution Returns A tensor \"\"\" target tf convert to tensor target output tf convert to tensor output target shape assert is compatible with output shape output from logits get logits output from logits \"Softmax\" \"categorical focal crossentropy\" output tf internal smart cond smart cond from logits lambda softmax output lambda output # scale preds so that the class probas of each sample sum to 1 output output tf reduce sum output axis axis keepdims True epsilon constant to tensor epsilon output dtype base dtype output tf clip by value output epsilon 1 0 - epsilon # Calculate cross entropy cce -target * tf math log output # Calculate factors modulating factor tf pow 1 0 - output gamma weighting factor tf multiply modulating factor alpha # Apply weighting factor focal cce tf multiply weighting factor cce focal cce tf reduce sum focal cce axis axis return focal cce"}
{"message": "Do we actually needed those? One we have the wheel we should be able to just install the wheel + pytest.", "timestamp": "2023-09-25T17:40:52Z", "file_name": "integration_tests/import_test.py", "range": {"start_line": 51, "end_line": 51, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1336205081", "html_url": "https://github.com/keras-team/keras/pull/18491#discussion_r1336205081", "attention_area": "        \"pip install -r requirements-common.txt\",", "file_path": "files/32/01/00000132.py", "old_file_path": null, "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": true}, "language": "python", "replies": {}, "diff_hunk": "@@ -0,0 +1,118 @@\n+import os\n+import re\n+import subprocess\n+\n+from keras import backend\n+\n+BACKEND_REQ = {\n+    \"tensorflow\": \"tensorflow\",\n+    \"torch\": \"torch torchvision\",\n+    \"jax\": \"jax jaxlib\",\n+}\n+\n+\n+def setup_package():\n+    subprocess.run(\"rm -rf tmp_build_dir\", shell=True)\n+    build_process = subprocess.run(\n+        \"python3 pip_build.py\",\n+        capture_output=True,\n+        text=True,\n+        shell=True,\n+    )\n+    print(build_process.stdout)\n+    match = re.search(\n+        r\"\\s[^\\s]*\\.whl\",\n+        build_process.stdout,\n+    )\n+    if not match:\n+        raise ValueError(\"Installing Keras package unsuccessful. \")\n+        print(build_process.stderr)\n+    whl_path = match.group()\n+    return whl_path\n+\n+\n+def create_virtualenv():\n+    env_setup = [\n+        # Create and activate virtual environment\n+        \"python3 -m venv test_env\",\n+        # \"source ./test_env/bin/activate\",\n+    ]\n+    os.environ[\"PATH\"] = (\n+        \"/test_env/bin/\" + os.pathsep + os.environ.get(\"PATH\", \"\")\n+    )\n+    run_commands_local(env_setup)\n+\n+\n+def manage_venv_installs(whl_path):\n+    other_backends = list(set(BACKEND_REQ.keys()) - {backend.backend()})\n+    install_setup = [\n+        # Installs the backend's package and common requirements\n+        \"pip install \" + BACKEND_REQ[backend.backend()],\n+        \"pip install -r requirements-common.txt\",", "source": "def manage_venv_installs(whl_path):\n    other_backends = list(set(BACKEND_REQ.keys()) - {backend.backend()})\n    install_setup = [\n        # Installs the backend's package and common requirements\n        \"pip install \" + BACKEND_REQ[backend.backend()],\n        \"pip install -r requirements-common.txt\",\n        \"pip install pytest\",\n        # Ensure other backends are uninstalled\n        \"pip uninstall -y \"\n        + BACKEND_REQ[other_backends[0]]\n        + \" \"\n        + BACKEND_REQ[other_backends[1]],\n        # Install `.whl` package\n        \"pip install \" + whl_path + \" --force-reinstall --no-dependencies\",\n    ]\n    run_commands_venv(install_setup)", "source_start_line": 46, "tokens": ["def", "manage_venv_installs", "(", "whl_path", ")", ":", "other_backends", "=", "list", "(", "set", "(", "BACKEND_REQ", ".", "keys", "(", ")", ")", "-", "{", "backend", ".", "backend", "(", ")", "}", ")", "install_setup", "=", "[", "\"pip install \"", "+", "BACKEND_REQ", "[", "backend", ".", "backend", "(", ")", "]", ",", "\"pip install -r requirements-common.txt\"", ",", "\"pip install pytest\"", ",", "\"pip uninstall -y \"", "+", "BACKEND_REQ", "[", "other_backends", "[", "0", "]", "]", "+", "\" \"", "+", "BACKEND_REQ", "[", "other_backends", "[", "1", "]", "]", ",", "\"pip install \"", "+", "whl_path", "+", "\" --force-reinstall --no-dependencies\"", ",", "]", "run_commands_venv", "(", "install_setup", ")"], "to_mask": {"VAR": ["install_setup", "other_backends", "whl_path"], "METHOD": ["backend", "keys", "list", "run_commands_venv", "set"]}, "attention_idx_tokens": [41, 42], "patch": "@@ -0,0 +1,118 @@\n+import os\n+import re\n+import subprocess\n+\n+from keras import backend\n+\n+BACKEND_REQ = {\n+    \"tensorflow\": \"tensorflow\",\n+    \"torch\": \"torch torchvision\",\n+    \"jax\": \"jax jaxlib\",\n+}\n+\n+\n+def setup_package():\n+    subprocess.run(\"rm -rf tmp_build_dir\", shell=True)\n+    build_process = subprocess.run(\n+        \"python3 pip_build.py\",\n+        capture_output=True,\n+        text=True,\n+        shell=True,\n+    )\n+    print(build_process.stdout)\n+    match = re.search(\n+        r\"\\s[^\\s]*\\.whl\",\n+        build_process.stdout,\n+    )\n+    if not match:\n+        raise ValueError(\"Installing Keras package unsuccessful. \")\n+        print(build_process.stderr)\n+    whl_path = match.group()\n+    return whl_path\n+\n+\n+def create_virtualenv():\n+    env_setup = [\n+        # Create and activate virtual environment\n+        \"python3 -m venv test_env\",\n+        # \"source ./test_env/bin/activate\",\n+    ]\n+    os.environ[\"PATH\"] = (\n+        \"/test_env/bin/\" + os.pathsep + os.environ.get(\"PATH\", \"\")\n+    )\n+    run_commands_local(env_setup)\n+\n+\n+def manage_venv_installs(whl_path):\n+    other_backends = list(set(BACKEND_REQ.keys()) - {backend.backend()})\n+    install_setup = [\n+        # Installs the backend's package and common requirements\n+        \"pip install \" + BACKEND_REQ[backend.backend()],\n+        \"pip install -r requirements-common.txt\",", "ext_attention_idx_tokens": [0, 75], "uid": "cc890a27", "question": "Do we actually needed those? One we have the wheel we should be able to just install the wheel + pytest.", "code": "def manage venv installs whl path other backends list set BACKEND REQ keys - {backend backend } install setup [ # Installs the backend s package and common requirements \"pip install \" + BACKEND REQ[backend backend ] \"pip install -r requirements-common txt\" \"pip install pytest\" # Ensure other backends are uninstalled \"pip uninstall -y \" + BACKEND REQ[other backends[0]] + \" \" + BACKEND REQ[other backends[1]] # Install ` whl` package \"pip install \" + whl path + \" --force-reinstall --no-dependencies\" ] run commands venv install setup"}
{"message": "Is it every possible to pass an optimizer that isn't an `Optimizer` instance? Wouldn't that blow up?", "timestamp": "2023-09-25T18:03:08Z", "file_name": "keras/engine/training.py", "range": {"start_line": 3686, "end_line": 3686, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1336226322", "html_url": "https://github.com/keras-team/keras/pull/18492#discussion_r1336226322", "attention_area": "            and isinstance(self.optimizer, optimizer.Optimizer)", "file_path": "files/33/01/00000133.py", "old_file_path": "files/34/01/00000134.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -3680,7 +3680,12 @@ def compile_from_config(self, config):\n             return\n         config = saving_lib.deserialize_keras_object(config)\n         self.compile(**config)\n-        if hasattr(self, \"optimizer\") and self.built:\n+        if (\n+            hasattr(self, \"optimizer\")\n+            # Exempt legacy optimizers.\n+            and isinstance(self.optimizer, optimizer.Optimizer)", "source": "def compile_from_config(self, config):\n        \"\"\"Compiles the model with the information given in config.\n\n        This method uses the information in the config (optimizer, loss,\n        metrics, etc.) to compile the model.\n\n        Args:\n            config: Dict containing information for compiling the model.\n        \"\"\"\n        has_overridden_compile = self.__class__.compile != Model.compile\n        if has_overridden_compile:\n            logging.warning(\n                \"`compile()` was not called as part of model loading \"\n                \"because the model's `compile()` method is custom. \"\n                \"All subclassed Models that have `compile()` \"\n                \"overridden should also override \"\n                \"`get_compile_config()` and `compile_from_config(config)`. \"\n                \"Alternatively, you can \"\n                \"call `compile()` manually after loading.\"\n            )\n            return\n        config = saving_lib.deserialize_keras_object(config)\n        self.compile(**config)\n        if (\n            hasattr(self, \"optimizer\")\n            # Exempt legacy optimizers.\n            and isinstance(self.optimizer, optimizer.Optimizer)\n            and self.built\n        ):\n            # Create optimizer variables.\n            self.optimizer.build(self.trainable_variables)", "source_start_line": 3660, "tokens": ["def", "compile_from_config", "(", "self", ",", "config", ")", ":", "\"\"\"Compiles the model with the information given in config.        This method uses the information in the config (optimizer, loss,        metrics, etc.) to compile the model.        Args:            config: Dict containing information for compiling the model.        \"\"\"", "has_overridden_compile", "=", "self", ".", "__class__", ".", "compile", "!=", "Model", ".", "compile", "if", "has_overridden_compile", ":", "logging", ".", "warning", "(", "\"`compile()` was not called as part of model loading \"", "\"because the model's `compile()` method is custom. \"", "\"All subclassed Models that have `compile()` \"", "\"overridden should also override \"", "\"`get_compile_config()` and `compile_from_config(config)`. \"", "\"Alternatively, you can \"", "\"call `compile()` manually after loading.\"", ")", "return", "config", "=", "saving_lib", ".", "deserialize_keras_object", "(", "config", ")", "self", ".", "compile", "(", "**", "config", ")", "if", "(", "hasattr", "(", "self", ",", "\"optimizer\"", ")", "and", "isinstance", "(", "self", ".", "optimizer", ",", "optimizer", ".", "Optimizer", ")", "and", "self", ".", "built", ")", ":", "self", ".", "optimizer", ".", "build", "(", "self", ".", "trainable_variables", ")"], "to_mask": {"VAR": ["config", "has_overridden_compile", "self"], "METHOD": ["build", "compile", "deserialize_keras_object", "hasattr", "isinstance", "warning"]}, "attention_idx_tokens": [59, 69], "patch": "@@ -3680,7 +3680,12 @@\n             return\n         config = saving_lib.deserialize_keras_object(config)\n         self.compile(**config)\n-        if hasattr(self, \"optimizer\") and self.built:\n+        if (\n+            hasattr(self, \"optimizer\")\n+            # Exempt legacy optimizers.\n+            and isinstance(self.optimizer, optimizer.Optimizer)", "ext_attention_idx_tokens": [51, 75], "uid": "010f3c42", "question": "Is it every possible to pass an optimizer that isn't an `Optimizer` instance? Wouldn't that blow up?", "code": "def compile from config self config \"\"\"Compiles the model with the information given in config This method uses the information in the config optimizer loss metrics etc to compile the model Args config Dict containing information for compiling the model \"\"\" has overridden compile self class compile ! Model compile if has overridden compile logging warning \"`compile ` was not called as part of model loading \" \"because the model s `compile ` method is custom \" \"All subclassed Models that have `compile ` \" \"overridden should also override \" \"`get compile config ` and `compile from config config ` \" \"Alternatively you can \" \"call `compile ` manually after loading \" return config saving lib deserialize keras object config self compile **config if hasattr self \"optimizer\" # Exempt legacy optimizers and isinstance self optimizer optimizer Optimizer and self built # Create optimizer variables self optimizer build self trainable variables"}
{"message": "Legacy optimizers simply don't exist in Keras 3, do they?", "timestamp": "2023-09-25T21:28:50Z", "file_name": "keras/engine/training.py", "range": {"start_line": 3686, "end_line": 3686, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1336406583", "html_url": "https://github.com/keras-team/keras/pull/18492#discussion_r1336406583", "attention_area": "            and isinstance(self.optimizer, optimizer.Optimizer)", "file_path": "files/33/01/00000133.py", "old_file_path": "files/34/01/00000134.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -3680,7 +3680,12 @@ def compile_from_config(self, config):\n             return\n         config = saving_lib.deserialize_keras_object(config)\n         self.compile(**config)\n-        if hasattr(self, \"optimizer\") and self.built:\n+        if (\n+            hasattr(self, \"optimizer\")\n+            # Exempt legacy optimizers.\n+            and isinstance(self.optimizer, optimizer.Optimizer)", "source": "def compile_from_config(self, config):\n        \"\"\"Compiles the model with the information given in config.\n\n        This method uses the information in the config (optimizer, loss,\n        metrics, etc.) to compile the model.\n\n        Args:\n            config: Dict containing information for compiling the model.\n        \"\"\"\n        has_overridden_compile = self.__class__.compile != Model.compile\n        if has_overridden_compile:\n            logging.warning(\n                \"`compile()` was not called as part of model loading \"\n                \"because the model's `compile()` method is custom. \"\n                \"All subclassed Models that have `compile()` \"\n                \"overridden should also override \"\n                \"`get_compile_config()` and `compile_from_config(config)`. \"\n                \"Alternatively, you can \"\n                \"call `compile()` manually after loading.\"\n            )\n            return\n        config = saving_lib.deserialize_keras_object(config)\n        self.compile(**config)\n        if (\n            hasattr(self, \"optimizer\")\n            # Exempt legacy optimizers.\n            and isinstance(self.optimizer, optimizer.Optimizer)\n            and self.built\n        ):\n            # Create optimizer variables.\n            self.optimizer.build(self.trainable_variables)", "source_start_line": 3660, "tokens": ["def", "compile_from_config", "(", "self", ",", "config", ")", ":", "\"\"\"Compiles the model with the information given in config.        This method uses the information in the config (optimizer, loss,        metrics, etc.) to compile the model.        Args:            config: Dict containing information for compiling the model.        \"\"\"", "has_overridden_compile", "=", "self", ".", "__class__", ".", "compile", "!=", "Model", ".", "compile", "if", "has_overridden_compile", ":", "logging", ".", "warning", "(", "\"`compile()` was not called as part of model loading \"", "\"because the model's `compile()` method is custom. \"", "\"All subclassed Models that have `compile()` \"", "\"overridden should also override \"", "\"`get_compile_config()` and `compile_from_config(config)`. \"", "\"Alternatively, you can \"", "\"call `compile()` manually after loading.\"", ")", "return", "config", "=", "saving_lib", ".", "deserialize_keras_object", "(", "config", ")", "self", ".", "compile", "(", "**", "config", ")", "if", "(", "hasattr", "(", "self", ",", "\"optimizer\"", ")", "and", "isinstance", "(", "self", ".", "optimizer", ",", "optimizer", ".", "Optimizer", ")", "and", "self", ".", "built", ")", ":", "self", ".", "optimizer", ".", "build", "(", "self", ".", "trainable_variables", ")"], "to_mask": {"VAR": ["config", "has_overridden_compile", "self"], "METHOD": ["build", "compile", "deserialize_keras_object", "hasattr", "isinstance", "warning"]}, "attention_idx_tokens": [59, 69], "patch": "@@ -3680,7 +3680,12 @@\n             return\n         config = saving_lib.deserialize_keras_object(config)\n         self.compile(**config)\n-        if hasattr(self, \"optimizer\") and self.built:\n+        if (\n+            hasattr(self, \"optimizer\")\n+            # Exempt legacy optimizers.\n+            and isinstance(self.optimizer, optimizer.Optimizer)", "ext_attention_idx_tokens": [51, 75], "uid": "bae100f0", "question": "Legacy optimizers simply don't exist in Keras 3, do they?", "code": "def compile from config self config \"\"\"Compiles the model with the information given in config This method uses the information in the config optimizer loss metrics etc to compile the model Args config Dict containing information for compiling the model \"\"\" has overridden compile self class compile ! Model compile if has overridden compile logging warning \"`compile ` was not called as part of model loading \" \"because the model s `compile ` method is custom \" \"All subclassed Models that have `compile ` \" \"overridden should also override \" \"`get compile config ` and `compile from config config ` \" \"Alternatively you can \" \"call `compile ` manually after loading \" return config saving lib deserialize keras object config self compile **config if hasattr self \"optimizer\" # Exempt legacy optimizers and isinstance self optimizer optimizer Optimizer and self built # Create optimizer variables self optimizer build self trainable variables"}
{"message": "Does it support tensors with unknown shapes (e.g. with TF)? Can the offsets be scalar tensors?", "timestamp": "2023-09-27T20:06:03Z", "file_name": "keras/ops/image.py", "range": {"start_line": 548, "end_line": 548, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1339148857", "html_url": "https://github.com/keras-team/keras/pull/18503#discussion_r1339148857", "attention_area": "    image, offset_height, offset_width, target_height, target_width, check_dims", "file_path": "files/55/01/00000155.py", "old_file_path": "files/56/01/00000156.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -501,3 +501,157 @@ def map_coordinates(\n         fill_mode,\n         fill_value,\n     )\n+\n+\n+class PadToBoundingBox(Operation):\n+    def __init__(\n+        self,\n+        offset_height,\n+        offset_width,\n+        target_height,\n+        target_width,\n+        check_dims=True,\n+    ):\n+        super().__init__()\n+        self.offset_height = offset_height\n+        self.offset_width = offset_width\n+        self.target_height = target_height\n+        self.target_width = target_width\n+        self.check_dims = check_dims\n+\n+    def call(self, image):\n+        return _pad_to_bounding_box(\n+            image,\n+            self.offset_height,\n+            self.offset_width,\n+            self.target_height,\n+            self.target_width,\n+            self.check_dims,\n+        )\n+\n+    def compute_output_spec(self, image):\n+        out_shape = (\n+            image.shape[0],\n+            self.target_height,\n+            self.target_width,\n+            image.shape[-1],\n+        )\n+        if len(image.shape) == 3:\n+            out_shape = out_shape[1:]\n+        return KerasTensor(\n+            shape=out_shape,\n+            dtype=image.dtype,\n+        )\n+\n+\n+def _pad_to_bounding_box(\n+    image, offset_height, offset_width, target_height, target_width, check_dims", "source": "def _pad_to_bounding_box(\n    image, offset_height, offset_width, target_height, target_width, check_dims\n):\n    image = backend.convert_to_tensor(image)\n    is_batch = True\n    image_shape = image.shape\n    if len(image_shape) == 3:\n        is_batch = False\n        image = backend.numpy.expand_dims(image, 0)\n    elif len(image_shape) != 4:\n        raise ValueError(\n            \"'image' (shape %s) must have either 3 or 4 dimensions.\"\n            % image_shape\n        )\n\n    batch, height, width, depth = image.shape\n    after_padding_width = target_width - offset_width - width\n    after_padding_height = target_height - offset_height - height\n\n    if check_dims:\n        if not offset_height >= 0:\n            raise ValueError(\"offset_height must be >= 0\")\n        if not offset_width >= 0:\n            raise ValueError(\"offset_width must be >= 0\")\n        if not after_padding_width >= 0:\n            raise ValueError(\"width must be <= target - offset\")\n        if not after_padding_height >= 0:\n            raise ValueError(\"height must be <= target - offset\")\n\n    paddings = backend.numpy.reshape(\n        backend.numpy.stack(\n            [\n                0,\n                0,\n                offset_height,\n                after_padding_height,\n                offset_width,\n                after_padding_width,\n                0,\n                0,\n            ]\n        ),\n        [4, 2],\n    )\n    padded = backend.numpy.pad(image, paddings)\n\n    padded_shape = [batch, target_height, target_width, depth]\n    padded = backend.numpy.reshape(padded, padded_shape)\n\n    if not is_batch:\n        padded = backend.numpy.squeeze(padded, axis=[0])\n    return padded", "source_start_line": 547, "tokens": ["def", "_pad_to_bounding_box", "(", "image", ",", "offset_height", ",", "offset_width", ",", "target_height", ",", "target_width", ",", "check_dims", ")", ":", "image", "=", "backend", ".", "convert_to_tensor", "(", "image", ")", "is_batch", "=", "True", "image_shape", "=", "image", ".", "shape", "if", "len", "(", "image_shape", ")", "==", "3", ":", "is_batch", "=", "False", "image", "=", "backend", ".", "numpy", ".", "expand_dims", "(", "image", ",", "0", ")", "elif", "len", "(", "image_shape", ")", "!=", "4", ":", "raise", "ValueError", "(", "\"'image' (shape %s) must have either 3 or 4 dimensions.\"", "%", "image_shape", ")", "batch", ",", "height", ",", "width", ",", "depth", "=", "image", ".", "shape", "after_padding_width", "=", "target_width", "-", "offset_width", "-", "width", "after_padding_height", "=", "target_height", "-", "offset_height", "-", "height", "if", "check_dims", ":", "if", "not", "offset_height", ">=", "0", ":", "raise", "ValueError", "(", "\"offset_height must be >= 0\"", ")", "if", "not", "offset_width", ">=", "0", ":", "raise", "ValueError", "(", "\"offset_width must be >= 0\"", ")", "if", "not", "after_padding_width", ">=", "0", ":", "raise", "ValueError", "(", "\"width must be <= target - offset\"", ")", "if", "not", "after_padding_height", ">=", "0", ":", "raise", "ValueError", "(", "\"height must be <= target - offset\"", ")", "paddings", "=", "backend", ".", "numpy", ".", "reshape", "(", "backend", ".", "numpy", ".", "stack", "(", "[", "0", ",", "0", ",", "offset_height", ",", "after_padding_height", ",", "offset_width", ",", "after_padding_width", ",", "0", ",", "0", ",", "]", ")", ",", "[", "4", ",", "2", "]", ",", ")", "padded", "=", "backend", ".", "numpy", ".", "pad", "(", "image", ",", "paddings", ")", "padded_shape", "=", "[", "batch", ",", "target_height", ",", "target_width", ",", "depth", "]", "padded", "=", "backend", ".", "numpy", ".", "reshape", "(", "padded", ",", "padded_shape", ")", "if", "not", "is_batch", ":", "padded", "=", "backend", ".", "numpy", ".", "squeeze", "(", "padded", ",", "axis", "=", "[", "0", "]", ")", "return", "padded"], "to_mask": {"VAR": ["after_padding_height", "after_padding_width", "batch", "check_dims", "depth", "height", "image", "image_shape", "is_batch", "offset_height", "offset_width", "padded", "padded_shape", "paddings", "target_height", "target_width", "width"], "METHOD": ["ValueError", "convert_to_tensor", "expand_dims", "len", "pad", "reshape", "squeeze", "stack"]}, "attention_idx_tokens": [3, 13], "patch": "@@ -501,3 +501,157 @@\n         fill_mode,\n         fill_value,\n     )\n+\n+\n+class PadToBoundingBox(Operation):\n+    def __init__(\n+        self,\n+        offset_height,\n+        offset_width,\n+        target_height,\n+        target_width,\n+        check_dims=True,\n+    ):\n+        super().__init__()\n+        self.offset_height = offset_height\n+        self.offset_width = offset_width\n+        self.target_height = target_height\n+        self.target_width = target_width\n+        self.check_dims = check_dims\n+\n+    def call(self, image):\n+        return _pad_to_bounding_box(\n+            image,\n+            self.offset_height,\n+            self.offset_width,\n+            self.target_height,\n+            self.target_width,\n+            self.check_dims,\n+        )\n+\n+    def compute_output_spec(self, image):\n+        out_shape = (\n+            image.shape[0],\n+            self.target_height,\n+            self.target_width,\n+            image.shape[-1],\n+        )\n+        if len(image.shape) == 3:\n+            out_shape = out_shape[1:]\n+        return KerasTensor(\n+            shape=out_shape,\n+            dtype=image.dtype,\n+        )\n+\n+\n+def _pad_to_bounding_box(\n+    image, offset_height, offset_width, target_height, target_width, check_dims", "ext_attention_idx_tokens": [0, 239], "uid": "26265f97", "question": "Does it support tensors with unknown shapes (e.g. with TF)? Can the offsets be scalar tensors?", "code": "def pad to bounding box image offset height offset width target height target width check dims image backend convert to tensor image is batch True image shape image shape if len image shape 3 is batch False image backend numpy expand dims image 0 elif len image shape ! 4 raise ValueError \" image shape %s must have either 3 or 4 dimensions \" % image shape batch height width depth image shape after padding width target width - offset width - width after padding height target height - offset height - height if check dims if not offset height > 0 raise ValueError \"offset height must be > 0\" if not offset width > 0 raise ValueError \"offset width must be > 0\" if not after padding width > 0 raise ValueError \"width must be < target - offset\" if not after padding height > 0 raise ValueError \"height must be < target - offset\" paddings backend numpy reshape backend numpy stack [ 0 0 offset height after padding height offset width after padding width 0 0 ] [4 2] padded backend numpy pad image paddings padded shape [batch target height target width depth] padded backend numpy reshape padded padded shape if not is batch padded backend numpy squeeze padded axis [0] return padded"}
{"message": "It should work in both situations in JAX, right?", "timestamp": "2023-10-06T08:43:34Z", "file_name": "keras/distribution/distribution_lib.py", "range": {"start_line": 537, "end_line": 537, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1348425987", "html_url": "https://github.com/keras-team/keras/pull/18536#discussion_r1348425987", "attention_area": "    backend. To change the layout of a value eagerly, please use", "file_path": "files/02/02/00000202.py", "old_file_path": "files/84/01/00000184.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -507,6 +529,28 @@ def _maybe_populate_device_mesh(self, layout):\n LayoutMap.get.__doc__ = LayoutMap.__getitem__.__doc__\n \n \n+@keras_export(\"keras.distribution.distribute_tensor\")\n+def distribute_tensor(tensor, tensor_layout):\n+    \"\"\"Change the layout of a Tensor value in the jit function execution.\n+\n+    Note that this might not work outside of the jitted function for certain\n+    backend. To change the layout of a value eagerly, please use", "source": "def distribute_tensor(tensor, tensor_layout):\n    \"\"\"Change the layout of a Tensor value in the jit function execution.\n\n    Note that this might not work outside of the jitted function for certain\n    backend. To change the layout of a value eagerly, please use\n    `backend.distribution_lib.distribute_value`.\n\n    Args:\n        tensor: a Tensor to change the layout.\n        tensor_layout: TensorLayout to be applied on the value.\n\n    Returns:\n        a new value with the specified tensor layout.\n    \"\"\"\n    if isinstance(tensor, KerasTensor):\n        # keras tensor is only used for building functional model, and can't be\n        # used to alter layout/sharding.\n        return tensor\n    return distribution_lib.distribute_tensor(tensor, tensor_layout)", "source_start_line": 533, "tokens": ["def", "distribute_tensor", "(", "tensor", ",", "tensor_layout", ")", ":", "\"\"\"Change the layout of a Tensor value in the jit function execution.    Note that this might not work outside of the jitted function for certain    backend. To change the layout of a value eagerly, please use    `backend.distribution_lib.distribute_value`.    Args:        tensor: a Tensor to change the layout.        tensor_layout: TensorLayout to be applied on the value.    Returns:        a new value with the specified tensor layout.    \"\"\"", "if", "isinstance", "(", "tensor", ",", "KerasTensor", ")", ":", "return", "tensor", "return", "distribution_lib", ".", "distribute_tensor", "(", "tensor", ",", "tensor_layout", ")"], "to_mask": {"VAR": ["tensor", "tensor_layout"], "METHOD": ["distribute_tensor", "isinstance"]}, "attention_idx_tokens": [null, null], "patch": "@@ -507,6 +529,28 @@\n LayoutMap.get.__doc__ = LayoutMap.__getitem__.__doc__\n \n \n+@keras_export(\"keras.distribution.distribute_tensor\")\n+def distribute_tensor(tensor, tensor_layout):\n+    \"\"\"Change the layout of a Tensor value in the jit function execution.\n+\n+    Note that this might not work outside of the jitted function for certain\n+    backend. To change the layout of a value eagerly, please use", "ext_attention_idx_tokens": [0, 27], "uid": "d8d92c15", "question": "It should work in both situations in JAX, right?", "code": "def distribute tensor tensor tensor layout \"\"\"Change the layout of a Tensor value in the jit function execution Note that this might not work outside of the jitted function for certain backend To change the layout of a value eagerly please use `backend distribution lib distribute value` Args tensor a Tensor to change the layout tensor layout TensorLayout to be applied on the value Returns a new value with the specified tensor layout \"\"\" if isinstance tensor KerasTensor # keras tensor is only used for building functional model and can t be # used to alter layout sharding return tensor return distribution lib distribute tensor tensor tensor layout"}
{"message": "The fact that instantiating a Keras object modifies a global config outside Keras might be problematic. What happens if we don't do it? What tests break?", "timestamp": "2023-10-07T07:41:52Z", "file_name": "keras/backend/torch/trainer.py", "range": {"start_line": 34, "end_line": 34, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1349481032", "html_url": "https://github.com/keras-team/keras/pull/18569#discussion_r1349481032", "attention_area": "        dynamo_config.suppress_errors = True", "file_path": "files/10/02/00000210.py", "old_file_path": "files/11/02/00000211.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -25,6 +26,13 @@ def __init__(self):\n         self.test_function = None\n         self.predict_function = None\n \n+        # Ensures maximum compatibility when jit_compile=True\n+        # by instructing dynamo to graph breaks and delegate to python\n+        # for functions that cannot be traced.\n+        # User can set this to False after instantiating the trainer\n+        # to see trace errors and fix them for better performance.\n+        dynamo_config.suppress_errors = True", "source": "def __init__(self):\n        super().__init__()\n        self.train_function = None\n        self.test_function = None\n        self.predict_function = None\n\n        # Ensures maximum compatibility when jit_compile=True\n        # by instructing dynamo to graph breaks and delegate to python\n        # for functions that cannot be traced.\n        # User can set this to False after instantiating the trainer\n        # to see trace errors and fix them for better performance.\n        dynamo_config.suppress_errors = True", "source_start_line": 23, "tokens": ["def", "__init__", "(", "self", ")", ":", "super", "(", ")", ".", "__init__", "(", ")", "self", ".", "train_function", "=", "None", "self", ".", "test_function", "=", "None", "self", ".", "predict_function", "=", "None", "dynamo_config", ".", "suppress_errors", "=", "True"], "to_mask": {"VAR": ["predict_function", "self", "suppress_errors", "test_function", "train_function"], "METHOD": ["__init__", "super"]}, "attention_idx_tokens": [28, 32], "patch": "@@ -25,6 +26,13 @@\n         self.test_function = None\n         self.predict_function = None\n \n+        # Ensures maximum compatibility when jit_compile=True\n+        # by instructing dynamo to graph breaks and delegate to python\n+        # for functions that cannot be traced.\n+        # User can set this to False after instantiating the trainer\n+        # to see trace errors and fix them for better performance.\n+        dynamo_config.suppress_errors = True", "ext_attention_idx_tokens": [28, 32], "uid": "e79841ec", "question": "The fact that instantiating a Keras object modifies a global config outside Keras might be problematic. What happens if we don't do it? What tests break?", "code": "def init self super init self train function None self test function None self predict function None # Ensures maximum compatibility when jit compile True # by instructing dynamo to graph breaks and delegate to python # for functions that cannot be traced # User can set this to False after instantiating the trainer # to see trace errors and fix them for better performance dynamo config suppress errors True"}
{"message": "Why are we pulling these out to toplevels? It is slightly confusing because we also have stateless versions for jax with the same name declared inline.\r\n\r\nProbably we should either keep them all inlined, or pull them all out, with a `stateless_` prefix for the stateless ones?", "timestamp": "2023-10-26T17:29:12Z", "file_name": "keras/optimizers/loss_scale_optimizer.py", "range": {"start_line": 158, "end_line": 158, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1373509092", "html_url": "https://github.com/keras-team/keras/pull/18691#discussion_r1373509092", "attention_area": "    def handle_finite_grads(self, grads, trainable_variables):", "file_path": "files/74/02/00000274.py", "old_file_path": "files/75/02/00000275.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -150,37 +150,87 @@ def apply(self, grads, trainable_variables=None):\n                 self.build(trainable_variables)\n             self.built = True\n \n-        def handle_finite_grads():\n-            scale = self.dynamic_scale\n-            # Unscale gradients.\n-            unscaled_grads = [\n-                g if g is None else ops.divide(g, scale) for g in grads\n-            ]\n-            self.inner_optimizer.apply(\n-                unscaled_grads, trainable_variables=trainable_variables\n-            )\n+        if backend.backend() == \"tensorflow\":\n+            self._tf_apply(grads, trainable_variables)\n+        else:\n+            self._common_apply(grads, trainable_variables)\n+\n+    def handle_finite_grads(self, grads, trainable_variables):", "source": "def handle_finite_grads(self, grads, trainable_variables):\n        scale = self.dynamic_scale\n        # Unscale gradients.\n        unscaled_grads = [\n            g if g is None else ops.divide(g, scale) for g in grads\n        ]\n        self.inner_optimizer.apply(\n            unscaled_grads, trainable_variables=trainable_variables\n        )\n\n        def upscale():\n            self.step_counter.assign(0)\n            self.dynamic_scale.assign(self.dynamic_scale * 2.0)\n\n        def increment():\n            self.step_counter.assign_add(1)\n\n        # Potentially upscale loss and reset counter.\n        ops.cond(\n            ops.equal(self.step_counter, self.dynamic_growth_steps - 1),\n            upscale,\n            increment,\n        )", "source_start_line": 158, "tokens": ["def", "handle_finite_grads", "(", "self", ",", "grads", ",", "trainable_variables", ")", ":", "scale", "=", "self", ".", "dynamic_scale", "unscaled_grads", "=", "[", "g", "if", "g", "is", "None", "else", "ops", ".", "divide", "(", "g", ",", "scale", ")", "for", "g", "in", "grads", "]", "self", ".", "inner_optimizer", ".", "apply", "(", "unscaled_grads", ",", "trainable_variables", "=", "trainable_variables", ")", "def", "upscale", "(", ")", ":", "self", ".", "step_counter", ".", "assign", "(", "0", ")", "self", ".", "dynamic_scale", ".", "assign", "(", "self", ".", "dynamic_scale", "*", "2.0", ")", "def", "increment", "(", ")", ":", "self", ".", "step_counter", ".", "assign_add", "(", "1", ")", "ops", ".", "cond", "(", "ops", ".", "equal", "(", "self", ".", "step_counter", ",", "self", ".", "dynamic_growth_steps", "-", "1", ")", ",", "upscale", ",", "increment", ",", ")"], "to_mask": {"VAR": ["grads", "scale", "self", "trainable_variables", "unscaled_grads"], "METHOD": ["apply", "assign", "assign_add", "cond", "divide", "equal"]}, "attention_idx_tokens": [0, 9], "patch": "@@ -150,37 +150,87 @@\n                 self.build(trainable_variables)\n             self.built = True\n \n-        def handle_finite_grads():\n-            scale = self.dynamic_scale\n-            # Unscale gradients.\n-            unscaled_grads = [\n-                g if g is None else ops.divide(g, scale) for g in grads\n-            ]\n-            self.inner_optimizer.apply(\n-                unscaled_grads, trainable_variables=trainable_variables\n-            )\n-\n-            def upscale():\n-                self.step_counter.assign(0)\n-                self.dynamic_scale.assign(self.dynamic_scale * 2.0)\n-\n-            def increment():\n-                self.step_counter.assign_add(1)\n-\n-            # Potentially upscale loss and reset counter.\n-            ops.cond(\n-                ops.equal(self.step_counter, self.dynamic_growth_steps - 1),\n-                upscale,\n-                increment,\n-            )\n+        if backend.backend() == \"tensorflow\":\n+            self._tf_apply(grads, trainable_variables)\n+        else:\n+            self._common_apply(grads, trainable_variables)\n+\n+    def handle_finite_grads(self, grads, trainable_variables):", "ext_attention_idx_tokens": [0, 110], "uid": "b5e0aae1", "question": "Why are we pulling these out to toplevels? It is slightly confusing because we also have stateless versions for jax with the same name declared inline.    Probably we should either keep them all inlined, or pull them all out, with a `stateless_` prefix for the stateless ones?", "code": "def handle finite grads self grads trainable variables scale self dynamic scale # Unscale gradients unscaled grads [ g if g is None else ops divide g scale for g in grads ] self inner optimizer apply unscaled grads trainable variables trainable variables def upscale self step counter assign 0 self dynamic scale assign self dynamic scale * 2 0 def increment self step counter assign add 1 # Potentially upscale loss and reset counter ops cond ops equal self step counter self dynamic growth steps - 1 upscale increment"}
{"message": "don't see the update yet, did you forget to push?", "timestamp": "2023-10-26T19:29:29Z", "file_name": "keras/optimizers/loss_scale_optimizer.py", "range": {"start_line": 158, "end_line": 158, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1373720630", "html_url": "https://github.com/keras-team/keras/pull/18691#discussion_r1373720630", "attention_area": "    def handle_finite_grads(self, grads, trainable_variables):", "file_path": "files/74/02/00000274.py", "old_file_path": "files/75/02/00000275.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -150,37 +150,87 @@ def apply(self, grads, trainable_variables=None):\n                 self.build(trainable_variables)\n             self.built = True\n \n-        def handle_finite_grads():\n-            scale = self.dynamic_scale\n-            # Unscale gradients.\n-            unscaled_grads = [\n-                g if g is None else ops.divide(g, scale) for g in grads\n-            ]\n-            self.inner_optimizer.apply(\n-                unscaled_grads, trainable_variables=trainable_variables\n-            )\n+        if backend.backend() == \"tensorflow\":\n+            self._tf_apply(grads, trainable_variables)\n+        else:\n+            self._common_apply(grads, trainable_variables)\n+\n+    def handle_finite_grads(self, grads, trainable_variables):", "source": "def handle_finite_grads(self, grads, trainable_variables):\n        scale = self.dynamic_scale\n        # Unscale gradients.\n        unscaled_grads = [\n            g if g is None else ops.divide(g, scale) for g in grads\n        ]\n        self.inner_optimizer.apply(\n            unscaled_grads, trainable_variables=trainable_variables\n        )\n\n        def upscale():\n            self.step_counter.assign(0)\n            self.dynamic_scale.assign(self.dynamic_scale * 2.0)\n\n        def increment():\n            self.step_counter.assign_add(1)\n\n        # Potentially upscale loss and reset counter.\n        ops.cond(\n            ops.equal(self.step_counter, self.dynamic_growth_steps - 1),\n            upscale,\n            increment,\n        )", "source_start_line": 158, "tokens": ["def", "handle_finite_grads", "(", "self", ",", "grads", ",", "trainable_variables", ")", ":", "scale", "=", "self", ".", "dynamic_scale", "unscaled_grads", "=", "[", "g", "if", "g", "is", "None", "else", "ops", ".", "divide", "(", "g", ",", "scale", ")", "for", "g", "in", "grads", "]", "self", ".", "inner_optimizer", ".", "apply", "(", "unscaled_grads", ",", "trainable_variables", "=", "trainable_variables", ")", "def", "upscale", "(", ")", ":", "self", ".", "step_counter", ".", "assign", "(", "0", ")", "self", ".", "dynamic_scale", ".", "assign", "(", "self", ".", "dynamic_scale", "*", "2.0", ")", "def", "increment", "(", ")", ":", "self", ".", "step_counter", ".", "assign_add", "(", "1", ")", "ops", ".", "cond", "(", "ops", ".", "equal", "(", "self", ".", "step_counter", ",", "self", ".", "dynamic_growth_steps", "-", "1", ")", ",", "upscale", ",", "increment", ",", ")"], "to_mask": {"VAR": ["grads", "scale", "self", "trainable_variables", "unscaled_grads"], "METHOD": ["apply", "assign", "assign_add", "cond", "divide", "equal"]}, "attention_idx_tokens": [0, 9], "patch": "@@ -150,37 +150,87 @@\n                 self.build(trainable_variables)\n             self.built = True\n \n-        def handle_finite_grads():\n-            scale = self.dynamic_scale\n-            # Unscale gradients.\n-            unscaled_grads = [\n-                g if g is None else ops.divide(g, scale) for g in grads\n-            ]\n-            self.inner_optimizer.apply(\n-                unscaled_grads, trainable_variables=trainable_variables\n-            )\n-\n-            def upscale():\n-                self.step_counter.assign(0)\n-                self.dynamic_scale.assign(self.dynamic_scale * 2.0)\n-\n-            def increment():\n-                self.step_counter.assign_add(1)\n-\n-            # Potentially upscale loss and reset counter.\n-            ops.cond(\n-                ops.equal(self.step_counter, self.dynamic_growth_steps - 1),\n-                upscale,\n-                increment,\n-            )\n+        if backend.backend() == \"tensorflow\":\n+            self._tf_apply(grads, trainable_variables)\n+        else:\n+            self._common_apply(grads, trainable_variables)\n+\n+    def handle_finite_grads(self, grads, trainable_variables):", "ext_attention_idx_tokens": [0, 110], "uid": "fc2e2349", "question": "don't see the update yet, did you forget to push?", "code": "def handle finite grads self grads trainable variables scale self dynamic scale # Unscale gradients unscaled grads [ g if g is None else ops divide g scale for g in grads ] self inner optimizer apply unscaled grads trainable variables trainable variables def upscale self step counter assign 0 self dynamic scale assign self dynamic scale * 2 0 def increment self step counter assign add 1 # Potentially upscale loss and reset counter ops cond ops equal self step counter self dynamic growth steps - 1 upscale increment"}
{"message": "Is it intentional? `log` operations in some cases provide more accurate results with double precision. I am not sure though if it's the same reason here", "timestamp": "2023-10-27T07:15:22Z", "file_name": "keras/backend/tensorflow/numpy.py", "range": {"start_line": 754, "end_line": 754, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1374163021", "html_url": "https://github.com/keras-team/keras/pull/18693#discussion_r1374163021", "attention_area": "    # TODO: tfnp.logaddexp incorrectly promote bfloat16 to float64", "file_path": "files/76/02/00000276.py", "old_file_path": "files/77/02/00000277.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -688,26 +695,64 @@ def linspace(\n \n @sparse.densifying_unary(-tfnp.inf)\n def log(x):\n-    return tfnp.log(x)\n+    x = convert_to_tensor(x)\n+    dtype = (\n+        config.floatx()\n+        if standardize_dtype(x.dtype) == \"int64\"\n+        else dtypes.result_type(x.dtype, float)\n+    )\n+    x = tf.cast(x, dtype)\n+    # TODO: tfnp.log incorrectly promote bfloat16 to float64\n+    return tf.cast(tfnp.log(x), dtype)\n \n \n @sparse.densifying_unary(-tfnp.inf)\n def log10(x):\n-    return tfnp.log10(x)\n+    x = convert_to_tensor(x)\n+    dtype = (\n+        config.floatx()\n+        if standardize_dtype(x.dtype) == \"int64\"\n+        else dtypes.result_type(x.dtype, float)\n+    )\n+    x = tf.cast(x, dtype)\n+    # TODO: tfnp.log10 incorrectly promote bfloat16 to float64\n+    return tf.cast(tfnp.log10(x), dtype)\n \n \n @sparse.elementwise_unary\n def log1p(x):\n-    return tfnp.log1p(x)\n+    x = convert_to_tensor(x)\n+    dtype = (\n+        config.floatx()\n+        if standardize_dtype(x.dtype) == \"int64\"\n+        else dtypes.result_type(x.dtype, float)\n+    )\n+    x = tf.cast(x, dtype)\n+    # TODO: tfnp.log1p incorrectly promote bfloat16 to float64\n+    return tf.cast(tfnp.log1p(x), dtype)\n \n \n @sparse.densifying_unary(-tfnp.inf)\n def log2(x):\n-    return tfnp.log2(x)\n+    x = convert_to_tensor(x)\n+    dtype = (\n+        config.floatx()\n+        if standardize_dtype(x.dtype) == \"int64\"\n+        else dtypes.result_type(x.dtype, float)\n+    )\n+    x = tf.cast(x, dtype)\n+    # TODO: tfnp.log10 incorrectly promote bfloat16 to float64\n+    return tf.cast(tfnp.log2(x), dtype)\n \n \n def logaddexp(x1, x2):\n-    return tfnp.logaddexp(x1, x2)\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n+    dtype = dtypes.result_type(x1.dtype, x2.dtype, float)\n+    x1 = tf.cast(x1, dtype)\n+    x2 = tf.cast(x2, dtype)\n+    # TODO: tfnp.logaddexp incorrectly promote bfloat16 to float64", "source": "def logaddexp(x1, x2):\n    x1 = convert_to_tensor(x1)\n    x2 = convert_to_tensor(x2)\n    dtype = dtypes.result_type(x1.dtype, x2.dtype, float)\n    x1 = tf.cast(x1, dtype)\n    x2 = tf.cast(x2, dtype)\n    # TODO: tfnp.logaddexp incorrectly promote bfloat16 to float64\n    return tf.cast(tfnp.logaddexp(x1, x2), dtype)", "source_start_line": 748, "tokens": ["def", "logaddexp", "(", "x1", ",", "x2", ")", ":", "x1", "=", "convert_to_tensor", "(", "x1", ")", "x2", "=", "convert_to_tensor", "(", "x2", ")", "dtype", "=", "dtypes", ".", "result_type", "(", "x1", ".", "dtype", ",", "x2", ".", "dtype", ",", "float", ")", "x1", "=", "tf", ".", "cast", "(", "x1", ",", "dtype", ")", "x2", "=", "tf", ".", "cast", "(", "x2", ",", "dtype", ")", "return", "tf", ".", "cast", "(", "tfnp", ".", "logaddexp", "(", "x1", ",", "x2", ")", ",", "dtype", ")"], "to_mask": {"VAR": ["dtype", "x1", "x2"], "METHOD": ["cast", "convert_to_tensor", "logaddexp", "result_type"]}, "attention_idx_tokens": [null, null], "patch": "@@ -688,26 +695,64 @@\n \n @sparse.densifying_unary(-tfnp.inf)\n def log(x):\n-    return tfnp.log(x)\n+    x = convert_to_tensor(x)\n+    dtype = (\n+        config.floatx()\n+        if standardize_dtype(x.dtype) == \"int64\"\n+        else dtypes.result_type(x.dtype, float)\n+    )\n+    x = tf.cast(x, dtype)\n+    # TODO: tfnp.log incorrectly promote bfloat16 to float64\n+    return tf.cast(tfnp.log(x), dtype)\n \n \n @sparse.densifying_unary(-tfnp.inf)\n def log10(x):\n-    return tfnp.log10(x)\n+    x = convert_to_tensor(x)\n+    dtype = (\n+        config.floatx()\n+        if standardize_dtype(x.dtype) == \"int64\"\n+        else dtypes.result_type(x.dtype, float)\n+    )\n+    x = tf.cast(x, dtype)\n+    # TODO: tfnp.log10 incorrectly promote bfloat16 to float64\n+    return tf.cast(tfnp.log10(x), dtype)\n \n \n @sparse.elementwise_unary\n def log1p(x):\n-    return tfnp.log1p(x)\n+    x = convert_to_tensor(x)\n+    dtype = (\n+        config.floatx()\n+        if standardize_dtype(x.dtype) == \"int64\"\n+        else dtypes.result_type(x.dtype, float)\n+    )\n+    x = tf.cast(x, dtype)\n+    # TODO: tfnp.log1p incorrectly promote bfloat16 to float64\n+    return tf.cast(tfnp.log1p(x), dtype)\n \n \n @sparse.densifying_unary(-tfnp.inf)\n def log2(x):\n-    return tfnp.log2(x)\n+    x = convert_to_tensor(x)\n+    dtype = (\n+        config.floatx()\n+        if standardize_dtype(x.dtype) == \"int64\"\n+        else dtypes.result_type(x.dtype, float)\n+    )\n+    x = tf.cast(x, dtype)\n+    # TODO: tfnp.log10 incorrectly promote bfloat16 to float64\n+    return tf.cast(tfnp.log2(x), dtype)\n \n \n def logaddexp(x1, x2):\n-    return tfnp.logaddexp(x1, x2)\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n+    dtype = dtypes.result_type(x1.dtype, x2.dtype, float)\n+    x1 = tf.cast(x1, dtype)\n+    x2 = tf.cast(x2, dtype)\n+    # TODO: tfnp.logaddexp incorrectly promote bfloat16 to float64", "ext_attention_idx_tokens": [0, 71], "uid": "fa0b3b72", "question": "Is it intentional? `log` operations in some cases provide more accurate results with double precision. I am not sure though if it's the same reason here", "code": "def logaddexp x1 x2 x1 convert to tensor x1 x2 convert to tensor x2 dtype dtypes result type x1 dtype x2 dtype float x1 tf cast x1 dtype x2 tf cast x2 dtype # TODO tfnp logaddexp incorrectly promote bfloat16 to float64 return tf cast tfnp logaddexp x1 x2 dtype"}
{"message": "I'm confused -- if there's dropout the test should be non deterministic, no? So the output should change from one execution to another?", "timestamp": "2023-11-13T17:22:04Z", "file_name": "keras/layers/attention/attention_test.py", "range": {"start_line": 111, "end_line": 111, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1391440579", "html_url": "https://github.com/keras-team/keras/pull/18766#discussion_r1391440579", "attention_area": "        self.assertAllClose(output, [[[1.0, 1.0], [1.0, 1.0]]])", "file_path": "files/01/03/00000301.py", "old_file_path": "files/02/03/00000302.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -99,3 +99,14 @@ def test_attention_errors(self):\n \n         with self.assertRaisesRegex(ValueError, \"length 2 or 3\"):\n             layer([tensor, tensor], mask=[tensor])\n+\n+    def test_attention_with_dropout(self):\n+        layer = layers.Attention(dropout=0.2)\n+        query = np.array([[[1.0, 0.0], [0.0, 1.0]]])\n+        value = np.array([[[1.0, 1.0], [1.0, 1.0]]])\n+        output, scores = layer(\n+            [query, value],\n+            return_attention_scores=True,\n+        )\n+        self.assertAllClose(output, [[[1.0, 1.0], [1.0, 1.0]]])", "source": "def test_attention_with_dropout(self):\n        layer = layers.Attention(dropout=0.2)\n        query = np.array([[[1.0, 0.0], [0.0, 1.0]]])\n        value = np.array([[[1.0, 1.0], [1.0, 1.0]]])\n        output, scores = layer(\n            [query, value],\n            return_attention_scores=True,\n        )\n        self.assertAllClose(output, [[[1.0, 1.0], [1.0, 1.0]]])\n        self.assertAllClose(scores, [[[0.5, 0.5], [0.5, 0.5]]])", "source_start_line": 103, "tokens": ["def", "test_attention_with_dropout", "(", "self", ")", ":", "layer", "=", "layers", ".", "Attention", "(", "dropout", "=", "0.2", ")", "query", "=", "np", ".", "array", "(", "[", "[", "[", "1.0", ",", "0.0", "]", ",", "[", "0.0", ",", "1.0", "]", "]", "]", ")", "value", "=", "np", ".", "array", "(", "[", "[", "[", "1.0", ",", "1.0", "]", ",", "[", "1.0", ",", "1.0", "]", "]", "]", ")", "output", ",", "scores", "=", "layer", "(", "[", "query", ",", "value", "]", ",", "return_attention_scores", "=", "True", ",", ")", "self", ".", "assertAllClose", "(", "output", ",", "[", "[", "[", "1.0", ",", "1.0", "]", ",", "[", "1.0", ",", "1.0", "]", "]", "]", ")", "self", ".", "assertAllClose", "(", "scores", ",", "[", "[", "[", "0.5", ",", "0.5", "]", ",", "[", "0.5", ",", "0.5", "]", "]", "]", ")"], "to_mask": {"VAR": ["layer", "output", "query", "scores", "self", "value"], "METHOD": ["Attention", "array", "assertAllClose", "layer"]}, "attention_idx_tokens": [77, 98], "patch": "@@ -99,3 +99,14 @@\n \n         with self.assertRaisesRegex(ValueError, \"length 2 or 3\"):\n             layer([tensor, tensor], mask=[tensor])\n+\n+    def test_attention_with_dropout(self):\n+        layer = layers.Attention(dropout=0.2)\n+        query = np.array([[[1.0, 0.0], [0.0, 1.0]]])\n+        value = np.array([[[1.0, 1.0], [1.0, 1.0]]])\n+        output, scores = layer(\n+            [query, value],\n+            return_attention_scores=True,\n+        )\n+        self.assertAllClose(output, [[[1.0, 1.0], [1.0, 1.0]]])", "ext_attention_idx_tokens": [0, 76], "uid": "6b125bef", "question": "I'm confused -- if there's dropout the test should be non deterministic, no? So the output should change from one execution to another?", "code": "def test attention with dropout self layer layers Attention dropout 0 2 query np array [[[1 0 0 0] [0 0 1 0]]] value np array [[[1 0 1 0] [1 0 1 0]]] output scores layer [query value] return attention scores True self assertAllClose output [[[1 0 1 0] [1 0 1 0]]] self assertAllClose scores [[[0 5 0 5] [0 5 0 5]]]"}
{"message": "I am not convinced that this is the best solution performance wise (it could be fine, not sure). Would it be better to just divide in float and use an epsilon fuzz factor to avoid division by zero? ", "timestamp": "2023-12-10T18:30:14Z", "file_name": "keras/layers/normalization/batch_normalization.py", "range": {"start_line": 332, "end_line": 332, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1421796237", "html_url": "https://github.com/keras-team/keras/pull/18921#discussion_r1421796237", "attention_area": "    def _divide_no_nan(self, x1, x2):", "file_path": "files/41/03/00000341.py", "old_file_path": "files/42/03/00000342.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -282,3 +287,57 @@ def get_config(self):\n             \"synchronized\": self.synchronized,\n         }\n         return {**base_config, **config}\n+\n+    def _moments(self, inputs, mask):\n+        if mask is None:\n+            return ops.moments(\n+                inputs,\n+                axes=self._reduction_axes,\n+                synchronized=self.synchronized,\n+            )\n+\n+        mask_weights = ops.cast(\n+            mask,\n+            inputs.dtype,\n+        )\n+        mask_weights_broadcasted = ops.expand_dims(\n+            mask_weights,\n+            axis=-1,\n+        )\n+        weighted_inputs = mask_weights_broadcasted * inputs\n+\n+        weighted_input_sum = ops.sum(\n+            weighted_inputs,\n+            self._reduction_axes,\n+            keepdims=True,\n+        )\n+        sum_of_weights = ops.sum(\n+            mask_weights_broadcasted,\n+            self._reduction_axes,\n+            keepdims=True,\n+        )\n+        mean = self._divide_no_nan(weighted_input_sum, sum_of_weights)\n+\n+        difference = inputs - mean\n+        squared_difference = difference * difference\n+        weighted_distsq = ops.sum(\n+            mask_weights_broadcasted * squared_difference,\n+            self._reduction_axes,\n+            keepdims=True,\n+        )\n+        variance = self._divide_no_nan(weighted_distsq, sum_of_weights)\n+\n+        return ops.squeeze(mean), ops.squeeze(variance)\n+\n+    def _divide_no_nan(self, x1, x2):", "source": "def _divide_no_nan(self, x1, x2):\n        original_dtype = x1.dtype\n        x2_binary = ops.cast(x2, dtype=\"bool\")\n        x2_mask = ops.cast(x2_binary, dtype=original_dtype)\n        x1_masked = x1 * x2_mask\n\n        x2_binary_inverted = ~x2_binary\n        x2_mask_inverted = ops.cast(x2_binary_inverted, original_dtype)\n        x2_masked = x2 + x2_mask_inverted\n\n        result = x1_masked / x2_masked\n        return result", "source_start_line": 332, "tokens": ["def", "_divide_no_nan", "(", "self", ",", "x1", ",", "x2", ")", ":", "original_dtype", "=", "x1", ".", "dtype", "x2_binary", "=", "ops", ".", "cast", "(", "x2", ",", "dtype", "=", "\"bool\"", ")", "x2_mask", "=", "ops", ".", "cast", "(", "x2_binary", ",", "dtype", "=", "original_dtype", ")", "x1_masked", "=", "x1", "*", "x2_mask", "x2_binary_inverted", "=", "~", "x2_binary", "x2_mask_inverted", "=", "ops", ".", "cast", "(", "x2_binary_inverted", ",", "original_dtype", ")", "x2_masked", "=", "x2", "+", "x2_mask_inverted", "result", "=", "x1_masked", "/", "x2_masked", "return", "result"], "to_mask": {"VAR": ["original_dtype", "result", "self", "x1", "x1_masked", "x2", "x2_binary", "x2_binary_inverted", "x2_mask", "x2_mask_inverted", "x2_masked"], "METHOD": ["cast"]}, "attention_idx_tokens": [0, 9], "patch": "@@ -282,3 +287,57 @@\n             \"synchronized\": self.synchronized,\n         }\n         return {**base_config, **config}\n+\n+    def _moments(self, inputs, mask):\n+        if mask is None:\n+            return ops.moments(\n+                inputs,\n+                axes=self._reduction_axes,\n+                synchronized=self.synchronized,\n+            )\n+\n+        mask_weights = ops.cast(\n+            mask,\n+            inputs.dtype,\n+        )\n+        mask_weights_broadcasted = ops.expand_dims(\n+            mask_weights,\n+            axis=-1,\n+        )\n+        weighted_inputs = mask_weights_broadcasted * inputs\n+\n+        weighted_input_sum = ops.sum(\n+            weighted_inputs,\n+            self._reduction_axes,\n+            keepdims=True,\n+        )\n+        sum_of_weights = ops.sum(\n+            mask_weights_broadcasted,\n+            self._reduction_axes,\n+            keepdims=True,\n+        )\n+        mean = self._divide_no_nan(weighted_input_sum, sum_of_weights)\n+\n+        difference = inputs - mean\n+        squared_difference = difference * difference\n+        weighted_distsq = ops.sum(\n+            mask_weights_broadcasted * squared_difference,\n+            self._reduction_axes,\n+            keepdims=True,\n+        )\n+        variance = self._divide_no_nan(weighted_distsq, sum_of_weights)\n+\n+        return ops.squeeze(mean), ops.squeeze(variance)\n+\n+    def _divide_no_nan(self, x1, x2):", "ext_attention_idx_tokens": [0, 62], "uid": "50f8f7be", "question": "I am not convinced that this is the best solution performance wise (it could be fine, not sure). Would it be better to just divide in float and use an epsilon fuzz factor to avoid division by zero? ", "code": "def divide no nan self x1 x2 original dtype x1 dtype x2 binary ops cast x2 dtype \"bool\" x2 mask ops cast x2 binary dtype original dtype x1 masked x1 * x2 mask x2 binary inverted ~x2 binary x2 mask inverted ops cast x2 binary inverted original dtype x2 masked x2 + x2 mask inverted result x1 masked x2 masked return result"}
{"message": "Any specific reason for having more than 6-7 decimal points?", "timestamp": "2023-12-14T17:22:17Z", "file_name": "keras/backend/jax/random.py", "range": {"start_line": 87, "end_line": 87, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1427018590", "html_url": "https://github.com/keras-team/keras/pull/18940#discussion_r1427018590", "attention_area": "    alpha = 1.6732632423543772848170429916717", "file_path": "files/62/03/00000362.py", "old_file_path": "files/63/03/00000363.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -81,6 +82,24 @@ def dropout(inputs, rate, noise_shape=None, seed=None):\n     )\n \n \n+def alpha_dropout(inputs, rate, noise_shape=None, seed=None):\n+    noise_shape = _get_concrete_noise_shape(inputs, noise_shape)\n+    alpha = 1.6732632423543772848170429916717", "source": "def alpha_dropout(inputs, rate, noise_shape=None, seed=None):\n    noise_shape = _get_concrete_noise_shape(inputs, noise_shape)\n    alpha = 1.6732632423543772848170429916717\n    scale = 1.0507009873554804934193349852946\n    alpha_p = -alpha * scale\n\n    kept_idx = jax.numpy.greater_equal(uniform(noise_shape, seed=seed), rate)\n    kept_idx = cast(kept_idx, inputs.dtype)\n\n    # Compute affine transformation parameters\n    a = ((1 - rate) * (1 + rate * alpha_p**2)) ** -0.5\n    b = -a * alpha_p * rate\n\n    # Apply mask\n    x = inputs * kept_idx + alpha_p * (1 - kept_idx)\n    return a * x + b", "source_start_line": 85, "tokens": ["def", "alpha_dropout", "(", "inputs", ",", "rate", ",", "noise_shape", "=", "None", ",", "seed", "=", "None", ")", ":", "noise_shape", "=", "_get_concrete_noise_shape", "(", "inputs", ",", "noise_shape", ")", "alpha", "=", "1.6732632423543772848170429916717", "scale", "=", "1.0507009873554804934193349852946", "alpha_p", "=", "-", "alpha", "*", "scale", "kept_idx", "=", "jax", ".", "numpy", ".", "greater_equal", "(", "uniform", "(", "noise_shape", ",", "seed", "=", "seed", ")", ",", "rate", ")", "kept_idx", "=", "cast", "(", "kept_idx", ",", "inputs", ".", "dtype", ")", "a", "=", "(", "(", "1", "-", "rate", ")", "*", "(", "1", "+", "rate", "*", "alpha_p", "**", "2", ")", ")", "**", "-", "0.5", "b", "=", "-", "a", "*", "alpha_p", "*", "rate", "x", "=", "inputs", "*", "kept_idx", "+", "alpha_p", "*", "(", "1", "-", "kept_idx", ")", "return", "a", "*", "x", "+", "b"], "to_mask": {"VAR": ["a", "alpha", "alpha_p", "b", "inputs", "kept_idx", "noise_shape", "rate", "scale", "seed", "x"], "METHOD": ["_get_concrete_noise_shape", "cast", "greater_equal", "uniform"]}, "attention_idx_tokens": [24, 26], "patch": "@@ -81,6 +82,24 @@\n     )\n \n \n+def alpha_dropout(inputs, rate, noise_shape=None, seed=None):\n+    noise_shape = _get_concrete_noise_shape(inputs, noise_shape)\n+    alpha = 1.6732632423543772848170429916717", "ext_attention_idx_tokens": [0, 113], "uid": "dc8cc887", "question": "Any specific reason for having more than 6-7 decimal points?", "code": "def alpha dropout inputs rate noise shape None seed None noise shape get concrete noise shape inputs noise shape alpha 1 6732632423543772848170429916717 scale 1 0507009873554804934193349852946 alpha p -alpha * scale kept idx jax numpy greater equal uniform noise shape seed seed rate kept idx cast kept idx inputs dtype # Compute affine transformation parameters a 1 - rate * 1 + rate * alpha p**2 ** -0 5 b -a * alpha p * rate # Apply mask x inputs * kept idx + alpha p * 1 - kept idx return a * x + b"}
{"message": "Just curious, does the existing jax optimizer support ema? or its from the base_optimizer?", "timestamp": "2023-12-18T18:30:33Z", "file_name": "keras/backend/jax/optimizer.py", "range": {"start_line": 77, "end_line": 77, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1430514463", "html_url": "https://github.com/keras-team/keras/pull/18951#discussion_r1430514463", "attention_area": "        if self.use_ema:", "file_path": "files/80/03/00000380.py", "old_file_path": null, "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": true}, "language": "python", "replies": {}, "diff_hunk": "@@ -0,0 +1,103 @@\n+import jax\n+from jax import numpy as jnp\n+\n+from keras.optimizers import base_optimizer\n+\n+\n+class JaxOptimizer(base_optimizer.BaseOptimizer):\n+    \"\"\"A class for JAX specific optimizer logic.\n+\n+    Its purpose is to route around statelessness\n+    requirements in cond ops used for EMA handling\n+    and gradient accumulation handling. We do this\n+    by skipping conditionals entirely.\n+    \"\"\"\n+\n+    def _backend_apply_gradients(self, grads, trainable_variables):\n+        if self.gradient_accumulation_steps:\n+            is_update_step = (\n+                self.iterations + 1\n+            ) % self.gradient_accumulation_steps == 0\n+            steps = self.gradient_accumulation_steps\n+\n+            current_trainable_vars_value = [\n+                v.value for v in trainable_variables\n+            ]\n+            current_optimizer_vars_value = [v.value for v in self.variables]\n+\n+            new_g_accs = jax.lax.cond(\n+                is_update_step,\n+                lambda: [\n+                    jnp.zeros(x.shape, dtype=x.dtype)\n+                    for x in self._accumulated_gradients\n+                ],\n+                lambda: [\n+                    grads[i] + self._accumulated_gradients[i]\n+                    for i in range(len(grads))\n+                ],\n+            )\n+\n+            grads = jax.lax.cond(\n+                is_update_step,\n+                lambda: [\n+                    (grads[i] + self._accumulated_gradients[i]) / steps\n+                    for i in range(len(grads))\n+                ],\n+                lambda: list(grads),\n+            )\n+\n+            self._backend_update_step(\n+                grads, trainable_variables, self.learning_rate\n+            )\n+            new_trainable_vars = jax.lax.cond(\n+                is_update_step,\n+                lambda: [v.value for v in trainable_variables],\n+                lambda: current_trainable_vars_value,\n+            )\n+            new_opt_vars = jax.lax.cond(\n+                is_update_step,\n+                lambda: [v.value for v in self.variables],\n+                lambda: current_optimizer_vars_value,\n+            )\n+\n+            for value, v in zip(new_trainable_vars, trainable_variables):\n+                v.assign(value)\n+\n+            for value, v in zip(new_opt_vars, self.variables):\n+                v.assign(value)\n+\n+            for n_g_acc, g_acc in zip(new_g_accs, self._accumulated_gradients):\n+                g_acc.assign(n_g_acc)\n+\n+        else:\n+            self._backend_update_step(\n+                grads, trainable_variables, self.learning_rate\n+            )\n+\n+        if self.use_ema:", "source": "def _backend_apply_gradients(self, grads, trainable_variables):\n        if self.gradient_accumulation_steps:\n            is_update_step = (\n                self.iterations + 1\n            ) % self.gradient_accumulation_steps == 0\n            steps = self.gradient_accumulation_steps\n\n            current_trainable_vars_value = [\n                v.value for v in trainable_variables\n            ]\n            current_optimizer_vars_value = [v.value for v in self.variables]\n\n            new_g_accs = jax.lax.cond(\n                is_update_step,\n                lambda: [\n                    jnp.zeros(x.shape, dtype=x.dtype)\n                    for x in self._accumulated_gradients\n                ],\n                lambda: [\n                    grads[i] + self._accumulated_gradients[i]\n                    for i in range(len(grads))\n                ],\n            )\n\n            grads = jax.lax.cond(\n                is_update_step,\n                lambda: [\n                    (grads[i] + self._accumulated_gradients[i]) / steps\n                    for i in range(len(grads))\n                ],\n                lambda: list(grads),\n            )\n\n            self._backend_update_step(\n                grads, trainable_variables, self.learning_rate\n            )\n            new_trainable_vars = jax.lax.cond(\n                is_update_step,\n                lambda: [v.value for v in trainable_variables],\n                lambda: current_trainable_vars_value,\n            )\n            new_opt_vars = jax.lax.cond(\n                is_update_step,\n                lambda: [v.value for v in self.variables],\n                lambda: current_optimizer_vars_value,\n            )\n\n            for value, v in zip(new_trainable_vars, trainable_variables):\n                v.assign(value)\n\n            for value, v in zip(new_opt_vars, self.variables):\n                v.assign(value)\n\n            for n_g_acc, g_acc in zip(new_g_accs, self._accumulated_gradients):\n                g_acc.assign(n_g_acc)\n\n        else:\n            self._backend_update_step(\n                grads, trainable_variables, self.learning_rate\n            )\n\n        if self.use_ema:\n            self._update_model_variables_moving_average(\n                self._trainable_variables\n            )\n            if self.ema_overwrite_frequency is not None:\n                should_overwrite_model_vars = (\n                    self.iterations + 1\n                ) % self.ema_overwrite_frequency == 0\n                should_overwrite_model_vars_int = (\n                    should_overwrite_model_vars.astype(\"int32\")\n                )\n                should_not_overwrite_model_vars_int = jnp.logical_not(\n                    should_overwrite_model_vars\n                ).astype(\"int32\")\n                current_trainable_vars_value = [\n                    v.value for v in self._trainable_variables\n                ]\n                for var, average_var in zip(\n                    self._trainable_variables,\n                    self._model_variables_moving_average,\n                ):\n                    var.assign(\n                        average_var * should_overwrite_model_vars_int\n                        + var.value * should_not_overwrite_model_vars_int\n                    )\n\n        self.iterations.assign_add(1)", "source_start_line": 16, "tokens": ["def", "_backend_apply_gradients", "(", "self", ",", "grads", ",", "trainable_variables", ")", ":", "if", "self", ".", "gradient_accumulation_steps", ":", "is_update_step", "=", "(", "self", ".", "iterations", "+", "1", ")", "%", "self", ".", "gradient_accumulation_steps", "==", "0", "steps", "=", "self", ".", "gradient_accumulation_steps", "current_trainable_vars_value", "=", "[", "v", ".", "value", "for", "v", "in", "trainable_variables", "]", "current_optimizer_vars_value", "=", "[", "v", ".", "value", "for", "v", "in", "self", ".", "variables", "]", "new_g_accs", "=", "jax", ".", "lax", ".", "cond", "(", "is_update_step", ",", "lambda", ":", "[", "jnp", ".", "zeros", "(", "x", ".", "shape", ",", "dtype", "=", "x", ".", "dtype", ")", "for", "x", "in", "self", ".", "_accumulated_gradients", "]", ",", "lambda", ":", "[", "grads", "[", "i", "]", "+", "self", ".", "_accumulated_gradients", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "grads", ")", ")", "]", ",", ")", "grads", "=", "jax", ".", "lax", ".", "cond", "(", "is_update_step", ",", "lambda", ":", "[", "(", "grads", "[", "i", "]", "+", "self", ".", "_accumulated_gradients", "[", "i", "]", ")", "/", "steps", "for", "i", "in", "range", "(", "len", "(", "grads", ")", ")", "]", ",", "lambda", ":", "list", "(", "grads", ")", ",", ")", "self", ".", "_backend_update_step", "(", "grads", ",", "trainable_variables", ",", "self", ".", "learning_rate", ")", "new_trainable_vars", "=", "jax", ".", "lax", ".", "cond", "(", "is_update_step", ",", "lambda", ":", "[", "v", ".", "value", "for", "v", "in", "trainable_variables", "]", ",", "lambda", ":", "current_trainable_vars_value", ",", ")", "new_opt_vars", "=", "jax", ".", "lax", ".", "cond", "(", "is_update_step", ",", "lambda", ":", "[", "v", ".", "value", "for", "v", "in", "self", ".", "variables", "]", ",", "lambda", ":", "current_optimizer_vars_value", ",", ")", "for", "value", ",", "v", "in", "zip", "(", "new_trainable_vars", ",", "trainable_variables", ")", ":", "v", ".", "assign", "(", "value", ")", "for", "value", ",", "v", "in", "zip", "(", "new_opt_vars", ",", "self", ".", "variables", ")", ":", "v", ".", "assign", "(", "value", ")", "for", "n_g_acc", ",", "g_acc", "in", "zip", "(", "new_g_accs", ",", "self", ".", "_accumulated_gradients", ")", ":", "g_acc", ".", "assign", "(", "n_g_acc", ")", "else", ":", "self", ".", "_backend_update_step", "(", "grads", ",", "trainable_variables", ",", "self", ".", "learning_rate", ")", "if", "self", ".", "use_ema", ":", "self", ".", "_update_model_variables_moving_average", "(", "self", ".", "_trainable_variables", ")", "if", "self", ".", "ema_overwrite_frequency", "is", "not", "None", ":", "should_overwrite_model_vars", "=", "(", "self", ".", "iterations", "+", "1", ")", "%", "self", ".", "ema_overwrite_frequency", "==", "0", "should_overwrite_model_vars_int", "=", "(", "should_overwrite_model_vars", ".", "astype", "(", "\"int32\"", ")", ")", "should_not_overwrite_model_vars_int", "=", "jnp", ".", "logical_not", "(", "should_overwrite_model_vars", ")", ".", "astype", "(", "\"int32\"", ")", "current_trainable_vars_value", "=", "[", "v", ".", "value", "for", "v", "in", "self", ".", "_trainable_variables", "]", "for", "var", ",", "average_var", "in", "zip", "(", "self", ".", "_trainable_variables", ",", "self", ".", "_model_variables_moving_average", ",", ")", ":", "var", ".", "assign", "(", "average_var", "*", "should_overwrite_model_vars_int", "+", "var", ".", "value", "*", "should_not_overwrite_model_vars_int", ")", "self", ".", "iterations", ".", "assign_add", "(", "1", ")"], "to_mask": {"VAR": ["average_var", "current_optimizer_vars_value", "current_trainable_vars_value", "g_acc", "grads", "is_update_step", "n_g_acc", "new_g_accs", "new_opt_vars", "new_trainable_vars", "self", "should_not_overwrite_model_vars_int", "should_overwrite_model_vars", "should_overwrite_model_vars_int", "steps", "trainable_variables", "v", "value", "var"], "METHOD": ["_backend_update_step", "_update_model_variables_moving_average", "assign", "assign_add", "astype", "cond", "len", "list", "logical_not", "range", "zeros", "zip"]}, "attention_idx_tokens": [309, 313], "patch": "@@ -0,0 +1,103 @@\n+import jax\n+from jax import numpy as jnp\n+\n+from keras.optimizers import base_optimizer\n+\n+\n+class JaxOptimizer(base_optimizer.BaseOptimizer):\n+    \"\"\"A class for JAX specific optimizer logic.\n+\n+    Its purpose is to route around statelessness\n+    requirements in cond ops used for EMA handling\n+    and gradient accumulation handling. We do this\n+    by skipping conditionals entirely.\n+    \"\"\"\n+\n+    def _backend_apply_gradients(self, grads, trainable_variables):\n+        if self.gradient_accumulation_steps:\n+            is_update_step = (\n+                self.iterations + 1\n+            ) % self.gradient_accumulation_steps == 0\n+            steps = self.gradient_accumulation_steps\n+\n+            current_trainable_vars_value = [\n+                v.value for v in trainable_variables\n+            ]\n+            current_optimizer_vars_value = [v.value for v in self.variables]\n+\n+            new_g_accs = jax.lax.cond(\n+                is_update_step,\n+                lambda: [\n+                    jnp.zeros(x.shape, dtype=x.dtype)\n+                    for x in self._accumulated_gradients\n+                ],\n+                lambda: [\n+                    grads[i] + self._accumulated_gradients[i]\n+                    for i in range(len(grads))\n+                ],\n+            )\n+\n+            grads = jax.lax.cond(\n+                is_update_step,\n+                lambda: [\n+                    (grads[i] + self._accumulated_gradients[i]) / steps\n+                    for i in range(len(grads))\n+                ],\n+                lambda: list(grads),\n+            )\n+\n+            self._backend_update_step(\n+                grads, trainable_variables, self.learning_rate\n+            )\n+            new_trainable_vars = jax.lax.cond(\n+                is_update_step,\n+                lambda: [v.value for v in trainable_variables],\n+                lambda: current_trainable_vars_value,\n+            )\n+            new_opt_vars = jax.lax.cond(\n+                is_update_step,\n+                lambda: [v.value for v in self.variables],\n+                lambda: current_optimizer_vars_value,\n+            )\n+\n+            for value, v in zip(new_trainable_vars, trainable_variables):\n+                v.assign(value)\n+\n+            for value, v in zip(new_opt_vars, self.variables):\n+                v.assign(value)\n+\n+            for n_g_acc, g_acc in zip(new_g_accs, self._accumulated_gradients):\n+                g_acc.assign(n_g_acc)\n+\n+        else:\n+            self._backend_update_step(\n+                grads, trainable_variables, self.learning_rate\n+            )\n+\n+        if self.use_ema:", "ext_attention_idx_tokens": [0, 411], "uid": "757a7e9a", "question": "Just curious, does the existing jax optimizer support ema? or its from the base_optimizer?", "code": "def backend apply gradients self grads trainable variables if self gradient accumulation steps is update step self iterations + 1 % self gradient accumulation steps 0 steps self gradient accumulation steps current trainable vars value [ v value for v in trainable variables ] current optimizer vars value [v value for v in self variables] new g accs jax lax cond is update step lambda [ jnp zeros x shape dtype x dtype for x in self accumulated gradients ] lambda [ grads[i] + self accumulated gradients[i] for i in range len grads ] grads jax lax cond is update step lambda [ grads[i] + self accumulated gradients[i] steps for i in range len grads ] lambda list grads self backend update step grads trainable variables self learning rate new trainable vars jax lax cond is update step lambda [v value for v in trainable variables] lambda current trainable vars value new opt vars jax lax cond is update step lambda [v value for v in self variables] lambda current optimizer vars value for value v in zip new trainable vars trainable variables v assign value for value v in zip new opt vars self variables v assign value for n g acc g acc in zip new g accs self accumulated gradients g acc assign n g acc else self backend update step grads trainable variables self learning rate if self use ema self update model variables moving average self trainable variables if self ema overwrite frequency is not None should overwrite model vars self iterations + 1 % self ema overwrite frequency 0 should overwrite model vars int should overwrite model vars astype \"int32\" should not overwrite model vars int jnp logical not should overwrite model vars astype \"int32\" current trainable vars value [ v value for v in self trainable variables ] for var average var in zip self trainable variables self model variables moving average var assign average var * should overwrite model vars int + var value * should not overwrite model vars int self iterations assign add 1"}
{"message": "So previously the test worked because the zip was zipping lists of different lengths?", "timestamp": "2023-12-18T19:17:28Z", "file_name": "keras/layers/layer_test.py", "range": {"start_line": 637, "end_line": 637, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1430555531", "html_url": "https://github.com/keras-team/keras/pull/18960#discussion_r1430555531", "attention_area": "        for ref_loss, loss in zip(layer1.losses, losses):", "file_path": "files/85/03/00000385.py", "old_file_path": "files/86/03/00000386.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -632,6 +633,7 @@ def call(self, x):\n             layer1.non_trainable_variables, non_trainable_variables\n         ):\n             self.assertAllClose(ref_v, v)\n+        self.assertLen(losses, 2)\n         for ref_loss, loss in zip(layer1.losses, losses):", "source": "def test_stateless_call(self):\n        class TestLayer(layers.Layer):\n            def __init__(self):\n                super().__init__()\n                self._seed_generator = backend.random.SeedGenerator(1337)\n                self.ntw = self.add_weight(\n                    shape=(),\n                    initializer=\"zeros\",\n                    trainable=False,\n                )\n                self.tw = self.add_weight(\n                    shape=(),\n                    initializer=\"zeros\",\n                    trainable=True,\n                    regularizer=\"l1\",\n                )\n                self.built = True\n\n            def call(self, x):\n                x = backend.convert_to_tensor(x, dtype=\"float32\")\n                self.add_loss(ops.sum(x))\n                self.ntw.assign(ops.sum(x))\n                x = x + backend.random.normal(\n                    shape=(), seed=self._seed_generator\n                )\n                return x + self.tw + self.ntw\n\n        data = np.random.random((3, 4))\n        layer = TestLayer()\n        out = layer(data)\n        layer1 = TestLayer()\n        out1 = layer1(data)\n        # Check that the layer is in fact deterministic\n        self.assertAllClose(out, out1)\n\n        # Test stateless_call correctness\n        layer2 = TestLayer()\n        trainable_variables = layer2.trainable_variables\n        non_trainable_variables = layer2.non_trainable_variables\n        out2, non_trainable_variables = layer2.stateless_call(\n            trainable_variables, non_trainable_variables, data\n        )\n        self.assertAllClose(out1, out2)\n        self.assertEqual(\n            len(layer1.non_trainable_variables), len(non_trainable_variables)\n        )\n        for ref_v, v in zip(\n            layer1.non_trainable_variables, non_trainable_variables\n        ):\n            self.assertAllClose(ref_v, v)\n\n        # Test with loss collection\n        layer3 = TestLayer()\n        trainable_variables = layer3.trainable_variables\n        non_trainable_variables = layer3.non_trainable_variables\n        out3, non_trainable_variables, losses = layer3.stateless_call(\n            trainable_variables,\n            non_trainable_variables,\n            data,\n            return_losses=True,\n        )\n        self.assertAllClose(out1, out3)\n        for ref_v, v in zip(\n            layer1.non_trainable_variables, non_trainable_variables\n        ):\n            self.assertAllClose(ref_v, v)\n        self.assertLen(losses, 2)\n        for ref_loss, loss in zip(layer1.losses, losses):\n            self.assertAllClose(ref_loss, loss)", "source_start_line": 570, "tokens": ["def", "test_stateless_call", "(", "self", ")", ":", "class", "TestLayer", "(", "layers", ".", "Layer", ")", ":", "def", "__init__", "(", "self", ")", ":", "super", "(", ")", ".", "__init__", "(", ")", "self", ".", "_seed_generator", "=", "backend", ".", "random", ".", "SeedGenerator", "(", "1337", ")", "self", ".", "ntw", "=", "self", ".", "add_weight", "(", "shape", "=", "(", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "False", ",", ")", "self", ".", "tw", "=", "self", ".", "add_weight", "(", "shape", "=", "(", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "True", ",", "regularizer", "=", "\"l1\"", ",", ")", "self", ".", "built", "=", "True", "def", "call", "(", "self", ",", "x", ")", ":", "x", "=", "backend", ".", "convert_to_tensor", "(", "x", ",", "dtype", "=", "\"float32\"", ")", "self", ".", "add_loss", "(", "ops", ".", "sum", "(", "x", ")", ")", "self", ".", "ntw", ".", "assign", "(", "ops", ".", "sum", "(", "x", ")", ")", "x", "=", "x", "+", "backend", ".", "random", ".", "normal", "(", "shape", "=", "(", ")", ",", "seed", "=", "self", ".", "_seed_generator", ")", "return", "x", "+", "self", ".", "tw", "+", "self", ".", "ntw", "data", "=", "np", ".", "random", ".", "random", "(", "(", "3", ",", "4", ")", ")", "layer", "=", "TestLayer", "(", ")", "out", "=", "layer", "(", "data", ")", "layer1", "=", "TestLayer", "(", ")", "out1", "=", "layer1", "(", "data", ")", "self", ".", "assertAllClose", "(", "out", ",", "out1", ")", "layer2", "=", "TestLayer", "(", ")", "trainable_variables", "=", "layer2", ".", "trainable_variables", "non_trainable_variables", "=", "layer2", ".", "non_trainable_variables", "out2", ",", "non_trainable_variables", "=", "layer2", ".", "stateless_call", "(", "trainable_variables", ",", "non_trainable_variables", ",", "data", ")", "self", ".", "assertAllClose", "(", "out1", ",", "out2", ")", "self", ".", "assertEqual", "(", "len", "(", "layer1", ".", "non_trainable_variables", ")", ",", "len", "(", "non_trainable_variables", ")", ")", "for", "ref_v", ",", "v", "in", "zip", "(", "layer1", ".", "non_trainable_variables", ",", "non_trainable_variables", ")", ":", "self", ".", "assertAllClose", "(", "ref_v", ",", "v", ")", "layer3", "=", "TestLayer", "(", ")", "trainable_variables", "=", "layer3", ".", "trainable_variables", "non_trainable_variables", "=", "layer3", ".", "non_trainable_variables", "out3", ",", "non_trainable_variables", ",", "losses", "=", "layer3", ".", "stateless_call", "(", "trainable_variables", ",", "non_trainable_variables", ",", "data", ",", "return_losses", "=", "True", ",", ")", "self", ".", "assertAllClose", "(", "out1", ",", "out3", ")", "for", "ref_v", ",", "v", "in", "zip", "(", "layer1", ".", "non_trainable_variables", ",", "non_trainable_variables", ")", ":", "self", ".", "assertAllClose", "(", "ref_v", ",", "v", ")", "self", ".", "assertLen", "(", "losses", ",", "2", ")", "for", "ref_loss", ",", "loss", "in", "zip", "(", "layer1", ".", "losses", ",", "losses", ")", ":", "self", ".", "assertAllClose", "(", "ref_loss", ",", "loss", ")"], "to_mask": {"VAR": ["_seed_generator", "built", "data", "layer", "layer1", "layer2", "layer3", "loss", "losses", "non_trainable_variables", "ntw", "out", "out1", "out2", "out3", "ref_loss", "ref_v", "self", "trainable_variables", "tw", "v", "x"], "METHOD": ["SeedGenerator", "TestLayer", "__init__", "add_loss", "add_weight", "assertAllClose", "assertEqual", "assertLen", "assign", "convert_to_tensor", "layer", "layer1", "len", "normal", "random", "stateless_call", "sum", "super", "zip"]}, "attention_idx_tokens": [360, 373], "patch": "@@ -632,6 +633,7 @@\n             layer1.non_trainable_variables, non_trainable_variables\n         ):\n             self.assertAllClose(ref_v, v)\n+        self.assertLen(losses, 2)\n         for ref_loss, loss in zip(layer1.losses, losses):", "ext_attention_idx_tokens": [352, 373], "uid": "ec51747f", "question": "So previously the test worked because the zip was zipping lists of different lengths?", "code": "def test stateless call self class TestLayer layers Layer def init self super init self seed generator backend random SeedGenerator 1337 self ntw self add weight shape initializer \"zeros\" trainable False self tw self add weight shape initializer \"zeros\" trainable True regularizer \"l1\" self built True def call self x x backend convert to tensor x dtype \"float32\" self add loss ops sum x self ntw assign ops sum x x x + backend random normal shape seed self seed generator return x + self tw + self ntw data np random random 3 4 layer TestLayer out layer data layer1 TestLayer out1 layer1 data # Check that the layer is in fact deterministic self assertAllClose out out1 # Test stateless call correctness layer2 TestLayer trainable variables layer2 trainable variables non trainable variables layer2 non trainable variables out2 non trainable variables layer2 stateless call trainable variables non trainable variables data self assertAllClose out1 out2 self assertEqual len layer1 non trainable variables len non trainable variables for ref v v in zip layer1 non trainable variables non trainable variables self assertAllClose ref v v # Test with loss collection layer3 TestLayer trainable variables layer3 trainable variables non trainable variables layer3 non trainable variables out3 non trainable variables losses layer3 stateless call trainable variables non trainable variables data return losses True self assertAllClose out1 out3 for ref v v in zip layer1 non trainable variables non trainable variables self assertAllClose ref v v self assertLen losses 2 for ref loss loss in zip layer1 losses losses self assertAllClose ref loss loss"}
{"message": "This sounds like a more user-friendly strategy.\r\n\r\nI have some questions about it:\r\n1. Is it acceptable to introduce some level of overhead/complexity to fine-tune `n`?\r\n2. `n` is only configurable at each epoch, and the statistics of one-epoch time might vary with different metrics and callbacks, etc. Is it fine to use one-epoch time to optimize `n`?\r\n3. There is a drawback to setting a large `n`: it will consume a lot of memory on the target device.\r\n\r\nReferences:\r\n- ResNet50 example from Flax uses `2`: https://github.com/google/flax/blob/85dfad242e56098849dbf05e7e4657b3a40820f9/examples/imagenet/train.py#L214\r\n- `torchtnt.utils.data.CudaDataPrefetcher` defaults to `2`: https://pytorch.org/tnt/stable/utils/generated/torchtnt.utils.data.CudaDataPrefetcher.html", "timestamp": "2023-12-26T01:54:27Z", "file_name": "keras/backend/jax/trainer.py", "range": {"start_line": 933, "end_line": 933, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1436190491", "html_url": "https://github.com/keras-team/keras/pull/18991#discussion_r1436190491", "attention_area": "        enqueue(n=2)  # TODO: should we make `n` configurable?", "file_path": "files/01/04/00000401.py", "old_file_path": "files/02/04/00000402.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -901,3 +888,49 @@ def _purge_model_variables(\n         if metric_variables:\n             for v in self.metrics_variables:\n                 v._value = None\n+\n+\n+def _distribute_data(data):\n+    distribution = distribution_lib.distribution()\n+    if distribution is not None:\n+\n+        def distribute_single_value(d):\n+            layout = distribution.get_data_layout(d.shape)\n+            return jax_distribution_lib.distribute_data_input(d, layout)\n+\n+        return jax.tree_util.tree_map(distribute_single_value, data)\n+    else:\n+        return jax.tree_util.tree_map(jax.device_put, data)\n+\n+\n+class JAXEpochIterator(EpochIterator):\n+    def _get_iterator(self, return_type=\"np\"):\n+        if return_type == \"np\":\n+            return self._prefetch_to_device(super()._get_iterator(return_type))\n+        else:\n+            return super()._get_iterator(return_type)\n+\n+    def _prefetch_to_device(self, numpy_iterator):\n+        \"\"\"Shard and prefetch batches on device.\n+\n+        Most of the implementation has been borrowed from\n+        `flax.jax_utils.prefetch_to_device`\n+\n+        This utility takes an iterator and returns a new iterator which fills an\n+        on device prefetch buffer. Eager prefetching can improve the performance\n+        of training loops significantly by overlapping compute and data\n+        transfer.\n+        \"\"\"\n+        queue = collections.deque()\n+\n+        # If you're training on GPUs, 2 is generally the best choice because\n+        # this guarantees that you can overlap a training step on GPU with a\n+        # data prefetch step on CPU.\n+        def enqueue(n=2):\n+            for data in itertools.islice(numpy_iterator, n):\n+                queue.append(_distribute_data(data))\n+\n+        enqueue(n=2)  # TODO: should we make `n` configurable?", "source": "def _prefetch_to_device(self, numpy_iterator):\n        \"\"\"Shard and prefetch batches on device.\n\n        Most of the implementation has been borrowed from\n        `flax.jax_utils.prefetch_to_device`\n\n        This utility takes an iterator and returns a new iterator which fills an\n        on device prefetch buffer. Eager prefetching can improve the performance\n        of training loops significantly by overlapping compute and data\n        transfer.\n        \"\"\"\n        queue = collections.deque()\n\n        # If you're training on GPUs, 2 is generally the best choice because\n        # this guarantees that you can overlap a training step on GPU with a\n        # data prefetch step on CPU.\n        def enqueue(n=2):\n            for data in itertools.islice(numpy_iterator, n):\n                queue.append(_distribute_data(data))\n\n        enqueue(n=2)  # TODO: should we make `n` configurable?\n        while queue:\n            yield queue.popleft()\n            enqueue(1)", "source_start_line": 913, "tokens": ["def", "_prefetch_to_device", "(", "self", ",", "numpy_iterator", ")", ":", "\"\"\"Shard and prefetch batches on device.        Most of the implementation has been borrowed from        `flax.jax_utils.prefetch_to_device`        This utility takes an iterator and returns a new iterator which fills an        on device prefetch buffer. Eager prefetching can improve the performance        of training loops significantly by overlapping compute and data        transfer.        \"\"\"", "queue", "=", "collections", ".", "deque", "(", ")", "def", "enqueue", "(", "n", "=", "2", ")", ":", "for", "data", "in", "itertools", ".", "islice", "(", "numpy_iterator", ",", "n", ")", ":", "queue", ".", "append", "(", "_distribute_data", "(", "data", ")", ")", "enqueue", "(", "n", "=", "2", ")", "while", "queue", ":", "yield", "queue", ".", "popleft", "(", ")", "enqueue", "(", "1", ")"], "to_mask": {"VAR": ["data", "n", "numpy_iterator", "queue", "self"], "METHOD": ["_distribute_data", "append", "deque", "enqueue", "islice", "popleft"]}, "attention_idx_tokens": [45, 50], "patch": "@@ -901,3 +888,49 @@\n         if metric_variables:\n             for v in self.metrics_variables:\n                 v._value = None\n+\n+\n+def _distribute_data(data):\n+    distribution = distribution_lib.distribution()\n+    if distribution is not None:\n+\n+        def distribute_single_value(d):\n+            layout = distribution.get_data_layout(d.shape)\n+            return jax_distribution_lib.distribute_data_input(d, layout)\n+\n+        return jax.tree_util.tree_map(distribute_single_value, data)\n+    else:\n+        return jax.tree_util.tree_map(jax.device_put, data)\n+\n+\n+class JAXEpochIterator(EpochIterator):\n+    def _get_iterator(self, return_type=\"np\"):\n+        if return_type == \"np\":\n+            return self._prefetch_to_device(super()._get_iterator(return_type))\n+        else:\n+            return super()._get_iterator(return_type)\n+\n+    def _prefetch_to_device(self, numpy_iterator):\n+        \"\"\"Shard and prefetch batches on device.\n+\n+        Most of the implementation has been borrowed from\n+        `flax.jax_utils.prefetch_to_device`\n+\n+        This utility takes an iterator and returns a new iterator which fills an\n+        on device prefetch buffer. Eager prefetching can improve the performance\n+        of training loops significantly by overlapping compute and data\n+        transfer.\n+        \"\"\"\n+        queue = collections.deque()\n+\n+        # If you're training on GPUs, 2 is generally the best choice because\n+        # this guarantees that you can overlap a training step on GPU with a\n+        # data prefetch step on CPU.\n+        def enqueue(n=2):\n+            for data in itertools.islice(numpy_iterator, n):\n+                queue.append(_distribute_data(data))\n+\n+        enqueue(n=2)  # TODO: should we make `n` configurable?", "ext_attention_idx_tokens": [0, 53], "uid": "0914763a", "question": "This sounds like a more user-friendly strategy.    I have some questions about it:  1. Is it acceptable to introduce some level of overhead/complexity to fine-tune `n`?  2. `n` is only configurable at each epoch, and the statistics of one-epoch time might vary with different metrics and callbacks, etc. Is it fine to use one-epoch time to optimize `n`?  3. There is a drawback to setting a large `n`: it will consume a lot of memory on the target device.    References:  - ResNet50 example from Flax uses `2`: https://github.com/google/flax/blob/85dfad242e56098849dbf05e7e4657b3a40820f9/examples/imagenet/train.py#L214  - `torchtnt.utils.data.CudaDataPrefetcher` defaults to `2`: https://pytorch.org/tnt/stable/utils/generated/torchtnt.utils.data.CudaDataPrefetcher.html", "code": "def prefetch to device self numpy iterator \"\"\"Shard and prefetch batches on device Most of the implementation has been borrowed from `flax jax utils prefetch to device` This utility takes an iterator and returns a new iterator which fills an on device prefetch buffer Eager prefetching can improve the performance of training loops significantly by overlapping compute and data transfer \"\"\" queue collections deque # If you re training on GPUs 2 is generally the best choice because # this guarantees that you can overlap a training step on GPU with a # data prefetch step on CPU def enqueue n 2 for data in itertools islice numpy iterator n queue append distribute data data enqueue n 2 # TODO should we make `n` configurable? while queue yield queue popleft enqueue 1"}
{"message": "This worked before didn't it?  It was when the rcParam was set that the problem was?  Or was the layout still getting set to None, and then falling back to the rcParam?  \r\n\r\nOtherwise if this works, I'm all for it!  I do wish all the context switching were simpler to debug, but...", "timestamp": "2023-01-13T16:26:39Z", "file_name": "lib/matplotlib/tests/test_figure.py", "range": {"start_line": 535, "end_line": 535, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1069661325", "html_url": "https://github.com/matplotlib/matplotlib/pull/24971#discussion_r1069661325", "attention_area": "def test_savefig_preserve_layout_engine(tmp_path):", "file_path": "files/73/00/00000073.py", "old_file_path": "files/74/00/00000074.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -532,6 +532,13 @@ def test_savefig_pixel_ratio(backend):\n     assert ratio1 == ratio2\n \n \n+def test_savefig_preserve_layout_engine(tmp_path):", "source": "def test_savefig_preserve_layout_engine(tmp_path):\n    fig = plt.figure(layout='compressed')\n    fig.savefig(tmp_path / 'foo.png', bbox_inches='tight')\n\n    assert fig.get_layout_engine()._compress", "source_start_line": 535, "tokens": ["def", "test_savefig_preserve_layout_engine", "(", "tmp_path", ")", ":", "fig", "=", "plt", ".", "figure", "(", "layout", "=", "'compressed'", ")", "fig", ".", "savefig", "(", "tmp_path", "/", "'foo.png'", ",", "bbox_inches", "=", "'tight'", ")", "assert", "fig", ".", "get_layout_engine", "(", ")", ".", "_compress"], "to_mask": {"VAR": ["fig", "tmp_path"], "METHOD": ["figure", "get_layout_engine", "savefig"]}, "attention_idx_tokens": [0, 5], "patch": "@@ -532,6 +532,13 @@\n     assert ratio1 == ratio2\n \n \n+def test_savefig_preserve_layout_engine(tmp_path):", "ext_attention_idx_tokens": [0, 35], "uid": "55bbac9c", "question": "This worked before didn't it?  It was when the rcParam was set that the problem was?  Or was the layout still getting set to None, and then falling back to the rcParam?      Otherwise if this works, I'm all for it!  I do wish all the context switching were simpler to debug, but...", "code": "def test savefig preserve layout engine tmp path fig plt figure layout compressed fig savefig tmp path foo png bbox inches tight assert fig get layout engine compress"}
{"message": "This might fix the coverage issue?", "timestamp": "2023-02-02T18:17:28Z", "file_name": "lib/matplotlib/tests/test_widgets.py", "range": {"start_line": 1657, "end_line": 1657, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1094909004", "html_url": "https://github.com/matplotlib/matplotlib/pull/25129#discussion_r1094909004", "attention_area": "    multi.onmove(event)", "file_path": "files/36/02/00000236.py", "old_file_path": "files/37/02/00000237.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1654,7 +1654,7 @@ def test_MultiCursor(horizOn, vertOn):\n     # Can't use `do_event` as that helper requires the widget\n     # to have a single .ax attribute.\n     event = mock_event(ax1, xdata=.5, ydata=.25)\n-    multi._onmove(event)\n+    multi.onmove(event)", "source": "def test_MultiCursor(horizOn, vertOn):\n    (ax1, ax3) = plt.figure().subplots(2, sharex=True)\n    ax2 = plt.figure().subplots()\n\n    # useblit=false to avoid having to draw the figure to cache the renderer\n    multi = widgets.MultiCursor(\n        None, (ax1, ax2), useblit=False, horizOn=horizOn, vertOn=vertOn\n    )\n\n    # Only two of the axes should have a line drawn on them.\n    assert len(multi.vlines) == 2\n    assert len(multi.hlines) == 2\n\n    # mock a motion_notify_event\n    # Can't use `do_event` as that helper requires the widget\n    # to have a single .ax attribute.\n    event = mock_event(ax1, xdata=.5, ydata=.25)\n    multi.onmove(event)\n\n    # the lines in the first two ax should both move\n    for l in multi.vlines:\n        assert l.get_xdata() == (.5, .5)\n    for l in multi.hlines:\n        assert l.get_ydata() == (.25, .25)\n    # The relevant lines get turned on after move.\n    assert len([line for line in multi.vlines if line.get_visible()]) == (\n        2 if vertOn else 0)\n    assert len([line for line in multi.hlines if line.get_visible()]) == (\n        2 if horizOn else 0)\n\n    # After toggling settings, the opposite lines should be visible after move.\n    multi.horizOn = not multi.horizOn\n    multi.vertOn = not multi.vertOn\n    event = mock_event(ax1, xdata=.5, ydata=.25)\n    multi.onmove(event)\n    assert len([line for line in multi.vlines if line.get_visible()]) == (\n        0 if vertOn else 2)\n    assert len([line for line in multi.hlines if line.get_visible()]) == (\n        0 if horizOn else 2)\n\n    # test a move event in an Axes not part of the MultiCursor\n    # the lines in ax1 and ax2 should not have moved.\n    event = mock_event(ax3, xdata=.75, ydata=.75)\n    multi.onmove(event)\n    for l in multi.vlines:\n        assert l.get_xdata() == (.5, .5)\n    for l in multi.hlines:\n        assert l.get_ydata() == (.25, .25)", "source_start_line": 1640, "tokens": ["def", "test_MultiCursor", "(", "horizOn", ",", "vertOn", ")", ":", "(", "ax1", ",", "ax3", ")", "=", "plt", ".", "figure", "(", ")", ".", "subplots", "(", "2", ",", "sharex", "=", "True", ")", "ax2", "=", "plt", ".", "figure", "(", ")", ".", "subplots", "(", ")", "multi", "=", "widgets", ".", "MultiCursor", "(", "None", ",", "(", "ax1", ",", "ax2", ")", ",", "useblit", "=", "False", ",", "horizOn", "=", "horizOn", ",", "vertOn", "=", "vertOn", ")", "assert", "len", "(", "multi", ".", "vlines", ")", "==", "2", "assert", "len", "(", "multi", ".", "hlines", ")", "==", "2", "event", "=", "mock_event", "(", "ax1", ",", "xdata", "=", ".5", ",", "ydata", "=", ".25", ")", "multi", ".", "onmove", "(", "event", ")", "for", "l", "in", "multi", ".", "vlines", ":", "assert", "l", ".", "get_xdata", "(", ")", "==", "(", ".5", ",", ".5", ")", "for", "l", "in", "multi", ".", "hlines", ":", "assert", "l", ".", "get_ydata", "(", ")", "==", "(", ".25", ",", ".25", ")", "assert", "len", "(", "[", "line", "for", "line", "in", "multi", ".", "vlines", "if", "line", ".", "get_visible", "(", ")", "]", ")", "==", "(", "2", "if", "vertOn", "else", "0", ")", "assert", "len", "(", "[", "line", "for", "line", "in", "multi", ".", "hlines", "if", "line", ".", "get_visible", "(", ")", "]", ")", "==", "(", "2", "if", "horizOn", "else", "0", ")", "multi", ".", "horizOn", "=", "not", "multi", ".", "horizOn", "multi", ".", "vertOn", "=", "not", "multi", ".", "vertOn", "event", "=", "mock_event", "(", "ax1", ",", "xdata", "=", ".5", ",", "ydata", "=", ".25", ")", "multi", ".", "onmove", "(", "event", ")", "assert", "len", "(", "[", "line", "for", "line", "in", "multi", ".", "vlines", "if", "line", ".", "get_visible", "(", ")", "]", ")", "==", "(", "0", "if", "vertOn", "else", "2", ")", "assert", "len", "(", "[", "line", "for", "line", "in", "multi", ".", "hlines", "if", "line", ".", "get_visible", "(", ")", "]", ")", "==", "(", "0", "if", "horizOn", "else", "2", ")", "event", "=", "mock_event", "(", "ax3", ",", "xdata", "=", ".75", ",", "ydata", "=", ".75", ")", "multi", ".", "onmove", "(", "event", ")", "for", "l", "in", "multi", ".", "vlines", ":", "assert", "l", ".", "get_xdata", "(", ")", "==", "(", ".5", ",", ".5", ")", "for", "l", "in", "multi", ".", "hlines", ":", "assert", "l", ".", "get_ydata", "(", ")", "==", "(", ".25", ",", ".25", ")"], "to_mask": {"VAR": ["ax2", "event", "horizOn", "l", "multi", "vertOn"], "METHOD": ["MultiCursor", "figure", "get_visible", "get_xdata", "get_ydata", "len", "mock_event", "onmove", "subplots"]}, "attention_idx_tokens": [97, 102], "patch": "@@ -1654,7 +1654,7 @@\n     # Can't use `do_event` as that helper requires the widget\n     # to have a single .ax attribute.\n     event = mock_event(ax1, xdata=.5, ydata=.25)\n-    multi._onmove(event)\n+    multi.onmove(event)", "ext_attention_idx_tokens": [97, 102], "uid": "4c8d2b2b", "question": "This might fix the coverage issue?", "code": "def test MultiCursor horizOn vertOn ax1 ax3 plt figure subplots 2 sharex True ax2 plt figure subplots # useblit false to avoid having to draw the figure to cache the renderer multi widgets MultiCursor None ax1 ax2 useblit False horizOn horizOn vertOn vertOn # Only two of the axes should have a line drawn on them assert len multi vlines 2 assert len multi hlines 2 # mock a motion notify event # Can t use `do event` as that helper requires the widget # to have a single ax attribute event mock event ax1 xdata 5 ydata 25 multi onmove event # the lines in the first two ax should both move for l in multi vlines assert l get xdata 5 5 for l in multi hlines assert l get ydata 25 25 # The relevant lines get turned on after move assert len [line for line in multi vlines if line get visible ] 2 if vertOn else 0 assert len [line for line in multi hlines if line get visible ] 2 if horizOn else 0 # After toggling settings the opposite lines should be visible after move multi horizOn not multi horizOn multi vertOn not multi vertOn event mock event ax1 xdata 5 ydata 25 multi onmove event assert len [line for line in multi vlines if line get visible ] 0 if vertOn else 2 assert len [line for line in multi hlines if line get visible ] 0 if horizOn else 2 # test a move event in an Axes not part of the MultiCursor # the lines in ax1 and ax2 should not have moved event mock event ax3 xdata 75 ydata 75 multi onmove event for l in multi vlines assert l get xdata 5 5 for l in multi hlines assert l get ydata 25 25"}
{"message": "And actually I'm confused - is the ASCII art also incorrect?  ", "timestamp": "2023-02-02T19:43:30Z", "file_name": "lib/matplotlib/axes/_axes.py", "range": {"start_line": 3729, "end_line": 3729, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1095013382", "html_url": "https://github.com/matplotlib/matplotlib/pull/25135#discussion_r1095013382", "attention_area": "        are those past the end of the whiskers.", "file_path": "files/39/02/00000239.py", "old_file_path": "files/40/02/00000240.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -3723,9 +3723,10 @@ def boxplot(self, x, notch=None, sym=None, vert=None, whis=None,\n         Draw a box and whisker plot.\n \n         The box extends from the first quartile (Q1) to the third\n-        quartile (Q3) of the data, with a line at the median.  The\n-        whiskers extend from the box by 1.5x the inter-quartile range\n-        (IQR).  Flier points are those past the end of the whiskers.\n+        quartile (Q3) of the data, with a line at the median. The\n+        whiskers extend from the box to the farthest point within\n+        1.5x the inter-quartile range (IQR) distance. Flier points\n+        are those past the end of the whiskers.", "source": "def boxplot(self, x, notch=None, sym=None, vert=None, whis=None,\n                positions=None, widths=None, patch_artist=None,\n                bootstrap=None, usermedians=None, conf_intervals=None,\n                meanline=None, showmeans=None, showcaps=None,\n                showbox=None, showfliers=None, boxprops=None,\n                labels=None, flierprops=None, medianprops=None,\n                meanprops=None, capprops=None, whiskerprops=None,\n                manage_ticks=True, autorange=False, zorder=None,\n                capwidths=None):\n        \"\"\"\n        Draw a box and whisker plot.\n\n        The box extends from the first quartile (Q1) to the third\n        quartile (Q3) of the data, with a line at the median. The\n        whiskers extend from the box to the farthest point within\n        1.5x the inter-quartile range (IQR) distance. Flier points\n        are those past the end of the whiskers.\n        See https://en.wikipedia.org/wiki/Box_plot for reference.\n\n        .. code-block:: none\n\n                  Q1-1.5IQR   Q1   median  Q3   Q3+1.5IQR\n                               |-----:-----|\n               o      |--------|     :     |--------|    o  o\n                               |-----:-----|\n             flier             <----------->            fliers\n                                    IQR\n\n\n        Parameters\n        ----------\n        x : Array or a sequence of vectors.\n            The input data.  If a 2D array, a boxplot is drawn for each column\n            in *x*.  If a sequence of 1D arrays, a boxplot is drawn for each\n            array in *x*.\n\n        notch : bool, default: False\n            Whether to draw a notched boxplot (`True`), or a rectangular\n            boxplot (`False`).  The notches represent the confidence interval\n            (CI) around the median.  The documentation for *bootstrap*\n            describes how the locations of the notches are computed by\n            default, but their locations may also be overridden by setting the\n            *conf_intervals* parameter.\n\n            .. note::\n\n                In cases where the values of the CI are less than the\n                lower quartile or greater than the upper quartile, the\n                notches will extend beyond the box, giving it a\n                distinctive \"flipped\" appearance. This is expected\n                behavior and consistent with other statistical\n                visualization packages.\n\n        sym : str, optional\n            The default symbol for flier points.  An empty string ('') hides\n            the fliers.  If `None`, then the fliers default to 'b+'.  More\n            control is provided by the *flierprops* parameter.\n\n        vert : bool, default: True\n            If `True`, draws vertical boxes.\n            If `False`, draw horizontal boxes.\n\n        whis : float or (float, float), default: 1.5\n            The position of the whiskers.\n\n            If a float, the lower whisker is at the lowest datum above\n            ``Q1 - whis*(Q3-Q1)``, and the upper whisker at the highest datum\n            below ``Q3 + whis*(Q3-Q1)``, where Q1 and Q3 are the first and\n            third quartiles.  The default value of ``whis = 1.5`` corresponds\n            to Tukey's original definition of boxplots.\n\n            If a pair of floats, they indicate the percentiles at which to\n            draw the whiskers (e.g., (5, 95)).  In particular, setting this to\n            (0, 100) results in whiskers covering the whole range of the data.\n\n            In the edge case where ``Q1 == Q3``, *whis* is automatically set\n            to (0, 100) (cover the whole range of the data) if *autorange* is\n            True.\n\n            Beyond the whiskers, data are considered outliers and are plotted\n            as individual points.\n\n        bootstrap : int, optional\n            Specifies whether to bootstrap the confidence intervals\n            around the median for notched boxplots. If *bootstrap* is\n            None, no bootstrapping is performed, and notches are\n            calculated using a Gaussian-based asymptotic approximation\n            (see McGill, R., Tukey, J.W., and Larsen, W.A., 1978, and\n            Kendall and Stuart, 1967). Otherwise, bootstrap specifies\n            the number of times to bootstrap the median to determine its\n            95% confidence intervals. Values between 1000 and 10000 are\n            recommended.\n\n        usermedians : 1D array-like, optional\n            A 1D array-like of length ``len(x)``.  Each entry that is not\n            `None` forces the value of the median for the corresponding\n            dataset.  For entries that are `None`, the medians are computed\n            by Matplotlib as normal.\n\n        conf_intervals : array-like, optional\n            A 2D array-like of shape ``(len(x), 2)``.  Each entry that is not\n            None forces the location of the corresponding notch (which is\n            only drawn if *notch* is `True`).  For entries that are `None`,\n            the notches are computed by the method specified by the other\n            parameters (e.g., *bootstrap*).\n\n        positions : array-like, optional\n            The positions of the boxes. The ticks and limits are\n            automatically set to match the positions. Defaults to\n            ``range(1, N+1)`` where N is the number of boxes to be drawn.\n\n        widths : float or array-like\n            The widths of the boxes.  The default is 0.5, or ``0.15*(distance\n            between extreme positions)``, if that is smaller.\n\n        patch_artist : bool, default: False\n            If `False` produces boxes with the Line2D artist. Otherwise,\n            boxes are drawn with Patch artists.\n\n        labels : sequence, optional\n            Labels for each dataset (one per dataset).\n\n        manage_ticks : bool, default: True\n            If True, the tick locations and labels will be adjusted to match\n            the boxplot positions.\n\n        autorange : bool, default: False\n            When `True` and the data are distributed such that the 25th and\n            75th percentiles are equal, *whis* is set to (0, 100) such\n            that the whisker ends are at the minimum and maximum of the data.\n\n        meanline : bool, default: False\n            If `True` (and *showmeans* is `True`), will try to render the\n            mean as a line spanning the full width of the box according to\n            *meanprops* (see below).  Not recommended if *shownotches* is also\n            True.  Otherwise, means will be shown as points.\n\n        zorder : float, default: ``Line2D.zorder = 2``\n            The zorder of the boxplot.\n\n        Returns\n        -------\n        dict\n          A dictionary mapping each component of the boxplot to a list\n          of the `.Line2D` instances created. That dictionary has the\n          following keys (assuming vertical boxplots):\n\n          - ``boxes``: the main body of the boxplot showing the\n            quartiles and the median's confidence intervals if\n            enabled.\n\n          - ``medians``: horizontal lines at the median of each box.\n\n          - ``whiskers``: the vertical lines extending to the most\n            extreme, non-outlier data points.\n\n          - ``caps``: the horizontal lines at the ends of the\n            whiskers.\n\n          - ``fliers``: points representing data that extend beyond\n            the whiskers (fliers).\n\n          - ``means``: points or lines representing the means.\n\n        Other Parameters\n        ----------------\n        showcaps : bool, default: True\n            Show the caps on the ends of whiskers.\n        showbox : bool, default: True\n            Show the central box.\n        showfliers : bool, default: True\n            Show the outliers beyond the caps.\n        showmeans : bool, default: False\n            Show the arithmetic means.\n        capprops : dict, default: None\n            The style of the caps.\n        capwidths : float or array, default: None\n            The widths of the caps.\n        boxprops : dict, default: None\n            The style of the box.\n        whiskerprops : dict, default: None\n            The style of the whiskers.\n        flierprops : dict, default: None\n            The style of the fliers.\n        medianprops : dict, default: None\n            The style of the median.\n        meanprops : dict, default: None\n            The style of the mean.\n        data : indexable object, optional\n            DATA_PARAMETER_PLACEHOLDER\n\n        See Also\n        --------\n        violinplot : Draw an estimate of the probability density function.\n        \"\"\"\n\n        # Missing arguments default to rcParams.\n        if whis is None:\n            whis = mpl.rcParams['boxplot.whiskers']\n        if bootstrap is None:\n            bootstrap = mpl.rcParams['boxplot.bootstrap']\n\n        bxpstats = cbook.boxplot_stats(x, whis=whis, bootstrap=bootstrap,\n                                       labels=labels, autorange=autorange)\n        if notch is None:\n            notch = mpl.rcParams['boxplot.notch']\n        if vert is None:\n            vert = mpl.rcParams['boxplot.vertical']\n        if patch_artist is None:\n            patch_artist = mpl.rcParams['boxplot.patchartist']\n        if meanline is None:\n            meanline = mpl.rcParams['boxplot.meanline']\n        if showmeans is None:\n            showmeans = mpl.rcParams['boxplot.showmeans']\n        if showcaps is None:\n            showcaps = mpl.rcParams['boxplot.showcaps']\n        if showbox is None:\n            showbox = mpl.rcParams['boxplot.showbox']\n        if showfliers is None:\n            showfliers = mpl.rcParams['boxplot.showfliers']\n\n        if boxprops is None:\n            boxprops = {}\n        if whiskerprops is None:\n            whiskerprops = {}\n        if capprops is None:\n            capprops = {}\n        if medianprops is None:\n            medianprops = {}\n        if meanprops is None:\n            meanprops = {}\n        if flierprops is None:\n            flierprops = {}\n\n        if patch_artist:\n            boxprops['linestyle'] = 'solid'  # Not consistent with bxp.\n            if 'color' in boxprops:\n                boxprops['edgecolor'] = boxprops.pop('color')\n\n        # if non-default sym value, put it into the flier dictionary\n        # the logic for providing the default symbol ('b+') now lives\n        # in bxp in the initial value of flierkw\n        # handle all of the *sym* related logic here so we only have to pass\n        # on the flierprops dict.\n        if sym is not None:\n            # no-flier case, which should really be done with\n            # 'showfliers=False' but none-the-less deal with it to keep back\n            # compatibility\n            if sym == '':\n                # blow away existing dict and make one for invisible markers\n                flierprops = dict(linestyle='none', marker='', color='none')\n                # turn the fliers off just to be safe\n                showfliers = False\n            # now process the symbol string\n            else:\n                # process the symbol string\n                # discarded linestyle\n                _, marker, color = _process_plot_format(sym)\n                # if we have a marker, use it\n                if marker is not None:\n                    flierprops['marker'] = marker\n                # if we have a color, use it\n                if color is not None:\n                    # assume that if color is passed in the user want\n                    # filled symbol, if the users want more control use\n                    # flierprops\n                    flierprops['color'] = color\n                    flierprops['markerfacecolor'] = color\n                    flierprops['markeredgecolor'] = color\n\n        # replace medians if necessary:\n        if usermedians is not None:\n            if (len(np.ravel(usermedians)) != len(bxpstats) or\n                    np.shape(usermedians)[0] != len(bxpstats)):\n                raise ValueError(\n                    \"'usermedians' and 'x' have different lengths\")\n            else:\n                # reassign medians as necessary\n                for stats, med in zip(bxpstats, usermedians):\n                    if med is not None:\n                        stats['med'] = med\n\n        if conf_intervals is not None:\n            if len(conf_intervals) != len(bxpstats):\n                raise ValueError(\n                    \"'conf_intervals' and 'x' have different lengths\")\n            else:\n                for stats, ci in zip(bxpstats, conf_intervals):\n                    if ci is not None:\n                        if len(ci) != 2:\n                            raise ValueError('each confidence interval must '\n                                             'have two values')\n                        else:\n                            if ci[0] is not None:\n                                stats['cilo'] = ci[0]\n                            if ci[1] is not None:\n                                stats['cihi'] = ci[1]\n\n        artists = self.bxp(bxpstats, positions=positions, widths=widths,\n                           vert=vert, patch_artist=patch_artist,\n                           shownotches=notch, showmeans=showmeans,\n                           showcaps=showcaps, showbox=showbox,\n                           boxprops=boxprops, flierprops=flierprops,\n                           medianprops=medianprops, meanprops=meanprops,\n                           meanline=meanline, showfliers=showfliers,\n                           capprops=capprops, whiskerprops=whiskerprops,\n                           manage_ticks=manage_ticks, zorder=zorder,\n                           capwidths=capwidths)\n        return artists", "source_start_line": 3713, "tokens": ["def", "boxplot", "(", "self", ",", "x", ",", "notch", "=", "None", ",", "sym", "=", "None", ",", "vert", "=", "None", ",", "whis", "=", "None", ",", "positions", "=", "None", ",", "widths", "=", "None", ",", "patch_artist", "=", "None", ",", "bootstrap", "=", "None", ",", "usermedians", "=", "None", ",", "conf_intervals", "=", "None", ",", "meanline", "=", "None", ",", "showmeans", "=", "None", ",", "showcaps", "=", "None", ",", "showbox", "=", "None", ",", "showfliers", "=", "None", ",", "boxprops", "=", "None", ",", "labels", "=", "None", ",", "flierprops", "=", "None", ",", "medianprops", "=", "None", ",", "meanprops", "=", "None", ",", "capprops", "=", "None", ",", "whiskerprops", "=", "None", ",", "manage_ticks", "=", "True", ",", "autorange", "=", "False", ",", "zorder", "=", "None", ",", "capwidths", "=", "None", ")", ":", "\"\"\"        Draw a box and whisker plot.        The box extends from the first quartile (Q1) to the third        quartile (Q3) of the data, with a line at the median. The        whiskers extend from the box to the farthest point within        1.5x the inter-quartile range (IQR) distance. Flier points        are those past the end of the whiskers.        See https://en.wikipedia.org/wiki/Box_plot for reference.        .. code-block:: none                  Q1-1.5IQR   Q1   median  Q3   Q3+1.5IQR                               |-----:-----|               o      |--------|     :     |--------|    o  o                               |-----:-----|             flier             <----------->            fliers                                    IQR        Parameters        ----------        x : Array or a sequence of vectors.            The input data.  If a 2D array, a boxplot is drawn for each column            in *x*.  If a sequence of 1D arrays, a boxplot is drawn for each            array in *x*.        notch : bool, default: False            Whether to draw a notched boxplot (`True`), or a rectangular            boxplot (`False`).  The notches represent the confidence interval            (CI) around the median.  The documentation for *bootstrap*            describes how the locations of the notches are computed by            default, but their locations may also be overridden by setting the            *conf_intervals* parameter.            .. note::                In cases where the values of the CI are less than the                lower quartile or greater than the upper quartile, the                notches will extend beyond the box, giving it a                distinctive \"flipped\" appearance. This is expected                behavior and consistent with other statistical                visualization packages.        sym : str, optional            The default symbol for flier points.  An empty string ('') hides            the fliers.  If `None`, then the fliers default to 'b+'.  More            control is provided by the *flierprops* parameter.        vert : bool, default: True            If `True`, draws vertical boxes.            If `False`, draw horizontal boxes.        whis : float or (float, float), default: 1.5            The position of the whiskers.            If a float, the lower whisker is at the lowest datum above            ``Q1 - whis*(Q3-Q1)``, and the upper whisker at the highest datum            below ``Q3 + whis*(Q3-Q1)``, where Q1 and Q3 are the first and            third quartiles.  The default value of ``whis = 1.5`` corresponds            to Tukey's original definition of boxplots.            If a pair of floats, they indicate the percentiles at which to            draw the whiskers (e.g., (5, 95)).  In particular, setting this to            (0, 100) results in whiskers covering the whole range of the data.            In the edge case where ``Q1 == Q3``, *whis* is automatically set            to (0, 100) (cover the whole range of the data) if *autorange* is            True.            Beyond the whiskers, data are considered outliers and are plotted            as individual points.        bootstrap : int, optional            Specifies whether to bootstrap the confidence intervals            around the median for notched boxplots. If *bootstrap* is            None, no bootstrapping is performed, and notches are            calculated using a Gaussian-based asymptotic approximation            (see McGill, R., Tukey, J.W., and Larsen, W.A., 1978, and            Kendall and Stuart, 1967). Otherwise, bootstrap specifies            the number of times to bootstrap the median to determine its            95% confidence intervals. Values between 1000 and 10000 are            recommended.        usermedians : 1D array-like, optional            A 1D array-like of length ``len(x)``.  Each entry that is not            `None` forces the value of the median for the corresponding            dataset.  For entries that are `None`, the medians are computed            by Matplotlib as normal.        conf_intervals : array-like, optional            A 2D array-like of shape ``(len(x), 2)``.  Each entry that is not            None forces the location of the corresponding notch (which is            only drawn if *notch* is `True`).  For entries that are `None`,            the notches are computed by the method specified by the other            parameters (e.g., *bootstrap*).        positions : array-like, optional            The positions of the boxes. The ticks and limits are            automatically set to match the positions. Defaults to            ``range(1, N+1)`` where N is the number of boxes to be drawn.        widths : float or array-like            The widths of the boxes.  The default is 0.5, or ``0.15*(distance            between extreme positions)``, if that is smaller.        patch_artist : bool, default: False            If `False` produces boxes with the Line2D artist. Otherwise,            boxes are drawn with Patch artists.        labels : sequence, optional            Labels for each dataset (one per dataset).        manage_ticks : bool, default: True            If True, the tick locations and labels will be adjusted to match            the boxplot positions.        autorange : bool, default: False            When `True` and the data are distributed such that the 25th and            75th percentiles are equal, *whis* is set to (0, 100) such            that the whisker ends are at the minimum and maximum of the data.        meanline : bool, default: False            If `True` (and *showmeans* is `True`), will try to render the            mean as a line spanning the full width of the box according to            *meanprops* (see below).  Not recommended if *shownotches* is also            True.  Otherwise, means will be shown as points.        zorder : float, default: ``Line2D.zorder = 2``            The zorder of the boxplot.        Returns        -------        dict          A dictionary mapping each component of the boxplot to a list          of the `.Line2D` instances created. That dictionary has the          following keys (assuming vertical boxplots):          - ``boxes``: the main body of the boxplot showing the            quartiles and the median's confidence intervals if            enabled.          - ``medians``: horizontal lines at the median of each box.          - ``whiskers``: the vertical lines extending to the most            extreme, non-outlier data points.          - ``caps``: the horizontal lines at the ends of the            whiskers.          - ``fliers``: points representing data that extend beyond            the whiskers (fliers).          - ``means``: points or lines representing the means.        Other Parameters        ----------------        showcaps : bool, default: True            Show the caps on the ends of whiskers.        showbox : bool, default: True            Show the central box.        showfliers : bool, default: True            Show the outliers beyond the caps.        showmeans : bool, default: False            Show the arithmetic means.        capprops : dict, default: None            The style of the caps.        capwidths : float or array, default: None            The widths of the caps.        boxprops : dict, default: None            The style of the box.        whiskerprops : dict, default: None            The style of the whiskers.        flierprops : dict, default: None            The style of the fliers.        medianprops : dict, default: None            The style of the median.        meanprops : dict, default: None            The style of the mean.        data : indexable object, optional            DATA_PARAMETER_PLACEHOLDER        See Also        --------        violinplot : Draw an estimate of the probability density function.        \"\"\"", "if", "whis", "is", "None", ":", "whis", "=", "mpl", ".", "rcParams", "[", "'boxplot.whiskers'", "]", "if", "bootstrap", "is", "None", ":", "bootstrap", "=", "mpl", ".", "rcParams", "[", "'boxplot.bootstrap'", "]", "bxpstats", "=", "cbook", ".", "boxplot_stats", "(", "x", ",", "whis", "=", "whis", ",", "bootstrap", "=", "bootstrap", ",", "labels", "=", "labels", ",", "autorange", "=", "autorange", ")", "if", "notch", "is", "None", ":", "notch", "=", "mpl", ".", "rcParams", "[", "'boxplot.notch'", "]", "if", "vert", "is", "None", ":", "vert", "=", "mpl", ".", "rcParams", "[", "'boxplot.vertical'", "]", "if", "patch_artist", "is", "None", ":", "patch_artist", "=", "mpl", ".", "rcParams", "[", "'boxplot.patchartist'", "]", "if", "meanline", "is", "None", ":", "meanline", "=", "mpl", ".", "rcParams", "[", "'boxplot.meanline'", "]", "if", "showmeans", "is", "None", ":", "showmeans", "=", "mpl", ".", "rcParams", "[", "'boxplot.showmeans'", "]", "if", "showcaps", "is", "None", ":", "showcaps", "=", "mpl", ".", "rcParams", "[", "'boxplot.showcaps'", "]", "if", "showbox", "is", "None", ":", "showbox", "=", "mpl", ".", "rcParams", "[", "'boxplot.showbox'", "]", "if", "showfliers", "is", "None", ":", "showfliers", "=", "mpl", ".", "rcParams", "[", "'boxplot.showfliers'", "]", "if", "boxprops", "is", "None", ":", "boxprops", "=", "{", "}", "if", "whiskerprops", "is", "None", ":", "whiskerprops", "=", "{", "}", "if", "capprops", "is", "None", ":", "capprops", "=", "{", "}", "if", "medianprops", "is", "None", ":", "medianprops", "=", "{", "}", "if", "meanprops", "is", "None", ":", "meanprops", "=", "{", "}", "if", "flierprops", "is", "None", ":", "flierprops", "=", "{", "}", "if", "patch_artist", ":", "boxprops", "[", "'linestyle'", "]", "=", "'solid'", "if", "'color'", "in", "boxprops", ":", "boxprops", "[", "'edgecolor'", "]", "=", "boxprops", ".", "pop", "(", "'color'", ")", "if", "sym", "is", "not", "None", ":", "if", "sym", "==", "''", ":", "flierprops", "=", "dict", "(", "linestyle", "=", "'none'", ",", "marker", "=", "''", ",", "color", "=", "'none'", ")", "showfliers", "=", "False", "else", ":", "_", ",", "marker", ",", "color", "=", "_process_plot_format", "(", "sym", ")", "if", "marker", "is", "not", "None", ":", "flierprops", "[", "'marker'", "]", "=", "marker", "if", "color", "is", "not", "None", ":", "flierprops", "[", "'color'", "]", "=", "color", "flierprops", "[", "'markerfacecolor'", "]", "=", "color", "flierprops", "[", "'markeredgecolor'", "]", "=", "color", "if", "usermedians", "is", "not", "None", ":", "if", "(", "len", "(", "np", ".", "ravel", "(", "usermedians", ")", ")", "!=", "len", "(", "bxpstats", ")", "or", "np", ".", "shape", "(", "usermedians", ")", "[", "0", "]", "!=", "len", "(", "bxpstats", ")", ")", ":", "raise", "ValueError", "(", "\"'usermedians' and 'x' have different lengths\"", ")", "else", ":", "for", "stats", ",", "med", "in", "zip", "(", "bxpstats", ",", "usermedians", ")", ":", "if", "med", "is", "not", "None", ":", "stats", "[", "'med'", "]", "=", "med", "if", "conf_intervals", "is", "not", "None", ":", "if", "len", "(", "conf_intervals", ")", "!=", "len", "(", "bxpstats", ")", ":", "raise", "ValueError", "(", "\"'conf_intervals' and 'x' have different lengths\"", ")", "else", ":", "for", "stats", ",", "ci", "in", "zip", "(", "bxpstats", ",", "conf_intervals", ")", ":", "if", "ci", "is", "not", "None", ":", "if", "len", "(", "ci", ")", "!=", "2", ":", "raise", "ValueError", "(", "'each confidence interval must '", "'have two values'", ")", "else", ":", "if", "ci", "[", "0", "]", "is", "not", "None", ":", "stats", "[", "'cilo'", "]", "=", "ci", "[", "0", "]", "if", "ci", "[", "1", "]", "is", "not", "None", ":", "stats", "[", "'cihi'", "]", "=", "ci", "[", "1", "]", "artists", "=", "self", ".", "bxp", "(", "bxpstats", ",", "positions", "=", "positions", ",", "widths", "=", "widths", ",", "vert", "=", "vert", ",", "patch_artist", "=", "patch_artist", ",", "shownotches", "=", "notch", ",", "showmeans", "=", "showmeans", ",", "showcaps", "=", "showcaps", ",", "showbox", "=", "showbox", ",", "boxprops", "=", "boxprops", ",", "flierprops", "=", "flierprops", ",", "medianprops", "=", "medianprops", ",", "meanprops", "=", "meanprops", ",", "meanline", "=", "meanline", ",", "showfliers", "=", "showfliers", ",", "capprops", "=", "capprops", ",", "whiskerprops", "=", "whiskerprops", ",", "manage_ticks", "=", "manage_ticks", ",", "zorder", "=", "zorder", ",", "capwidths", "=", "capwidths", ")", "return", "artists"], "to_mask": {"VAR": ["_", "artists", "autorange", "bootstrap", "boxprops", "bxpstats", "capprops", "capwidths", "ci", "color", "conf_intervals", "flierprops", "labels", "manage_ticks", "marker", "meanline", "meanprops", "med", "medianprops", "notch", "patch_artist", "positions", "self", "showbox", "showcaps", "showfliers", "showmeans", "stats", "sym", "usermedians", "vert", "whis", "whiskerprops", "widths", "x", "zorder"], "METHOD": ["ValueError", "_process_plot_format", "boxplot_stats", "bxp", "dict", "len", "pop", "ravel", "shape", "zip"]}, "attention_idx_tokens": [null, null], "patch": "@@ -3723,9 +3723,10 @@\n         Draw a box and whisker plot.\n \n         The box extends from the first quartile (Q1) to the third\n-        quartile (Q3) of the data, with a line at the median.  The\n-        whiskers extend from the box by 1.5x the inter-quartile range\n-        (IQR).  Flier points are those past the end of the whiskers.\n+        quartile (Q3) of the data, with a line at the median. The\n+        whiskers extend from the box to the farthest point within\n+        1.5x the inter-quartile range (IQR) distance. Flier points\n+        are those past the end of the whiskers.", "ext_attention_idx_tokens": [null, null], "uid": "e677d177", "question": "And actually I'm confused - is the ASCII art also incorrect?  ", "code": "def boxplot self x notch None sym None vert None whis None positions None widths None patch artist None bootstrap None usermedians None conf intervals None meanline None showmeans None showcaps None showbox None showfliers None boxprops None labels None flierprops None medianprops None meanprops None capprops None whiskerprops None manage ticks True autorange False zorder None capwidths None \"\"\" Draw a box and whisker plot The box extends from the first quartile Q1 to the third quartile Q3 of the data with a line at the median The whiskers extend from the box to the farthest point within 1 5x the inter-quartile range IQR distance Flier points are those past the end of the whiskers See https en wikipedia org wiki Box plot for reference code-block none Q1-1 5IQR Q1 median Q3 Q3+1 5IQR |----- -----| o |--------| |--------| o o |----- -----| flier <-----------> fliers IQR Parameters ---------- x Array or a sequence of vectors The input data If a 2D array a boxplot is drawn for each column in *x* If a sequence of 1D arrays a boxplot is drawn for each array in *x* notch bool default False Whether to draw a notched boxplot `True` or a rectangular boxplot `False` The notches represent the confidence interval CI around the median The documentation for *bootstrap* describes how the locations of the notches are computed by default but their locations may also be overridden by setting the *conf intervals* parameter note In cases where the values of the CI are less than the lower quartile or greater than the upper quartile the notches will extend beyond the box giving it a distinctive \"flipped\" appearance This is expected behavior and consistent with other statistical visualization packages sym str optional The default symbol for flier points An empty string hides the fliers If `None` then the fliers default to b+ More control is provided by the *flierprops* parameter vert bool default True If `True` draws vertical boxes If `False` draw horizontal boxes whis float or float float default 1 5 The position of the whiskers If a float the lower whisker is at the lowest datum above ``Q1 - whis* Q3-Q1 `` and the upper whisker at the highest datum below ``Q3 + whis* Q3-Q1 `` where Q1 and Q3 are the first and third quartiles The default value of ``whis 1 5`` corresponds to Tukey s original definition of boxplots If a pair of floats they indicate the percentiles at which to draw the whiskers e g 5 95 In particular setting this to 0 100 results in whiskers covering the whole range of the data In the edge case where ``Q1 Q3`` *whis* is automatically set to 0 100 cover the whole range of the data if *autorange* is True Beyond the whiskers data are considered outliers and are plotted as individual points bootstrap int optional Specifies whether to bootstrap the confidence intervals around the median for notched boxplots If *bootstrap* is None no bootstrapping is performed and notches are calculated using a Gaussian-based asymptotic approximation see McGill R Tukey J W and Larsen W A 1978 and Kendall and Stuart 1967 Otherwise bootstrap specifies the number of times to bootstrap the median to determine its 95% confidence intervals Values between 1000 and 10000 are recommended usermedians 1D array-like optional A 1D array-like of length ``len x `` Each entry that is not `None` forces the value of the median for the corresponding dataset For entries that are `None` the medians are computed by Matplotlib as normal conf intervals array-like optional A 2D array-like of shape `` len x 2 `` Each entry that is not None forces the location of the corresponding notch which is only drawn if *notch* is `True` For entries that are `None` the notches are computed by the method specified by the other parameters e g *bootstrap* positions array-like optional The positions of the boxes The ticks and limits are automatically set to match the positions Defaults to ``range 1 N+1 `` where N is the number of boxes to be drawn widths float or array-like The widths of the boxes The default is 0 5 or ``0 15* distance between extreme positions `` if that is smaller patch artist bool default False If `False` produces boxes with the Line2D artist Otherwise boxes are drawn with Patch artists labels sequence optional Labels for each dataset one per dataset manage ticks bool default True If True the tick locations and labels will be adjusted to match the boxplot positions autorange bool default False When `True` and the data are distributed such that the 25th and 75th percentiles are equal *whis* is set to 0 100 such that the whisker ends are at the minimum and maximum of the data meanline bool default False If `True` and *showmeans* is `True` will try to render the mean as a line spanning the full width of the box according to *meanprops* see below Not recommended if *shownotches* is also True Otherwise means will be shown as points zorder float default ``Line2D zorder 2`` The zorder of the boxplot Returns ------- dict A dictionary mapping each component of the boxplot to a list of the ` Line2D` instances created That dictionary has the following keys assuming vertical boxplots - ``boxes`` the main body of the boxplot showing the quartiles and the median s confidence intervals if enabled - ``medians`` horizontal lines at the median of each box - ``whiskers`` the vertical lines extending to the most extreme non-outlier data points - ``caps`` the horizontal lines at the ends of the whiskers - ``fliers`` points representing data that extend beyond the whiskers fliers - ``means`` points or lines representing the means Other Parameters ---------------- showcaps bool default True Show the caps on the ends of whiskers showbox bool default True Show the central box showfliers bool default True Show the outliers beyond the caps showmeans bool default False Show the arithmetic means capprops dict default None The style of the caps capwidths float or array default None The widths of the caps boxprops dict default None The style of the box whiskerprops dict default None The style of the whiskers flierprops dict default None The style of the fliers medianprops dict default None The style of the median meanprops dict default None The style of the mean data indexable object optional DATA PARAMETER PLACEHOLDER See Also -------- violinplot Draw an estimate of the probability density function \"\"\" # Missing arguments default to rcParams if whis is None whis mpl rcParams[ boxplot whiskers ] if bootstrap is None bootstrap mpl rcParams[ boxplot bootstrap ] bxpstats cbook boxplot stats x whis whis bootstrap bootstrap labels labels autorange autorange if notch is None notch mpl rcParams[ boxplot notch ] if vert is None vert mpl rcParams[ boxplot vertical ] if patch artist is None patch artist mpl rcParams[ boxplot patchartist ] if meanline is None meanline mpl rcParams[ boxplot meanline ] if showmeans is None showmeans mpl rcParams[ boxplot showmeans ] if showcaps is None showcaps mpl rcParams[ boxplot showcaps ] if showbox is None showbox mpl rcParams[ boxplot showbox ] if showfliers is None showfliers mpl rcParams[ boxplot showfliers ] if boxprops is None boxprops {} if whiskerprops is None whiskerprops {} if capprops is None capprops {} if medianprops is None medianprops {} if meanprops is None meanprops {} if flierprops is None flierprops {} if patch artist boxprops[ linestyle ] solid # Not consistent with bxp if color in boxprops boxprops[ edgecolor ] boxprops pop color # if non-default sym value put it into the flier dictionary # the logic for providing the default symbol b+ now lives # in bxp in the initial value of flierkw # handle all of the *sym* related logic here so we only have to pass # on the flierprops dict if sym is not None # no-flier case which should really be done with # showfliers False but none-the-less deal with it to keep back # compatibility if sym # blow away existing dict and make one for invisible markers flierprops dict linestyle none marker color none # turn the fliers off just to be safe showfliers False # now process the symbol string else # process the symbol string # discarded linestyle marker color process plot format sym # if we have a marker use it if marker is not None flierprops[ marker ] marker # if we have a color use it if color is not None # assume that if color is passed in the user want # filled symbol if the users want more control use # flierprops flierprops[ color ] color flierprops[ markerfacecolor ] color flierprops[ markeredgecolor ] color # replace medians if necessary if usermedians is not None if len np ravel usermedians ! len bxpstats or np shape usermedians [0] ! len bxpstats raise ValueError \" usermedians and x have different lengths\" else # reassign medians as necessary for stats med in zip bxpstats usermedians if med is not None stats[ med ] med if conf intervals is not None if len conf intervals ! len bxpstats raise ValueError \" conf intervals and x have different lengths\" else for stats ci in zip bxpstats conf intervals if ci is not None if len ci ! 2 raise ValueError each confidence interval must have two values else if ci[0] is not None stats[ cilo ] ci[0] if ci[1] is not None stats[ cihi ] ci[1] artists self bxp bxpstats positions positions widths widths vert vert patch artist patch artist shownotches notch showmeans showmeans showcaps showcaps showbox showbox boxprops boxprops flierprops flierprops medianprops medianprops meanprops meanprops meanline meanline showfliers showfliers capprops capprops whiskerprops whiskerprops manage ticks manage ticks zorder zorder capwidths capwidths return artists"}
{"message": "also, is it the farthest data point and hence why you said \"farthest point\"? ", "timestamp": "2023-02-02T19:49:08Z", "file_name": "lib/matplotlib/axes/_axes.py", "range": {"start_line": 3729, "end_line": 3729, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1095019679", "html_url": "https://github.com/matplotlib/matplotlib/pull/25135#discussion_r1095019679", "attention_area": "        are those past the end of the whiskers.", "file_path": "files/39/02/00000239.py", "old_file_path": "files/40/02/00000240.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -3723,9 +3723,10 @@ def boxplot(self, x, notch=None, sym=None, vert=None, whis=None,\n         Draw a box and whisker plot.\n \n         The box extends from the first quartile (Q1) to the third\n-        quartile (Q3) of the data, with a line at the median.  The\n-        whiskers extend from the box by 1.5x the inter-quartile range\n-        (IQR).  Flier points are those past the end of the whiskers.\n+        quartile (Q3) of the data, with a line at the median. The\n+        whiskers extend from the box to the farthest point within\n+        1.5x the inter-quartile range (IQR) distance. Flier points\n+        are those past the end of the whiskers.", "source": "def boxplot(self, x, notch=None, sym=None, vert=None, whis=None,\n                positions=None, widths=None, patch_artist=None,\n                bootstrap=None, usermedians=None, conf_intervals=None,\n                meanline=None, showmeans=None, showcaps=None,\n                showbox=None, showfliers=None, boxprops=None,\n                labels=None, flierprops=None, medianprops=None,\n                meanprops=None, capprops=None, whiskerprops=None,\n                manage_ticks=True, autorange=False, zorder=None,\n                capwidths=None):\n        \"\"\"\n        Draw a box and whisker plot.\n\n        The box extends from the first quartile (Q1) to the third\n        quartile (Q3) of the data, with a line at the median. The\n        whiskers extend from the box to the farthest point within\n        1.5x the inter-quartile range (IQR) distance. Flier points\n        are those past the end of the whiskers.\n        See https://en.wikipedia.org/wiki/Box_plot for reference.\n\n        .. code-block:: none\n\n                  Q1-1.5IQR   Q1   median  Q3   Q3+1.5IQR\n                               |-----:-----|\n               o      |--------|     :     |--------|    o  o\n                               |-----:-----|\n             flier             <----------->            fliers\n                                    IQR\n\n\n        Parameters\n        ----------\n        x : Array or a sequence of vectors.\n            The input data.  If a 2D array, a boxplot is drawn for each column\n            in *x*.  If a sequence of 1D arrays, a boxplot is drawn for each\n            array in *x*.\n\n        notch : bool, default: False\n            Whether to draw a notched boxplot (`True`), or a rectangular\n            boxplot (`False`).  The notches represent the confidence interval\n            (CI) around the median.  The documentation for *bootstrap*\n            describes how the locations of the notches are computed by\n            default, but their locations may also be overridden by setting the\n            *conf_intervals* parameter.\n\n            .. note::\n\n                In cases where the values of the CI are less than the\n                lower quartile or greater than the upper quartile, the\n                notches will extend beyond the box, giving it a\n                distinctive \"flipped\" appearance. This is expected\n                behavior and consistent with other statistical\n                visualization packages.\n\n        sym : str, optional\n            The default symbol for flier points.  An empty string ('') hides\n            the fliers.  If `None`, then the fliers default to 'b+'.  More\n            control is provided by the *flierprops* parameter.\n\n        vert : bool, default: True\n            If `True`, draws vertical boxes.\n            If `False`, draw horizontal boxes.\n\n        whis : float or (float, float), default: 1.5\n            The position of the whiskers.\n\n            If a float, the lower whisker is at the lowest datum above\n            ``Q1 - whis*(Q3-Q1)``, and the upper whisker at the highest datum\n            below ``Q3 + whis*(Q3-Q1)``, where Q1 and Q3 are the first and\n            third quartiles.  The default value of ``whis = 1.5`` corresponds\n            to Tukey's original definition of boxplots.\n\n            If a pair of floats, they indicate the percentiles at which to\n            draw the whiskers (e.g., (5, 95)).  In particular, setting this to\n            (0, 100) results in whiskers covering the whole range of the data.\n\n            In the edge case where ``Q1 == Q3``, *whis* is automatically set\n            to (0, 100) (cover the whole range of the data) if *autorange* is\n            True.\n\n            Beyond the whiskers, data are considered outliers and are plotted\n            as individual points.\n\n        bootstrap : int, optional\n            Specifies whether to bootstrap the confidence intervals\n            around the median for notched boxplots. If *bootstrap* is\n            None, no bootstrapping is performed, and notches are\n            calculated using a Gaussian-based asymptotic approximation\n            (see McGill, R., Tukey, J.W., and Larsen, W.A., 1978, and\n            Kendall and Stuart, 1967). Otherwise, bootstrap specifies\n            the number of times to bootstrap the median to determine its\n            95% confidence intervals. Values between 1000 and 10000 are\n            recommended.\n\n        usermedians : 1D array-like, optional\n            A 1D array-like of length ``len(x)``.  Each entry that is not\n            `None` forces the value of the median for the corresponding\n            dataset.  For entries that are `None`, the medians are computed\n            by Matplotlib as normal.\n\n        conf_intervals : array-like, optional\n            A 2D array-like of shape ``(len(x), 2)``.  Each entry that is not\n            None forces the location of the corresponding notch (which is\n            only drawn if *notch* is `True`).  For entries that are `None`,\n            the notches are computed by the method specified by the other\n            parameters (e.g., *bootstrap*).\n\n        positions : array-like, optional\n            The positions of the boxes. The ticks and limits are\n            automatically set to match the positions. Defaults to\n            ``range(1, N+1)`` where N is the number of boxes to be drawn.\n\n        widths : float or array-like\n            The widths of the boxes.  The default is 0.5, or ``0.15*(distance\n            between extreme positions)``, if that is smaller.\n\n        patch_artist : bool, default: False\n            If `False` produces boxes with the Line2D artist. Otherwise,\n            boxes are drawn with Patch artists.\n\n        labels : sequence, optional\n            Labels for each dataset (one per dataset).\n\n        manage_ticks : bool, default: True\n            If True, the tick locations and labels will be adjusted to match\n            the boxplot positions.\n\n        autorange : bool, default: False\n            When `True` and the data are distributed such that the 25th and\n            75th percentiles are equal, *whis* is set to (0, 100) such\n            that the whisker ends are at the minimum and maximum of the data.\n\n        meanline : bool, default: False\n            If `True` (and *showmeans* is `True`), will try to render the\n            mean as a line spanning the full width of the box according to\n            *meanprops* (see below).  Not recommended if *shownotches* is also\n            True.  Otherwise, means will be shown as points.\n\n        zorder : float, default: ``Line2D.zorder = 2``\n            The zorder of the boxplot.\n\n        Returns\n        -------\n        dict\n          A dictionary mapping each component of the boxplot to a list\n          of the `.Line2D` instances created. That dictionary has the\n          following keys (assuming vertical boxplots):\n\n          - ``boxes``: the main body of the boxplot showing the\n            quartiles and the median's confidence intervals if\n            enabled.\n\n          - ``medians``: horizontal lines at the median of each box.\n\n          - ``whiskers``: the vertical lines extending to the most\n            extreme, non-outlier data points.\n\n          - ``caps``: the horizontal lines at the ends of the\n            whiskers.\n\n          - ``fliers``: points representing data that extend beyond\n            the whiskers (fliers).\n\n          - ``means``: points or lines representing the means.\n\n        Other Parameters\n        ----------------\n        showcaps : bool, default: True\n            Show the caps on the ends of whiskers.\n        showbox : bool, default: True\n            Show the central box.\n        showfliers : bool, default: True\n            Show the outliers beyond the caps.\n        showmeans : bool, default: False\n            Show the arithmetic means.\n        capprops : dict, default: None\n            The style of the caps.\n        capwidths : float or array, default: None\n            The widths of the caps.\n        boxprops : dict, default: None\n            The style of the box.\n        whiskerprops : dict, default: None\n            The style of the whiskers.\n        flierprops : dict, default: None\n            The style of the fliers.\n        medianprops : dict, default: None\n            The style of the median.\n        meanprops : dict, default: None\n            The style of the mean.\n        data : indexable object, optional\n            DATA_PARAMETER_PLACEHOLDER\n\n        See Also\n        --------\n        violinplot : Draw an estimate of the probability density function.\n        \"\"\"\n\n        # Missing arguments default to rcParams.\n        if whis is None:\n            whis = mpl.rcParams['boxplot.whiskers']\n        if bootstrap is None:\n            bootstrap = mpl.rcParams['boxplot.bootstrap']\n\n        bxpstats = cbook.boxplot_stats(x, whis=whis, bootstrap=bootstrap,\n                                       labels=labels, autorange=autorange)\n        if notch is None:\n            notch = mpl.rcParams['boxplot.notch']\n        if vert is None:\n            vert = mpl.rcParams['boxplot.vertical']\n        if patch_artist is None:\n            patch_artist = mpl.rcParams['boxplot.patchartist']\n        if meanline is None:\n            meanline = mpl.rcParams['boxplot.meanline']\n        if showmeans is None:\n            showmeans = mpl.rcParams['boxplot.showmeans']\n        if showcaps is None:\n            showcaps = mpl.rcParams['boxplot.showcaps']\n        if showbox is None:\n            showbox = mpl.rcParams['boxplot.showbox']\n        if showfliers is None:\n            showfliers = mpl.rcParams['boxplot.showfliers']\n\n        if boxprops is None:\n            boxprops = {}\n        if whiskerprops is None:\n            whiskerprops = {}\n        if capprops is None:\n            capprops = {}\n        if medianprops is None:\n            medianprops = {}\n        if meanprops is None:\n            meanprops = {}\n        if flierprops is None:\n            flierprops = {}\n\n        if patch_artist:\n            boxprops['linestyle'] = 'solid'  # Not consistent with bxp.\n            if 'color' in boxprops:\n                boxprops['edgecolor'] = boxprops.pop('color')\n\n        # if non-default sym value, put it into the flier dictionary\n        # the logic for providing the default symbol ('b+') now lives\n        # in bxp in the initial value of flierkw\n        # handle all of the *sym* related logic here so we only have to pass\n        # on the flierprops dict.\n        if sym is not None:\n            # no-flier case, which should really be done with\n            # 'showfliers=False' but none-the-less deal with it to keep back\n            # compatibility\n            if sym == '':\n                # blow away existing dict and make one for invisible markers\n                flierprops = dict(linestyle='none', marker='', color='none')\n                # turn the fliers off just to be safe\n                showfliers = False\n            # now process the symbol string\n            else:\n                # process the symbol string\n                # discarded linestyle\n                _, marker, color = _process_plot_format(sym)\n                # if we have a marker, use it\n                if marker is not None:\n                    flierprops['marker'] = marker\n                # if we have a color, use it\n                if color is not None:\n                    # assume that if color is passed in the user want\n                    # filled symbol, if the users want more control use\n                    # flierprops\n                    flierprops['color'] = color\n                    flierprops['markerfacecolor'] = color\n                    flierprops['markeredgecolor'] = color\n\n        # replace medians if necessary:\n        if usermedians is not None:\n            if (len(np.ravel(usermedians)) != len(bxpstats) or\n                    np.shape(usermedians)[0] != len(bxpstats)):\n                raise ValueError(\n                    \"'usermedians' and 'x' have different lengths\")\n            else:\n                # reassign medians as necessary\n                for stats, med in zip(bxpstats, usermedians):\n                    if med is not None:\n                        stats['med'] = med\n\n        if conf_intervals is not None:\n            if len(conf_intervals) != len(bxpstats):\n                raise ValueError(\n                    \"'conf_intervals' and 'x' have different lengths\")\n            else:\n                for stats, ci in zip(bxpstats, conf_intervals):\n                    if ci is not None:\n                        if len(ci) != 2:\n                            raise ValueError('each confidence interval must '\n                                             'have two values')\n                        else:\n                            if ci[0] is not None:\n                                stats['cilo'] = ci[0]\n                            if ci[1] is not None:\n                                stats['cihi'] = ci[1]\n\n        artists = self.bxp(bxpstats, positions=positions, widths=widths,\n                           vert=vert, patch_artist=patch_artist,\n                           shownotches=notch, showmeans=showmeans,\n                           showcaps=showcaps, showbox=showbox,\n                           boxprops=boxprops, flierprops=flierprops,\n                           medianprops=medianprops, meanprops=meanprops,\n                           meanline=meanline, showfliers=showfliers,\n                           capprops=capprops, whiskerprops=whiskerprops,\n                           manage_ticks=manage_ticks, zorder=zorder,\n                           capwidths=capwidths)\n        return artists", "source_start_line": 3713, "tokens": ["def", "boxplot", "(", "self", ",", "x", ",", "notch", "=", "None", ",", "sym", "=", "None", ",", "vert", "=", "None", ",", "whis", "=", "None", ",", "positions", "=", "None", ",", "widths", "=", "None", ",", "patch_artist", "=", "None", ",", "bootstrap", "=", "None", ",", "usermedians", "=", "None", ",", "conf_intervals", "=", "None", ",", "meanline", "=", "None", ",", "showmeans", "=", "None", ",", "showcaps", "=", "None", ",", "showbox", "=", "None", ",", "showfliers", "=", "None", ",", "boxprops", "=", "None", ",", "labels", "=", "None", ",", "flierprops", "=", "None", ",", "medianprops", "=", "None", ",", "meanprops", "=", "None", ",", "capprops", "=", "None", ",", "whiskerprops", "=", "None", ",", "manage_ticks", "=", "True", ",", "autorange", "=", "False", ",", "zorder", "=", "None", ",", "capwidths", "=", "None", ")", ":", "\"\"\"        Draw a box and whisker plot.        The box extends from the first quartile (Q1) to the third        quartile (Q3) of the data, with a line at the median. The        whiskers extend from the box to the farthest point within        1.5x the inter-quartile range (IQR) distance. Flier points        are those past the end of the whiskers.        See https://en.wikipedia.org/wiki/Box_plot for reference.        .. code-block:: none                  Q1-1.5IQR   Q1   median  Q3   Q3+1.5IQR                               |-----:-----|               o      |--------|     :     |--------|    o  o                               |-----:-----|             flier             <----------->            fliers                                    IQR        Parameters        ----------        x : Array or a sequence of vectors.            The input data.  If a 2D array, a boxplot is drawn for each column            in *x*.  If a sequence of 1D arrays, a boxplot is drawn for each            array in *x*.        notch : bool, default: False            Whether to draw a notched boxplot (`True`), or a rectangular            boxplot (`False`).  The notches represent the confidence interval            (CI) around the median.  The documentation for *bootstrap*            describes how the locations of the notches are computed by            default, but their locations may also be overridden by setting the            *conf_intervals* parameter.            .. note::                In cases where the values of the CI are less than the                lower quartile or greater than the upper quartile, the                notches will extend beyond the box, giving it a                distinctive \"flipped\" appearance. This is expected                behavior and consistent with other statistical                visualization packages.        sym : str, optional            The default symbol for flier points.  An empty string ('') hides            the fliers.  If `None`, then the fliers default to 'b+'.  More            control is provided by the *flierprops* parameter.        vert : bool, default: True            If `True`, draws vertical boxes.            If `False`, draw horizontal boxes.        whis : float or (float, float), default: 1.5            The position of the whiskers.            If a float, the lower whisker is at the lowest datum above            ``Q1 - whis*(Q3-Q1)``, and the upper whisker at the highest datum            below ``Q3 + whis*(Q3-Q1)``, where Q1 and Q3 are the first and            third quartiles.  The default value of ``whis = 1.5`` corresponds            to Tukey's original definition of boxplots.            If a pair of floats, they indicate the percentiles at which to            draw the whiskers (e.g., (5, 95)).  In particular, setting this to            (0, 100) results in whiskers covering the whole range of the data.            In the edge case where ``Q1 == Q3``, *whis* is automatically set            to (0, 100) (cover the whole range of the data) if *autorange* is            True.            Beyond the whiskers, data are considered outliers and are plotted            as individual points.        bootstrap : int, optional            Specifies whether to bootstrap the confidence intervals            around the median for notched boxplots. If *bootstrap* is            None, no bootstrapping is performed, and notches are            calculated using a Gaussian-based asymptotic approximation            (see McGill, R., Tukey, J.W., and Larsen, W.A., 1978, and            Kendall and Stuart, 1967). Otherwise, bootstrap specifies            the number of times to bootstrap the median to determine its            95% confidence intervals. Values between 1000 and 10000 are            recommended.        usermedians : 1D array-like, optional            A 1D array-like of length ``len(x)``.  Each entry that is not            `None` forces the value of the median for the corresponding            dataset.  For entries that are `None`, the medians are computed            by Matplotlib as normal.        conf_intervals : array-like, optional            A 2D array-like of shape ``(len(x), 2)``.  Each entry that is not            None forces the location of the corresponding notch (which is            only drawn if *notch* is `True`).  For entries that are `None`,            the notches are computed by the method specified by the other            parameters (e.g., *bootstrap*).        positions : array-like, optional            The positions of the boxes. The ticks and limits are            automatically set to match the positions. Defaults to            ``range(1, N+1)`` where N is the number of boxes to be drawn.        widths : float or array-like            The widths of the boxes.  The default is 0.5, or ``0.15*(distance            between extreme positions)``, if that is smaller.        patch_artist : bool, default: False            If `False` produces boxes with the Line2D artist. Otherwise,            boxes are drawn with Patch artists.        labels : sequence, optional            Labels for each dataset (one per dataset).        manage_ticks : bool, default: True            If True, the tick locations and labels will be adjusted to match            the boxplot positions.        autorange : bool, default: False            When `True` and the data are distributed such that the 25th and            75th percentiles are equal, *whis* is set to (0, 100) such            that the whisker ends are at the minimum and maximum of the data.        meanline : bool, default: False            If `True` (and *showmeans* is `True`), will try to render the            mean as a line spanning the full width of the box according to            *meanprops* (see below).  Not recommended if *shownotches* is also            True.  Otherwise, means will be shown as points.        zorder : float, default: ``Line2D.zorder = 2``            The zorder of the boxplot.        Returns        -------        dict          A dictionary mapping each component of the boxplot to a list          of the `.Line2D` instances created. That dictionary has the          following keys (assuming vertical boxplots):          - ``boxes``: the main body of the boxplot showing the            quartiles and the median's confidence intervals if            enabled.          - ``medians``: horizontal lines at the median of each box.          - ``whiskers``: the vertical lines extending to the most            extreme, non-outlier data points.          - ``caps``: the horizontal lines at the ends of the            whiskers.          - ``fliers``: points representing data that extend beyond            the whiskers (fliers).          - ``means``: points or lines representing the means.        Other Parameters        ----------------        showcaps : bool, default: True            Show the caps on the ends of whiskers.        showbox : bool, default: True            Show the central box.        showfliers : bool, default: True            Show the outliers beyond the caps.        showmeans : bool, default: False            Show the arithmetic means.        capprops : dict, default: None            The style of the caps.        capwidths : float or array, default: None            The widths of the caps.        boxprops : dict, default: None            The style of the box.        whiskerprops : dict, default: None            The style of the whiskers.        flierprops : dict, default: None            The style of the fliers.        medianprops : dict, default: None            The style of the median.        meanprops : dict, default: None            The style of the mean.        data : indexable object, optional            DATA_PARAMETER_PLACEHOLDER        See Also        --------        violinplot : Draw an estimate of the probability density function.        \"\"\"", "if", "whis", "is", "None", ":", "whis", "=", "mpl", ".", "rcParams", "[", "'boxplot.whiskers'", "]", "if", "bootstrap", "is", "None", ":", "bootstrap", "=", "mpl", ".", "rcParams", "[", "'boxplot.bootstrap'", "]", "bxpstats", "=", "cbook", ".", "boxplot_stats", "(", "x", ",", "whis", "=", "whis", ",", "bootstrap", "=", "bootstrap", ",", "labels", "=", "labels", ",", "autorange", "=", "autorange", ")", "if", "notch", "is", "None", ":", "notch", "=", "mpl", ".", "rcParams", "[", "'boxplot.notch'", "]", "if", "vert", "is", "None", ":", "vert", "=", "mpl", ".", "rcParams", "[", "'boxplot.vertical'", "]", "if", "patch_artist", "is", "None", ":", "patch_artist", "=", "mpl", ".", "rcParams", "[", "'boxplot.patchartist'", "]", "if", "meanline", "is", "None", ":", "meanline", "=", "mpl", ".", "rcParams", "[", "'boxplot.meanline'", "]", "if", "showmeans", "is", "None", ":", "showmeans", "=", "mpl", ".", "rcParams", "[", "'boxplot.showmeans'", "]", "if", "showcaps", "is", "None", ":", "showcaps", "=", "mpl", ".", "rcParams", "[", "'boxplot.showcaps'", "]", "if", "showbox", "is", "None", ":", "showbox", "=", "mpl", ".", "rcParams", "[", "'boxplot.showbox'", "]", "if", "showfliers", "is", "None", ":", "showfliers", "=", "mpl", ".", "rcParams", "[", "'boxplot.showfliers'", "]", "if", "boxprops", "is", "None", ":", "boxprops", "=", "{", "}", "if", "whiskerprops", "is", "None", ":", "whiskerprops", "=", "{", "}", "if", "capprops", "is", "None", ":", "capprops", "=", "{", "}", "if", "medianprops", "is", "None", ":", "medianprops", "=", "{", "}", "if", "meanprops", "is", "None", ":", "meanprops", "=", "{", "}", "if", "flierprops", "is", "None", ":", "flierprops", "=", "{", "}", "if", "patch_artist", ":", "boxprops", "[", "'linestyle'", "]", "=", "'solid'", "if", "'color'", "in", "boxprops", ":", "boxprops", "[", "'edgecolor'", "]", "=", "boxprops", ".", "pop", "(", "'color'", ")", "if", "sym", "is", "not", "None", ":", "if", "sym", "==", "''", ":", "flierprops", "=", "dict", "(", "linestyle", "=", "'none'", ",", "marker", "=", "''", ",", "color", "=", "'none'", ")", "showfliers", "=", "False", "else", ":", "_", ",", "marker", ",", "color", "=", "_process_plot_format", "(", "sym", ")", "if", "marker", "is", "not", "None", ":", "flierprops", "[", "'marker'", "]", "=", "marker", "if", "color", "is", "not", "None", ":", "flierprops", "[", "'color'", "]", "=", "color", "flierprops", "[", "'markerfacecolor'", "]", "=", "color", "flierprops", "[", "'markeredgecolor'", "]", "=", "color", "if", "usermedians", "is", "not", "None", ":", "if", "(", "len", "(", "np", ".", "ravel", "(", "usermedians", ")", ")", "!=", "len", "(", "bxpstats", ")", "or", "np", ".", "shape", "(", "usermedians", ")", "[", "0", "]", "!=", "len", "(", "bxpstats", ")", ")", ":", "raise", "ValueError", "(", "\"'usermedians' and 'x' have different lengths\"", ")", "else", ":", "for", "stats", ",", "med", "in", "zip", "(", "bxpstats", ",", "usermedians", ")", ":", "if", "med", "is", "not", "None", ":", "stats", "[", "'med'", "]", "=", "med", "if", "conf_intervals", "is", "not", "None", ":", "if", "len", "(", "conf_intervals", ")", "!=", "len", "(", "bxpstats", ")", ":", "raise", "ValueError", "(", "\"'conf_intervals' and 'x' have different lengths\"", ")", "else", ":", "for", "stats", ",", "ci", "in", "zip", "(", "bxpstats", ",", "conf_intervals", ")", ":", "if", "ci", "is", "not", "None", ":", "if", "len", "(", "ci", ")", "!=", "2", ":", "raise", "ValueError", "(", "'each confidence interval must '", "'have two values'", ")", "else", ":", "if", "ci", "[", "0", "]", "is", "not", "None", ":", "stats", "[", "'cilo'", "]", "=", "ci", "[", "0", "]", "if", "ci", "[", "1", "]", "is", "not", "None", ":", "stats", "[", "'cihi'", "]", "=", "ci", "[", "1", "]", "artists", "=", "self", ".", "bxp", "(", "bxpstats", ",", "positions", "=", "positions", ",", "widths", "=", "widths", ",", "vert", "=", "vert", ",", "patch_artist", "=", "patch_artist", ",", "shownotches", "=", "notch", ",", "showmeans", "=", "showmeans", ",", "showcaps", "=", "showcaps", ",", "showbox", "=", "showbox", ",", "boxprops", "=", "boxprops", ",", "flierprops", "=", "flierprops", ",", "medianprops", "=", "medianprops", ",", "meanprops", "=", "meanprops", ",", "meanline", "=", "meanline", ",", "showfliers", "=", "showfliers", ",", "capprops", "=", "capprops", ",", "whiskerprops", "=", "whiskerprops", ",", "manage_ticks", "=", "manage_ticks", ",", "zorder", "=", "zorder", ",", "capwidths", "=", "capwidths", ")", "return", "artists"], "to_mask": {"VAR": ["_", "artists", "autorange", "bootstrap", "boxprops", "bxpstats", "capprops", "capwidths", "ci", "color", "conf_intervals", "flierprops", "labels", "manage_ticks", "marker", "meanline", "meanprops", "med", "medianprops", "notch", "patch_artist", "positions", "self", "showbox", "showcaps", "showfliers", "showmeans", "stats", "sym", "usermedians", "vert", "whis", "whiskerprops", "widths", "x", "zorder"], "METHOD": ["ValueError", "_process_plot_format", "boxplot_stats", "bxp", "dict", "len", "pop", "ravel", "shape", "zip"]}, "attention_idx_tokens": [null, null], "patch": "@@ -3723,9 +3723,10 @@\n         Draw a box and whisker plot.\n \n         The box extends from the first quartile (Q1) to the third\n-        quartile (Q3) of the data, with a line at the median.  The\n-        whiskers extend from the box by 1.5x the inter-quartile range\n-        (IQR).  Flier points are those past the end of the whiskers.\n+        quartile (Q3) of the data, with a line at the median. The\n+        whiskers extend from the box to the farthest point within\n+        1.5x the inter-quartile range (IQR) distance. Flier points\n+        are those past the end of the whiskers.", "ext_attention_idx_tokens": [null, null], "uid": "899437bb", "question": "also, is it the farthest data point and hence why you said \"farthest point\"? ", "code": "def boxplot self x notch None sym None vert None whis None positions None widths None patch artist None bootstrap None usermedians None conf intervals None meanline None showmeans None showcaps None showbox None showfliers None boxprops None labels None flierprops None medianprops None meanprops None capprops None whiskerprops None manage ticks True autorange False zorder None capwidths None \"\"\" Draw a box and whisker plot The box extends from the first quartile Q1 to the third quartile Q3 of the data with a line at the median The whiskers extend from the box to the farthest point within 1 5x the inter-quartile range IQR distance Flier points are those past the end of the whiskers See https en wikipedia org wiki Box plot for reference code-block none Q1-1 5IQR Q1 median Q3 Q3+1 5IQR |----- -----| o |--------| |--------| o o |----- -----| flier <-----------> fliers IQR Parameters ---------- x Array or a sequence of vectors The input data If a 2D array a boxplot is drawn for each column in *x* If a sequence of 1D arrays a boxplot is drawn for each array in *x* notch bool default False Whether to draw a notched boxplot `True` or a rectangular boxplot `False` The notches represent the confidence interval CI around the median The documentation for *bootstrap* describes how the locations of the notches are computed by default but their locations may also be overridden by setting the *conf intervals* parameter note In cases where the values of the CI are less than the lower quartile or greater than the upper quartile the notches will extend beyond the box giving it a distinctive \"flipped\" appearance This is expected behavior and consistent with other statistical visualization packages sym str optional The default symbol for flier points An empty string hides the fliers If `None` then the fliers default to b+ More control is provided by the *flierprops* parameter vert bool default True If `True` draws vertical boxes If `False` draw horizontal boxes whis float or float float default 1 5 The position of the whiskers If a float the lower whisker is at the lowest datum above ``Q1 - whis* Q3-Q1 `` and the upper whisker at the highest datum below ``Q3 + whis* Q3-Q1 `` where Q1 and Q3 are the first and third quartiles The default value of ``whis 1 5`` corresponds to Tukey s original definition of boxplots If a pair of floats they indicate the percentiles at which to draw the whiskers e g 5 95 In particular setting this to 0 100 results in whiskers covering the whole range of the data In the edge case where ``Q1 Q3`` *whis* is automatically set to 0 100 cover the whole range of the data if *autorange* is True Beyond the whiskers data are considered outliers and are plotted as individual points bootstrap int optional Specifies whether to bootstrap the confidence intervals around the median for notched boxplots If *bootstrap* is None no bootstrapping is performed and notches are calculated using a Gaussian-based asymptotic approximation see McGill R Tukey J W and Larsen W A 1978 and Kendall and Stuart 1967 Otherwise bootstrap specifies the number of times to bootstrap the median to determine its 95% confidence intervals Values between 1000 and 10000 are recommended usermedians 1D array-like optional A 1D array-like of length ``len x `` Each entry that is not `None` forces the value of the median for the corresponding dataset For entries that are `None` the medians are computed by Matplotlib as normal conf intervals array-like optional A 2D array-like of shape `` len x 2 `` Each entry that is not None forces the location of the corresponding notch which is only drawn if *notch* is `True` For entries that are `None` the notches are computed by the method specified by the other parameters e g *bootstrap* positions array-like optional The positions of the boxes The ticks and limits are automatically set to match the positions Defaults to ``range 1 N+1 `` where N is the number of boxes to be drawn widths float or array-like The widths of the boxes The default is 0 5 or ``0 15* distance between extreme positions `` if that is smaller patch artist bool default False If `False` produces boxes with the Line2D artist Otherwise boxes are drawn with Patch artists labels sequence optional Labels for each dataset one per dataset manage ticks bool default True If True the tick locations and labels will be adjusted to match the boxplot positions autorange bool default False When `True` and the data are distributed such that the 25th and 75th percentiles are equal *whis* is set to 0 100 such that the whisker ends are at the minimum and maximum of the data meanline bool default False If `True` and *showmeans* is `True` will try to render the mean as a line spanning the full width of the box according to *meanprops* see below Not recommended if *shownotches* is also True Otherwise means will be shown as points zorder float default ``Line2D zorder 2`` The zorder of the boxplot Returns ------- dict A dictionary mapping each component of the boxplot to a list of the ` Line2D` instances created That dictionary has the following keys assuming vertical boxplots - ``boxes`` the main body of the boxplot showing the quartiles and the median s confidence intervals if enabled - ``medians`` horizontal lines at the median of each box - ``whiskers`` the vertical lines extending to the most extreme non-outlier data points - ``caps`` the horizontal lines at the ends of the whiskers - ``fliers`` points representing data that extend beyond the whiskers fliers - ``means`` points or lines representing the means Other Parameters ---------------- showcaps bool default True Show the caps on the ends of whiskers showbox bool default True Show the central box showfliers bool default True Show the outliers beyond the caps showmeans bool default False Show the arithmetic means capprops dict default None The style of the caps capwidths float or array default None The widths of the caps boxprops dict default None The style of the box whiskerprops dict default None The style of the whiskers flierprops dict default None The style of the fliers medianprops dict default None The style of the median meanprops dict default None The style of the mean data indexable object optional DATA PARAMETER PLACEHOLDER See Also -------- violinplot Draw an estimate of the probability density function \"\"\" # Missing arguments default to rcParams if whis is None whis mpl rcParams[ boxplot whiskers ] if bootstrap is None bootstrap mpl rcParams[ boxplot bootstrap ] bxpstats cbook boxplot stats x whis whis bootstrap bootstrap labels labels autorange autorange if notch is None notch mpl rcParams[ boxplot notch ] if vert is None vert mpl rcParams[ boxplot vertical ] if patch artist is None patch artist mpl rcParams[ boxplot patchartist ] if meanline is None meanline mpl rcParams[ boxplot meanline ] if showmeans is None showmeans mpl rcParams[ boxplot showmeans ] if showcaps is None showcaps mpl rcParams[ boxplot showcaps ] if showbox is None showbox mpl rcParams[ boxplot showbox ] if showfliers is None showfliers mpl rcParams[ boxplot showfliers ] if boxprops is None boxprops {} if whiskerprops is None whiskerprops {} if capprops is None capprops {} if medianprops is None medianprops {} if meanprops is None meanprops {} if flierprops is None flierprops {} if patch artist boxprops[ linestyle ] solid # Not consistent with bxp if color in boxprops boxprops[ edgecolor ] boxprops pop color # if non-default sym value put it into the flier dictionary # the logic for providing the default symbol b+ now lives # in bxp in the initial value of flierkw # handle all of the *sym* related logic here so we only have to pass # on the flierprops dict if sym is not None # no-flier case which should really be done with # showfliers False but none-the-less deal with it to keep back # compatibility if sym # blow away existing dict and make one for invisible markers flierprops dict linestyle none marker color none # turn the fliers off just to be safe showfliers False # now process the symbol string else # process the symbol string # discarded linestyle marker color process plot format sym # if we have a marker use it if marker is not None flierprops[ marker ] marker # if we have a color use it if color is not None # assume that if color is passed in the user want # filled symbol if the users want more control use # flierprops flierprops[ color ] color flierprops[ markerfacecolor ] color flierprops[ markeredgecolor ] color # replace medians if necessary if usermedians is not None if len np ravel usermedians ! len bxpstats or np shape usermedians [0] ! len bxpstats raise ValueError \" usermedians and x have different lengths\" else # reassign medians as necessary for stats med in zip bxpstats usermedians if med is not None stats[ med ] med if conf intervals is not None if len conf intervals ! len bxpstats raise ValueError \" conf intervals and x have different lengths\" else for stats ci in zip bxpstats conf intervals if ci is not None if len ci ! 2 raise ValueError each confidence interval must have two values else if ci[0] is not None stats[ cilo ] ci[0] if ci[1] is not None stats[ cihi ] ci[1] artists self bxp bxpstats positions positions widths widths vert vert patch artist patch artist shownotches notch showmeans showmeans showcaps showcaps showbox showbox boxprops boxprops flierprops flierprops medianprops medianprops meanprops meanprops meanline meanline showfliers showfliers capprops capprops whiskerprops whiskerprops manage ticks manage ticks zorder zorder capwidths capwidths return artists"}
{"message": "ping @oscargus here?", "timestamp": "2023-02-03T08:21:25Z", "file_name": "lib/matplotlib/axis.py", "range": {"start_line": 1165, "end_line": 1165, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1095472023", "html_url": "https://github.com/matplotlib/matplotlib/pull/24983#discussion_r1095472023", "attention_area": "    def _get_axis_name(self):", "file_path": "files/56/02/00000256.py", "old_file_path": "files/57/02/00000257.py", "filters": {"comment_message": false, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1154,6 +1162,11 @@ def set_default_intervals(self):\n         # attribute, and the derived code below will check for that\n         # and use it if it's available (else just use 0..1)\n \n+    def _get_axis_name(self):", "source": "def _get_axis_name(self):\n        \"\"\"Return the axis name.\"\"\"\n        return [name for name, axis in self.axes._axis_map.items()\n                if axis is self][0]", "source_start_line": 1165, "tokens": ["def", "_get_axis_name", "(", "self", ")", ":", "\"\"\"Return the axis name.\"\"\"", "return", "[", "name", "for", "name", ",", "axis", "in", "self", ".", "axes", ".", "_axis_map", ".", "items", "(", ")", "if", "axis", "is", "self", "]", "[", "0", "]"], "to_mask": {"VAR": ["axis", "name", "self"], "METHOD": ["items"]}, "attention_idx_tokens": [0, 5], "patch": "@@ -1154,6 +1162,11 @@\n         # attribute, and the derived code below will check for that\n         # and use it if it's available (else just use 0..1)\n \n+    def _get_axis_name(self):", "ext_attention_idx_tokens": [0, 31], "uid": "c35e1ed7", "question": "ping @oscargus here?", "code": "def get axis name self \"\"\"Return the axis name \"\"\" return [name for name axis in self axes axis map items if axis is self][0]"}
{"message": "Again, not a problem if thats how the rest of the tests are in this file - definitely an idiosyncratic structure!  OTOH, are we sure we don't want this in `test_backend_tools.py`?  ", "timestamp": "2023-02-08T15:09:34Z", "file_name": "lib/matplotlib/tests/test_backend_tk.py", "range": {"start_line": 193, "end_line": 193, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1100271585", "html_url": "https://github.com/matplotlib/matplotlib/pull/25174#discussion_r1100271585", "attention_area": "", "file_path": "files/79/02/00000279.py", "old_file_path": "files/80/02/00000280.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -177,6 +177,42 @@ def test_never_update():\n     # checks them.\n \n \n+@pytest.mark.backend('TkAgg', skip_on_importerror=True)\n+@_isolated_tk_test(success_count=1)\n+def test_toolbar_button_la_mode_icon():\n+    # test that icon in LA mode can be used for buttons\n+    # see GH#25164\n+    import tempfile\n+    import warnings\n+\n+    from PIL import Image\n+\n+    import matplotlib\n+    import matplotlib.pyplot as plt\n+    from matplotlib.backend_tools import ToolToggleBase\n+", "source": "def test_toolbar_button_la_mode_icon():\n    # test that icon in LA mode can be used for buttons\n    # see GH#25164\n    import tempfile\n    import warnings\n\n    from PIL import Image\n\n    import matplotlib\n    import matplotlib.pyplot as plt\n    from matplotlib.backend_tools import ToolToggleBase\n\n    # tweaking toolbar raises an UserWarning\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", UserWarning)\n        matplotlib.rcParams[\"toolbar\"] = \"toolmanager\"\n\n    # create an icon in LA mode\n    with tempfile.TemporaryDirectory() as tempdir:\n        img = Image.new(\"LA\", (26, 26))\n        tmp_img_path = os.path.join(tempdir, \"test_la_icon.png\")\n        img.save(tmp_img_path)\n\n        class CustomTool(ToolToggleBase):\n            image = tmp_img_path\n\n        fig = plt.figure()\n        toolmanager = fig.canvas.manager.toolmanager\n        toolbar = fig.canvas.manager.toolbar\n        toolmanager.add_tool(\"test\", CustomTool)\n        toolbar.add_tool(\"test\", \"group\")\n        print(\"success\")", "source_start_line": 182, "tokens": ["def", "test_toolbar_button_la_mode_icon", "(", ")", ":", "import", "tempfile", "import", "warnings", "from", "PIL", "import", "Image", "import", "matplotlib", "import", "matplotlib", ".", "pyplot", "as", "plt", "from", "matplotlib", ".", "backend_tools", "import", "ToolToggleBase", "with", "warnings", ".", "catch_warnings", "(", ")", ":", "warnings", ".", "simplefilter", "(", "\"ignore\"", ",", "UserWarning", ")", "matplotlib", ".", "rcParams", "[", "\"toolbar\"", "]", "=", "\"toolmanager\"", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tempdir", ":", "img", "=", "Image", ".", "new", "(", "\"LA\"", ",", "(", "26", ",", "26", ")", ")", "tmp_img_path", "=", "os", ".", "path", ".", "join", "(", "tempdir", ",", "\"test_la_icon.png\"", ")", "img", ".", "save", "(", "tmp_img_path", ")", "class", "CustomTool", "(", "ToolToggleBase", ")", ":", "image", "=", "tmp_img_path", "fig", "=", "plt", ".", "figure", "(", ")", "toolmanager", "=", "fig", ".", "canvas", ".", "manager", ".", "toolmanager", "toolbar", "=", "fig", ".", "canvas", ".", "manager", ".", "toolbar", "toolmanager", ".", "add_tool", "(", "\"test\"", ",", "CustomTool", ")", "toolbar", ".", "add_tool", "(", "\"test\"", ",", "\"group\"", ")", "print", "(", "\"success\"", ")"], "to_mask": {"VAR": ["fig", "image", "img", "tempdir", "tmp_img_path", "toolbar", "toolmanager"], "METHOD": ["TemporaryDirectory", "add_tool", "catch_warnings", "figure", "join", "new", "print", "save", "simplefilter"]}, "attention_idx_tokens": [null, null], "patch": "@@ -177,6 +177,42 @@\n     # checks them.\n \n \n+@pytest.mark.backend('TkAgg', skip_on_importerror=True)\n+@_isolated_tk_test(success_count=1)\n+def test_toolbar_button_la_mode_icon():\n+    # test that icon in LA mode can be used for buttons\n+    # see GH#25164\n+    import tempfile\n+    import warnings\n+\n+    from PIL import Image\n+\n+    import matplotlib\n+    import matplotlib.pyplot as plt\n+    from matplotlib.backend_tools import ToolToggleBase\n+", "ext_attention_idx_tokens": [0, 144], "uid": "983e4ae3", "question": "Again, not a problem if thats how the rest of the tests are in this file - definitely an idiosyncratic structure!  OTOH, are we sure we don't want this in `test_backend_tools.py`?  ", "code": "def test toolbar button la mode icon # test that icon in LA mode can be used for buttons # see GH#25164 import tempfile import warnings from PIL import Image import matplotlib import matplotlib pyplot as plt from matplotlib backend tools import ToolToggleBase # tweaking toolbar raises an UserWarning with warnings catch warnings warnings simplefilter \"ignore\" UserWarning matplotlib rcParams[\"toolbar\"] \"toolmanager\" # create an icon in LA mode with tempfile TemporaryDirectory as tempdir img Image new \"LA\" 26 26 tmp img path os path join tempdir \"test la icon png\" img save tmp img path class CustomTool ToolToggleBase image tmp img path fig plt figure toolmanager fig canvas manager toolmanager toolbar fig canvas manager toolbar toolmanager add tool \"test\" CustomTool toolbar add tool \"test\" \"group\" print \"success\""}
{"message": "Just to check, this changes an E result to a F result?", "timestamp": "2023-02-09T19:03:56Z", "file_name": "lib/matplotlib/tests/test_backends_interactive.py", "range": {"start_line": 203, "end_line": 203, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1101906344", "html_url": "https://github.com/matplotlib/matplotlib/pull/25174#discussion_r1101906344", "attention_area": "    except subprocess.CalledProcessError as err:", "file_path": "files/07/03/00000307.py", "old_file_path": "files/08/03/00000308.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -168,11 +193,17 @@ def test_interactive_backend(env, toolbar):\n             pytest.skip(\"toolmanager is not implemented for macosx.\")\n     if env[\"MPLBACKEND\"] == \"wx\":\n         pytest.skip(\"wx backend is deprecated; tests failed on appveyor\")\n-    proc = _run_helper(_test_interactive_impl,\n-                       json.dumps({\"toolbar\": toolbar}),\n-                       timeout=_test_timeout,\n-                       extra_env=env)\n-\n+    try:\n+        proc = _run_helper(\n+                _test_interactive_impl,\n+                json.dumps({\"toolbar\": toolbar}),\n+                timeout=_test_timeout,\n+                extra_env=env,\n+                )\n+    except subprocess.CalledProcessError as err:", "source": "def test_interactive_backend(env, toolbar):\n    if env[\"MPLBACKEND\"] == \"macosx\":\n        if toolbar == \"toolmanager\":\n            pytest.skip(\"toolmanager is not implemented for macosx.\")\n    if env[\"MPLBACKEND\"] == \"wx\":\n        pytest.skip(\"wx backend is deprecated; tests failed on appveyor\")\n    try:\n        proc = _run_helper(\n                _test_interactive_impl,\n                json.dumps({\"toolbar\": toolbar}),\n                timeout=_test_timeout,\n                extra_env=env,\n                )\n    except subprocess.CalledProcessError as err:\n        pytest.fail(\n                \"Subprocess failed to test intended behavior\\n\"\n                + str(err.stderr))\n    assert proc.stdout.count(\"CloseEvent\") == 1", "source_start_line": 190, "tokens": ["def", "test_interactive_backend", "(", "env", ",", "toolbar", ")", ":", "if", "env", "[", "\"MPLBACKEND\"", "]", "==", "\"macosx\"", ":", "if", "toolbar", "==", "\"toolmanager\"", ":", "pytest", ".", "skip", "(", "\"toolmanager is not implemented for macosx.\"", ")", "if", "env", "[", "\"MPLBACKEND\"", "]", "==", "\"wx\"", ":", "pytest", ".", "skip", "(", "\"wx backend is deprecated; tests failed on appveyor\"", ")", "try", ":", "proc", "=", "_run_helper", "(", "_test_interactive_impl", ",", "json", ".", "dumps", "(", "{", "\"toolbar\"", ":", "toolbar", "}", ")", ",", "timeout", "=", "_test_timeout", ",", "extra_env", "=", "env", ",", ")", "except", "subprocess", ".", "CalledProcessError", "as", "err", ":", "pytest", ".", "fail", "(", "\"Subprocess failed to test intended behavior\\n\"", "+", "str", "(", "err", ".", "stderr", ")", ")", "assert", "proc", ".", "stdout", ".", "count", "(", "\"CloseEvent\"", ")", "==", "1"], "to_mask": {"VAR": ["env", "err", "proc", "toolbar"], "METHOD": ["_run_helper", "count", "dumps", "fail", "skip", "str"]}, "attention_idx_tokens": [69, 75], "patch": "@@ -168,11 +193,17 @@\n             pytest.skip(\"toolmanager is not implemented for macosx.\")\n     if env[\"MPLBACKEND\"] == \"wx\":\n         pytest.skip(\"wx backend is deprecated; tests failed on appveyor\")\n-    proc = _run_helper(_test_interactive_impl,\n-                       json.dumps({\"toolbar\": toolbar}),\n-                       timeout=_test_timeout,\n-                       extra_env=env)\n-\n+    try:\n+        proc = _run_helper(\n+                _test_interactive_impl,\n+                json.dumps({\"toolbar\": toolbar}),\n+                timeout=_test_timeout,\n+                extra_env=env,\n+                )\n+    except subprocess.CalledProcessError as err:", "ext_attention_idx_tokens": [41, 99], "uid": "17f179de", "question": "Just to check, this changes an E result to a F result?", "code": "def test interactive backend env toolbar if env[\"MPLBACKEND\"] \"macosx\" if toolbar \"toolmanager\" pytest skip \"toolmanager is not implemented for macosx \" if env[\"MPLBACKEND\"] \"wx\" pytest skip \"wx backend is deprecated; tests failed on appveyor\" try proc run helper test interactive impl json dumps {\"toolbar\" toolbar} timeout test timeout extra env env except subprocess CalledProcessError as err pytest fail \"Subprocess failed to test intended behavior\\n\" + str err stderr assert proc stdout count \"CloseEvent\" 1"}
{"message": "Is there a reason `mpl_round` doesn't work here?  Does `mpl_round` handle 0.5 differently?  ", "timestamp": "2023-02-13T17:17:28Z", "file_name": "src/mplutils.h", "range": {"start_line": 39, "end_line": 39, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1104792840", "html_url": "https://github.com/matplotlib/matplotlib/pull/25207#discussion_r1104792840", "attention_area": "    return (double)mpl_round_to_int(v);", "file_path": "files/29/03/00000329.h", "old_file_path": "files/30/03/00000330.h", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": true}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -29,9 +29,14 @@\n #endif\n \n \n+inline int mpl_round_to_int(double v)\n+{\n+    return (int)(v + ((v >= 0.0) ? 0.5 : -0.5));\n+}\n+\n inline double mpl_round(double v)\n {\n-    return (double)(int)(v + ((v >= 0.0) ? 0.5 : -0.5));\n+    return (double)mpl_round_to_int(v);", "source": "inline double mpl_round(double v)\n{\n    return (double)mpl_round_to_int(v);\n}", "source_start_line": 37, "tokens": ["inline", "double", "mpl_round", "(", "double", "v", ")", "{", "return", "(", "double", ")", "mpl_round_to_int", "(", "v", ")", ";", "}"], "to_mask": {"VAR": ["v"], "METHOD": ["mpl_round_to_int"]}, "attention_idx_tokens": [8, 16], "patch": "@@ -29,9 +29,14 @@\n #endif\n \n \n+inline int mpl_round_to_int(double v)\n+{\n+    return (int)(v + ((v >= 0.0) ? 0.5 : -0.5));\n+}\n+\n inline double mpl_round(double v)\n {\n-    return (double)(int)(v + ((v >= 0.0) ? 0.5 : -0.5));\n+    return (double)mpl_round_to_int(v);", "ext_attention_idx_tokens": [0, 17], "uid": "d90d405e", "question": "Is there a reason `mpl_round` doesn't work here?  Does `mpl_round` handle 0.5 differently?  ", "code": "inline double mpl round double v { return double mpl round to int v ; }"}
{"message": "This is now fixed. I wonder if one should do something similar for the other locators?", "timestamp": "2023-02-26T10:37:29Z", "file_name": "lib/matplotlib/ticker.py", "range": {"start_line": 2457, "end_line": 2457, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1118060261", "html_url": "https://github.com/matplotlib/matplotlib/pull/24991#discussion_r1118060261", "attention_area": "                for other_ax in [*ax._shared_axes[\"x\"].get_siblings(ax),", "file_path": "files/03/04/00000403.py", "old_file_path": "files/05/04/00000405.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -2451,7 +2451,17 @@ def nonsingular(self, vmin, vmax):\n                 \"log-scaled.\")\n             vmin, vmax = 1, 10\n         else:\n-            minpos = self.axis.get_minpos()\n+            ax = self.axis.axes\n+            shared_axises = [\n+                other_axis\n+                for other_ax in [*ax._shared_axes[\"x\"].get_siblings(ax),", "source": "def nonsingular(self, vmin, vmax):\n        if vmin > vmax:\n            vmin, vmax = vmax, vmin\n        if not np.isfinite(vmin) or not np.isfinite(vmax):\n            vmin, vmax = 1, 10  # Initial range, no data plotted yet.\n        elif vmax <= 0:\n            _api.warn_external(\n                \"Data has no positive values, and therefore cannot be \"\n                \"log-scaled.\")\n            vmin, vmax = 1, 10\n        else:\n            ax = self.axis.axes\n            shared_axises = [\n                other_axis\n                for other_ax in [*ax._shared_axes[\"x\"].get_siblings(ax),\n                                 *ax._shared_axes[\"y\"].get_siblings(ax),\n                                 *ax._shared_axes[\"z\"].get_siblings(ax)]\n                for other_axis in other_ax._axis_map.values()\n                if other_axis.get_major_locator() is self]\n            minpos = min((\n                self.axis.get_minpos(),\n                * (other_axis.get_minpos() for other_axis in shared_axises)))\n            if not np.isfinite(minpos):\n                minpos = 1e-300  # This should never take effect.\n            if vmin <= 0:\n                vmin = minpos\n            if vmin == vmax:\n                vmin = _decade_less(vmin, self._base)\n                vmax = _decade_greater(vmax, self._base)\n        return vmin, vmax", "source_start_line": 2443, "tokens": ["def", "nonsingular", "(", "self", ",", "vmin", ",", "vmax", ")", ":", "if", "vmin", ">", "vmax", ":", "vmin", ",", "vmax", "=", "vmax", ",", "vmin", "if", "not", "np", ".", "isfinite", "(", "vmin", ")", "or", "not", "np", ".", "isfinite", "(", "vmax", ")", ":", "vmin", ",", "vmax", "=", "1", ",", "10", "elif", "vmax", "<=", "0", ":", "_api", ".", "warn_external", "(", "\"Data has no positive values, and therefore cannot be \"", "\"log-scaled.\"", ")", "vmin", ",", "vmax", "=", "1", ",", "10", "else", ":", "ax", "=", "self", ".", "axis", ".", "axes", "shared_axises", "=", "[", "other_axis", "for", "other_ax", "in", "[", "*", "ax", ".", "_shared_axes", "[", "\"x\"", "]", ".", "get_siblings", "(", "ax", ")", ",", "*", "ax", ".", "_shared_axes", "[", "\"y\"", "]", ".", "get_siblings", "(", "ax", ")", ",", "*", "ax", ".", "_shared_axes", "[", "\"z\"", "]", ".", "get_siblings", "(", "ax", ")", "]", "for", "other_axis", "in", "other_ax", ".", "_axis_map", ".", "values", "(", ")", "if", "other_axis", ".", "get_major_locator", "(", ")", "is", "self", "]", "minpos", "=", "min", "(", "(", "self", ".", "axis", ".", "get_minpos", "(", ")", ",", "*", "(", "other_axis", ".", "get_minpos", "(", ")", "for", "other_axis", "in", "shared_axises", ")", ")", ")", "if", "not", "np", ".", "isfinite", "(", "minpos", ")", ":", "minpos", "=", "1e-300", "if", "vmin", "<=", "0", ":", "vmin", "=", "minpos", "if", "vmin", "==", "vmax", ":", "vmin", "=", "_decade_less", "(", "vmin", ",", "self", ".", "_base", ")", "vmax", "=", "_decade_greater", "(", "vmax", ",", "self", ".", "_base", ")", "return", "vmin", ",", "vmax"], "to_mask": {"VAR": ["ax", "minpos", "self", "shared_axises", "vmax", "vmin"], "METHOD": ["_decade_greater", "_decade_less", "get_major_locator", "get_minpos", "get_siblings", "isfinite", "min", "values", "warn_external"]}, "attention_idx_tokens": [78, 94], "patch": "@@ -2451,7 +2451,17 @@\n                 \"log-scaled.\")\n             vmin, vmax = 1, 10\n         else:\n-            minpos = self.axis.get_minpos()\n+            ax = self.axis.axes\n+            shared_axises = [\n+                other_axis\n+                for other_ax in [*ax._shared_axes[\"x\"].get_siblings(ax),", "ext_attention_idx_tokens": [67, 175], "uid": "a674222f", "question": "This is now fixed. I wonder if one should do something similar for the other locators?", "code": "def nonsingular self vmin vmax if vmin > vmax vmin vmax vmax vmin if not np isfinite vmin or not np isfinite vmax vmin vmax 1 10 # Initial range no data plotted yet elif vmax < 0 api warn external \"Data has no positive values and therefore cannot be \" \"log-scaled \" vmin vmax 1 10 else ax self axis axes shared axises [ other axis for other ax in [*ax shared axes[\"x\"] get siblings ax *ax shared axes[\"y\"] get siblings ax *ax shared axes[\"z\"] get siblings ax ] for other axis in other ax axis map values if other axis get major locator is self] minpos min self axis get minpos * other axis get minpos for other axis in shared axises if not np isfinite minpos minpos 1e-300 # This should never take effect if vmin < 0 vmin minpos if vmin vmax vmin decade less vmin self base vmax decade greater vmax self base return vmin vmax"}
{"message": "It only gets triggered when dragging a legend, afaik mpl isn't testing any interactivity, is it?", "timestamp": "2023-03-10T16:58:42Z", "file_name": "lib/matplotlib/legend.py", "range": {"start_line": 80, "end_line": 80, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1132625776", "html_url": "https://github.com/matplotlib/matplotlib/pull/25428#discussion_r1132625776", "attention_area": "            self._update_bbox_to_anchor(self.get_loc_in_canvas())", "file_path": "files/25/04/00000425.py", "old_file_path": "files/74/04/00000474.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -77,7 +77,7 @@ def finalize_offset(self):\n         if self._update == \"loc\":\n             self._update_loc(self.get_loc_in_canvas())\n         elif self._update == \"bbox\":\n-            self._bbox_to_anchor(self.get_loc_in_canvas())\n+            self._update_bbox_to_anchor(self.get_loc_in_canvas())", "source": "def finalize_offset(self):\n        if self._update == \"loc\":\n            self._update_loc(self.get_loc_in_canvas())\n        elif self._update == \"bbox\":\n            self._update_bbox_to_anchor(self.get_loc_in_canvas())", "source_start_line": 76, "tokens": ["def", "finalize_offset", "(", "self", ")", ":", "if", "self", ".", "_update", "==", "\"loc\"", ":", "self", ".", "_update_loc", "(", "self", ".", "get_loc_in_canvas", "(", ")", ")", "elif", "self", ".", "_update", "==", "\"bbox\"", ":", "self", ".", "_update_bbox_to_anchor", "(", "self", ".", "get_loc_in_canvas", "(", ")", ")"], "to_mask": {"VAR": ["self"], "METHOD": ["_update_bbox_to_anchor", "_update_loc", "get_loc_in_canvas"]}, "attention_idx_tokens": [30, 39], "patch": "@@ -77,7 +77,7 @@\n         if self._update == \"loc\":\n             self._update_loc(self.get_loc_in_canvas())\n         elif self._update == \"bbox\":\n-            self._bbox_to_anchor(self.get_loc_in_canvas())\n+            self._update_bbox_to_anchor(self.get_loc_in_canvas())", "ext_attention_idx_tokens": [30, 39], "uid": "8d5659c9", "question": "It only gets triggered when dragging a legend, afaik mpl isn't testing any interactivity, is it?", "code": "def finalize offset self if self update \"loc\" self update loc self get loc in canvas elif self update \"bbox\" self update bbox to anchor self get loc in canvas"}
{"message": "Why would we?", "timestamp": "2023-03-13T20:18:58Z", "file_name": "lib/matplotlib/offsetbox.py", "range": {"start_line": 1504, "end_line": 1504, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1134571784", "html_url": "https://github.com/matplotlib/matplotlib/pull/25442#discussion_r1134571784", "attention_area": "        self._disconnectors = [", "file_path": "files/88/04/00000488.py", "old_file_path": "files/89/04/00000489.py", "filters": {"comment_message": false, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1500,16 +1500,23 @@ def __init__(self, ref_artist, use_blit=False):\n             ref_artist.set_picker(True)\n         self.got_artist = False\n         self._use_blit = use_blit and self.canvas.supports_blit\n-        self.cids = [\n-            self.canvas.callbacks._connect_picklable(\n-                'pick_event', self.on_pick),\n-            self.canvas.callbacks._connect_picklable(\n-                'button_release_event', self.on_release),\n+        callbacks = ref_artist.figure._canvas_callbacks\n+        self._disconnectors = [", "source": "def __init__(self, ref_artist, use_blit=False):\n        self.ref_artist = ref_artist\n        if not ref_artist.pickable():\n            ref_artist.set_picker(True)\n        self.got_artist = False\n        self._use_blit = use_blit and self.canvas.supports_blit\n        callbacks = ref_artist.figure._canvas_callbacks\n        self._disconnectors = [\n            functools.partial(\n                callbacks.disconnect, callbacks._connect_picklable(name, func))\n            for name, func in [\n                (\"pick_event\", self.on_pick),\n                (\"button_release_event\", self.on_release),\n                (\"motion_notify_event\", self.on_motion),\n            ]\n        ]", "source_start_line": 1497, "tokens": ["def", "__init__", "(", "self", ",", "ref_artist", ",", "use_blit", "=", "False", ")", ":", "self", ".", "ref_artist", "=", "ref_artist", "if", "not", "ref_artist", ".", "pickable", "(", ")", ":", "ref_artist", ".", "set_picker", "(", "True", ")", "self", ".", "got_artist", "=", "False", "self", ".", "_use_blit", "=", "use_blit", "and", "self", ".", "canvas", ".", "supports_blit", "callbacks", "=", "ref_artist", ".", "figure", ".", "_canvas_callbacks", "self", ".", "_disconnectors", "=", "[", "functools", ".", "partial", "(", "callbacks", ".", "disconnect", ",", "callbacks", ".", "_connect_picklable", "(", "name", ",", "func", ")", ")", "for", "name", ",", "func", "in", "[", "(", "\"pick_event\"", ",", "self", ".", "on_pick", ")", ",", "(", "\"button_release_event\"", ",", "self", ".", "on_release", ")", ",", "(", "\"motion_notify_event\"", ",", "self", ".", "on_motion", ")", ",", "]", "]"], "to_mask": {"VAR": ["_disconnectors", "_use_blit", "callbacks", "func", "got_artist", "name", "ref_artist", "self", "use_blit"], "METHOD": ["_connect_picklable", "partial", "pickable", "set_picker"]}, "attention_idx_tokens": [54, 58], "patch": "@@ -1500,16 +1500,23 @@\n             ref_artist.set_picker(True)\n         self.got_artist = False\n         self._use_blit = use_blit and self.canvas.supports_blit\n-        self.cids = [\n-            self.canvas.callbacks._connect_picklable(\n-                'pick_event', self.on_pick),\n-            self.canvas.callbacks._connect_picklable(\n-                'button_release_event', self.on_release),\n+        callbacks = ref_artist.figure._canvas_callbacks\n+        self._disconnectors = [", "ext_attention_idx_tokens": [47, 107], "uid": "8e5461dd", "question": "Why would we?", "code": "def init self ref artist use blit False self ref artist ref artist if not ref artist pickable ref artist set picker True self got artist False self use blit use blit and self canvas supports blit callbacks ref artist figure canvas callbacks self disconnectors [ functools partial callbacks disconnect callbacks connect picklable name func for name func in [ \"pick event\" self on pick \"button release event\" self on release \"motion notify event\" self on motion ] ]"}
{"message": "Not sure what this line is for?", "timestamp": "2023-04-11T08:09:22Z", "file_name": "lib/matplotlib/sphinxext/figmpl_directive.py", "range": {"start_line": 191, "end_line": 191, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1162450713", "html_url": "https://github.com/matplotlib/matplotlib/pull/25515#discussion_r1162450713", "attention_area": "        imagerel = imagerel + ''", "file_path": "files/27/06/00000627.py", "old_file_path": null, "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": true}, "language": "python", "replies": {}, "diff_hunk": "@@ -0,0 +1,294 @@\n+\"\"\"\n+Implements a ``.. figure-mpl::`` directive that is like\n+``.. figure::`` except it allows ``srcset=`` to be passed to the image tag, hence\n+allowing responsive resolution images.\n+\n+There is no particular reason this could not be used standalone, but is meant\n+to be used with :doc:`/api/sphinxext_plot_directive_api`.\n+\n+Note that the directory organization is a bit different than ``.. figure::``.\n+See the *FigureMpl* documentation below.\n+\n+\"\"\"\n+from docutils import nodes\n+\n+from docutils.parsers.rst import directives\n+from docutils.parsers.rst.directives.images import Figure, Image\n+\n+import os\n+from os.path import relpath\n+from pathlib import PurePosixPath, Path\n+import shutil\n+\n+from sphinx.errors import ExtensionError\n+\n+import matplotlib\n+\n+\n+class figmplnode(nodes.General, nodes.Element):\n+    pass\n+\n+\n+class FigureMpl(Figure):\n+    \"\"\"\n+    Implements a directive to allow an optional hidpi image.  Meant to be\n+    used with the *plot_srcset* configuration option in conf.py,\n+    and gets set in the TEMPLATE of plot_directive.py\n+\n+    e.g.::\n+\n+        .. figure-mpl:: plot_directive/some_plots-1.png\n+            :alt: bar\n+            :srcset: plot_directive/some_plots-1.png,\n+                     plot_directive/some_plots-1.2x.png 2.00x\n+            :class: plot-directive\n+\n+    The resulting html (at ``some_plots.html``) is::\n+\n+        <img src=\"sphx_glr_bar_001_hidpi.png\"\n+            srcset=\"_images/some_plot-1.png,\n+                    _images/some_plots-1.2x.png 2.00 x\",\n+            alt=\"bar\"\n+            class=\"plot_directive\" />\n+\n+    Note that the handling of subdirectories is different than that used by the sphinx\n+    figure directive::\n+\n+        .. figure-mpl:: plot_directive/nestedpage/index-1.png\n+            :alt: bar\n+            :srcset: plot_directive/nestedpage/index-1.png\n+                     plot_directive/nestedpage/index-1.2x.png 2.00x\n+            :class: plot_directive\n+\n+    The resulting html (at ``nestedpage/index.html``)::\n+\n+        <img src=\"../_images/nestedpage-index-1.png\"\n+            srcset=\"../_images/nestedpage-index-1.png,\n+                    ../_images/_images/nestedpage-index-1.2x.png 2x\",\n+            alt=\"bar\"\n+            class=\"sphx-glr-single-img\" />\n+\n+    where the subdirectory is included in the image name for uniqueness.\n+    \"\"\"\n+\n+    has_content = False\n+    required_arguments = 1\n+    optional_arguments = 2\n+    final_argument_whitespace = False\n+    option_spec = {\n+        'alt': directives.unchanged,\n+        'height': directives.length_or_unitless,\n+        'width': directives.length_or_percentage_or_unitless,\n+        'scale': directives.nonnegative_int,\n+        'align': Image.align,\n+        'class': directives.class_option,\n+        'caption': directives.unchanged,\n+        'srcset': directives.unchanged,\n+    }\n+\n+    def run(self):\n+\n+        image_node = figmplnode()\n+\n+        imagenm = self.arguments[0]\n+        image_node['alt'] = self.options.get('alt', '')\n+        image_node['align'] = self.options.get('align', None)\n+        image_node['class'] = self.options.get('class', None)\n+        image_node['width'] = self.options.get('width', None)\n+        image_node['height'] = self.options.get('height', None)\n+        image_node['scale'] = self.options.get('scale', None)\n+        image_node['caption'] = self.options.get('caption', None)\n+\n+        # we would like uri to be the highest dpi version so that\n+        # latex etc will use that.  But for now, lets just make\n+        # imagenm\n+\n+        image_node['uri'] = imagenm\n+        image_node['srcset'] = self.options.get('srcset', None)\n+\n+        return [image_node]\n+\n+\n+def _parse_srcsetNodes(st):\n+    \"\"\"\n+    parse srcset...\n+    \"\"\"\n+    entries = st.split(',')\n+    srcset = {}\n+    for entry in entries:\n+        spl = entry.strip().split(' ')\n+        if len(spl) == 1:\n+            srcset[0] = spl[0]\n+        elif len(spl) == 2:\n+            mult = spl[1][:-1]\n+            srcset[float(mult)] = spl[0]\n+        else:\n+            raise ExtensionError(f'srcset argument \"{entry}\" is invalid.')\n+    return srcset\n+\n+\n+def _copy_images_figmpl(self, node):\n+\n+    # these will be the temporary place the plot-directive put the images eg:\n+    # ../../../build/html/plot_directive/users/explain/artists/index-1.png\n+    if node['srcset']:\n+        srcset = _parse_srcsetNodes(node['srcset'])\n+    else:\n+        srcset = None\n+\n+    # the rst file's location:  eg /Users/username/matplotlib/doc/users/explain/artists\n+    docsource = PurePosixPath(self.document['source']).parent\n+\n+    # get the relpath relative to root:\n+    srctop = self.builder.srcdir\n+    rel = relpath(docsource, srctop).replace('.', '').replace('/', '-')\n+    if len(rel):\n+        rel += '-'\n+    # eg: users/explain/artists\n+\n+    imagedir = PurePosixPath(self.builder.imagedir)\n+    imagedir = PurePosixPath(self.builder.outdir) / imagedir\n+    # eg: /Users/username/matplotlib/doc/build/html/_images/users/explain/artists\n+\n+    Path(imagedir).mkdir(parents=True, exist_ok=True)\n+\n+    # copy all the sources to the imagedir:\n+    if srcset:\n+        for mult in srcset:\n+            # the entries in srcset are relative to docsource's directory\n+            abspath = PurePosixPath(docsource, srcset[mult])\n+            name = rel + abspath.name\n+            shutil.copyfile(abspath, imagedir / name)\n+    else:\n+        abspath = PurePosixPath(docsource, node['uri'])\n+        name = rel + abspath.name\n+        shutil.copyfile(abspath, imagedir / name)\n+\n+    return imagedir, srcset, rel\n+\n+\n+def visit_figmpl_html(self, node):\n+\n+    imagedir, srcset, rel = _copy_images_figmpl(self, node)\n+\n+    # /doc/examples/subd/plot_1.rst\n+    docsource = PurePosixPath(self.document['source'])\n+    # /doc/\n+    # make sure to add the trailing slash:\n+    srctop = PurePosixPath(self.builder.srcdir, '')\n+    # examples/subd/plot_1.rst\n+    relsource = relpath(docsource, srctop)\n+    # /doc/build/html\n+    desttop = PurePosixPath(self.builder.outdir, '')\n+    # /doc/build/html/examples/subd\n+    dest = desttop / relsource\n+\n+    # ../../_images/ for dirhtml and ../_images/ for html\n+    imagerel = relpath(imagedir, os.path.dirname(dest))\n+    if self.builder.name == \"dirhtml\":\n+        imagerel = '..' + imagerel + ''\n+    else:  # html\n+        imagerel = imagerel + ''", "source": "def visit_figmpl_html(self, node):\n\n    imagedir, srcset, rel = _copy_images_figmpl(self, node)\n\n    # /doc/examples/subd/plot_1.rst\n    docsource = PurePosixPath(self.document['source'])\n    # /doc/\n    # make sure to add the trailing slash:\n    srctop = PurePosixPath(self.builder.srcdir, '')\n    # examples/subd/plot_1.rst\n    relsource = relpath(docsource, srctop)\n    # /doc/build/html\n    desttop = PurePosixPath(self.builder.outdir, '')\n    # /doc/build/html/examples/subd\n    dest = desttop / relsource\n\n    # ../../_images/ for dirhtml and ../_images/ for html\n    imagerel = relpath(imagedir, os.path.dirname(dest))\n    if self.builder.name == \"dirhtml\":\n        imagerel = '..' + imagerel + ''\n    else:  # html\n        imagerel = imagerel + ''\n\n    # make uri also be relative...\n    nm = PurePosixPath(node['uri'][1:]).name\n    uri = imagerel + '/' + rel + nm\n\n    # make srcset str.  Need to change all the prefixes!\n    if srcset:\n        srcsetst = ''\n        maxmult = -1\n        for mult in srcset:\n            nm = PurePosixPath(srcset[mult][1:]).name\n            # ../../_images/plot_1_2_0x.png\n            path = imagerel + '/' + rel + nm\n            srcsetst += f'{path}'\n            if mult == 0:\n                srcsetst += ', '\n            else:\n                srcsetst += f' {mult:1.2f}x, '\n\n            if mult > maxmult:\n                maxmult = mult\n                maxsrc = path\n\n        # trim trailing comma and space...\n        srcsetst = srcsetst[:-2]\n    else:\n        srcsetst = ''\n        maxsrc = uri\n\n    alt = node['alt']\n    if node['class'] is not None:\n        classst = ''\n        for cl in node['class']:\n            classst += cl + ' '\n        classst = f'class=\"{classst}\"'\n\n    else:\n        classst = ''\n\n# <figure class=\"align-default\" id=\"id1\">\n# <a class=\"reference internal image-reference\" href=\"_images/index-1.2x.png\">\n# <img alt=\"_images/index-1.2x.png\" src=\"_images/index-1.2x.png\" style=\"width: 53%;\" />\n# </a>\n# <figcaption>\n# <p><span class=\"caption-text\">Figure caption is here....</span>\n# <a class=\"headerlink\" href=\"#id1\" title=\"Permalink to this image\">#</a></p>\n# </figcaption>\n# </figure>\n\n    stylers = ['width', 'height', 'scale']\n    stylest = ''\n    for style in stylers:\n        if node[style]:\n            stylest += f'{style}: {node[style]};'\n\n    figalign = node['align'] if node['align'] else 'center'\n\n    img_block = (f'<img src=\"{uri}\" style=\"{stylest}\" srcset=\"{srcsetst}\" ' +\n                 f'alt=\"{alt}\" {classst}/>')\n    html_block = f'<figure class=\"align-{figalign}\">\\n'\n    html_block += f'  <a class=\"reference internal image-reference\" href=\"{maxsrc}\">\\n'\n    html_block += '    ' + img_block + '\\n  </a>\\n'\n    if node['caption']:\n        html_block += '  <figcaption>\\n'\n        html_block += f'   <p><span class=\"caption-text\">{node[\"caption\"]}</span></p>\\n'\n        html_block += '  </figcaption>\\n'\n    html_block += '</figure>\\n'\n    self.body.append(html_block)", "source_start_line": 170, "tokens": ["def", "visit_figmpl_html", "(", "self", ",", "node", ")", ":", "imagedir", ",", "srcset", ",", "rel", "=", "_copy_images_figmpl", "(", "self", ",", "node", ")", "docsource", "=", "PurePosixPath", "(", "self", ".", "document", "[", "'source'", "]", ")", "srctop", "=", "PurePosixPath", "(", "self", ".", "builder", ".", "srcdir", ",", "''", ")", "relsource", "=", "relpath", "(", "docsource", ",", "srctop", ")", "desttop", "=", "PurePosixPath", "(", "self", ".", "builder", ".", "outdir", ",", "''", ")", "dest", "=", "desttop", "/", "relsource", "imagerel", "=", "relpath", "(", "imagedir", ",", "os", ".", "path", ".", "dirname", "(", "dest", ")", ")", "if", "self", ".", "builder", ".", "name", "==", "\"dirhtml\"", ":", "imagerel", "=", "'..'", "+", "imagerel", "+", "''", "else", ":", "imagerel", "=", "imagerel", "+", "''", "nm", "=", "PurePosixPath", "(", "node", "[", "'uri'", "]", "[", "1", ":", "]", ")", ".", "name", "uri", "=", "imagerel", "+", "'/'", "+", "rel", "+", "nm", "if", "srcset", ":", "srcsetst", "=", "''", "maxmult", "=", "-", "1", "for", "mult", "in", "srcset", ":", "nm", "=", "PurePosixPath", "(", "srcset", "[", "mult", "]", "[", "1", ":", "]", ")", ".", "name", "path", "=", "imagerel", "+", "'/'", "+", "rel", "+", "nm", "srcsetst", "+=", "f'", "{", "path", "}", "'", "if", "mult", "==", "0", ":", "srcsetst", "+=", "', '", "else", ":", "srcsetst", "+=", "f'", "{", "mult", ":", "}", "'", "if", "mult", ">", "maxmult", ":", "maxmult", "=", "mult", "maxsrc", "=", "path", "srcsetst", "=", "srcsetst", "[", ":", "-", "2", "]", "else", ":", "srcsetst", "=", "''", "maxsrc", "=", "uri", "alt", "=", "node", "[", "'alt'", "]", "if", "node", "[", "'class'", "]", "is", "not", "None", ":", "classst", "=", "''", "for", "cl", "in", "node", "[", "'class'", "]", ":", "classst", "+=", "cl", "+", "' '", "classst", "=", "f'", "{", "classst", "}", "'", "else", ":", "classst", "=", "''", "stylers", "=", "[", "'width'", ",", "'height'", ",", "'scale'", "]", "stylest", "=", "''", "for", "style", "in", "stylers", ":", "if", "node", "[", "style", "]", ":", "stylest", "+=", "f'", "{", "style", "}", "{", "node", "[", "style", "]", "}", "'", "figalign", "=", "node", "[", "'align'", "]", "if", "node", "[", "'align'", "]", "else", "'center'", "img_block", "=", "(", "f'", "{", "uri", "}", "{", "stylest", "}", "{", "srcsetst", "}", "'", "+", "f'", "{", "alt", "}", "{", "classst", "}", "'", ")", "html_block", "=", "f'", "{", "figalign", "}", "\\n", "'", "html_block", "+=", "f'", "{", "maxsrc", "}", "\\n", "'", "html_block", "+=", "'    '", "+", "img_block", "+", "'\\n  </a>\\n'", "if", "node", "[", "'caption'", "]", ":", "html_block", "+=", "'  <figcaption>\\n'", "html_block", "+=", "f'", "{", "node", "[", "\"caption\"", "]", "}", "\\n", "'", "html_block", "+=", "'  </figcaption>\\n'", "html_block", "+=", "'</figure>\\n'", "self", ".", "body", ".", "append", "(", "html_block", ")"], "to_mask": {"VAR": ["alt", "cl", "classst", "dest", "desttop", "docsource", "figalign", "html_block", "imagedir", "imagerel", "img_block", "maxmult", "maxsrc", "mult", "nm", "node", "path", "rel", "relsource", "self", "srcset", "srcsetst", "srctop", "style", "stylers", "stylest", "uri"], "METHOD": ["PurePosixPath", "_copy_images_figmpl", "append", "dirname", "relpath"]}, "attention_idx_tokens": [101, 105], "patch": "@@ -0,0 +1,294 @@\n+\"\"\"\n+Implements a ``.. figure-mpl::`` directive that is like\n+``.. figure::`` except it allows ``srcset=`` to be passed to the image tag, hence\n+allowing responsive resolution images.\n+\n+There is no particular reason this could not be used standalone, but is meant\n+to be used with :doc:`/api/sphinxext_plot_directive_api`.\n+\n+Note that the directory organization is a bit different than ``.. figure::``.\n+See the *FigureMpl* documentation below.\n+\n+\"\"\"\n+from docutils import nodes\n+\n+from docutils.parsers.rst import directives\n+from docutils.parsers.rst.directives.images import Figure, Image\n+\n+import os\n+from os.path import relpath\n+from pathlib import PurePosixPath, Path\n+import shutil\n+\n+from sphinx.errors import ExtensionError\n+\n+import matplotlib\n+\n+\n+class figmplnode(nodes.General, nodes.Element):\n+    pass\n+\n+\n+class FigureMpl(Figure):\n+    \"\"\"\n+    Implements a directive to allow an optional hidpi image.  Meant to be\n+    used with the *plot_srcset* configuration option in conf.py,\n+    and gets set in the TEMPLATE of plot_directive.py\n+\n+    e.g.::\n+\n+        .. figure-mpl:: plot_directive/some_plots-1.png\n+            :alt: bar\n+            :srcset: plot_directive/some_plots-1.png,\n+                     plot_directive/some_plots-1.2x.png 2.00x\n+            :class: plot-directive\n+\n+    The resulting html (at ``some_plots.html``) is::\n+\n+        <img src=\"sphx_glr_bar_001_hidpi.png\"\n+            srcset=\"_images/some_plot-1.png,\n+                    _images/some_plots-1.2x.png 2.00 x\",\n+            alt=\"bar\"\n+            class=\"plot_directive\" />\n+\n+    Note that the handling of subdirectories is different than that used by the sphinx\n+    figure directive::\n+\n+        .. figure-mpl:: plot_directive/nestedpage/index-1.png\n+            :alt: bar\n+            :srcset: plot_directive/nestedpage/index-1.png\n+                     plot_directive/nestedpage/index-1.2x.png 2.00x\n+            :class: plot_directive\n+\n+    The resulting html (at ``nestedpage/index.html``)::\n+\n+        <img src=\"../_images/nestedpage-index-1.png\"\n+            srcset=\"../_images/nestedpage-index-1.png,\n+                    ../_images/_images/nestedpage-index-1.2x.png 2x\",\n+            alt=\"bar\"\n+            class=\"sphx-glr-single-img\" />\n+\n+    where the subdirectory is included in the image name for uniqueness.\n+    \"\"\"\n+\n+    has_content = False\n+    required_arguments = 1\n+    optional_arguments = 2\n+    final_argument_whitespace = False\n+    option_spec = {\n+        'alt': directives.unchanged,\n+        'height': directives.length_or_unitless,\n+        'width': directives.length_or_percentage_or_unitless,\n+        'scale': directives.nonnegative_int,\n+        'align': Image.align,\n+        'class': directives.class_option,\n+        'caption': directives.unchanged,\n+        'srcset': directives.unchanged,\n+    }\n+\n+    def run(self):\n+\n+        image_node = figmplnode()\n+\n+        imagenm = self.arguments[0]\n+        image_node['alt'] = self.options.get('alt', '')\n+        image_node['align'] = self.options.get('align', None)\n+        image_node['class'] = self.options.get('class', None)\n+        image_node['width'] = self.options.get('width', None)\n+        image_node['height'] = self.options.get('height', None)\n+        image_node['scale'] = self.options.get('scale', None)\n+        image_node['caption'] = self.options.get('caption', None)\n+\n+        # we would like uri to be the highest dpi version so that\n+        # latex etc will use that.  But for now, lets just make\n+        # imagenm\n+\n+        image_node['uri'] = imagenm\n+        image_node['srcset'] = self.options.get('srcset', None)\n+\n+        return [image_node]\n+\n+\n+def _parse_srcsetNodes(st):\n+    \"\"\"\n+    parse srcset...\n+    \"\"\"\n+    entries = st.split(',')\n+    srcset = {}\n+    for entry in entries:\n+        spl = entry.strip().split(' ')\n+        if len(spl) == 1:\n+            srcset[0] = spl[0]\n+        elif len(spl) == 2:\n+            mult = spl[1][:-1]\n+            srcset[float(mult)] = spl[0]\n+        else:\n+            raise ExtensionError(f'srcset argument \"{entry}\" is invalid.')\n+    return srcset\n+\n+\n+def _copy_images_figmpl(self, node):\n+\n+    # these will be the temporary place the plot-directive put the images eg:\n+    # ../../../build/html/plot_directive/users/explain/artists/index-1.png\n+    if node['srcset']:\n+        srcset = _parse_srcsetNodes(node['srcset'])\n+    else:\n+        srcset = None\n+\n+    # the rst file's location:  eg /Users/username/matplotlib/doc/users/explain/artists\n+    docsource = PurePosixPath(self.document['source']).parent\n+\n+    # get the relpath relative to root:\n+    srctop = self.builder.srcdir\n+    rel = relpath(docsource, srctop).replace('.', '').replace('/', '-')\n+    if len(rel):\n+        rel += '-'\n+    # eg: users/explain/artists\n+\n+    imagedir = PurePosixPath(self.builder.imagedir)\n+    imagedir = PurePosixPath(self.builder.outdir) / imagedir\n+    # eg: /Users/username/matplotlib/doc/build/html/_images/users/explain/artists\n+\n+    Path(imagedir).mkdir(parents=True, exist_ok=True)\n+\n+    # copy all the sources to the imagedir:\n+    if srcset:\n+        for mult in srcset:\n+            # the entries in srcset are relative to docsource's directory\n+            abspath = PurePosixPath(docsource, srcset[mult])\n+            name = rel + abspath.name\n+            shutil.copyfile(abspath, imagedir / name)\n+    else:\n+        abspath = PurePosixPath(docsource, node['uri'])\n+        name = rel + abspath.name\n+        shutil.copyfile(abspath, imagedir / name)\n+\n+    return imagedir, srcset, rel\n+\n+\n+def visit_figmpl_html(self, node):\n+\n+    imagedir, srcset, rel = _copy_images_figmpl(self, node)\n+\n+    # /doc/examples/subd/plot_1.rst\n+    docsource = PurePosixPath(self.document['source'])\n+    # /doc/\n+    # make sure to add the trailing slash:\n+    srctop = PurePosixPath(self.builder.srcdir, '')\n+    # examples/subd/plot_1.rst\n+    relsource = relpath(docsource, srctop)\n+    # /doc/build/html\n+    desttop = PurePosixPath(self.builder.outdir, '')\n+    # /doc/build/html/examples/subd\n+    dest = desttop / relsource\n+\n+    # ../../_images/ for dirhtml and ../_images/ for html\n+    imagerel = relpath(imagedir, os.path.dirname(dest))\n+    if self.builder.name == \"dirhtml\":\n+        imagerel = '..' + imagerel + ''\n+    else:  # html\n+        imagerel = imagerel + ''", "ext_attention_idx_tokens": [0, 393], "uid": "d3e1c9d8", "question": "Not sure what this line is for?", "code": "def visit figmpl html self node imagedir srcset rel copy images figmpl self node # doc examples subd plot 1 rst docsource PurePosixPath self document[ source ] # doc # make sure to add the trailing slash srctop PurePosixPath self builder srcdir # examples subd plot 1 rst relsource relpath docsource srctop # doc build html desttop PurePosixPath self builder outdir # doc build html examples subd dest desttop relsource # images for dirhtml and images for html imagerel relpath imagedir os path dirname dest if self builder name \"dirhtml\" imagerel + imagerel + else # html imagerel imagerel + # make uri also be relative nm PurePosixPath node[ uri ][1 ] name uri imagerel + + rel + nm # make srcset str Need to change all the prefixes! if srcset srcsetst maxmult -1 for mult in srcset nm PurePosixPath srcset[mult][1 ] name # images plot 1 2 0x png path imagerel + + rel + nm srcsetst + f {path} if mult 0 srcsetst + else srcsetst + f {mult 1 2f}x if mult > maxmult maxmult mult maxsrc path # trim trailing comma and space srcsetst srcsetst[ -2] else srcsetst maxsrc uri alt node[ alt ] if node[ class ] is not None classst for cl in node[ class ] classst + cl + classst f class \"{classst}\" else classst # <figure class \"align-default\" id \"id1\"> # <a class \"reference internal image-reference\" href \" images index-1 2x png\"> # <img alt \" images index-1 2x png\" src \" images index-1 2x png\" style \"width 53%;\" > # < a> # <figcaption> # <p><span class \"caption-text\">Figure caption is here < span> # <a class \"headerlink\" href \"#id1\" title \"Permalink to this image\">#< a>< p> # < figcaption> # < figure> stylers [ width height scale ] stylest for style in stylers if node[style] stylest + f {style} {node[style]}; figalign node[ align ] if node[ align ] else center img block f <img src \"{uri}\" style \"{stylest}\" srcset \"{srcsetst}\" + f alt \"{alt}\" {classst} > html block f <figure class \"align-{figalign}\">\\n html block + f <a class \"reference internal image-reference\" href \"{maxsrc}\">\\n html block + + img block + \\n < a>\\n if node[ caption ] html block + <figcaption>\\n html block + f <p><span class \"caption-text\">{node[\"caption\"]}< span>< p>\\n html block + < figcaption>\\n html block + < figure>\\n self body append html block"}
{"message": "Thats true... OTOH, if we pass `_safe_first_element(12)` do we want it to error?\r\n\r\n", "timestamp": "2023-04-15T21:37:46Z", "file_name": "lib/matplotlib/cbook.py", "range": {"start_line": 1664, "end_line": 1664, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1167640568", "html_url": "https://github.com/matplotlib/matplotlib/pull/25667#discussion_r1167640568", "attention_area": "            return obj", "file_path": "files/73/06/00000673.py", "old_file_path": "files/74/06/00000674.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1657,7 +1657,11 @@ def safe_isfinite(val):\n         raise RuntimeError(\"matplotlib does not \"\n                            \"support generators as input\")\n     else:\n-        return next(val for val in obj if safe_isfinite(val))\n+        try:\n+            return next(val for val in obj if safe_isfinite(val))\n+        except TypeError:\n+            # not an iterable...\n+            return obj", "source": "def _safe_first_finite(obj, *, skip_nonfinite=True):\n    \"\"\"\n    Return the first non-None (and optionally finite) element in *obj*.\n\n    This is a method for internal use.\n\n    This is a type-independent way of obtaining the first non-None element,\n    supporting both index access and the iterator protocol.\n    The first non-None element will be obtained when skip_none is True.\n    \"\"\"\n    def safe_isfinite(val):\n        if val is None:\n            return False\n        try:\n            return np.isfinite(val) if np.isscalar(val) else True\n        except TypeError:\n            # This is something that NumPy cannot make heads or tails of,\n            # assume \"finite\"\n            return True\n    if skip_nonfinite is False:\n        if isinstance(obj, collections.abc.Iterator):\n            # needed to accept `array.flat` as input.\n            # np.flatiter reports as an instance of collections.Iterator\n            # but can still be indexed via [].\n            # This has the side effect of re-setting the iterator, but\n            # that is acceptable.\n            try:\n                return obj[0]\n            except TypeError:\n                pass\n            raise RuntimeError(\"matplotlib does not support generators \"\n                               \"as input\")\n        return next(iter(obj))\n    elif isinstance(obj, np.flatiter):\n        # TODO do the finite filtering on this\n        return obj[0]\n    elif isinstance(obj, collections.abc.Iterator):\n        raise RuntimeError(\"matplotlib does not \"\n                           \"support generators as input\")\n    else:\n        try:\n            return next(val for val in obj if safe_isfinite(val))\n        except TypeError:\n            # not an iterable...\n            return obj", "source_start_line": 1620, "tokens": ["def", "_safe_first_finite", "(", "obj", ",", "*", ",", "skip_nonfinite", "=", "True", ")", ":", "\"\"\"    Return the first non-None (and optionally finite) element in *obj*.    This is a method for internal use.    This is a type-independent way of obtaining the first non-None element,    supporting both index access and the iterator protocol.    The first non-None element will be obtained when skip_none is True.    \"\"\"", "def", "safe_isfinite", "(", "val", ")", ":", "if", "val", "is", "None", ":", "return", "False", "try", ":", "return", "np", ".", "isfinite", "(", "val", ")", "if", "np", ".", "isscalar", "(", "val", ")", "else", "True", "except", "TypeError", ":", "return", "True", "if", "skip_nonfinite", "is", "False", ":", "if", "isinstance", "(", "obj", ",", "collections", ".", "abc", ".", "Iterator", ")", ":", "try", ":", "return", "obj", "[", "0", "]", "except", "TypeError", ":", "pass", "raise", "RuntimeError", "(", "\"matplotlib does not support generators \"", "\"as input\"", ")", "return", "next", "(", "iter", "(", "obj", ")", ")", "elif", "isinstance", "(", "obj", ",", "np", ".", "flatiter", ")", ":", "return", "obj", "[", "0", "]", "elif", "isinstance", "(", "obj", ",", "collections", ".", "abc", ".", "Iterator", ")", ":", "raise", "RuntimeError", "(", "\"matplotlib does not \"", "\"support generators as input\"", ")", "else", ":", "try", ":", "return", "next", "(", "val", "for", "val", "in", "obj", "if", "safe_isfinite", "(", "val", ")", ")", "except", "TypeError", ":", "return", "obj"], "to_mask": {"VAR": ["obj", "skip_nonfinite", "val"], "METHOD": ["RuntimeError", "isfinite", "isinstance", "isscalar", "iter", "next", "safe_isfinite"]}, "attention_idx_tokens": [145, 146], "patch": "@@ -1657,7 +1657,11 @@\n         raise RuntimeError(\"matplotlib does not \"\n                            \"support generators as input\")\n     else:\n-        return next((val for val in obj if safe_isfinite(val)), safe_first_element(obj))\n+        try:\n+            return next(val for val in obj if safe_isfinite(val))\n+        except TypeError:\n+            # not an iterable...\n+            return obj", "ext_attention_idx_tokens": [126, 146], "uid": "afefb553", "question": "Thats true... OTOH, if we pass `_safe_first_element(12)` do we want it to error?    ", "code": "def safe first finite obj * skip nonfinite True \"\"\" Return the first non-None and optionally finite element in *obj* This is a method for internal use This is a type-independent way of obtaining the first non-None element supporting both index access and the iterator protocol The first non-None element will be obtained when skip none is True \"\"\" def safe isfinite val if val is None return False try return np isfinite val if np isscalar val else True except TypeError # This is something that NumPy cannot make heads or tails of # assume \"finite\" return True if skip nonfinite is False if isinstance obj collections abc Iterator # needed to accept `array flat` as input # np flatiter reports as an instance of collections Iterator # but can still be indexed via [] # This has the side effect of re-setting the iterator but # that is acceptable try return obj[0] except TypeError pass raise RuntimeError \"matplotlib does not support generators \" \"as input\" return next iter obj elif isinstance obj np flatiter # TODO do the finite filtering on this return obj[0] elif isinstance obj collections abc Iterator raise RuntimeError \"matplotlib does not \" \"support generators as input\" else try return next val for val in obj if safe isfinite val except TypeError # not an iterable return obj"}
{"message": "I will add sich methods here https://github.com/matplotlib/matplotlib/blob/main/lib/matplotlib/patches.py#L1506-L1655\n\nDo you also see a marker property of Ellipse Patches? ", "timestamp": "2023-04-30T13:20:31Z", "file_name": "galleries/examples/shapes_and_collections/ellipse_arrow.py", "range": {"start_line": 32, "end_line": 32, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1181230804", "html_url": "https://github.com/matplotlib/matplotlib/pull/25779#discussion_r1181230804", "attention_area": "def getMinorMajor(ellipse: Ellipse) -> Tuple[list, list]:", "file_path": "files/61/07/00000761.py", "old_file_path": null, "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": true}, "language": "python", "replies": {}, "diff_hunk": "@@ -0,0 +1,113 @@\n+\"\"\"\n+===================================\n+Ellipse with orientation arrow Demo\n+===================================\n+\n+This demo shows how to draw an ellipse with\n+an orientation arrow (clockwise or counterclockwise).\n+Compare this to the :doc:`Ellipse collection example\n+</gallery/shapes_and_collections/ellipse_collection>`.\n+\"\"\"\n+\n+from typing import Tuple\n+\n+import matplotlib.pyplot as plt\n+import numpy as np\n+\n+from matplotlib.markers import MarkerStyle\n+from matplotlib.patches import Ellipse\n+from matplotlib.transforms import Affine2D\n+\n+# %%\n+#\n+# A method to calculate the end points of the ellipse major, minor axis\n+# \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n+#\n+# Calculates the minor axis and major axis end points of the ellipse.\n+# It needs the ellipse parameter like width, height, angle.\n+# The output are 2 lists of 2 xy coordinates\n+# (minor((x0, y0), (x1, y1)), major((x0, y0), (x1, y1))).\n+\n+\n+def getMinorMajor(ellipse: Ellipse) -> Tuple[list, list]:", "source": "def getMinorMajor(ellipse: Ellipse) -> Tuple[list, list]:\n    \"\"\"\n    Calculates the end points of minor and major axis of an ellipse.\n\n    Parameters\n    ----------\n    ellipse : ~matplotlib.patches.Ellipse\n        Ellipse patch.\n\n    Returns\n    -------\n    ~typing.Tuple[list, list]\n    \"\"\"\n    # Calculate the endpoints of the minor axis\n    x0_minor = ellipse.center[0] - ellipse.height / 2 * np.sin(\n        np.deg2rad(ellipse.angle)\n    )\n    y0_minor = ellipse.center[1] + ellipse.height / 2 * np.cos(\n        np.deg2rad(ellipse.angle)\n    )\n    x1_minor = ellipse.center[0] + ellipse.height / 2 * np.sin(\n        np.deg2rad(ellipse.angle)\n    )\n    y1_minor = ellipse.center[1] - ellipse.height / 2 * np.cos(\n        np.deg2rad(ellipse.angle)\n    )\n\n    # Calculate the endpoints of the major axis\n    x0_major = ellipse.center[0] - ellipse.width / 2 * np.cos(np.deg2rad(ellipse.angle))\n    y0_major = ellipse.center[1] - ellipse.width / 2 * np.sin(np.deg2rad(ellipse.angle))\n    x1_major = ellipse.center[0] + ellipse.width / 2 * np.cos(np.deg2rad(ellipse.angle))\n    y1_major = ellipse.center[1] + ellipse.width / 2 * np.sin(np.deg2rad(ellipse.angle))\n    return [(x0_minor, y0_minor), (x1_minor, y1_minor)], [\n        (x0_major, y0_major),\n        (x1_major, y1_major),\n    ]", "source_start_line": 32, "tokens": ["def", "getMinorMajor", "(", "ellipse", ":", "Ellipse", ")", "->", "Tuple", "[", "list", ",", "list", "]", ":", "\"\"\"    Calculates the end points of minor and major axis of an ellipse.    Parameters    ----------    ellipse : ~matplotlib.patches.Ellipse        Ellipse patch.    Returns    -------    ~typing.Tuple[list, list]    \"\"\"", "x0_minor", "=", "ellipse", ".", "center", "[", "0", "]", "-", "ellipse", ".", "height", "/", "2", "*", "np", ".", "sin", "(", "np", ".", "deg2rad", "(", "ellipse", ".", "angle", ")", ")", "y0_minor", "=", "ellipse", ".", "center", "[", "1", "]", "+", "ellipse", ".", "height", "/", "2", "*", "np", ".", "cos", "(", "np", ".", "deg2rad", "(", "ellipse", ".", "angle", ")", ")", "x1_minor", "=", "ellipse", ".", "center", "[", "0", "]", "+", "ellipse", ".", "height", "/", "2", "*", "np", ".", "sin", "(", "np", ".", "deg2rad", "(", "ellipse", ".", "angle", ")", ")", "y1_minor", "=", "ellipse", ".", "center", "[", "1", "]", "-", "ellipse", ".", "height", "/", "2", "*", "np", ".", "cos", "(", "np", ".", "deg2rad", "(", "ellipse", ".", "angle", ")", ")", "x0_major", "=", "ellipse", ".", "center", "[", "0", "]", "-", "ellipse", ".", "width", "/", "2", "*", "np", ".", "cos", "(", "np", ".", "deg2rad", "(", "ellipse", ".", "angle", ")", ")", "y0_major", "=", "ellipse", ".", "center", "[", "1", "]", "-", "ellipse", ".", "width", "/", "2", "*", "np", ".", "sin", "(", "np", ".", "deg2rad", "(", "ellipse", ".", "angle", ")", ")", "x1_major", "=", "ellipse", ".", "center", "[", "0", "]", "+", "ellipse", ".", "width", "/", "2", "*", "np", ".", "cos", "(", "np", ".", "deg2rad", "(", "ellipse", ".", "angle", ")", ")", "y1_major", "=", "ellipse", ".", "center", "[", "1", "]", "+", "ellipse", ".", "width", "/", "2", "*", "np", ".", "sin", "(", "np", ".", "deg2rad", "(", "ellipse", ".", "angle", ")", ")", "return", "[", "(", "x0_minor", ",", "y0_minor", ")", ",", "(", "x1_minor", ",", "y1_minor", ")", "]", ",", "[", "(", "x0_major", ",", "y0_major", ")", ",", "(", "x1_major", ",", "y1_major", ")", ",", "]"], "to_mask": {"VAR": ["ellipse", "x0_major", "x0_minor", "x1_major", "x1_minor", "y0_major", "y0_minor", "y1_major", "y1_minor"], "METHOD": ["cos", "deg2rad", "sin"]}, "attention_idx_tokens": [0, 14], "patch": "@@ -0,0 +1,113 @@\n+\"\"\"\n+===================================\n+Ellipse with orientation arrow Demo\n+===================================\n+\n+This demo shows how to draw an ellipse with\n+an orientation arrow (clockwise or counterclockwise).\n+Compare this to the :doc:`Ellipse collection example\n+</gallery/shapes_and_collections/ellipse_collection>`.\n+\"\"\"\n+\n+from typing import Tuple\n+\n+import matplotlib.pyplot as plt\n+import numpy as np\n+\n+from matplotlib.markers import MarkerStyle\n+from matplotlib.patches import Ellipse\n+from matplotlib.transforms import Affine2D\n+\n+# %%\n+#\n+# A method to calculate the end points of the ellipse major, minor axis\n+# \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n+#\n+# Calculates the minor axis and major axis end points of the ellipse.\n+# It needs the ellipse parameter like width, height, angle.\n+# The output are 2 lists of 2 xy coordinates\n+# (minor((x0, y0), (x1, y1)), major((x0, y0), (x1, y1))).\n+\n+\n+def getMinorMajor(ellipse: Ellipse) -> Tuple[list, list]:", "ext_attention_idx_tokens": [0, 268], "uid": "97722146", "question": "I will add sich methods here https://github.com/matplotlib/matplotlib/blob/main/lib/matplotlib/patches.py#L1506-L1655  Do you also see a marker property of Ellipse Patches? ", "code": "def getMinorMajor ellipse Ellipse -> Tuple[list list] \"\"\" Calculates the end points of minor and major axis of an ellipse Parameters ---------- ellipse ~matplotlib patches Ellipse Ellipse patch Returns ------- ~typing Tuple[list list] \"\"\" # Calculate the endpoints of the minor axis x0 minor ellipse center[0] - ellipse height 2 * np sin np deg2rad ellipse angle y0 minor ellipse center[1] + ellipse height 2 * np cos np deg2rad ellipse angle x1 minor ellipse center[0] + ellipse height 2 * np sin np deg2rad ellipse angle y1 minor ellipse center[1] - ellipse height 2 * np cos np deg2rad ellipse angle # Calculate the endpoints of the major axis x0 major ellipse center[0] - ellipse width 2 * np cos np deg2rad ellipse angle y0 major ellipse center[1] - ellipse width 2 * np sin np deg2rad ellipse angle x1 major ellipse center[0] + ellipse width 2 * np cos np deg2rad ellipse angle y1 major ellipse center[1] + ellipse width 2 * np sin np deg2rad ellipse angle return [ x0 minor y0 minor x1 minor y1 minor ] [ x0 major y0 major x1 major y1 major ]"}
{"message": "Is everybody fine with the shading in RGB space or do we need to look into saturation?", "timestamp": "2023-05-11T23:54:52Z", "file_name": "lib/matplotlib/patches.py", "range": {"start_line": 633, "end_line": 633, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1191786183", "html_url": "https://github.com/matplotlib/matplotlib/pull/25389#discussion_r1191786183", "attention_area": "            shadow is black, if 1, the shadow has the same color as the *patch*.", "file_path": "files/28/08/00000828.py", "old_file_path": "files/30/08/00000830.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -628,6 +628,12 @@ def __init__(self, patch, ox, oy, **kwargs):\n         ox, oy : float\n             The shift of the shadow in data coordinates, scaled by a factor\n             of dpi/72.\n+        shade : float, default: 0.3\n+            How the darkness of the shadow relates to the original color. If 0, the\n+            shadow is black, if 1, the shadow has the same color as the *patch*.", "source": "def __init__(self, patch, ox, oy, *, shade=0.3, **kwargs):\n        \"\"\"\n        Create a shadow of the given *patch*.\n\n        By default, the shadow will have the same face color as the *patch*,\n        but darkened. The darkness can be controlled by *shade*.\n\n        Parameters\n        ----------\n        patch : `.Patch`\n            The patch to create the shadow for.\n        ox, oy : float\n            The shift of the shadow in data coordinates, scaled by a factor\n            of dpi/72.\n        shade : float, default: 0.3\n            How the darkness of the shadow relates to the original color. If 0, the\n            shadow is black, if 1, the shadow has the same color as the *patch*.\n\n            .. versionadded:: 3.8\n\n        **kwargs\n            Properties of the shadow patch. Supported keys are:\n\n            %(Patch:kwdoc)s\n        \"\"\"\n        super().__init__()\n        self.patch = patch\n        self._ox, self._oy = ox, oy\n        self._shadow_transform = transforms.Affine2D()\n\n        self.update_from(self.patch)\n        if not 0 <= shade <= 1:\n            raise ValueError(\"shade must be between 0 and 1.\")\n        color = shade * np.asarray(colors.to_rgb(self.patch.get_facecolor()))\n        self.update({'facecolor': color, 'edgecolor': color, 'alpha': 0.5,\n                     # Place shadow patch directly behind the inherited patch.\n                     'zorder': np.nextafter(self.patch.zorder, -np.inf),\n                     **kwargs})", "source_start_line": 617, "tokens": ["def", "__init__", "(", "self", ",", "patch", ",", "ox", ",", "oy", ",", "*", ",", "shade", "=", "0.3", ",", "**", "kwargs", ")", ":", "\"\"\"        Create a shadow of the given *patch*.        By default, the shadow will have the same face color as the *patch*,        but darkened. The darkness can be controlled by *shade*.        Parameters        ----------        patch : `.Patch`            The patch to create the shadow for.        ox, oy : float            The shift of the shadow in data coordinates, scaled by a factor            of dpi/72.        shade : float, default: 0.3            How the darkness of the shadow relates to the original color. If 0, the            shadow is black, if 1, the shadow has the same color as the *patch*.            .. versionadded:: 3.8        **kwargs            Properties of the shadow patch. Supported keys are:            %(Patch:kwdoc)s        \"\"\"", "super", "(", ")", ".", "__init__", "(", ")", "self", ".", "patch", "=", "patch", "self", ".", "_ox", ",", "self", ".", "_oy", "=", "ox", ",", "oy", "self", ".", "_shadow_transform", "=", "transforms", ".", "Affine2D", "(", ")", "self", ".", "update_from", "(", "self", ".", "patch", ")", "if", "not", "0", "<=", "shade", "<=", "1", ":", "raise", "ValueError", "(", "\"shade must be between 0 and 1.\"", ")", "color", "=", "shade", "*", "np", ".", "asarray", "(", "colors", ".", "to_rgb", "(", "self", ".", "patch", ".", "get_facecolor", "(", ")", ")", ")", "self", ".", "update", "(", "{", "'facecolor'", ":", "color", ",", "'edgecolor'", ":", "color", ",", "'alpha'", ":", "0.5", ",", "'zorder'", ":", "np", ".", "nextafter", "(", "self", ".", "patch", ".", "zorder", ",", "-", "np", ".", "inf", ")", ",", "**", "kwargs", "}", ")"], "to_mask": {"VAR": ["_shadow_transform", "color", "ox", "oy", "patch", "self", "shade"], "METHOD": ["Affine2D", "ValueError", "__init__", "asarray", "get_facecolor", "nextafter", "super", "to_rgb", "update", "update_from"]}, "attention_idx_tokens": [null, null], "patch": "@@ -628,6 +628,12 @@\n         ox, oy : float\n             The shift of the shadow in data coordinates, scaled by a factor\n             of dpi/72.\n+        shade : float, default: 0.3\n+            How the darkness of the shadow relates to the original color. If 0, the\n+            shadow is black, if 1, the shadow has the same color as the *patch*.", "ext_attention_idx_tokens": [null, null], "uid": "08e68c50", "question": "Is everybody fine with the shading in RGB space or do we need to look into saturation?", "code": "def init self patch ox oy * shade 0 3 **kwargs \"\"\" Create a shadow of the given *patch* By default the shadow will have the same face color as the *patch* but darkened The darkness can be controlled by *shade* Parameters ---------- patch ` Patch` The patch to create the shadow for ox oy float The shift of the shadow in data coordinates scaled by a factor of dpi 72 shade float default 0 3 How the darkness of the shadow relates to the original color If 0 the shadow is black if 1 the shadow has the same color as the *patch* versionadded 3 8 **kwargs Properties of the shadow patch Supported keys are % Patch kwdoc s \"\"\" super init self patch patch self ox self oy ox oy self shadow transform transforms Affine2D self update from self patch if not 0 < shade < 1 raise ValueError \"shade must be between 0 and 1 \" color shade * np asarray colors to rgb self patch get facecolor self update { facecolor color edgecolor color alpha 0 5 # Place shadow patch directly behind the inherited patch zorder np nextafter self patch zorder -np inf **kwargs}"}
{"message": "Clearly I'm no authority on this, but warning and re-raising seem pretty logical to do because it just crashes otherwise.  \r\n\r\nI also didn't fully understand your comment -- like why should there be no GUI at all with block=True/sleep enabled. The couple of examples I tried all seemed to work (switching to a different backend and continuing as intended). I'm very likely missing something, but is the expected behavior here something different? ", "timestamp": "2023-05-12T22:08:48Z", "file_name": "lib/matplotlib/pyplot.py", "range": {"start_line": 405, "end_line": 405, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1192828490", "html_url": "https://github.com/matplotlib/matplotlib/pull/25870#discussion_r1192828490", "attention_area": "    except ImportError as err:", "file_path": "files/33/08/00000833.py", "old_file_path": "files/35/08/00000835.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -398,7 +400,11 @@ def draw_if_interactive():\n \n     # make sure the repl display hook is installed in case we become\n     # interactive\n-    install_repl_displayhook()\n+    try:\n+        install_repl_displayhook()\n+    except ImportError as err:", "source": "def switch_backend(newbackend):\n    \"\"\"\n    Set the pyplot backend.\n\n    Switching to an interactive backend is possible only if no event loop for\n    another interactive backend has started.  Switching to and from\n    non-interactive backends is always possible.\n\n    If the new backend is different than the current backend then all open\n    Figures will be closed via ``plt.close('all')``.\n\n    Parameters\n    ----------\n    newbackend : str\n        The case-insensitive name of the backend to use.\n\n    \"\"\"\n    global _backend_mod\n    # make sure the init is pulled up so we can assign to it later\n    import matplotlib.backends\n\n    if newbackend is rcsetup._auto_backend_sentinel:\n        current_framework = cbook._get_running_interactive_framework()\n        mapping = {'qt': 'qtagg',\n                   'gtk3': 'gtk3agg',\n                   'gtk4': 'gtk4agg',\n                   'wx': 'wxagg',\n                   'tk': 'tkagg',\n                   'macosx': 'macosx',\n                   'headless': 'agg'}\n\n        best_guess = mapping.get(current_framework, None)\n        if best_guess is not None:\n            candidates = [best_guess]\n        else:\n            candidates = []\n        candidates += [\n            \"macosx\", \"qtagg\", \"gtk4agg\", \"gtk3agg\", \"tkagg\", \"wxagg\"]\n\n        # Don't try to fallback on the cairo-based backends as they each have\n        # an additional dependency (pycairo) over the agg-based backend, and\n        # are of worse quality.\n        for candidate in candidates:\n            try:\n                switch_backend(candidate)\n            except ImportError:\n                continue\n            else:\n                rcParamsOrig['backend'] = candidate\n                return\n        else:\n            # Switching to Agg should always succeed; if it doesn't, let the\n            # exception propagate out.\n            switch_backend(\"agg\")\n            rcParamsOrig[\"backend\"] = \"agg\"\n            return\n    # have to escape the switch on access logic\n    old_backend = dict.__getitem__(rcParams, 'backend')\n\n    backend_mod = importlib.import_module(\n        cbook._backend_module_name(newbackend))\n\n    required_framework = backend_mod.FigureCanvas.required_interactive_framework\n    if required_framework is not None:\n        current_framework = cbook._get_running_interactive_framework()\n        if (current_framework and required_framework\n                and current_framework != required_framework):\n            raise ImportError(\n                \"Cannot load backend {!r} which requires the {!r} interactive \"\n                \"framework, as {!r} is currently running\".format(\n                    newbackend, required_framework, current_framework))\n\n    # Load the new_figure_manager() and show() functions from the backend.\n\n    # Classically, backends can directly export these functions.  This should\n    # keep working for backcompat.\n    new_figure_manager = getattr(backend_mod, \"new_figure_manager\", None)\n    show = getattr(backend_mod, \"show\", None)\n\n    # In that classical approach, backends are implemented as modules, but\n    # \"inherit\" default method implementations from backend_bases._Backend.\n    # This is achieved by creating a \"class\" that inherits from\n    # backend_bases._Backend and whose body is filled with the module globals.\n    class backend_mod(matplotlib.backend_bases._Backend):\n        locals().update(vars(backend_mod))\n\n    # However, the newer approach for defining new_figure_manager and\n    # show is to derive them from canvas methods.  In that case, also\n    # update backend_mod accordingly; also, per-backend customization of\n    # draw_if_interactive is disabled.\n    if new_figure_manager is None:\n        # Only try to get the canvas class if have opted into the new scheme.\n        canvas_class = backend_mod.FigureCanvas\n\n        def new_figure_manager_given_figure(num, figure):\n            return canvas_class.new_manager(figure, num)\n\n        def new_figure_manager(num, *args, FigureClass=Figure, **kwargs):\n            fig = FigureClass(*args, **kwargs)\n            return new_figure_manager_given_figure(num, fig)\n\n        def draw_if_interactive():\n            if matplotlib.is_interactive():\n                manager = _pylab_helpers.Gcf.get_active()\n                if manager:\n                    manager.canvas.draw_idle()\n\n        backend_mod.new_figure_manager_given_figure = \\\n            new_figure_manager_given_figure\n        backend_mod.new_figure_manager = new_figure_manager\n        backend_mod.draw_if_interactive = draw_if_interactive\n\n    # If the manager explicitly overrides pyplot_show, use it even if a global\n    # show is already present, as the latter may be here for backcompat.\n    manager_class = getattr(getattr(backend_mod, \"FigureCanvas\", None),\n                            \"manager_class\", None)\n    # We can't compare directly manager_class.pyplot_show and FMB.pyplot_show because\n    # pyplot_show is a classmethod so the above constructs are bound classmethods, and\n    # thus always different (being bound to different classes).  We also have to use\n    # getattr_static instead of vars as manager_class could have no __dict__.\n    manager_pyplot_show = inspect.getattr_static(manager_class, \"pyplot_show\", None)\n    base_pyplot_show = inspect.getattr_static(FigureManagerBase, \"pyplot_show\", None)\n    if (show is None\n            or (manager_pyplot_show is not None\n                and manager_pyplot_show != base_pyplot_show)):\n        backend_mod.show = manager_class.pyplot_show\n\n    _log.debug(\"Loaded backend %s version %s.\",\n               newbackend, backend_mod.backend_version)\n\n    rcParams['backend'] = rcParamsDefault['backend'] = newbackend\n    _backend_mod = backend_mod\n    for func_name in [\"new_figure_manager\", \"draw_if_interactive\", \"show\"]:\n        globals()[func_name].__signature__ = inspect.signature(\n            getattr(backend_mod, func_name))\n    # Need to keep a global reference to the backend for compatibility reasons.\n    # See https://github.com/matplotlib/matplotlib/issues/6092\n    matplotlib.backends.backend = newbackend\n    if not cbook._str_equal(old_backend, newbackend):\n        close(\"all\")\n\n    # make sure the repl display hook is installed in case we become\n    # interactive\n    try:\n        install_repl_displayhook()\n    except ImportError as err:\n        _log.warning(str(err))\n        raise ImportError", "source_start_line": 260, "tokens": ["def", "switch_backend", "(", "newbackend", ")", ":", "\"\"\"    Set the pyplot backend.    Switching to an interactive backend is possible only if no event loop for    another interactive backend has started.  Switching to and from    non-interactive backends is always possible.    If the new backend is different than the current backend then all open    Figures will be closed via ``plt.close('all')``.    Parameters    ----------    newbackend : str        The case-insensitive name of the backend to use.    \"\"\"", "global", "_backend_mod", "import", "matplotlib", ".", "backends", "if", "newbackend", "is", "rcsetup", ".", "_auto_backend_sentinel", ":", "current_framework", "=", "cbook", ".", "_get_running_interactive_framework", "(", ")", "mapping", "=", "{", "'qt'", ":", "'qtagg'", ",", "'gtk3'", ":", "'gtk3agg'", ",", "'gtk4'", ":", "'gtk4agg'", ",", "'wx'", ":", "'wxagg'", ",", "'tk'", ":", "'tkagg'", ",", "'macosx'", ":", "'macosx'", ",", "'headless'", ":", "'agg'", "}", "best_guess", "=", "mapping", ".", "get", "(", "current_framework", ",", "None", ")", "if", "best_guess", "is", "not", "None", ":", "candidates", "=", "[", "best_guess", "]", "else", ":", "candidates", "=", "[", "]", "candidates", "+=", "[", "\"macosx\"", ",", "\"qtagg\"", ",", "\"gtk4agg\"", ",", "\"gtk3agg\"", ",", "\"tkagg\"", ",", "\"wxagg\"", "]", "for", "candidate", "in", "candidates", ":", "try", ":", "switch_backend", "(", "candidate", ")", "except", "ImportError", ":", "continue", "else", ":", "rcParamsOrig", "[", "'backend'", "]", "=", "candidate", "return", "else", ":", "switch_backend", "(", "\"agg\"", ")", "rcParamsOrig", "[", "\"backend\"", "]", "=", "\"agg\"", "return", "old_backend", "=", "dict", ".", "__getitem__", "(", "rcParams", ",", "'backend'", ")", "backend_mod", "=", "importlib", ".", "import_module", "(", "cbook", ".", "_backend_module_name", "(", "newbackend", ")", ")", "required_framework", "=", "backend_mod", ".", "FigureCanvas", ".", "required_interactive_framework", "if", "required_framework", "is", "not", "None", ":", "current_framework", "=", "cbook", ".", "_get_running_interactive_framework", "(", ")", "if", "(", "current_framework", "and", "required_framework", "and", "current_framework", "!=", "required_framework", ")", ":", "raise", "ImportError", "(", "\"Cannot load backend {!r} which requires the {!r} interactive \"", "\"framework, as {!r} is currently running\"", ".", "format", "(", "newbackend", ",", "required_framework", ",", "current_framework", ")", ")", "new_figure_manager", "=", "getattr", "(", "backend_mod", ",", "\"new_figure_manager\"", ",", "None", ")", "show", "=", "getattr", "(", "backend_mod", ",", "\"show\"", ",", "None", ")", "class", "backend_mod", "(", "matplotlib", ".", "backend_bases", ".", "_Backend", ")", ":", "locals", "(", ")", ".", "update", "(", "vars", "(", "backend_mod", ")", ")", "if", "new_figure_manager", "is", "None", ":", "canvas_class", "=", "backend_mod", ".", "FigureCanvas", "def", "new_figure_manager_given_figure", "(", "num", ",", "figure", ")", ":", "return", "canvas_class", ".", "new_manager", "(", "figure", ",", "num", ")", "def", "new_figure_manager", "(", "num", ",", "*", "args", ",", "FigureClass", "=", "Figure", ",", "**", "kwargs", ")", ":", "fig", "=", "FigureClass", "(", "*", "args", ",", "**", "kwargs", ")", "return", "new_figure_manager_given_figure", "(", "num", ",", "fig", ")", "def", "draw_if_interactive", "(", ")", ":", "if", "matplotlib", ".", "is_interactive", "(", ")", ":", "manager", "=", "_pylab_helpers", ".", "Gcf", ".", "get_active", "(", ")", "if", "manager", ":", "manager", ".", "canvas", ".", "draw_idle", "(", ")", "backend_mod", ".", "new_figure_manager_given_figure", "=", "new_figure_manager_given_figure", "backend_mod", ".", "new_figure_manager", "=", "new_figure_manager", "backend_mod", ".", "draw_if_interactive", "=", "draw_if_interactive", "manager_class", "=", "getattr", "(", "getattr", "(", "backend_mod", ",", "\"FigureCanvas\"", ",", "None", ")", ",", "\"manager_class\"", ",", "None", ")", "manager_pyplot_show", "=", "inspect", ".", "getattr_static", "(", "manager_class", ",", "\"pyplot_show\"", ",", "None", ")", "base_pyplot_show", "=", "inspect", ".", "getattr_static", "(", "FigureManagerBase", ",", "\"pyplot_show\"", ",", "None", ")", "if", "(", "show", "is", "None", "or", "(", "manager_pyplot_show", "is", "not", "None", "and", "manager_pyplot_show", "!=", "base_pyplot_show", ")", ")", ":", "backend_mod", ".", "show", "=", "manager_class", ".", "pyplot_show", "_log", ".", "debug", "(", "\"Loaded backend %s version %s.\"", ",", "newbackend", ",", "backend_mod", ".", "backend_version", ")", "rcParams", "[", "'backend'", "]", "=", "rcParamsDefault", "[", "'backend'", "]", "=", "newbackend", "_backend_mod", "=", "backend_mod", "for", "func_name", "in", "[", "\"new_figure_manager\"", ",", "\"draw_if_interactive\"", ",", "\"show\"", "]", ":", "globals", "(", ")", "[", "func_name", "]", ".", "__signature__", "=", "inspect", ".", "signature", "(", "getattr", "(", "backend_mod", ",", "func_name", ")", ")", "matplotlib", ".", "backends", ".", "backend", "=", "newbackend", "if", "not", "cbook", ".", "_str_equal", "(", "old_backend", ",", "newbackend", ")", ":", "close", "(", "\"all\"", ")", "try", ":", "install_repl_displayhook", "(", ")", "except", "ImportError", "as", "err", ":", "_log", ".", "warning", "(", "str", "(", "err", ")", ")", "raise", "ImportError"], "to_mask": {"VAR": ["FigureClass", "__signature__", "_backend_mod", "args", "backend", "backend_mod", "base_pyplot_show", "best_guess", "candidate", "candidates", "canvas_class", "current_framework", "draw_if_interactive", "err", "fig", "figure", "func_name", "manager", "manager_class", "manager_pyplot_show", "mapping", "new_figure_manager", "new_figure_manager_given_figure", "newbackend", "num", "old_backend", "required_framework", "show"], "METHOD": ["FigureClass", "ImportError", "__getitem__", "_backend_module_name", "_get_running_interactive_framework", "_str_equal", "close", "debug", "draw_idle", "format", "get", "get_active", "getattr", "getattr_static", "globals", "import_module", "install_repl_displayhook", "is_interactive", "locals", "new_figure_manager_given_figure", "new_manager", "signature", "str", "switch_backend", "update", "vars", "warning"]}, "attention_idx_tokens": [503, 507], "patch": "@@ -398,7 +400,11 @@\n \n     # make sure the repl display hook is installed in case we become\n     # interactive\n-    install_repl_displayhook()\n+    try:\n+        install_repl_displayhook()\n+    except ImportError as err:", "ext_attention_idx_tokens": [498, 518], "uid": "ac22a8ea", "question": "Clearly I'm no authority on this, but warning and re-raising seem pretty logical to do because it just crashes otherwise.      I also didn't fully understand your comment -- like why should there be no GUI at all with block=True/sleep enabled. The couple of examples I tried all seemed to work (switching to a different backend and continuing as intended). I'm very likely missing something, but is the expected behavior here something different? ", "code": "def switch backend newbackend \"\"\" Set the pyplot backend Switching to an interactive backend is possible only if no event loop for another interactive backend has started Switching to and from non-interactive backends is always possible If the new backend is different than the current backend then all open Figures will be closed via ``plt close all `` Parameters ---------- newbackend str The case-insensitive name of the backend to use \"\"\" global backend mod # make sure the init is pulled up so we can assign to it later import matplotlib backends if newbackend is rcsetup auto backend sentinel current framework cbook get running interactive framework mapping { qt qtagg gtk3 gtk3agg gtk4 gtk4agg wx wxagg tk tkagg macosx macosx headless agg } best guess mapping get current framework None if best guess is not None candidates [best guess] else candidates [] candidates + [ \"macosx\" \"qtagg\" \"gtk4agg\" \"gtk3agg\" \"tkagg\" \"wxagg\"] # Don t try to fallback on the cairo-based backends as they each have # an additional dependency pycairo over the agg-based backend and # are of worse quality for candidate in candidates try switch backend candidate except ImportError continue else rcParamsOrig[ backend ] candidate return else # Switching to Agg should always succeed; if it doesn t let the # exception propagate out switch backend \"agg\" rcParamsOrig[\"backend\"] \"agg\" return # have to escape the switch on access logic old backend dict getitem rcParams backend backend mod importlib import module cbook backend module name newbackend required framework backend mod FigureCanvas required interactive framework if required framework is not None current framework cbook get running interactive framework if current framework and required framework and current framework ! required framework raise ImportError \"Cannot load backend {!r} which requires the {!r} interactive \" \"framework as {!r} is currently running\" format newbackend required framework current framework # Load the new figure manager and show functions from the backend # Classically backends can directly export these functions This should # keep working for backcompat new figure manager getattr backend mod \"new figure manager\" None show getattr backend mod \"show\" None # In that classical approach backends are implemented as modules but # \"inherit\" default method implementations from backend bases Backend # This is achieved by creating a \"class\" that inherits from # backend bases Backend and whose body is filled with the module globals class backend mod matplotlib backend bases Backend locals update vars backend mod # However the newer approach for defining new figure manager and # show is to derive them from canvas methods In that case also # update backend mod accordingly; also per-backend customization of # draw if interactive is disabled if new figure manager is None # Only try to get the canvas class if have opted into the new scheme canvas class backend mod FigureCanvas def new figure manager given figure num figure return canvas class new manager figure num def new figure manager num *args FigureClass Figure **kwargs fig FigureClass *args **kwargs return new figure manager given figure num fig def draw if interactive if matplotlib is interactive manager pylab helpers Gcf get active if manager manager canvas draw idle backend mod new figure manager given figure \\ new figure manager given figure backend mod new figure manager new figure manager backend mod draw if interactive draw if interactive # If the manager explicitly overrides pyplot show use it even if a global # show is already present as the latter may be here for backcompat manager class getattr getattr backend mod \"FigureCanvas\" None \"manager class\" None # We can t compare directly manager class pyplot show and FMB pyplot show because # pyplot show is a classmethod so the above constructs are bound classmethods and # thus always different being bound to different classes We also have to use # getattr static instead of vars as manager class could have no dict manager pyplot show inspect getattr static manager class \"pyplot show\" None base pyplot show inspect getattr static FigureManagerBase \"pyplot show\" None if show is None or manager pyplot show is not None and manager pyplot show ! base pyplot show backend mod show manager class pyplot show log debug \"Loaded backend %s version %s \" newbackend backend mod backend version rcParams[ backend ] rcParamsDefault[ backend ] newbackend backend mod backend mod for func name in [\"new figure manager\" \"draw if interactive\" \"show\"] globals [func name] signature inspect signature getattr backend mod func name # Need to keep a global reference to the backend for compatibility reasons # See https github com matplotlib matplotlib issues 6092 matplotlib backends backend newbackend if not cbook str equal old backend newbackend close \"all\" # make sure the repl display hook is installed in case we become # interactive try install repl displayhook except ImportError as err log warning str err raise ImportError"}
{"message": "What I mean is what does relative to font size mean - like if I set offset to (12,12) in font size, what does that mean for how far the offset is from the text?.", "timestamp": "2023-05-21T15:19:03Z", "file_name": "lib/matplotlib/text.py", "range": {"start_line": 1703, "end_line": 1703, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1199784815", "html_url": "https://github.com/matplotlib/matplotlib/pull/25940#discussion_r1199784815", "attention_area": "            'offset fontsize'   Offset (relative to fontsize) from the *xy* value", "file_path": "files/60/08/00000860.py", "old_file_path": "files/61/08/00000861.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1701,15 +1693,15 @@ def transform(renderer) -> Transform\n or callable, default: value of *xycoords*\n             The coordinate system that *xytext* is given in.\n \n-            All *xycoords* values are valid as well as the following\n-            strings:\n+            All *xycoords* values are valid as well as the following strings:\n \n-            =================   =========================================\n+            =================   =================================================\n             Value               Description\n-            =================   =========================================\n+            =================   =================================================\n             'offset points'     Offset (in points) from the *xy* value\n             'offset pixels'     Offset (in pixels) from the *xy* value\n-            =================   =========================================\n+            'offset fontsize'   Offset (relative to fontsize) from the *xy* value", "source": "def __init__(self, text, xy,\n                 xytext=None,\n                 xycoords='data',\n                 textcoords=None,\n                 arrowprops=None,\n                 annotation_clip=None,\n                 **kwargs):\n        \"\"\"\n        Annotate the point *xy* with text *text*.\n\n        In the simplest form, the text is placed at *xy*.\n\n        Optionally, the text can be displayed in another position *xytext*.\n        An arrow pointing from the text to the annotated point *xy* can then\n        be added by defining *arrowprops*.\n\n        Parameters\n        ----------\n        text : str\n            The text of the annotation.\n\n        xy : (float, float)\n            The point *(x, y)* to annotate. The coordinate system is determined\n            by *xycoords*.\n\n        xytext : (float, float), default: *xy*\n            The position *(x, y)* to place the text at. The coordinate system\n            is determined by *textcoords*.\n\n        xycoords : single or two-tuple of str or `.Artist` or `.Transform` or \\\ncallable, default: 'data'\n\n            The coordinate system that *xy* is given in. The following types\n            of values are supported:\n\n            - One of the following strings:\n\n              ==================== ============================================\n              Value                Description\n              ==================== ============================================\n              'figure points'      Points from the lower left of the figure\n              'figure pixels'      Pixels from the lower left of the figure\n              'figure fraction'    Fraction of figure from lower left\n              'subfigure points'   Points from the lower left of the subfigure\n              'subfigure pixels'   Pixels from the lower left of the subfigure\n              'subfigure fraction' Fraction of subfigure from lower left\n              'axes points'        Points from lower left corner of axes\n              'axes pixels'        Pixels from lower left corner of axes\n              'axes fraction'      Fraction of axes from lower left\n              'data'               Use the coordinate system of the object\n                                   being annotated (default)\n              'polar'              *(theta, r)* if not native 'data'\n                                   coordinates\n              ==================== ============================================\n\n              Note that 'subfigure pixels' and 'figure pixels' are the same\n              for the parent figure, so users who want code that is usable in\n              a subfigure can use 'subfigure pixels'.\n\n            - An `.Artist`: *xy* is interpreted as a fraction of the artist's\n              `~matplotlib.transforms.Bbox`. E.g. *(0, 0)* would be the lower\n              left corner of the bounding box and *(0.5, 1)* would be the\n              center top of the bounding box.\n\n            - A `.Transform` to transform *xy* to screen coordinates.\n\n            - A function with one of the following signatures::\n\n                def transform(renderer) -> Bbox\n                def transform(renderer) -> Transform\n\n              where *renderer* is a `.RendererBase` subclass.\n\n              The result of the function is interpreted like the `.Artist` and\n              `.Transform` cases above.\n\n            - A tuple *(xcoords, ycoords)* specifying separate coordinate\n              systems for *x* and *y*. *xcoords* and *ycoords* must each be\n              of one of the above described types.\n\n            See :ref:`plotting-guide-annotation` for more details.\n\n        textcoords : single or two-tuple of str or `.Artist` or `.Transform` \\\nor callable, default: value of *xycoords*\n            The coordinate system that *xytext* is given in.\n\n            All *xycoords* values are valid as well as the following strings:\n\n            =================   =================================================\n            Value               Description\n            =================   =================================================\n            'offset points'     Offset (in points) from the *xy* value\n            'offset pixels'     Offset (in pixels) from the *xy* value\n            'offset fontsize'   Offset (relative to fontsize) from the *xy* value\n            =================   =================================================\n\n        arrowprops : dict, optional\n            The properties used to draw a `.FancyArrowPatch` arrow between the\n            positions *xy* and *xytext*.  Defaults to None, i.e. no arrow is\n            drawn.\n\n            For historical reasons there are two different ways to specify\n            arrows, \"simple\" and \"fancy\":\n\n            **Simple arrow:**\n\n            If *arrowprops* does not contain the key 'arrowstyle' the\n            allowed keys are:\n\n            ==========   ======================================================\n            Key          Description\n            ==========   ======================================================\n            width        The width of the arrow in points\n            headwidth    The width of the base of the arrow head in points\n            headlength   The length of the arrow head in points\n            shrink       Fraction of total length to shrink from both ends\n            ?            Any key to :class:`matplotlib.patches.FancyArrowPatch`\n            ==========   ======================================================\n\n            The arrow is attached to the edge of the text box, the exact\n            position (corners or centers) depending on where it's pointing to.\n\n            **Fancy arrow:**\n\n            This is used if 'arrowstyle' is provided in the *arrowprops*.\n\n            Valid keys are the following `~matplotlib.patches.FancyArrowPatch`\n            parameters:\n\n            ===============  ==================================================\n            Key              Description\n            ===============  ==================================================\n            arrowstyle       the arrow style\n            connectionstyle  the connection style\n            relpos           see below; default is (0.5, 0.5)\n            patchA           default is bounding box of the text\n            patchB           default is None\n            shrinkA          default is 2 points\n            shrinkB          default is 2 points\n            mutation_scale   default is text size (in points)\n            mutation_aspect  default is 1.\n            ?                any key for :class:`matplotlib.patches.PathPatch`\n            ===============  ==================================================\n\n            The exact starting point position of the arrow is defined by\n            *relpos*. It's a tuple of relative coordinates of the text box,\n            where (0, 0) is the lower left corner and (1, 1) is the upper\n            right corner. Values <0 and >1 are supported and specify points\n            outside the text box. By default (0.5, 0.5), so the starting point\n            is centered in the text box.\n\n        annotation_clip : bool or None, default: None\n            Whether to clip (i.e. not draw) the annotation when the annotation\n            point *xy* is outside the axes area.\n\n            - If *True*, the annotation will be clipped when *xy* is outside\n              the axes.\n            - If *False*, the annotation will always be drawn.\n            - If *None*, the annotation will be clipped when *xy* is outside\n              the axes and *xycoords* is 'data'.\n\n        **kwargs\n            Additional kwargs are passed to `~matplotlib.text.Text`.\n\n        Returns\n        -------\n        `.Annotation`\n\n        See Also\n        --------\n        :ref:`plotting-guide-annotation`\n\n        \"\"\"\n        _AnnotationBase.__init__(self,\n                                 xy,\n                                 xycoords=xycoords,\n                                 annotation_clip=annotation_clip)\n        # warn about wonky input data\n        if (xytext is None and\n                textcoords is not None and\n                textcoords != xycoords):\n            _api.warn_external(\"You have used the `textcoords` kwarg, but \"\n                               \"not the `xytext` kwarg.  This can lead to \"\n                               \"surprising results.\")\n\n        # clean up textcoords and assign default\n        if textcoords is None:\n            textcoords = self.xycoords\n        self._textcoords = textcoords\n\n        # cleanup xytext defaults\n        if xytext is None:\n            xytext = self.xy\n        x, y = xytext\n\n        self.arrowprops = arrowprops\n        if arrowprops is not None:\n            arrowprops = arrowprops.copy()\n            if \"arrowstyle\" in arrowprops:\n                self._arrow_relpos = arrowprops.pop(\"relpos\", (0.5, 0.5))\n            else:\n                # modified YAArrow API to be used with FancyArrowPatch\n                for key in [\n                        'width', 'headwidth', 'headlength', 'shrink', 'frac']:\n                    arrowprops.pop(key, None)\n            self.arrow_patch = FancyArrowPatch((0, 0), (1, 1), **arrowprops)\n        else:\n            self.arrow_patch = None\n\n        # Must come last, as some kwargs may be propagated to arrow_patch.\n        Text.__init__(self, x, y, text, **kwargs)", "source_start_line": 1610, "tokens": ["def", "__init__", "(", "self", ",", "text", ",", "xy", ",", "xytext", "=", "None", ",", "xycoords", "=", "'data'", ",", "textcoords", "=", "None", ",", "arrowprops", "=", "None", ",", "annotation_clip", "=", "None", ",", "**", "kwargs", ")", ":", "\"\"\"        Annotate the point *xy* with text *text*.        In the simplest form, the text is placed at *xy*.        Optionally, the text can be displayed in another position *xytext*.        An arrow pointing from the text to the annotated point *xy* can then        be added by defining *arrowprops*.        Parameters        ----------        text : str            The text of the annotation.        xy : (float, float)            The point *(x, y)* to annotate. The coordinate system is determined            by *xycoords*.        xytext : (float, float), default: *xy*            The position *(x, y)* to place the text at. The coordinate system            is determined by *textcoords*.        xycoords : single or two-tuple of str or `.Artist` or `.Transform` or \\callable, default: 'data'            The coordinate system that *xy* is given in. The following types            of values are supported:            - One of the following strings:              ==================== ============================================              Value                Description              ==================== ============================================              'figure points'      Points from the lower left of the figure              'figure pixels'      Pixels from the lower left of the figure              'figure fraction'    Fraction of figure from lower left              'subfigure points'   Points from the lower left of the subfigure              'subfigure pixels'   Pixels from the lower left of the subfigure              'subfigure fraction' Fraction of subfigure from lower left              'axes points'        Points from lower left corner of axes              'axes pixels'        Pixels from lower left corner of axes              'axes fraction'      Fraction of axes from lower left              'data'               Use the coordinate system of the object                                   being annotated (default)              'polar'              *(theta, r)* if not native 'data'                                   coordinates              ==================== ============================================              Note that 'subfigure pixels' and 'figure pixels' are the same              for the parent figure, so users who want code that is usable in              a subfigure can use 'subfigure pixels'.            - An `.Artist`: *xy* is interpreted as a fraction of the artist's              `~matplotlib.transforms.Bbox`. E.g. *(0, 0)* would be the lower              left corner of the bounding box and *(0.5, 1)* would be the              center top of the bounding box.            - A `.Transform` to transform *xy* to screen coordinates.            - A function with one of the following signatures::                def transform(renderer) -> Bbox                def transform(renderer) -> Transform              where *renderer* is a `.RendererBase` subclass.              The result of the function is interpreted like the `.Artist` and              `.Transform` cases above.            - A tuple *(xcoords, ycoords)* specifying separate coordinate              systems for *x* and *y*. *xcoords* and *ycoords* must each be              of one of the above described types.            See :ref:`plotting-guide-annotation` for more details.        textcoords : single or two-tuple of str or `.Artist` or `.Transform` \\or callable, default: value of *xycoords*            The coordinate system that *xytext* is given in.            All *xycoords* values are valid as well as the following strings:            =================   =================================================            Value               Description            =================   =================================================            'offset points'     Offset (in points) from the *xy* value            'offset pixels'     Offset (in pixels) from the *xy* value            'offset fontsize'   Offset (relative to fontsize) from the *xy* value            =================   =================================================        arrowprops : dict, optional            The properties used to draw a `.FancyArrowPatch` arrow between the            positions *xy* and *xytext*.  Defaults to None, i.e. no arrow is            drawn.            For historical reasons there are two different ways to specify            arrows, \"simple\" and \"fancy\":            **Simple arrow:**            If *arrowprops* does not contain the key 'arrowstyle' the            allowed keys are:            ==========   ======================================================            Key          Description            ==========   ======================================================            width        The width of the arrow in points            headwidth    The width of the base of the arrow head in points            headlength   The length of the arrow head in points            shrink       Fraction of total length to shrink from both ends            ?            Any key to :class:`matplotlib.patches.FancyArrowPatch`            ==========   ======================================================            The arrow is attached to the edge of the text box, the exact            position (corners or centers) depending on where it's pointing to.            **Fancy arrow:**            This is used if 'arrowstyle' is provided in the *arrowprops*.            Valid keys are the following `~matplotlib.patches.FancyArrowPatch`            parameters:            ===============  ==================================================            Key              Description            ===============  ==================================================            arrowstyle       the arrow style            connectionstyle  the connection style            relpos           see below; default is (0.5, 0.5)            patchA           default is bounding box of the text            patchB           default is None            shrinkA          default is 2 points            shrinkB          default is 2 points            mutation_scale   default is text size (in points)            mutation_aspect  default is 1.            ?                any key for :class:`matplotlib.patches.PathPatch`            ===============  ==================================================            The exact starting point position of the arrow is defined by            *relpos*. It's a tuple of relative coordinates of the text box,            where (0, 0) is the lower left corner and (1, 1) is the upper            right corner. Values <0 and >1 are supported and specify points            outside the text box. By default (0.5, 0.5), so the starting point            is centered in the text box.        annotation_clip : bool or None, default: None            Whether to clip (i.e. not draw) the annotation when the annotation            point *xy* is outside the axes area.            - If *True*, the annotation will be clipped when *xy* is outside              the axes.            - If *False*, the annotation will always be drawn.            - If *None*, the annotation will be clipped when *xy* is outside              the axes and *xycoords* is 'data'.        **kwargs            Additional kwargs are passed to `~matplotlib.text.Text`.        Returns        -------        `.Annotation`        See Also        --------        :ref:`plotting-guide-annotation`        \"\"\"", "_AnnotationBase", ".", "__init__", "(", "self", ",", "xy", ",", "xycoords", "=", "xycoords", ",", "annotation_clip", "=", "annotation_clip", ")", "if", "(", "xytext", "is", "None", "and", "textcoords", "is", "not", "None", "and", "textcoords", "!=", "xycoords", ")", ":", "_api", ".", "warn_external", "(", "\"You have used the `textcoords` kwarg, but \"", "\"not the `xytext` kwarg.  This can lead to \"", "\"surprising results.\"", ")", "if", "textcoords", "is", "None", ":", "textcoords", "=", "self", ".", "xycoords", "self", ".", "_textcoords", "=", "textcoords", "if", "xytext", "is", "None", ":", "xytext", "=", "self", ".", "xy", "x", ",", "y", "=", "xytext", "self", ".", "arrowprops", "=", "arrowprops", "if", "arrowprops", "is", "not", "None", ":", "arrowprops", "=", "arrowprops", ".", "copy", "(", ")", "if", "\"arrowstyle\"", "in", "arrowprops", ":", "self", ".", "_arrow_relpos", "=", "arrowprops", ".", "pop", "(", "\"relpos\"", ",", "(", "0.5", ",", "0.5", ")", ")", "else", ":", "for", "key", "in", "[", "'width'", ",", "'headwidth'", ",", "'headlength'", ",", "'shrink'", ",", "'frac'", "]", ":", "arrowprops", ".", "pop", "(", "key", ",", "None", ")", "self", ".", "arrow_patch", "=", "FancyArrowPatch", "(", "(", "0", ",", "0", ")", ",", "(", "1", ",", "1", ")", ",", "**", "arrowprops", ")", "else", ":", "self", ".", "arrow_patch", "=", "None", "Text", ".", "__init__", "(", "self", ",", "x", ",", "y", ",", "text", ",", "**", "kwargs", ")"], "to_mask": {"VAR": ["_arrow_relpos", "_textcoords", "annotation_clip", "arrow_patch", "arrowprops", "key", "self", "text", "textcoords", "x", "xy", "xycoords", "xytext", "y"], "METHOD": ["FancyArrowPatch", "__init__", "copy", "pop", "warn_external"]}, "attention_idx_tokens": [null, null], "patch": "@@ -1701,15 +1693,15 @@\n or callable, default: value of *xycoords*\n             The coordinate system that *xytext* is given in.\n \n-            All *xycoords* values are valid as well as the following\n-            strings:\n+            All *xycoords* values are valid as well as the following strings:\n \n-            =================   =========================================\n+            =================   =================================================\n             Value               Description\n-            =================   =========================================\n+            =================   =================================================\n             'offset points'     Offset (in points) from the *xy* value\n             'offset pixels'     Offset (in pixels) from the *xy* value\n-            =================   =========================================\n+            'offset fontsize'   Offset (relative to fontsize) from the *xy* value", "ext_attention_idx_tokens": [null, null], "uid": "36cbaf57", "question": "What I mean is what does relative to font size mean - like if I set offset to (12,12) in font size, what does that mean for how far the offset is from the text?.", "code": "def init self text xy xytext None xycoords data textcoords None arrowprops None annotation clip None **kwargs \"\"\" Annotate the point *xy* with text *text* In the simplest form the text is placed at *xy* Optionally the text can be displayed in another position *xytext* An arrow pointing from the text to the annotated point *xy* can then be added by defining *arrowprops* Parameters ---------- text str The text of the annotation xy float float The point * x y * to annotate The coordinate system is determined by *xycoords* xytext float float default *xy* The position * x y * to place the text at The coordinate system is determined by *textcoords* xycoords single or two-tuple of str or ` Artist` or ` Transform` or \\ callable default data The coordinate system that *xy* is given in The following types of values are supported - One of the following strings Value Description figure points Points from the lower left of the figure figure pixels Pixels from the lower left of the figure figure fraction Fraction of figure from lower left subfigure points Points from the lower left of the subfigure subfigure pixels Pixels from the lower left of the subfigure subfigure fraction Fraction of subfigure from lower left axes points Points from lower left corner of axes axes pixels Pixels from lower left corner of axes axes fraction Fraction of axes from lower left data Use the coordinate system of the object being annotated default polar * theta r * if not native data coordinates Note that subfigure pixels and figure pixels are the same for the parent figure so users who want code that is usable in a subfigure can use subfigure pixels - An ` Artist` *xy* is interpreted as a fraction of the artist s `~matplotlib transforms Bbox` E g * 0 0 * would be the lower left corner of the bounding box and * 0 5 1 * would be the center top of the bounding box - A ` Transform` to transform *xy* to screen coordinates - A function with one of the following signatures def transform renderer -> Bbox def transform renderer -> Transform where *renderer* is a ` RendererBase` subclass The result of the function is interpreted like the ` Artist` and ` Transform` cases above - A tuple * xcoords ycoords * specifying separate coordinate systems for *x* and *y* *xcoords* and *ycoords* must each be of one of the above described types See ref `plotting-guide-annotation` for more details textcoords single or two-tuple of str or ` Artist` or ` Transform` \\ or callable default value of *xycoords* The coordinate system that *xytext* is given in All *xycoords* values are valid as well as the following strings Value Description offset points Offset in points from the *xy* value offset pixels Offset in pixels from the *xy* value offset fontsize Offset relative to fontsize from the *xy* value arrowprops dict optional The properties used to draw a ` FancyArrowPatch` arrow between the positions *xy* and *xytext* Defaults to None i e no arrow is drawn For historical reasons there are two different ways to specify arrows \"simple\" and \"fancy\" **Simple arrow ** If *arrowprops* does not contain the key arrowstyle the allowed keys are Key Description width The width of the arrow in points headwidth The width of the base of the arrow head in points headlength The length of the arrow head in points shrink Fraction of total length to shrink from both ends ? Any key to class `matplotlib patches FancyArrowPatch` The arrow is attached to the edge of the text box the exact position corners or centers depending on where it s pointing to **Fancy arrow ** This is used if arrowstyle is provided in the *arrowprops* Valid keys are the following `~matplotlib patches FancyArrowPatch` parameters Key Description arrowstyle the arrow style connectionstyle the connection style relpos see below; default is 0 5 0 5 patchA default is bounding box of the text patchB default is None shrinkA default is 2 points shrinkB default is 2 points mutation scale default is text size in points mutation aspect default is 1 ? any key for class `matplotlib patches PathPatch` The exact starting point position of the arrow is defined by *relpos* It s a tuple of relative coordinates of the text box where 0 0 is the lower left corner and 1 1 is the upper right corner Values <0 and >1 are supported and specify points outside the text box By default 0 5 0 5 so the starting point is centered in the text box annotation clip bool or None default None Whether to clip i e not draw the annotation when the annotation point *xy* is outside the axes area - If *True* the annotation will be clipped when *xy* is outside the axes - If *False* the annotation will always be drawn - If *None* the annotation will be clipped when *xy* is outside the axes and *xycoords* is data **kwargs Additional kwargs are passed to `~matplotlib text Text` Returns ------- ` Annotation` See Also -------- ref `plotting-guide-annotation` \"\"\" AnnotationBase init self xy xycoords xycoords annotation clip annotation clip # warn about wonky input data if xytext is None and textcoords is not None and textcoords ! xycoords api warn external \"You have used the `textcoords` kwarg but \" \"not the `xytext` kwarg This can lead to \" \"surprising results \" # clean up textcoords and assign default if textcoords is None textcoords self xycoords self textcoords textcoords # cleanup xytext defaults if xytext is None xytext self xy x y xytext self arrowprops arrowprops if arrowprops is not None arrowprops arrowprops copy if \"arrowstyle\" in arrowprops self arrow relpos arrowprops pop \"relpos\" 0 5 0 5 else # modified YAArrow API to be used with FancyArrowPatch for key in [ width headwidth headlength shrink frac ] arrowprops pop key None self arrow patch FancyArrowPatch 0 0 1 1 **arrowprops else self arrow patch None # Must come last as some kwargs may be propagated to arrow patch Text init self x y text **kwargs"}
{"message": "What is this?", "timestamp": "2023-05-23T08:06:21Z", "file_name": "lib/matplotlib/figure.py", "range": {"start_line": 1556, "end_line": 1556, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1201741072", "html_url": "https://github.com/matplotlib/matplotlib/pull/25954#discussion_r1201741072", "attention_area": "            ``subfigure`` is new in v3.4, and the API is still provisional.", "file_path": "files/62/08/00000862.py", "old_file_path": "files/63/08/00000863.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1552,6 +1552,9 @@ def subfigures(self, nrows=1, ncols=1, squeeze=True,\n         the same as a figure, but cannot print itself.\n         See :doc:`/gallery/subplots_axes_and_figures/subfigures`.\n \n+        .. note::\n+            ``subfigure`` is new in v3.4, and the API is still provisional.", "source": "def subfigures(self, nrows=1, ncols=1, squeeze=True,\n                   wspace=None, hspace=None,\n                   width_ratios=None, height_ratios=None,\n                   **kwargs):\n        \"\"\"\n        Add a set of subfigures to this figure or subfigure.\n\n        A subfigure has the same artist methods as a figure, and is logically\n        the same as a figure, but cannot print itself.\n        See :doc:`/gallery/subplots_axes_and_figures/subfigures`.\n\n        .. note::\n            ``subfigure`` is new in v3.4, and the API is still provisional.\n\n        Parameters\n        ----------\n        nrows, ncols : int, default: 1\n            Number of rows/columns of the subfigure grid.\n\n        squeeze : bool, default: True\n            If True, extra dimensions are squeezed out from the returned\n            array of subfigures.\n\n        wspace, hspace : float, default: None\n            The amount of width/height reserved for space between subfigures,\n            expressed as a fraction of the average subfigure width/height.\n            If not given, the values will be inferred from a figure or\n            rcParams when necessary.\n\n        width_ratios : array-like of length *ncols*, optional\n            Defines the relative widths of the columns. Each column gets a\n            relative width of ``width_ratios[i] / sum(width_ratios)``.\n            If not given, all columns will have the same width.\n\n        height_ratios : array-like of length *nrows*, optional\n            Defines the relative heights of the rows. Each row gets a\n            relative height of ``height_ratios[i] / sum(height_ratios)``.\n            If not given, all rows will have the same height.\n        \"\"\"\n        gs = GridSpec(nrows=nrows, ncols=ncols, figure=self,\n                      wspace=wspace, hspace=hspace,\n                      width_ratios=width_ratios,\n                      height_ratios=height_ratios)\n\n        sfarr = np.empty((nrows, ncols), dtype=object)\n        for i in range(ncols):\n            for j in range(nrows):\n                sfarr[j, i] = self.add_subfigure(gs[j, i], **kwargs)\n\n        if squeeze:\n            # Discarding unneeded dimensions that equal 1.  If we only have one\n            # subfigure, just return it instead of a 1-element array.\n            return sfarr.item() if sfarr.size == 1 else sfarr.squeeze()\n        else:\n            # Returned axis array will be always 2-d, even if nrows=ncols=1.\n            return sfarr", "source_start_line": 1544, "tokens": ["def", "subfigures", "(", "self", ",", "nrows", "=", "1", ",", "ncols", "=", "1", ",", "squeeze", "=", "True", ",", "wspace", "=", "None", ",", "hspace", "=", "None", ",", "width_ratios", "=", "None", ",", "height_ratios", "=", "None", ",", "**", "kwargs", ")", ":", "\"\"\"        Add a set of subfigures to this figure or subfigure.        A subfigure has the same artist methods as a figure, and is logically        the same as a figure, but cannot print itself.        See :doc:`/gallery/subplots_axes_and_figures/subfigures`.        .. note::            ``subfigure`` is new in v3.4, and the API is still provisional.        Parameters        ----------        nrows, ncols : int, default: 1            Number of rows/columns of the subfigure grid.        squeeze : bool, default: True            If True, extra dimensions are squeezed out from the returned            array of subfigures.        wspace, hspace : float, default: None            The amount of width/height reserved for space between subfigures,            expressed as a fraction of the average subfigure width/height.            If not given, the values will be inferred from a figure or            rcParams when necessary.        width_ratios : array-like of length *ncols*, optional            Defines the relative widths of the columns. Each column gets a            relative width of ``width_ratios[i] / sum(width_ratios)``.            If not given, all columns will have the same width.        height_ratios : array-like of length *nrows*, optional            Defines the relative heights of the rows. Each row gets a            relative height of ``height_ratios[i] / sum(height_ratios)``.            If not given, all rows will have the same height.        \"\"\"", "gs", "=", "GridSpec", "(", "nrows", "=", "nrows", ",", "ncols", "=", "ncols", ",", "figure", "=", "self", ",", "wspace", "=", "wspace", ",", "hspace", "=", "hspace", ",", "width_ratios", "=", "width_ratios", ",", "height_ratios", "=", "height_ratios", ")", "sfarr", "=", "np", ".", "empty", "(", "(", "nrows", ",", "ncols", ")", ",", "dtype", "=", "object", ")", "for", "i", "in", "range", "(", "ncols", ")", ":", "for", "j", "in", "range", "(", "nrows", ")", ":", "sfarr", "[", "j", ",", "i", "]", "=", "self", ".", "add_subfigure", "(", "gs", "[", "j", ",", "i", "]", ",", "**", "kwargs", ")", "if", "squeeze", ":", "return", "sfarr", ".", "item", "(", ")", "if", "sfarr", ".", "size", "==", "1", "else", "sfarr", ".", "squeeze", "(", ")", "else", ":", "return", "sfarr"], "to_mask": {"VAR": ["gs", "height_ratios", "hspace", "i", "j", "ncols", "nrows", "self", "sfarr", "squeeze", "width_ratios", "wspace"], "METHOD": ["GridSpec", "add_subfigure", "empty", "item", "range", "squeeze"]}, "attention_idx_tokens": [null, null], "patch": "@@ -1552,6 +1552,9 @@\n         the same as a figure, but cannot print itself.\n         See :doc:`/gallery/subplots_axes_and_figures/subfigures`.\n \n+        .. note::\n+            ``subfigure`` is new in v3.4, and the API is still provisional.", "ext_attention_idx_tokens": [null, null], "uid": "0d7dfab1", "question": "What is this?", "code": "def subfigures self nrows 1 ncols 1 squeeze True wspace None hspace None width ratios None height ratios None **kwargs \"\"\" Add a set of subfigures to this figure or subfigure A subfigure has the same artist methods as a figure and is logically the same as a figure but cannot print itself See doc ` gallery subplots axes and figures subfigures` note ``subfigure`` is new in v3 4 and the API is still provisional Parameters ---------- nrows ncols int default 1 Number of rows columns of the subfigure grid squeeze bool default True If True extra dimensions are squeezed out from the returned array of subfigures wspace hspace float default None The amount of width height reserved for space between subfigures expressed as a fraction of the average subfigure width height If not given the values will be inferred from a figure or rcParams when necessary width ratios array-like of length *ncols* optional Defines the relative widths of the columns Each column gets a relative width of ``width ratios[i] sum width ratios `` If not given all columns will have the same width height ratios array-like of length *nrows* optional Defines the relative heights of the rows Each row gets a relative height of ``height ratios[i] sum height ratios `` If not given all rows will have the same height \"\"\" gs GridSpec nrows nrows ncols ncols figure self wspace wspace hspace hspace width ratios width ratios height ratios height ratios sfarr np empty nrows ncols dtype object for i in range ncols for j in range nrows sfarr[j i] self add subfigure gs[j i] **kwargs if squeeze # Discarding unneeded dimensions that equal 1 If we only have one # subfigure just return it instead of a 1-element array return sfarr item if sfarr size 1 else sfarr squeeze else # Returned axis array will be always 2-d even if nrows ncols 1 return sfarr"}
{"message": "Can you also add bar since we also recommend bar Y the top for plotting precomputed histograms?", "timestamp": "2023-05-23T12:44:32Z", "file_name": "lib/matplotlib/axes/_axes.py", "range": {"start_line": 6703, "end_line": 6703, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1202261956", "html_url": "https://github.com/matplotlib/matplotlib/pull/25955#discussion_r1202261956", "attention_area": "        stairs : Plot a pre-computed histogram", "file_path": "files/64/08/00000864.py", "old_file_path": "files/65/08/00000865.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -6700,12 +6700,14 @@ def hist(self, x, bins=None, range=None, density=False, weights=None,\n         --------\n         hist2d : 2D histogram with rectangular bins\n         hexbin : 2D histogram with hexagonal bins\n+        stairs : Plot a pre-computed histogram", "source": "def hist(self, x, bins=None, range=None, density=False, weights=None,\n             cumulative=False, bottom=None, histtype='bar', align='mid',\n             orientation='vertical', rwidth=None, log=False,\n             color=None, label=None, stacked=False, **kwargs):\n        \"\"\"\n        Compute and plot a histogram.\n\n        This method uses `numpy.histogram` to bin the data in *x* and count the\n        number of values in each bin, then draws the distribution either as a\n        `.BarContainer` or `.Polygon`. The *bins*, *range*, *density*, and\n        *weights* parameters are forwarded to `numpy.histogram`.\n\n        If the data has already been binned and counted, use `~.bar` or\n        `~.stairs` to plot the distribution::\n\n            counts, bins = np.histogram(x)\n            plt.stairs(counts, bins)\n\n        Alternatively, plot pre-computed bins and counts using ``hist()`` by\n        treating each bin as a single point with a weight equal to its count::\n\n            plt.hist(bins[:-1], bins, weights=counts)\n\n        The data input *x* can be a singular array, a list of datasets of\n        potentially different lengths ([*x0*, *x1*, ...]), or a 2D ndarray in\n        which each column is a dataset. Note that the ndarray form is\n        transposed relative to the list form. If the input is an array, then\n        the return value is a tuple (*n*, *bins*, *patches*); if the input is a\n        sequence of arrays, then the return value is a tuple\n        ([*n0*, *n1*, ...], *bins*, [*patches0*, *patches1*, ...]).\n\n        Masked arrays are not supported.\n\n        Parameters\n        ----------\n        x : (n,) array or sequence of (n,) arrays\n            Input values, this takes either a single array or a sequence of\n            arrays which are not required to be of the same length.\n\n        bins : int or sequence or str, default: :rc:`hist.bins`\n            If *bins* is an integer, it defines the number of equal-width bins\n            in the range.\n\n            If *bins* is a sequence, it defines the bin edges, including the\n            left edge of the first bin and the right edge of the last bin;\n            in this case, bins may be unequally spaced.  All but the last\n            (righthand-most) bin is half-open.  In other words, if *bins* is::\n\n                [1, 2, 3, 4]\n\n            then the first bin is ``[1, 2)`` (including 1, but excluding 2) and\n            the second ``[2, 3)``.  The last bin, however, is ``[3, 4]``, which\n            *includes* 4.\n\n            If *bins* is a string, it is one of the binning strategies\n            supported by `numpy.histogram_bin_edges`: 'auto', 'fd', 'doane',\n            'scott', 'stone', 'rice', 'sturges', or 'sqrt'.\n\n        range : tuple or None, default: None\n            The lower and upper range of the bins. Lower and upper outliers\n            are ignored. If not provided, *range* is ``(x.min(), x.max())``.\n            Range has no effect if *bins* is a sequence.\n\n            If *bins* is a sequence or *range* is specified, autoscaling\n            is based on the specified bin range instead of the\n            range of x.\n\n        density : bool, default: False\n            If ``True``, draw and return a probability density: each bin\n            will display the bin's raw count divided by the total number of\n            counts *and the bin width*\n            (``density = counts / (sum(counts) * np.diff(bins))``),\n            so that the area under the histogram integrates to 1\n            (``np.sum(density * np.diff(bins)) == 1``).\n\n            If *stacked* is also ``True``, the sum of the histograms is\n            normalized to 1.\n\n        weights : (n,) array-like or None, default: None\n            An array of weights, of the same shape as *x*.  Each value in\n            *x* only contributes its associated weight towards the bin count\n            (instead of 1).  If *density* is ``True``, the weights are\n            normalized, so that the integral of the density over the range\n            remains 1.\n\n        cumulative : bool or -1, default: False\n            If ``True``, then a histogram is computed where each bin gives the\n            counts in that bin plus all bins for smaller values. The last bin\n            gives the total number of datapoints.\n\n            If *density* is also ``True`` then the histogram is normalized such\n            that the last bin equals 1.\n\n            If *cumulative* is a number less than 0 (e.g., -1), the direction\n            of accumulation is reversed.  In this case, if *density* is also\n            ``True``, then the histogram is normalized such that the first bin\n            equals 1.\n\n        bottom : array-like, scalar, or None, default: None\n            Location of the bottom of each bin, i.e. bins are drawn from\n            ``bottom`` to ``bottom + hist(x, bins)`` If a scalar, the bottom\n            of each bin is shifted by the same amount. If an array, each bin\n            is shifted independently and the length of bottom must match the\n            number of bins. If None, defaults to 0.\n\n        histtype : {'bar', 'barstacked', 'step', 'stepfilled'}, default: 'bar'\n            The type of histogram to draw.\n\n            - 'bar' is a traditional bar-type histogram.  If multiple data\n              are given the bars are arranged side by side.\n            - 'barstacked' is a bar-type histogram where multiple\n              data are stacked on top of each other.\n            - 'step' generates a lineplot that is by default unfilled.\n            - 'stepfilled' generates a lineplot that is by default filled.\n\n        align : {'left', 'mid', 'right'}, default: 'mid'\n            The horizontal alignment of the histogram bars.\n\n            - 'left': bars are centered on the left bin edges.\n            - 'mid': bars are centered between the bin edges.\n            - 'right': bars are centered on the right bin edges.\n\n        orientation : {'vertical', 'horizontal'}, default: 'vertical'\n            If 'horizontal', `~.Axes.barh` will be used for bar-type histograms\n            and the *bottom* kwarg will be the left edges.\n\n        rwidth : float or None, default: None\n            The relative width of the bars as a fraction of the bin width.  If\n            ``None``, automatically compute the width.\n\n            Ignored if *histtype* is 'step' or 'stepfilled'.\n\n        log : bool, default: False\n            If ``True``, the histogram axis will be set to a log scale.\n\n        color : color or array-like of colors or None, default: None\n            Color or sequence of colors, one per dataset.  Default (``None``)\n            uses the standard line color sequence.\n\n        label : str or None, default: None\n            String, or sequence of strings to match multiple datasets.  Bar\n            charts yield multiple patches per dataset, but only the first gets\n            the label, so that `~.Axes.legend` will work as expected.\n\n        stacked : bool, default: False\n            If ``True``, multiple data are stacked on top of each other If\n            ``False`` multiple data are arranged side by side if histtype is\n            'bar' or on top of each other if histtype is 'step'\n\n        Returns\n        -------\n        n : array or list of arrays\n            The values of the histogram bins. See *density* and *weights* for a\n            description of the possible semantics.  If input *x* is an array,\n            then this is an array of length *nbins*. If input is a sequence of\n            arrays ``[data1, data2, ...]``, then this is a list of arrays with\n            the values of the histograms for each of the arrays in the same\n            order.  The dtype of the array *n* (or of its element arrays) will\n            always be float even if no weighting or normalization is used.\n\n        bins : array\n            The edges of the bins. Length nbins + 1 (nbins left edges and right\n            edge of last bin).  Always a single array even when multiple data\n            sets are passed in.\n\n        patches : `.BarContainer` or list of a single `.Polygon` or list of \\\nsuch objects\n            Container of individual artists used to create the histogram\n            or list of such containers if there are multiple input datasets.\n\n        Other Parameters\n        ----------------\n        data : indexable object, optional\n            DATA_PARAMETER_PLACEHOLDER\n\n        **kwargs\n            `~matplotlib.patches.Patch` properties\n\n        See Also\n        --------\n        hist2d : 2D histogram with rectangular bins\n        hexbin : 2D histogram with hexagonal bins\n        stairs : Plot a pre-computed histogram\n\n        Notes\n        -----\n        For large numbers of bins (>1000), plotting can be significantly\n        accelerated by setting *histtype* to 'step' or 'stepfilled' rather\n        than 'bar' or 'barstacked', or by using `~.Axes.stairs` to plot a\n        pre-computed histogram (``plt.stairs(*np.histogram(data))``).\n        \"\"\"\n        # Avoid shadowing the builtin.\n        bin_range = range\n        from builtins import range\n\n        if np.isscalar(x):\n            x = [x]\n\n        if bins is None:\n            bins = mpl.rcParams['hist.bins']\n\n        # Validate string inputs here to avoid cluttering subsequent code.\n        _api.check_in_list(['bar', 'barstacked', 'step', 'stepfilled'],\n                           histtype=histtype)\n        _api.check_in_list(['left', 'mid', 'right'], align=align)\n        _api.check_in_list(['horizontal', 'vertical'], orientation=orientation)\n\n        if histtype == 'barstacked' and not stacked:\n            stacked = True\n\n        # Massage 'x' for processing.\n        x = cbook._reshape_2D(x, 'x')\n        nx = len(x)  # number of datasets\n\n        # Process unit information.  _process_unit_info sets the unit and\n        # converts the first dataset; then we convert each following dataset\n        # one at a time.\n        if orientation == \"vertical\":\n            convert_units = self.convert_xunits\n            x = [*self._process_unit_info([(\"x\", x[0])], kwargs),\n                 *map(convert_units, x[1:])]\n        else:  # horizontal\n            convert_units = self.convert_yunits\n            x = [*self._process_unit_info([(\"y\", x[0])], kwargs),\n                 *map(convert_units, x[1:])]\n\n        if bin_range is not None:\n            bin_range = convert_units(bin_range)\n\n        if not cbook.is_scalar_or_string(bins):\n            bins = convert_units(bins)\n\n        # We need to do to 'weights' what was done to 'x'\n        if weights is not None:\n            w = cbook._reshape_2D(weights, 'weights')\n        else:\n            w = [None] * nx\n\n        if len(w) != nx:\n            raise ValueError('weights should have the same shape as x')\n\n        input_empty = True\n        for xi, wi in zip(x, w):\n            len_xi = len(xi)\n            if wi is not None and len(wi) != len_xi:\n                raise ValueError('weights should have the same shape as x')\n            if len_xi:\n                input_empty = False\n\n        if color is None:\n            colors = [self._get_lines.get_next_color() for i in range(nx)]\n        else:\n            colors = mcolors.to_rgba_array(color)\n            if len(colors) != nx:\n                raise ValueError(f\"The 'color' keyword argument must have one \"\n                                 f\"color per dataset, but {nx} datasets and \"\n                                 f\"{len(colors)} colors were provided\")\n\n        hist_kwargs = dict()\n\n        # if the bin_range is not given, compute without nan numpy\n        # does not do this for us when guessing the range (but will\n        # happily ignore nans when computing the histogram).\n        if bin_range is None:\n            xmin = np.inf\n            xmax = -np.inf\n            for xi in x:\n                if len(xi):\n                    # python's min/max ignore nan,\n                    # np.minnan returns nan for all nan input\n                    xmin = min(xmin, np.nanmin(xi))\n                    xmax = max(xmax, np.nanmax(xi))\n            if xmin <= xmax:  # Only happens if we have seen a finite value.\n                bin_range = (xmin, xmax)\n\n        # If bins are not specified either explicitly or via range,\n        # we need to figure out the range required for all datasets,\n        # and supply that to np.histogram.\n        if not input_empty and len(x) > 1:\n            if weights is not None:\n                _w = np.concatenate(w)\n            else:\n                _w = None\n            bins = np.histogram_bin_edges(\n                np.concatenate(x), bins, bin_range, _w)\n        else:\n            hist_kwargs['range'] = bin_range\n\n        density = bool(density)\n        if density and not stacked:\n            hist_kwargs['density'] = density\n\n        # List to store all the top coordinates of the histograms\n        tops = []  # Will have shape (n_datasets, n_bins).\n        # Loop through datasets\n        for i in range(nx):\n            # this will automatically overwrite bins,\n            # so that each histogram uses the same bins\n            m, bins = np.histogram(x[i], bins, weights=w[i], **hist_kwargs)\n            tops.append(m)\n        tops = np.array(tops, float)  # causes problems later if it's an int\n        bins = np.array(bins, float)  # causes problems if float16\n        if stacked:\n            tops = tops.cumsum(axis=0)\n            # If a stacked density plot, normalize so the area of all the\n            # stacked histograms together is 1\n            if density:\n                tops = (tops / np.diff(bins)) / tops[-1].sum()\n        if cumulative:\n            slc = slice(None)\n            if isinstance(cumulative, Number) and cumulative < 0:\n                slc = slice(None, None, -1)\n            if density:\n                tops = (tops * np.diff(bins))[:, slc].cumsum(axis=1)[:, slc]\n            else:\n                tops = tops[:, slc].cumsum(axis=1)[:, slc]\n\n        patches = []\n\n        if histtype.startswith('bar'):\n\n            totwidth = np.diff(bins)\n\n            if rwidth is not None:\n                dr = np.clip(rwidth, 0, 1)\n            elif (len(tops) > 1 and\n                  ((not stacked) or mpl.rcParams['_internal.classic_mode'])):\n                dr = 0.8\n            else:\n                dr = 1.0\n\n            if histtype == 'bar' and not stacked:\n                width = dr * totwidth / nx\n                dw = width\n                boffset = -0.5 * dr * totwidth * (1 - 1 / nx)\n            elif histtype == 'barstacked' or stacked:\n                width = dr * totwidth\n                boffset, dw = 0.0, 0.0\n\n            if align == 'mid':\n                boffset += 0.5 * totwidth\n            elif align == 'right':\n                boffset += totwidth\n\n            if orientation == 'horizontal':\n                _barfunc = self.barh\n                bottom_kwarg = 'left'\n            else:  # orientation == 'vertical'\n                _barfunc = self.bar\n                bottom_kwarg = 'bottom'\n\n            for top, color in zip(tops, colors):\n                if bottom is None:\n                    bottom = np.zeros(len(top))\n                if stacked:\n                    height = top - bottom\n                else:\n                    height = top\n                bars = _barfunc(bins[:-1]+boffset, height, width,\n                                align='center', log=log,\n                                color=color, **{bottom_kwarg: bottom})\n                patches.append(bars)\n                if stacked:\n                    bottom = top\n                boffset += dw\n            # Remove stickies from all bars but the lowest ones, as otherwise\n            # margin expansion would be unable to cross the stickies in the\n            # middle of the bars.\n            for bars in patches[1:]:\n                for patch in bars:\n                    patch.sticky_edges.x[:] = patch.sticky_edges.y[:] = []\n\n        elif histtype.startswith('step'):\n            # these define the perimeter of the polygon\n            x = np.zeros(4 * len(bins) - 3)\n            y = np.zeros(4 * len(bins) - 3)\n\n            x[0:2*len(bins)-1:2], x[1:2*len(bins)-1:2] = bins, bins[:-1]\n            x[2*len(bins)-1:] = x[1:2*len(bins)-1][::-1]\n\n            if bottom is None:\n                bottom = 0\n\n            y[1:2*len(bins)-1:2] = y[2:2*len(bins):2] = bottom\n            y[2*len(bins)-1:] = y[1:2*len(bins)-1][::-1]\n\n            if log:\n                if orientation == 'horizontal':\n                    self.set_xscale('log', nonpositive='clip')\n                else:  # orientation == 'vertical'\n                    self.set_yscale('log', nonpositive='clip')\n\n            if align == 'left':\n                x -= 0.5*(bins[1]-bins[0])\n            elif align == 'right':\n                x += 0.5*(bins[1]-bins[0])\n\n            # If fill kwarg is set, it will be passed to the patch collection,\n            # overriding this\n            fill = (histtype == 'stepfilled')\n\n            xvals, yvals = [], []\n            for top in tops:\n                if stacked:\n                    # top of the previous polygon becomes the bottom\n                    y[2*len(bins)-1:] = y[1:2*len(bins)-1][::-1]\n                # set the top of this polygon\n                y[1:2*len(bins)-1:2] = y[2:2*len(bins):2] = top + bottom\n\n                # The starting point of the polygon has not yet been\n                # updated. So far only the endpoint was adjusted. This\n                # assignment closes the polygon. The redundant endpoint is\n                # later discarded (for step and stepfilled).\n                y[0] = y[-1]\n\n                if orientation == 'horizontal':\n                    xvals.append(y.copy())\n                    yvals.append(x.copy())\n                else:\n                    xvals.append(x.copy())\n                    yvals.append(y.copy())\n\n            # stepfill is closed, step is not\n            split = -1 if fill else 2 * len(bins)\n            # add patches in reverse order so that when stacking,\n            # items lower in the stack are plotted on top of\n            # items higher in the stack\n            for x, y, color in reversed(list(zip(xvals, yvals, colors))):\n                patches.append(self.fill(\n                    x[:split], y[:split],\n                    closed=True if fill else None,\n                    facecolor=color,\n                    edgecolor=None if fill else color,\n                    fill=fill if fill else None,\n                    zorder=None if fill else mlines.Line2D.zorder))\n            for patch_list in patches:\n                for patch in patch_list:\n                    if orientation == 'vertical':\n                        patch.sticky_edges.y.append(0)\n                    elif orientation == 'horizontal':\n                        patch.sticky_edges.x.append(0)\n\n            # we return patches, so put it back in the expected order\n            patches.reverse()\n\n        # If None, make all labels None (via zip_longest below); otherwise,\n        # cast each element to str, but keep a single str as it.\n        labels = [] if label is None else np.atleast_1d(np.asarray(label, str))\n        for patch, lbl in itertools.zip_longest(patches, labels):\n            if patch:\n                p = patch[0]\n                p._internal_update(kwargs)\n                if lbl is not None:\n                    p.set_label(lbl)\n                for p in patch[1:]:\n                    p._internal_update(kwargs)\n                    p.set_label('_nolegend_')\n\n        if nx == 1:\n            return tops[0], bins, patches[0]\n        else:\n            patch_type = (\"BarContainer\" if histtype.startswith(\"bar\")\n                          else \"list[Polygon]\")\n            return tops, bins, cbook.silent_list(patch_type, patches)", "source_start_line": 6521, "tokens": ["def", "hist", "(", "self", ",", "x", ",", "bins", "=", "None", ",", "range", "=", "None", ",", "density", "=", "False", ",", "weights", "=", "None", ",", "cumulative", "=", "False", ",", "bottom", "=", "None", ",", "histtype", "=", "'bar'", ",", "align", "=", "'mid'", ",", "orientation", "=", "'vertical'", ",", "rwidth", "=", "None", ",", "log", "=", "False", ",", "color", "=", "None", ",", "label", "=", "None", ",", "stacked", "=", "False", ",", "**", "kwargs", ")", ":", "\"\"\"        Compute and plot a histogram.        This method uses `numpy.histogram` to bin the data in *x* and count the        number of values in each bin, then draws the distribution either as a        `.BarContainer` or `.Polygon`. The *bins*, *range*, *density*, and        *weights* parameters are forwarded to `numpy.histogram`.        If the data has already been binned and counted, use `~.bar` or        `~.stairs` to plot the distribution::            counts, bins = np.histogram(x)            plt.stairs(counts, bins)        Alternatively, plot pre-computed bins and counts using ``hist()`` by        treating each bin as a single point with a weight equal to its count::            plt.hist(bins[:-1], bins, weights=counts)        The data input *x* can be a singular array, a list of datasets of        potentially different lengths ([*x0*, *x1*, ...]), or a 2D ndarray in        which each column is a dataset. Note that the ndarray form is        transposed relative to the list form. If the input is an array, then        the return value is a tuple (*n*, *bins*, *patches*); if the input is a        sequence of arrays, then the return value is a tuple        ([*n0*, *n1*, ...], *bins*, [*patches0*, *patches1*, ...]).        Masked arrays are not supported.        Parameters        ----------        x : (n,) array or sequence of (n,) arrays            Input values, this takes either a single array or a sequence of            arrays which are not required to be of the same length.        bins : int or sequence or str, default: :rc:`hist.bins`            If *bins* is an integer, it defines the number of equal-width bins            in the range.            If *bins* is a sequence, it defines the bin edges, including the            left edge of the first bin and the right edge of the last bin;            in this case, bins may be unequally spaced.  All but the last            (righthand-most) bin is half-open.  In other words, if *bins* is::                [1, 2, 3, 4]            then the first bin is ``[1, 2)`` (including 1, but excluding 2) and            the second ``[2, 3)``.  The last bin, however, is ``[3, 4]``, which            *includes* 4.            If *bins* is a string, it is one of the binning strategies            supported by `numpy.histogram_bin_edges`: 'auto', 'fd', 'doane',            'scott', 'stone', 'rice', 'sturges', or 'sqrt'.        range : tuple or None, default: None            The lower and upper range of the bins. Lower and upper outliers            are ignored. If not provided, *range* is ``(x.min(), x.max())``.            Range has no effect if *bins* is a sequence.            If *bins* is a sequence or *range* is specified, autoscaling            is based on the specified bin range instead of the            range of x.        density : bool, default: False            If ``True``, draw and return a probability density: each bin            will display the bin's raw count divided by the total number of            counts *and the bin width*            (``density = counts / (sum(counts) * np.diff(bins))``),            so that the area under the histogram integrates to 1            (``np.sum(density * np.diff(bins)) == 1``).            If *stacked* is also ``True``, the sum of the histograms is            normalized to 1.        weights : (n,) array-like or None, default: None            An array of weights, of the same shape as *x*.  Each value in            *x* only contributes its associated weight towards the bin count            (instead of 1).  If *density* is ``True``, the weights are            normalized, so that the integral of the density over the range            remains 1.        cumulative : bool or -1, default: False            If ``True``, then a histogram is computed where each bin gives the            counts in that bin plus all bins for smaller values. The last bin            gives the total number of datapoints.            If *density* is also ``True`` then the histogram is normalized such            that the last bin equals 1.            If *cumulative* is a number less than 0 (e.g., -1), the direction            of accumulation is reversed.  In this case, if *density* is also            ``True``, then the histogram is normalized such that the first bin            equals 1.        bottom : array-like, scalar, or None, default: None            Location of the bottom of each bin, i.e. bins are drawn from            ``bottom`` to ``bottom + hist(x, bins)`` If a scalar, the bottom            of each bin is shifted by the same amount. If an array, each bin            is shifted independently and the length of bottom must match the            number of bins. If None, defaults to 0.        histtype : {'bar', 'barstacked', 'step', 'stepfilled'}, default: 'bar'            The type of histogram to draw.            - 'bar' is a traditional bar-type histogram.  If multiple data              are given the bars are arranged side by side.            - 'barstacked' is a bar-type histogram where multiple              data are stacked on top of each other.            - 'step' generates a lineplot that is by default unfilled.            - 'stepfilled' generates a lineplot that is by default filled.        align : {'left', 'mid', 'right'}, default: 'mid'            The horizontal alignment of the histogram bars.            - 'left': bars are centered on the left bin edges.            - 'mid': bars are centered between the bin edges.            - 'right': bars are centered on the right bin edges.        orientation : {'vertical', 'horizontal'}, default: 'vertical'            If 'horizontal', `~.Axes.barh` will be used for bar-type histograms            and the *bottom* kwarg will be the left edges.        rwidth : float or None, default: None            The relative width of the bars as a fraction of the bin width.  If            ``None``, automatically compute the width.            Ignored if *histtype* is 'step' or 'stepfilled'.        log : bool, default: False            If ``True``, the histogram axis will be set to a log scale.        color : color or array-like of colors or None, default: None            Color or sequence of colors, one per dataset.  Default (``None``)            uses the standard line color sequence.        label : str or None, default: None            String, or sequence of strings to match multiple datasets.  Bar            charts yield multiple patches per dataset, but only the first gets            the label, so that `~.Axes.legend` will work as expected.        stacked : bool, default: False            If ``True``, multiple data are stacked on top of each other If            ``False`` multiple data are arranged side by side if histtype is            'bar' or on top of each other if histtype is 'step'        Returns        -------        n : array or list of arrays            The values of the histogram bins. See *density* and *weights* for a            description of the possible semantics.  If input *x* is an array,            then this is an array of length *nbins*. If input is a sequence of            arrays ``[data1, data2, ...]``, then this is a list of arrays with            the values of the histograms for each of the arrays in the same            order.  The dtype of the array *n* (or of its element arrays) will            always be float even if no weighting or normalization is used.        bins : array            The edges of the bins. Length nbins + 1 (nbins left edges and right            edge of last bin).  Always a single array even when multiple data            sets are passed in.        patches : `.BarContainer` or list of a single `.Polygon` or list of \\such objects            Container of individual artists used to create the histogram            or list of such containers if there are multiple input datasets.        Other Parameters        ----------------        data : indexable object, optional            DATA_PARAMETER_PLACEHOLDER        **kwargs            `~matplotlib.patches.Patch` properties        See Also        --------        hist2d : 2D histogram with rectangular bins        hexbin : 2D histogram with hexagonal bins        stairs : Plot a pre-computed histogram        Notes        -----        For large numbers of bins (>1000), plotting can be significantly        accelerated by setting *histtype* to 'step' or 'stepfilled' rather        than 'bar' or 'barstacked', or by using `~.Axes.stairs` to plot a        pre-computed histogram (``plt.stairs(*np.histogram(data))``).        \"\"\"", "bin_range", "=", "range", "from", "builtins", "import", "range", "if", "np", ".", "isscalar", "(", "x", ")", ":", "x", "=", "[", "x", "]", "if", "bins", "is", "None", ":", "bins", "=", "mpl", ".", "rcParams", "[", "'hist.bins'", "]", "_api", ".", "check_in_list", "(", "[", "'bar'", ",", "'barstacked'", ",", "'step'", ",", "'stepfilled'", "]", ",", "histtype", "=", "histtype", ")", "_api", ".", "check_in_list", "(", "[", "'left'", ",", "'mid'", ",", "'right'", "]", ",", "align", "=", "align", ")", "_api", ".", "check_in_list", "(", "[", "'horizontal'", ",", "'vertical'", "]", ",", "orientation", "=", "orientation", ")", "if", "histtype", "==", "'barstacked'", "and", "not", "stacked", ":", "stacked", "=", "True", "x", "=", "cbook", ".", "_reshape_2D", "(", "x", ",", "'x'", ")", "nx", "=", "len", "(", "x", ")", "if", "orientation", "==", "\"vertical\"", ":", "convert_units", "=", "self", ".", "convert_xunits", "x", "=", "[", "*", "self", ".", "_process_unit_info", "(", "[", "(", "\"x\"", ",", "x", "[", "0", "]", ")", "]", ",", "kwargs", ")", ",", "*", "map", "(", "convert_units", ",", "x", "[", "1", ":", "]", ")", "]", "else", ":", "convert_units", "=", "self", ".", "convert_yunits", "x", "=", "[", "*", "self", ".", "_process_unit_info", "(", "[", "(", "\"y\"", ",", "x", "[", "0", "]", ")", "]", ",", "kwargs", ")", ",", "*", "map", "(", "convert_units", ",", "x", "[", "1", ":", "]", ")", "]", "if", "bin_range", "is", "not", "None", ":", "bin_range", "=", "convert_units", "(", "bin_range", ")", "if", "not", "cbook", ".", "is_scalar_or_string", "(", "bins", ")", ":", "bins", "=", "convert_units", "(", "bins", ")", "if", "weights", "is", "not", "None", ":", "w", "=", "cbook", ".", "_reshape_2D", "(", "weights", ",", "'weights'", ")", "else", ":", "w", "=", "[", "None", "]", "*", "nx", "if", "len", "(", "w", ")", "!=", "nx", ":", "raise", "ValueError", "(", "'weights should have the same shape as x'", ")", "input_empty", "=", "True", "for", "xi", ",", "wi", "in", "zip", "(", "x", ",", "w", ")", ":", "len_xi", "=", "len", "(", "xi", ")", "if", "wi", "is", "not", "None", "and", "len", "(", "wi", ")", "!=", "len_xi", ":", "raise", "ValueError", "(", "'weights should have the same shape as x'", ")", "if", "len_xi", ":", "input_empty", "=", "False", "if", "color", "is", "None", ":", "colors", "=", "[", "self", ".", "_get_lines", ".", "get_next_color", "(", ")", "for", "i", "in", "range", "(", "nx", ")", "]", "else", ":", "colors", "=", "mcolors", ".", "to_rgba_array", "(", "color", ")", "if", "len", "(", "colors", ")", "!=", "nx", ":", "raise", "ValueError", "(", "f\"The 'color' keyword argument must have one \"", "f\"", "{", "nx", "}", "\"", "f\"", "{", "len", "(", "colors", ")", "}", "\"", ")", "hist_kwargs", "=", "dict", "(", ")", "if", "bin_range", "is", "None", ":", "xmin", "=", "np", ".", "inf", "xmax", "=", "-", "np", ".", "inf", "for", "xi", "in", "x", ":", "if", "len", "(", "xi", ")", ":", "xmin", "=", "min", "(", "xmin", ",", "np", ".", "nanmin", "(", "xi", ")", ")", "xmax", "=", "max", "(", "xmax", ",", "np", ".", "nanmax", "(", "xi", ")", ")", "if", "xmin", "<=", "xmax", ":", "bin_range", "=", "(", "xmin", ",", "xmax", ")", "if", "not", "input_empty", "and", "len", "(", "x", ")", ">", "1", ":", "if", "weights", "is", "not", "None", ":", "_w", "=", "np", ".", "concatenate", "(", "w", ")", "else", ":", "_w", "=", "None", "bins", "=", "np", ".", "histogram_bin_edges", "(", "np", ".", "concatenate", "(", "x", ")", ",", "bins", ",", "bin_range", ",", "_w", ")", "else", ":", "hist_kwargs", "[", "'range'", "]", "=", "bin_range", "density", "=", "bool", "(", "density", ")", "if", "density", "and", "not", "stacked", ":", "hist_kwargs", "[", "'density'", "]", "=", "density", "tops", "=", "[", "]", "for", "i", "in", "range", "(", "nx", ")", ":", "m", ",", "bins", "=", "np", ".", "histogram", "(", "x", "[", "i", "]", ",", "bins", ",", "weights", "=", "w", "[", "i", "]", ",", "**", "hist_kwargs", ")", "tops", ".", "append", "(", "m", ")", "tops", "=", "np", ".", "array", "(", "tops", ",", "float", ")", "bins", "=", "np", ".", "array", "(", "bins", ",", "float", ")", "if", "stacked", ":", "tops", "=", "tops", ".", "cumsum", "(", "axis", "=", "0", ")", "if", "density", ":", "tops", "=", "(", "tops", "/", "np", ".", "diff", "(", "bins", ")", ")", "/", "tops", "[", "-", "1", "]", ".", "sum", "(", ")", "if", "cumulative", ":", "slc", "=", "slice", "(", "None", ")", "if", "isinstance", "(", "cumulative", ",", "Number", ")", "and", "cumulative", "<", "0", ":", "slc", "=", "slice", "(", "None", ",", "None", ",", "-", "1", ")", "if", "density", ":", "tops", "=", "(", "tops", "*", "np", ".", "diff", "(", "bins", ")", ")", "[", ":", ",", "slc", "]", ".", "cumsum", "(", "axis", "=", "1", ")", "[", ":", ",", "slc", "]", "else", ":", "tops", "=", "tops", "[", ":", ",", "slc", "]", ".", "cumsum", "(", "axis", "=", "1", ")", "[", ":", ",", "slc", "]", "patches", "=", "[", "]", "if", "histtype", ".", "startswith", "(", "'bar'", ")", ":", "totwidth", "=", "np", ".", "diff", "(", "bins", ")", "if", "rwidth", "is", "not", "None", ":", "dr", "=", "np", ".", "clip", "(", "rwidth", ",", "0", ",", "1", ")", "elif", "(", "len", "(", "tops", ")", ">", "1", "and", "(", "(", "not", "stacked", ")", "or", "mpl", ".", "rcParams", "[", "'_internal.classic_mode'", "]", ")", ")", ":", "dr", "=", "0.8", "else", ":", "dr", "=", "1.0", "if", "histtype", "==", "'bar'", "and", "not", "stacked", ":", "width", "=", "dr", "*", "totwidth", "/", "nx", "dw", "=", "width", "boffset", "=", "-", "0.5", "*", "dr", "*", "totwidth", "*", "(", "1", "-", "1", "/", "nx", ")", "elif", "histtype", "==", "'barstacked'", "or", "stacked", ":", "width", "=", "dr", "*", "totwidth", "boffset", ",", "dw", "=", "0.0", ",", "0.0", "if", "align", "==", "'mid'", ":", "boffset", "+=", "0.5", "*", "totwidth", "elif", "align", "==", "'right'", ":", "boffset", "+=", "totwidth", "if", "orientation", "==", "'horizontal'", ":", "_barfunc", "=", "self", ".", "barh", "bottom_kwarg", "=", "'left'", "else", ":", "_barfunc", "=", "self", ".", "bar", "bottom_kwarg", "=", "'bottom'", "for", "top", ",", "color", "in", "zip", "(", "tops", ",", "colors", ")", ":", "if", "bottom", "is", "None", ":", "bottom", "=", "np", ".", "zeros", "(", "len", "(", "top", ")", ")", "if", "stacked", ":", "height", "=", "top", "-", "bottom", "else", ":", "height", "=", "top", "bars", "=", "_barfunc", "(", "bins", "[", ":", "-", "1", "]", "+", "boffset", ",", "height", ",", "width", ",", "align", "=", "'center'", ",", "log", "=", "log", ",", "color", "=", "color", ",", "**", "{", "bottom_kwarg", ":", "bottom", "}", ")", "patches", ".", "append", "(", "bars", ")", "if", "stacked", ":", "bottom", "=", "top", "boffset", "+=", "dw", "for", "bars", "in", "patches", "[", "1", ":", "]", ":", "for", "patch", "in", "bars", ":", "patch", ".", "sticky_edges", ".", "x", "[", ":", "]", "=", "patch", ".", "sticky_edges", ".", "y", "[", ":", "]", "=", "[", "]", "elif", "histtype", ".", "startswith", "(", "'step'", ")", ":", "x", "=", "np", ".", "zeros", "(", "4", "*", "len", "(", "bins", ")", "-", "3", ")", "y", "=", "np", ".", "zeros", "(", "4", "*", "len", "(", "bins", ")", "-", "3", ")", "x", "[", "0", ":", "2", "*", "len", "(", "bins", ")", "-", "1", ":", "2", "]", ",", "x", "[", "1", ":", "2", "*", "len", "(", "bins", ")", "-", "1", ":", "2", "]", "=", "bins", ",", "bins", "[", ":", "-", "1", "]", "x", "[", "2", "*", "len", "(", "bins", ")", "-", "1", ":", "]", "=", "x", "[", "1", ":", "2", "*", "len", "(", "bins", ")", "-", "1", "]", "[", ":", ":", "-", "1", "]", "if", "bottom", "is", "None", ":", "bottom", "=", "0", "y", "[", "1", ":", "2", "*", "len", "(", "bins", ")", "-", "1", ":", "2", "]", "=", "y", "[", "2", ":", "2", "*", "len", "(", "bins", ")", ":", "2", "]", "=", "bottom", "y", "[", "2", "*", "len", "(", "bins", ")", "-", "1", ":", "]", "=", "y", "[", "1", ":", "2", "*", "len", "(", "bins", ")", "-", "1", "]", "[", ":", ":", "-", "1", "]", "if", "log", ":", "if", "orientation", "==", "'horizontal'", ":", "self", ".", "set_xscale", "(", "'log'", ",", "nonpositive", "=", "'clip'", ")", "else", ":", "self", ".", "set_yscale", "(", "'log'", ",", "nonpositive", "=", "'clip'", ")", "if", "align", "==", "'left'", ":", "x", "-=", "0.5", "*", "(", "bins", "[", "1", "]", "-", "bins", "[", "0", "]", ")", "elif", "align", "==", "'right'", ":", "x", "+=", "0.5", "*", "(", "bins", "[", "1", "]", "-", "bins", "[", "0", "]", ")", "fill", "=", "(", "histtype", "==", "'stepfilled'", ")", "xvals", ",", "yvals", "=", "[", "]", ",", "[", "]", "for", "top", "in", "tops", ":", "if", "stacked", ":", "y", "[", "2", "*", "len", "(", "bins", ")", "-", "1", ":", "]", "=", "y", "[", "1", ":", "2", "*", "len", "(", "bins", ")", "-", "1", "]", "[", ":", ":", "-", "1", "]", "y", "[", "1", ":", "2", "*", "len", "(", "bins", ")", "-", "1", ":", "2", "]", "=", "y", "[", "2", ":", "2", "*", "len", "(", "bins", ")", ":", "2", "]", "=", "top", "+", "bottom", "y", "[", "0", "]", "=", "y", "[", "-", "1", "]", "if", "orientation", "==", "'horizontal'", ":", "xvals", ".", "append", "(", "y", ".", "copy", "(", ")", ")", "yvals", ".", "append", "(", "x", ".", "copy", "(", ")", ")", "else", ":", "xvals", ".", "append", "(", "x", ".", "copy", "(", ")", ")", "yvals", ".", "append", "(", "y", ".", "copy", "(", ")", ")", "split", "=", "-", "1", "if", "fill", "else", "2", "*", "len", "(", "bins", ")", "for", "x", ",", "y", ",", "color", "in", "reversed", "(", "list", "(", "zip", "(", "xvals", ",", "yvals", ",", "colors", ")", ")", ")", ":", "patches", ".", "append", "(", "self", ".", "fill", "(", "x", "[", ":", "split", "]", ",", "y", "[", ":", "split", "]", ",", "closed", "=", "True", "if", "fill", "else", "None", ",", "facecolor", "=", "color", ",", "edgecolor", "=", "None", "if", "fill", "else", "color", ",", "fill", "=", "fill", "if", "fill", "else", "None", ",", "zorder", "=", "None", "if", "fill", "else", "mlines", ".", "Line2D", ".", "zorder", ")", ")", "for", "patch_list", "in", "patches", ":", "for", "patch", "in", "patch_list", ":", "if", "orientation", "==", "'vertical'", ":", "patch", ".", "sticky_edges", ".", "y", ".", "append", "(", "0", ")", "elif", "orientation", "==", "'horizontal'", ":", "patch", ".", "sticky_edges", ".", "x", ".", "append", "(", "0", ")", "patches", ".", "reverse", "(", ")", "labels", "=", "[", "]", "if", "label", "is", "None", "else", "np", ".", "atleast_1d", "(", "np", ".", "asarray", "(", "label", ",", "str", ")", ")", "for", "patch", ",", "lbl", "in", "itertools", ".", "zip_longest", "(", "patches", ",", "labels", ")", ":", "if", "patch", ":", "p", "=", "patch", "[", "0", "]", "p", ".", "_internal_update", "(", "kwargs", ")", "if", "lbl", "is", "not", "None", ":", "p", ".", "set_label", "(", "lbl", ")", "for", "p", "in", "patch", "[", "1", ":", "]", ":", "p", ".", "_internal_update", "(", "kwargs", ")", "p", ".", "set_label", "(", "'_nolegend_'", ")", "if", "nx", "==", "1", ":", "return", "tops", "[", "0", "]", ",", "bins", ",", "patches", "[", "0", "]", "else", ":", "patch_type", "=", "(", "\"BarContainer\"", "if", "histtype", ".", "startswith", "(", "\"bar\"", ")", "else", "\"list[Polygon]\"", ")", "return", "tops", ",", "bins", ",", "cbook", ".", "silent_list", "(", "patch_type", ",", "patches", ")"], "to_mask": {"VAR": ["_barfunc", "_w", "align", "bars", "bin_range", "bins", "boffset", "bottom", "bottom_kwarg", "color", "colors", "convert_units", "cumulative", "density", "dr", "dw", "fill", "height", "hist_kwargs", "histtype", "i", "input_empty", "label", "labels", "lbl", "len_xi", "log", "m", "nx", "orientation", "p", "patch", "patch_list", "patch_type", "patches", "range", "rwidth", "self", "slc", "split", "stacked", "top", "tops", "totwidth", "w", "weights", "wi", "width", "x", "xi", "xmax", "xmin", "xvals", "y", "yvals"], "METHOD": ["ValueError", "_barfunc", "_internal_update", "_process_unit_info", "_reshape_2D", "append", "array", "asarray", "atleast_1d", "bool", "check_in_list", "clip", "concatenate", "convert_units", "copy", "cumsum", "dict", "diff", "fill", "get_next_color", "histogram", "histogram_bin_edges", "is_scalar_or_string", "isinstance", "isscalar", "len", "list", "map", "max", "min", "nanmax", "nanmin", "range", "reverse", "reversed", "set_label", "set_xscale", "set_yscale", "silent_list", "slice", "startswith", "sum", "to_rgba_array", "zeros", "zip", "zip_longest"]}, "attention_idx_tokens": [null, null], "patch": "@@ -6700,12 +6700,14 @@\n         --------\n         hist2d : 2D histogram with rectangular bins\n         hexbin : 2D histogram with hexagonal bins\n+        stairs : Plot a pre-computed histogram", "ext_attention_idx_tokens": [null, null], "uid": "1948c251", "question": "Can you also add bar since we also recommend bar Y the top for plotting precomputed histograms?", "code": "def hist self x bins None range None density False weights None cumulative False bottom None histtype bar align mid orientation vertical rwidth None log False color None label None stacked False **kwargs \"\"\" Compute and plot a histogram This method uses `numpy histogram` to bin the data in *x* and count the number of values in each bin then draws the distribution either as a ` BarContainer` or ` Polygon` The *bins* *range* *density* and *weights* parameters are forwarded to `numpy histogram` If the data has already been binned and counted use `~ bar` or `~ stairs` to plot the distribution counts bins np histogram x plt stairs counts bins Alternatively plot pre-computed bins and counts using ``hist `` by treating each bin as a single point with a weight equal to its count plt hist bins[ -1] bins weights counts The data input *x* can be a singular array a list of datasets of potentially different lengths [*x0* *x1* ] or a 2D ndarray in which each column is a dataset Note that the ndarray form is transposed relative to the list form If the input is an array then the return value is a tuple *n* *bins* *patches* ; if the input is a sequence of arrays then the return value is a tuple [*n0* *n1* ] *bins* [*patches0* *patches1* ] Masked arrays are not supported Parameters ---------- x n array or sequence of n arrays Input values this takes either a single array or a sequence of arrays which are not required to be of the same length bins int or sequence or str default rc `hist bins` If *bins* is an integer it defines the number of equal-width bins in the range If *bins* is a sequence it defines the bin edges including the left edge of the first bin and the right edge of the last bin; in this case bins may be unequally spaced All but the last righthand-most bin is half-open In other words if *bins* is [1 2 3 4] then the first bin is ``[1 2 `` including 1 but excluding 2 and the second ``[2 3 `` The last bin however is ``[3 4]`` which *includes* 4 If *bins* is a string it is one of the binning strategies supported by `numpy histogram bin edges` auto fd doane scott stone rice sturges or sqrt range tuple or None default None The lower and upper range of the bins Lower and upper outliers are ignored If not provided *range* is `` x min x max `` Range has no effect if *bins* is a sequence If *bins* is a sequence or *range* is specified autoscaling is based on the specified bin range instead of the range of x density bool default False If ``True`` draw and return a probability density each bin will display the bin s raw count divided by the total number of counts *and the bin width* ``density counts sum counts * np diff bins `` so that the area under the histogram integrates to 1 ``np sum density * np diff bins 1`` If *stacked* is also ``True`` the sum of the histograms is normalized to 1 weights n array-like or None default None An array of weights of the same shape as *x* Each value in *x* only contributes its associated weight towards the bin count instead of 1 If *density* is ``True`` the weights are normalized so that the integral of the density over the range remains 1 cumulative bool or -1 default False If ``True`` then a histogram is computed where each bin gives the counts in that bin plus all bins for smaller values The last bin gives the total number of datapoints If *density* is also ``True`` then the histogram is normalized such that the last bin equals 1 If *cumulative* is a number less than 0 e g -1 the direction of accumulation is reversed In this case if *density* is also ``True`` then the histogram is normalized such that the first bin equals 1 bottom array-like scalar or None default None Location of the bottom of each bin i e bins are drawn from ``bottom`` to ``bottom + hist x bins `` If a scalar the bottom of each bin is shifted by the same amount If an array each bin is shifted independently and the length of bottom must match the number of bins If None defaults to 0 histtype { bar barstacked step stepfilled } default bar The type of histogram to draw - bar is a traditional bar-type histogram If multiple data are given the bars are arranged side by side - barstacked is a bar-type histogram where multiple data are stacked on top of each other - step generates a lineplot that is by default unfilled - stepfilled generates a lineplot that is by default filled align { left mid right } default mid The horizontal alignment of the histogram bars - left bars are centered on the left bin edges - mid bars are centered between the bin edges - right bars are centered on the right bin edges orientation { vertical horizontal } default vertical If horizontal `~ Axes barh` will be used for bar-type histograms and the *bottom* kwarg will be the left edges rwidth float or None default None The relative width of the bars as a fraction of the bin width If ``None`` automatically compute the width Ignored if *histtype* is step or stepfilled log bool default False If ``True`` the histogram axis will be set to a log scale color color or array-like of colors or None default None Color or sequence of colors one per dataset Default ``None`` uses the standard line color sequence label str or None default None String or sequence of strings to match multiple datasets Bar charts yield multiple patches per dataset but only the first gets the label so that `~ Axes legend` will work as expected stacked bool default False If ``True`` multiple data are stacked on top of each other If ``False`` multiple data are arranged side by side if histtype is bar or on top of each other if histtype is step Returns ------- n array or list of arrays The values of the histogram bins See *density* and *weights* for a description of the possible semantics If input *x* is an array then this is an array of length *nbins* If input is a sequence of arrays ``[data1 data2 ]`` then this is a list of arrays with the values of the histograms for each of the arrays in the same order The dtype of the array *n* or of its element arrays will always be float even if no weighting or normalization is used bins array The edges of the bins Length nbins + 1 nbins left edges and right edge of last bin Always a single array even when multiple data sets are passed in patches ` BarContainer` or list of a single ` Polygon` or list of \\ such objects Container of individual artists used to create the histogram or list of such containers if there are multiple input datasets Other Parameters ---------------- data indexable object optional DATA PARAMETER PLACEHOLDER **kwargs `~matplotlib patches Patch` properties See Also -------- hist2d 2D histogram with rectangular bins hexbin 2D histogram with hexagonal bins stairs Plot a pre-computed histogram Notes ----- For large numbers of bins >1000 plotting can be significantly accelerated by setting *histtype* to step or stepfilled rather than bar or barstacked or by using `~ Axes stairs` to plot a pre-computed histogram ``plt stairs *np histogram data `` \"\"\" # Avoid shadowing the builtin bin range range from builtins import range if np isscalar x x [x] if bins is None bins mpl rcParams[ hist bins ] # Validate string inputs here to avoid cluttering subsequent code api check in list [ bar barstacked step stepfilled ] histtype histtype api check in list [ left mid right ] align align api check in list [ horizontal vertical ] orientation orientation if histtype barstacked and not stacked stacked True # Massage x for processing x cbook reshape 2D x x nx len x # number of datasets # Process unit information process unit info sets the unit and # converts the first dataset; then we convert each following dataset # one at a time if orientation \"vertical\" convert units self convert xunits x [*self process unit info [ \"x\" x[0] ] kwargs *map convert units x[1 ] ] else # horizontal convert units self convert yunits x [*self process unit info [ \"y\" x[0] ] kwargs *map convert units x[1 ] ] if bin range is not None bin range convert units bin range if not cbook is scalar or string bins bins convert units bins # We need to do to weights what was done to x if weights is not None w cbook reshape 2D weights weights else w [None] * nx if len w ! nx raise ValueError weights should have the same shape as x input empty True for xi wi in zip x w len xi len xi if wi is not None and len wi ! len xi raise ValueError weights should have the same shape as x if len xi input empty False if color is None colors [self get lines get next color for i in range nx ] else colors mcolors to rgba array color if len colors ! nx raise ValueError f\"The color keyword argument must have one \" f\"color per dataset but {nx} datasets and \" f\"{len colors } colors were provided\" hist kwargs dict # if the bin range is not given compute without nan numpy # does not do this for us when guessing the range but will # happily ignore nans when computing the histogram if bin range is None xmin np inf xmax -np inf for xi in x if len xi # python s min max ignore nan # np minnan returns nan for all nan input xmin min xmin np nanmin xi xmax max xmax np nanmax xi if xmin < xmax # Only happens if we have seen a finite value bin range xmin xmax # If bins are not specified either explicitly or via range # we need to figure out the range required for all datasets # and supply that to np histogram if not input empty and len x > 1 if weights is not None w np concatenate w else w None bins np histogram bin edges np concatenate x bins bin range w else hist kwargs[ range ] bin range density bool density if density and not stacked hist kwargs[ density ] density # List to store all the top coordinates of the histograms tops [] # Will have shape n datasets n bins # Loop through datasets for i in range nx # this will automatically overwrite bins # so that each histogram uses the same bins m bins np histogram x[i] bins weights w[i] **hist kwargs tops append m tops np array tops float # causes problems later if it s an int bins np array bins float # causes problems if float16 if stacked tops tops cumsum axis 0 # If a stacked density plot normalize so the area of all the # stacked histograms together is 1 if density tops tops np diff bins tops[-1] sum if cumulative slc slice None if isinstance cumulative Number and cumulative < 0 slc slice None None -1 if density tops tops * np diff bins [ slc] cumsum axis 1 [ slc] else tops tops[ slc] cumsum axis 1 [ slc] patches [] if histtype startswith bar totwidth np diff bins if rwidth is not None dr np clip rwidth 0 1 elif len tops > 1 and not stacked or mpl rcParams[ internal classic mode ] dr 0 8 else dr 1 0 if histtype bar and not stacked width dr * totwidth nx dw width boffset -0 5 * dr * totwidth * 1 - 1 nx elif histtype barstacked or stacked width dr * totwidth boffset dw 0 0 0 0 if align mid boffset + 0 5 * totwidth elif align right boffset + totwidth if orientation horizontal barfunc self barh bottom kwarg left else # orientation vertical barfunc self bar bottom kwarg bottom for top color in zip tops colors if bottom is None bottom np zeros len top if stacked height top - bottom else height top bars barfunc bins[ -1]+boffset height width align center log log color color **{bottom kwarg bottom} patches append bars if stacked bottom top boffset + dw # Remove stickies from all bars but the lowest ones as otherwise # margin expansion would be unable to cross the stickies in the # middle of the bars for bars in patches[1 ] for patch in bars patch sticky edges x[ ] patch sticky edges y[ ] [] elif histtype startswith step # these define the perimeter of the polygon x np zeros 4 * len bins - 3 y np zeros 4 * len bins - 3 x[0 2*len bins -1 2] x[1 2*len bins -1 2] bins bins[ -1] x[2*len bins -1 ] x[1 2*len bins -1][ -1] if bottom is None bottom 0 y[1 2*len bins -1 2] y[2 2*len bins 2] bottom y[2*len bins -1 ] y[1 2*len bins -1][ -1] if log if orientation horizontal self set xscale log nonpositive clip else # orientation vertical self set yscale log nonpositive clip if align left x - 0 5* bins[1]-bins[0] elif align right x + 0 5* bins[1]-bins[0] # If fill kwarg is set it will be passed to the patch collection # overriding this fill histtype stepfilled xvals yvals [] [] for top in tops if stacked # top of the previous polygon becomes the bottom y[2*len bins -1 ] y[1 2*len bins -1][ -1] # set the top of this polygon y[1 2*len bins -1 2] y[2 2*len bins 2] top + bottom # The starting point of the polygon has not yet been # updated So far only the endpoint was adjusted This # assignment closes the polygon The redundant endpoint is # later discarded for step and stepfilled y[0] y[-1] if orientation horizontal xvals append y copy yvals append x copy else xvals append x copy yvals append y copy # stepfill is closed step is not split -1 if fill else 2 * len bins # add patches in reverse order so that when stacking # items lower in the stack are plotted on top of # items higher in the stack for x y color in reversed list zip xvals yvals colors patches append self fill x[ split] y[ split] closed True if fill else None facecolor color edgecolor None if fill else color fill fill if fill else None zorder None if fill else mlines Line2D zorder for patch list in patches for patch in patch list if orientation vertical patch sticky edges y append 0 elif orientation horizontal patch sticky edges x append 0 # we return patches so put it back in the expected order patches reverse # If None make all labels None via zip longest below ; otherwise # cast each element to str but keep a single str as it labels [] if label is None else np atleast 1d np asarray label str for patch lbl in itertools zip longest patches labels if patch p patch[0] p internal update kwargs if lbl is not None p set label lbl for p in patch[1 ] p internal update kwargs p set label nolegend if nx 1 return tops[0] bins patches[0] else patch type \"BarContainer\" if histtype startswith \"bar\" else \"list[Polygon]\" return tops bins cbook silent list patch type patches"}
{"message": "I take it that there will be another update to this and @ksunden was only sorting out the parsing? \n\nBut this line should go.", "timestamp": "2023-07-04T08:58:29Z", "file_name": "lib/matplotlib/_mathtext.py", "range": {"start_line": 1703, "end_line": 1703, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1251722685", "html_url": "https://github.com/matplotlib/matplotlib/pull/26151#discussion_r1251722685", "attention_area": "    print(csname, args, err)", "file_path": "files/65/10/00001065.py", "old_file_path": "files/67/10/00001067.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1700,6 +1700,7 @@ def names(elt):\n     csname = expr.split(\"{\", 1)[0]\n     err = (csname + \"\".join(\"{%s}\" % name for name in names(args))\n            if expr == csname else expr)\n+    print(csname, args, err)", "source": "def cmd(expr, args):\n    r\"\"\"\n    Helper to define TeX commands.\n\n    ``cmd(\"\\cmd\", args)`` is equivalent to\n    ``\"\\cmd\" - (args | Error(\"Expected \\cmd{arg}{...}\"))`` where the names in\n    the error message are taken from element names in *args*.  If *expr*\n    already includes arguments (e.g. \"\\cmd{arg}{...}\"), then they are stripped\n    when constructing the parse element, but kept (and *expr* is used as is) in\n    the error message.\n    \"\"\"\n\n    def names(elt):\n        if isinstance(elt, ParseExpression):\n            for expr in elt.exprs:\n                yield from names(expr)\n        elif elt.resultsName:\n            yield elt.resultsName\n\n    csname = expr.split(\"{\", 1)[0]\n    err = (csname + \"\".join(\"{%s}\" % name for name in names(args))\n           if expr == csname else expr)\n    print(csname, args, err)\n    return csname - (args | Error(f\"Expected {err}\"))", "source_start_line": 1681, "tokens": ["def", "cmd", "(", "expr", ",", "args", ")", ":", "r\"\"\"    Helper to define TeX commands.    ``cmd(\"\\cmd\", args)`` is equivalent to    ``\"\\cmd\" - (args | Error(\"Expected \\cmd{arg}{...}\"))`` where the names in    the error message are taken from element names in *args*.  If *expr*    already includes arguments (e.g. \"\\cmd{arg}{...}\"), then they are stripped    when constructing the parse element, but kept (and *expr* is used as is) in    the error message.    \"\"\"", "def", "names", "(", "elt", ")", ":", "if", "isinstance", "(", "elt", ",", "ParseExpression", ")", ":", "for", "expr", "in", "elt", ".", "exprs", ":", "yield", "from", "names", "(", "expr", ")", "elif", "elt", ".", "resultsName", ":", "yield", "elt", ".", "resultsName", "csname", "=", "expr", ".", "split", "(", "\"{\"", ",", "1", ")", "[", "0", "]", "err", "=", "(", "csname", "+", "\"\"", ".", "join", "(", "\"{%s}\"", "%", "name", "for", "name", "in", "names", "(", "args", ")", ")", "if", "expr", "==", "csname", "else", "expr", ")", "print", "(", "csname", ",", "args", ",", "err", ")", "return", "csname", "-", "(", "args", "|", "Error", "(", "f\"", "{", "err", "}", "\"", ")", ")"], "to_mask": {"VAR": ["args", "csname", "elt", "err", "expr"], "METHOD": ["Error", "isinstance", "join", "names", "print", "split"]}, "attention_idx_tokens": [85, 92], "patch": "@@ -1700,6 +1700,7 @@\n     csname = expr.split(\"{\", 1)[0]\n     err = (csname + \"\".join(\"{%s}\" % name for name in names(args))\n            if expr == csname else expr)\n+    print(csname, args, err)", "ext_attention_idx_tokens": [85, 107], "uid": "c50ba87b", "question": "I take it that there will be another update to this and @ksunden was only sorting out the parsing?   But this line should go.", "code": "def cmd expr args r\"\"\" Helper to define TeX commands ``cmd \"\\cmd\" args `` is equivalent to ``\"\\cmd\" - args | Error \"Expected \\cmd{arg}{ }\" `` where the names in the error message are taken from element names in *args* If *expr* already includes arguments e g \"\\cmd{arg}{ }\" then they are stripped when constructing the parse element but kept and *expr* is used as is in the error message \"\"\" def names elt if isinstance elt ParseExpression for expr in elt exprs yield from names expr elif elt resultsName yield elt resultsName csname expr split \"{\" 1 [0] err csname + \"\" join \"{%s}\" % name for name in names args if expr csname else expr print csname args err return csname - args | Error f\"Expected {err}\""}
{"message": "Are we sure that None will never be passed here? What about third-party libraries etc? It may require an API change note if nothing else.", "timestamp": "2023-07-14T03:12:40Z", "file_name": "lib/matplotlib/transforms.py", "range": {"start_line": 113, "end_line": 113, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1263246915", "html_url": "https://github.com/matplotlib/matplotlib/pull/26303#discussion_r1263246915", "attention_area": "    def __init__(self, shorthand_name=''):", "file_path": "files/16/11/00001116.py", "old_file_path": "files/17/11/00001117.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -110,7 +110,7 @@ class TransformNode:\n     invalidated, even if 'self' is already invalid.\n     \"\"\"\n \n-    def __init__(self, shorthand_name=None):\n+    def __init__(self, shorthand_name=''):", "source": "def __init__(self, shorthand_name=''):\n        \"\"\"\n        Parameters\n        ----------\n        shorthand_name : str\n            A string representing the \"name\" of the transform. The name carries\n            no significance other than to improve the readability of\n            ``str(transform)`` when DEBUG=True.\n        \"\"\"\n        self._parents = {}\n        # Initially invalid, until first computation.\n        self._invalid = self._INVALID_FULL\n        self._shorthand_name = shorthand_name", "source_start_line": 113, "tokens": ["def", "__init__", "(", "self", ",", "shorthand_name", "=", "''", ")", ":", "\"\"\"        Parameters        ----------        shorthand_name : str            A string representing the \"name\" of the transform. The name carries            no significance other than to improve the readability of            ``str(transform)`` when DEBUG=True.        \"\"\"", "self", ".", "_parents", "=", "{", "}", "self", ".", "_invalid", "=", "self", ".", "_INVALID_FULL", "self", ".", "_shorthand_name", "=", "shorthand_name"], "to_mask": {"VAR": ["_invalid", "_parents", "_shorthand_name", "self", "shorthand_name"], "METHOD": []}, "attention_idx_tokens": [0, 9], "patch": "@@ -110,7 +110,7 @@\n     invalidated, even if 'self' is already invalid.\n     \"\"\"\n \n-    def __init__(self, shorthand_name=None):\n+    def __init__(self, shorthand_name=''):", "ext_attention_idx_tokens": [0, 10], "uid": "51c6f6f0", "question": "Are we sure that None will never be passed here? What about third-party libraries etc? It may require an API change note if nothing else.", "code": "def init self shorthand name \"\"\" Parameters ---------- shorthand name str A string representing the \"name\" of the transform The name carries no significance other than to improve the readability of ``str transform `` when DEBUG True \"\"\" self parents {} # Initially invalid until first computation self invalid self INVALID FULL self shorthand name shorthand name"}
{"message": "What's the best way to issue that deprecation warning? I'm having trouble finding an example where we do that for a possible value of an argument.", "timestamp": "2023-08-02T02:11:26Z", "file_name": "lib/mpl_toolkits/mplot3d/axis3d.py", "range": {"start_line": 189, "end_line": 189, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1281307641", "html_url": "https://github.com/matplotlib/matplotlib/pull/25830#discussion_r1281307641", "attention_area": "    def set_ticks_position(self, position):", "file_path": "files/95/11/00001195.py", "old_file_path": "files/96/11/00001196.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -183,6 +186,54 @@ def get_minor_ticks(self, numticks=None):\n                 obj.set_transform(self.axes.transData)\n         return ticks\n \n+    def set_ticks_position(self, position):", "source": "def set_ticks_position(self, position):\n        \"\"\"\n        Set the ticks position.\n\n        Parameters\n        ----------\n        str : {'lower', 'upper', 'both', 'default', 'none'}\n            The position of the bolded axis lines, ticks, and tick labels.\n        \"\"\"\n        _api.check_in_list(['lower', 'upper', 'both', 'default', 'none'],\n                           position=position)\n        self._tick_position = position", "source_start_line": 189, "tokens": ["def", "set_ticks_position", "(", "self", ",", "position", ")", ":", "\"\"\"        Set the ticks position.        Parameters        ----------        str : {'lower', 'upper', 'both', 'default', 'none'}            The position of the bolded axis lines, ticks, and tick labels.        \"\"\"", "_api", ".", "check_in_list", "(", "[", "'lower'", ",", "'upper'", ",", "'both'", ",", "'default'", ",", "'none'", "]", ",", "position", "=", "position", ")", "self", ".", "_tick_position", "=", "position"], "to_mask": {"VAR": ["_tick_position", "position", "self"], "METHOD": ["check_in_list"]}, "attention_idx_tokens": [0, 7], "patch": "@@ -183,6 +186,54 @@\n                 obj.set_transform(self.axes.transData)\n         return ticks\n \n+    def set_ticks_position(self, position):", "ext_attention_idx_tokens": [0, 33], "uid": "17b1c837", "question": "What's the best way to issue that deprecation warning? I'm having trouble finding an example where we do that for a possible value of an argument.", "code": "def set ticks position self position \"\"\" Set the ticks position Parameters ---------- str { lower upper both default none } The position of the bolded axis lines ticks and tick labels \"\"\" api check in list [ lower upper both default none ] position position self tick position position"}
{"message": "It looks like Pillow has 3.12 wheels now; maybe we don't need to skip this?", "timestamp": "2023-08-18T07:49:58Z", "file_name": "lib/matplotlib/tests/test_agg.py", "range": {"start_line": 255, "end_line": 255, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1298129444", "html_url": "https://github.com/matplotlib/matplotlib/pull/24711#discussion_r1298129444", "attention_area": "        pytest.skip(\"No WEBP support\")", "file_path": "files/46/12/00001246.py", "old_file_path": "files/47/12/00001247.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -250,6 +250,9 @@ def test_pil_kwargs_tiff():\n \n \n def test_pil_kwargs_webp():\n+    Image.init()\n+    if \"WEBP\" not in Image.SAVE:\n+        pytest.skip(\"No WEBP support\")", "source": "def test_pil_kwargs_webp():\n    Image.init()\n    if \"WEBP\" not in Image.SAVE:\n        pytest.skip(\"No WEBP support\")\n    plt.plot([0, 1, 2], [0, 1, 0])\n    buf_small = io.BytesIO()\n    pil_kwargs_low = {\"quality\": 1}\n    plt.savefig(buf_small, format=\"webp\", pil_kwargs=pil_kwargs_low)\n    assert len(pil_kwargs_low) == 1\n    buf_large = io.BytesIO()\n    pil_kwargs_high = {\"quality\": 100}\n    plt.savefig(buf_large, format=\"webp\", pil_kwargs=pil_kwargs_high)\n    assert len(pil_kwargs_high) == 1\n    assert buf_large.getbuffer().nbytes > buf_small.getbuffer().nbytes", "source_start_line": 252, "tokens": ["def", "test_pil_kwargs_webp", "(", ")", ":", "Image", ".", "init", "(", ")", "if", "\"WEBP\"", "not", "in", "Image", ".", "SAVE", ":", "pytest", ".", "skip", "(", "\"No WEBP support\"", ")", "plt", ".", "plot", "(", "[", "0", ",", "1", ",", "2", "]", ",", "[", "0", ",", "1", ",", "0", "]", ")", "buf_small", "=", "io", ".", "BytesIO", "(", ")", "pil_kwargs_low", "=", "{", "\"quality\"", ":", "1", "}", "plt", ".", "savefig", "(", "buf_small", ",", "format", "=", "\"webp\"", ",", "pil_kwargs", "=", "pil_kwargs_low", ")", "assert", "len", "(", "pil_kwargs_low", ")", "==", "1", "buf_large", "=", "io", ".", "BytesIO", "(", ")", "pil_kwargs_high", "=", "{", "\"quality\"", ":", "100", "}", "plt", ".", "savefig", "(", "buf_large", ",", "format", "=", "\"webp\"", ",", "pil_kwargs", "=", "pil_kwargs_high", ")", "assert", "len", "(", "pil_kwargs_high", ")", "==", "1", "assert", "buf_large", ".", "getbuffer", "(", ")", ".", "nbytes", ">", "buf_small", ".", "getbuffer", "(", ")", ".", "nbytes"], "to_mask": {"VAR": ["buf_large", "buf_small", "pil_kwargs_high", "pil_kwargs_low"], "METHOD": ["BytesIO", "getbuffer", "init", "len", "plot", "savefig", "skip"]}, "attention_idx_tokens": [18, 23], "patch": "@@ -250,6 +250,9 @@\n \n \n def test_pil_kwargs_webp():\n+    Image.init()\n+    if \"WEBP\" not in Image.SAVE:\n+        pytest.skip(\"No WEBP support\")", "ext_attention_idx_tokens": [5, 43], "uid": "76750635", "question": "It looks like Pillow has 3.12 wheels now; maybe we don't need to skip this?", "code": "def test pil kwargs webp Image init if \"WEBP\" not in Image SAVE pytest skip \"No WEBP support\" plt plot [0 1 2] [0 1 0] buf small io BytesIO pil kwargs low {\"quality\" 1} plt savefig buf small format \"webp\" pil kwargs pil kwargs low assert len pil kwargs low 1 buf large io BytesIO pil kwargs high {\"quality\" 100} plt savefig buf large format \"webp\" pil kwargs pil kwargs high assert len pil kwargs high 1 assert buf large getbuffer nbytes > buf small getbuffer nbytes"}
{"message": "what information is `low-level` supposed to impart here?", "timestamp": "2023-08-30T00:47:02Z", "file_name": "lib/matplotlib/figure.py", "range": {"start_line": 1504, "end_line": 1504, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1309482498", "html_url": "https://github.com/matplotlib/matplotlib/pull/26629#discussion_r1309482498", "attention_area": "        Create a low-level `.GridSpec` that has this figure as a parent.", "file_path": "files/79/12/00001279.py", "old_file_path": "files/81/12/00001281.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1501,8 +1501,7 @@ def align_labels(self, axs=None):\n \n     def add_gridspec(self, nrows=1, ncols=1, **kwargs):\n         \"\"\"\n-        Return a `.GridSpec` that has this figure as a parent.  This allows\n-        complex layout of Axes in the figure.\n+        Create a low-level `.GridSpec` that has this figure as a parent.", "source": "def add_gridspec(self, nrows=1, ncols=1, **kwargs):\n        \"\"\"\n        Create a low-level `.GridSpec` that has this figure as a parent.\n\n        Parameters\n        ----------\n        nrows : int, default: 1\n            Number of rows in grid.\n\n        ncols : int, default: 1\n            Number of columns in grid.\n\n        Returns\n        -------\n        `.GridSpec`\n\n        Other Parameters\n        ----------------\n        **kwargs\n            Keyword arguments are passed to `.GridSpec`.\n\n        See Also\n        --------\n        matplotlib.pyplot.subplots\n\n        Examples\n        --------\n        Adding a subplot that spans two rows::\n\n            fig = plt.figure()\n            gs = fig.add_gridspec(2, 2)\n            ax1 = fig.add_subplot(gs[0, 0])\n            ax2 = fig.add_subplot(gs[1, 0])\n            # spans two rows:\n            ax3 = fig.add_subplot(gs[:, 1])\n\n        \"\"\"\n\n        _ = kwargs.pop('figure', None)  # pop in case user has added this...\n        gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)\n        return gs", "source_start_line": 1502, "tokens": ["def", "add_gridspec", "(", "self", ",", "nrows", "=", "1", ",", "ncols", "=", "1", ",", "**", "kwargs", ")", ":", "\"\"\"        Create a low-level `.GridSpec` that has this figure as a parent.        Parameters        ----------        nrows : int, default: 1            Number of rows in grid.        ncols : int, default: 1            Number of columns in grid.        Returns        -------        `.GridSpec`        Other Parameters        ----------------        **kwargs            Keyword arguments are passed to `.GridSpec`.        See Also        --------        matplotlib.pyplot.subplots        Examples        --------        Adding a subplot that spans two rows::            fig = plt.figure()            gs = fig.add_gridspec(2, 2)            ax1 = fig.add_subplot(gs[0, 0])            ax2 = fig.add_subplot(gs[1, 0])            # spans two rows:            ax3 = fig.add_subplot(gs[:, 1])        \"\"\"", "_", "=", "kwargs", ".", "pop", "(", "'figure'", ",", "None", ")", "gs", "=", "GridSpec", "(", "nrows", "=", "nrows", ",", "ncols", "=", "ncols", ",", "figure", "=", "self", ",", "**", "kwargs", ")", "return", "gs"], "to_mask": {"VAR": ["_", "gs", "ncols", "nrows", "self"], "METHOD": ["GridSpec", "pop"]}, "attention_idx_tokens": [null, null], "patch": "@@ -1501,8 +1501,7 @@\n \n     def add_gridspec(self, nrows=1, ncols=1, **kwargs):\n         \"\"\"\n-        Return a `.GridSpec` that has this figure as a parent.  This allows\n-        complex layout of Axes in the figure.\n+        Create a low-level `.GridSpec` that has this figure as a parent.", "ext_attention_idx_tokens": [null, null], "uid": "8ddeeae4", "question": "what information is `low-level` supposed to impart here?", "code": "def add gridspec self nrows 1 ncols 1 **kwargs \"\"\" Create a low-level ` GridSpec` that has this figure as a parent Parameters ---------- nrows int default 1 Number of rows in grid ncols int default 1 Number of columns in grid Returns ------- ` GridSpec` Other Parameters ---------------- **kwargs Keyword arguments are passed to ` GridSpec` See Also -------- matplotlib pyplot subplots Examples -------- Adding a subplot that spans two rows fig plt figure gs fig add gridspec 2 2 ax1 fig add subplot gs[0 0] ax2 fig add subplot gs[1 0] # spans two rows ax3 fig add subplot gs[ 1] \"\"\" kwargs pop figure None # pop in case user has added this gs GridSpec nrows nrows ncols ncols figure self **kwargs return gs"}
{"message": "Is there a way to say that explicitly? ", "timestamp": "2023-08-30T02:26:14Z", "file_name": "lib/matplotlib/figure.py", "range": {"start_line": 1504, "end_line": 1504, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1309546508", "html_url": "https://github.com/matplotlib/matplotlib/pull/26629#discussion_r1309546508", "attention_area": "        Create a low-level `.GridSpec` that has this figure as a parent.", "file_path": "files/79/12/00001279.py", "old_file_path": "files/81/12/00001281.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1501,8 +1501,7 @@ def align_labels(self, axs=None):\n \n     def add_gridspec(self, nrows=1, ncols=1, **kwargs):\n         \"\"\"\n-        Return a `.GridSpec` that has this figure as a parent.  This allows\n-        complex layout of Axes in the figure.\n+        Create a low-level `.GridSpec` that has this figure as a parent.", "source": "def add_gridspec(self, nrows=1, ncols=1, **kwargs):\n        \"\"\"\n        Create a low-level `.GridSpec` that has this figure as a parent.\n\n        Parameters\n        ----------\n        nrows : int, default: 1\n            Number of rows in grid.\n\n        ncols : int, default: 1\n            Number of columns in grid.\n\n        Returns\n        -------\n        `.GridSpec`\n\n        Other Parameters\n        ----------------\n        **kwargs\n            Keyword arguments are passed to `.GridSpec`.\n\n        See Also\n        --------\n        matplotlib.pyplot.subplots\n\n        Examples\n        --------\n        Adding a subplot that spans two rows::\n\n            fig = plt.figure()\n            gs = fig.add_gridspec(2, 2)\n            ax1 = fig.add_subplot(gs[0, 0])\n            ax2 = fig.add_subplot(gs[1, 0])\n            # spans two rows:\n            ax3 = fig.add_subplot(gs[:, 1])\n\n        \"\"\"\n\n        _ = kwargs.pop('figure', None)  # pop in case user has added this...\n        gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)\n        return gs", "source_start_line": 1502, "tokens": ["def", "add_gridspec", "(", "self", ",", "nrows", "=", "1", ",", "ncols", "=", "1", ",", "**", "kwargs", ")", ":", "\"\"\"        Create a low-level `.GridSpec` that has this figure as a parent.        Parameters        ----------        nrows : int, default: 1            Number of rows in grid.        ncols : int, default: 1            Number of columns in grid.        Returns        -------        `.GridSpec`        Other Parameters        ----------------        **kwargs            Keyword arguments are passed to `.GridSpec`.        See Also        --------        matplotlib.pyplot.subplots        Examples        --------        Adding a subplot that spans two rows::            fig = plt.figure()            gs = fig.add_gridspec(2, 2)            ax1 = fig.add_subplot(gs[0, 0])            ax2 = fig.add_subplot(gs[1, 0])            # spans two rows:            ax3 = fig.add_subplot(gs[:, 1])        \"\"\"", "_", "=", "kwargs", ".", "pop", "(", "'figure'", ",", "None", ")", "gs", "=", "GridSpec", "(", "nrows", "=", "nrows", ",", "ncols", "=", "ncols", ",", "figure", "=", "self", ",", "**", "kwargs", ")", "return", "gs"], "to_mask": {"VAR": ["_", "gs", "ncols", "nrows", "self"], "METHOD": ["GridSpec", "pop"]}, "attention_idx_tokens": [null, null], "patch": "@@ -1501,8 +1501,7 @@\n \n     def add_gridspec(self, nrows=1, ncols=1, **kwargs):\n         \"\"\"\n-        Return a `.GridSpec` that has this figure as a parent.  This allows\n-        complex layout of Axes in the figure.\n+        Create a low-level `.GridSpec` that has this figure as a parent.", "ext_attention_idx_tokens": [null, null], "uid": "2c810fa4", "question": "Is there a way to say that explicitly? ", "code": "def add gridspec self nrows 1 ncols 1 **kwargs \"\"\" Create a low-level ` GridSpec` that has this figure as a parent Parameters ---------- nrows int default 1 Number of rows in grid ncols int default 1 Number of columns in grid Returns ------- ` GridSpec` Other Parameters ---------------- **kwargs Keyword arguments are passed to ` GridSpec` See Also -------- matplotlib pyplot subplots Examples -------- Adding a subplot that spans two rows fig plt figure gs fig add gridspec 2 2 ax1 fig add subplot gs[0 0] ax2 fig add subplot gs[1 0] # spans two rows ax3 fig add subplot gs[ 1] \"\"\" kwargs pop figure None # pop in case user has added this gs GridSpec nrows nrows ncols ncols figure self **kwargs return gs"}
{"message": "Can you explain this song and dance? ", "timestamp": "2023-09-02T01:53:57Z", "file_name": "lib/matplotlib/tests/test_ticker.py", "range": {"start_line": 1659, "end_line": 1659, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1313684828", "html_url": "https://github.com/matplotlib/matplotlib/pull/26680#discussion_r1313684828", "attention_area": "def test_locale_comma():", "file_path": "files/10/13/00001310.py", "old_file_path": "files/11/13/00001311.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1640,22 +1640,31 @@ def test_latex(self, is_latex, usetex, expected):\n             assert fmt.format_pct(50, 100) == expected\n \n \n-def test_locale_comma():\n-    currentLocale = locale.getlocale()\n+def _impl_locale_comma():\n     try:\n         locale.setlocale(locale.LC_ALL, 'de_DE.UTF-8')\n-        ticks = mticker.ScalarFormatter(useMathText=True, useLocale=True)\n-        fmt = '$\\\\mathdefault{%1.1f}$'\n-        x = ticks._format_maybe_minus_and_locale(fmt, 0.5)\n-        assert x == '$\\\\mathdefault{0{,}5}$'\n-        # Do not change , in the format string\n-        fmt = ',$\\\\mathdefault{,%1.1f},$'\n-        x = ticks._format_maybe_minus_and_locale(fmt, 0.5)\n-        assert x == ',$\\\\mathdefault{,0{,}5},$'\n     except locale.Error:\n-        pytest.skip(\"Locale de_DE.UTF-8 is not supported on this machine\")\n-    finally:\n-        locale.setlocale(locale.LC_ALL, currentLocale)\n+        print('SKIP: Locale de_DE.UTF-8 is not supported on this machine')\n+        return\n+    ticks = mticker.ScalarFormatter(useMathText=True, useLocale=True)\n+    fmt = '$\\\\mathdefault{%1.1f}$'\n+    x = ticks._format_maybe_minus_and_locale(fmt, 0.5)\n+    assert x == '$\\\\mathdefault{0{,}5}$'\n+    # Do not change , in the format string\n+    fmt = ',$\\\\mathdefault{,%1.1f},$'\n+    x = ticks._format_maybe_minus_and_locale(fmt, 0.5)\n+    assert x == ',$\\\\mathdefault{,0{,}5},$'\n+\n+\n+def test_locale_comma():", "source": "def test_locale_comma():\n    proc = mpl.testing.subprocess_run_helper(_impl_locale_comma, timeout=60,\n                                             extra_env={'MPLBACKEND': 'Agg'})\n    skip_msg = next((line[len('SKIP:'):].strip()\n                     for line in proc.stdout.splitlines()\n                     if line.startswith('SKIP:')),\n                    '')\n    if skip_msg:\n        pytest.skip(skip_msg)", "source_start_line": 1659, "tokens": ["def", "test_locale_comma", "(", ")", ":", "proc", "=", "mpl", ".", "testing", ".", "subprocess_run_helper", "(", "_impl_locale_comma", ",", "timeout", "=", "60", ",", "extra_env", "=", "{", "'MPLBACKEND'", ":", "'Agg'", "}", ")", "skip_msg", "=", "next", "(", "(", "line", "[", "len", "(", "'SKIP:'", ")", ":", "]", ".", "strip", "(", ")", "for", "line", "in", "proc", ".", "stdout", ".", "splitlines", "(", ")", "if", "line", ".", "startswith", "(", "'SKIP:'", ")", ")", ",", "''", ")", "if", "skip_msg", ":", "pytest", ".", "skip", "(", "skip_msg", ")"], "to_mask": {"VAR": ["proc", "skip_msg"], "METHOD": ["len", "next", "skip", "splitlines", "startswith", "strip", "subprocess_run_helper"]}, "attention_idx_tokens": [0, 4], "patch": "@@ -1640,22 +1640,31 @@\n             assert fmt.format_pct(50, 100) == expected\n \n \n-def test_locale_comma():\n-    currentLocale = locale.getlocale()\n+def _impl_locale_comma():\n     try:\n         locale.setlocale(locale.LC_ALL, 'de_DE.UTF-8')\n-        ticks = mticker.ScalarFormatter(useMathText=True, useLocale=True)\n-        fmt = '$\\\\mathdefault{%1.1f}$'\n-        x = ticks._format_maybe_minus_and_locale(fmt, 0.5)\n-        assert x == '$\\\\mathdefault{0{,}5}$'\n-        # Do not change , in the format string\n-        fmt = ',$\\\\mathdefault{,%1.1f},$'\n-        x = ticks._format_maybe_minus_and_locale(fmt, 0.5)\n-        assert x == ',$\\\\mathdefault{,0{,}5},$'\n     except locale.Error:\n-        pytest.skip(\"Locale de_DE.UTF-8 is not supported on this machine\")\n-    finally:\n-        locale.setlocale(locale.LC_ALL, currentLocale)\n+        print('SKIP: Locale de_DE.UTF-8 is not supported on this machine')\n+        return\n+    ticks = mticker.ScalarFormatter(useMathText=True, useLocale=True)\n+    fmt = '$\\\\mathdefault{%1.1f}$'\n+    x = ticks._format_maybe_minus_and_locale(fmt, 0.5)\n+    assert x == '$\\\\mathdefault{0{,}5}$'\n+    # Do not change , in the format string\n+    fmt = ',$\\\\mathdefault{,%1.1f},$'\n+    x = ticks._format_maybe_minus_and_locale(fmt, 0.5)\n+    assert x == ',$\\\\mathdefault{,0{,}5},$'\n+\n+\n+def test_locale_comma():", "ext_attention_idx_tokens": [0, 73], "uid": "cc1160c0", "question": "Can you explain this song and dance? ", "code": "def test locale comma proc mpl testing subprocess run helper impl locale comma timeout 60 extra env { MPLBACKEND Agg } skip msg next line[len SKIP ] strip for line in proc stdout splitlines if line startswith SKIP if skip msg pytest skip skip msg"}
{"message": "Sure, but they are in a private module and I have another PR stalled for adding the fully qualified paths, so I selected to take, what appeared to be, the easy way.\n\n(Is this PR an improvement compared to the previous?)", "timestamp": "2023-09-12T06:17:26Z", "file_name": "lib/matplotlib/_constrained_layout.py", "range": {"start_line": 608, "end_line": 608, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1322476916", "html_url": "https://github.com/matplotlib/matplotlib/pull/26705#discussion_r1322476916", "attention_area": "    renderer : Renderer", "file_path": "files/29/13/00001329.py", "old_file_path": "files/28/13/00001328.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -602,8 +604,8 @@ def get_pos_and_bbox(ax, renderer):\n \n     Parameters\n     ----------\n-    ax\n-    renderer\n+    ax : Axes\n+    renderer : Renderer", "source": "def get_pos_and_bbox(ax, renderer):\n    \"\"\"\n    Get the position and the bbox for the axes.\n\n    Parameters\n    ----------\n    ax : Axes\n    renderer : Renderer\n\n    Returns\n    -------\n    pos : Bbox\n        Position in figure coordinates.\n    bbox : Bbox\n        Tight bounding box in figure coordinates.\n    \"\"\"\n    fig = ax.figure\n    pos = ax.get_position(original=True)\n    # pos is in panel co-ords, but we need in figure for the layout\n    pos = pos.transformed(fig.transSubfigure - fig.transFigure)\n    tightbbox = martist._get_tightbbox_for_layout_only(ax, renderer)\n    if tightbbox is None:\n        bbox = pos\n    else:\n        bbox = tightbbox.transformed(fig.transFigure.inverted())\n    return pos, bbox", "source_start_line": 601, "tokens": ["def", "get_pos_and_bbox", "(", "ax", ",", "renderer", ")", ":", "\"\"\"    Get the position and the bbox for the axes.    Parameters    ----------    ax : Axes    renderer : Renderer    Returns    -------    pos : Bbox        Position in figure coordinates.    bbox : Bbox        Tight bounding box in figure coordinates.    \"\"\"", "fig", "=", "ax", ".", "figure", "pos", "=", "ax", ".", "get_position", "(", "original", "=", "True", ")", "pos", "=", "pos", ".", "transformed", "(", "fig", ".", "transSubfigure", "-", "fig", ".", "transFigure", ")", "tightbbox", "=", "martist", ".", "_get_tightbbox_for_layout_only", "(", "ax", ",", "renderer", ")", "if", "tightbbox", "is", "None", ":", "bbox", "=", "pos", "else", ":", "bbox", "=", "tightbbox", ".", "transformed", "(", "fig", ".", "transFigure", ".", "inverted", "(", ")", ")", "return", "pos", ",", "bbox"], "to_mask": {"VAR": ["ax", "bbox", "fig", "pos", "renderer", "tightbbox"], "METHOD": ["_get_tightbbox_for_layout_only", "get_position", "inverted", "transformed"]}, "attention_idx_tokens": [null, null], "patch": "@@ -602,8 +604,8 @@\n \n     Parameters\n     ----------\n-    ax\n-    renderer\n+    ax : Axes\n+    renderer : Renderer", "ext_attention_idx_tokens": [null, null], "uid": "e633d665", "question": "Sure, but they are in a private module and I have another PR stalled for adding the fully qualified paths, so I selected to take, what appeared to be, the easy way.  (Is this PR an improvement compared to the previous?)", "code": "def get pos and bbox ax renderer \"\"\" Get the position and the bbox for the axes Parameters ---------- ax Axes renderer Renderer Returns ------- pos Bbox Position in figure coordinates bbox Bbox Tight bounding box in figure coordinates \"\"\" fig ax figure pos ax get position original True # pos is in panel co-ords but we need in figure for the layout pos pos transformed fig transSubfigure - fig transFigure tightbbox martist get tightbbox for layout only ax renderer if tightbbox is None bbox pos else bbox tightbbox transformed fig transFigure inverted return pos bbox"}
{"message": "Were these changes intentional?", "timestamp": "2023-09-22T18:44:03Z", "file_name": "lib/matplotlib/collections.py", "range": {"start_line": 2316, "end_line": 2316, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1334716077", "html_url": "https://github.com/matplotlib/matplotlib/pull/26874#discussion_r1334716077", "attention_area": "                                 \"the compressed values is deprecated. \"", "file_path": "files/56/13/00001356.py", "old_file_path": "files/58/13/00001358.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -2344,9 +2313,9 @@ def set_array(self, A):\n         # elements and thus compression occurring.\n         if self._deprecated_compression and np.ndim(A) == 1:\n             _api.warn_deprecated(\"3.8\", message=\"Setting a PolyQuadMesh array using \"\n-                                                \"the compressed values is deprecated. \"\n-                                                \"Pass the full 2D shape of the original array \"\n-                                                f\"{prev_unmask.shape} including the masked elements.\")\n+                                 \"the compressed values is deprecated. \"", "source": "def set_array(self, A):\n        # docstring inherited\n        prev_unmask = self._get_unmasked_polys()\n        # MPL <3.8 compressed the mask, so we need to handle flattened 1d input\n        # until the deprecation expires, also only warning when there are masked\n        # elements and thus compression occurring.\n        if self._deprecated_compression and np.ndim(A) == 1:\n            _api.warn_deprecated(\"3.8\", message=\"Setting a PolyQuadMesh array using \"\n                                 \"the compressed values is deprecated. \"\n                                 \"Pass the full 2D shape of the original array \"\n                                 f\"{prev_unmask.shape} including the masked elements.\")\n            Afull = np.empty(self._original_mask.shape)\n            Afull[~self._original_mask] = A\n            # We also want to update the mask with any potential\n            # new masked elements that came in. But, we don't want\n            # to update any of the compression from the original\n            mask = self._original_mask.copy()\n            mask[~self._original_mask] |= np.ma.getmask(A)\n            A = np.ma.array(Afull, mask=mask)\n            return super().set_array(A)\n        self._deprecated_compression = False\n        super().set_array(A)\n        # If the mask has changed at all we need to update\n        # the set of Polys that we are drawing\n        if not np.array_equal(prev_unmask, self._get_unmasked_polys()):\n            self._set_unmasked_verts()", "source_start_line": 2308, "tokens": ["def", "set_array", "(", "self", ",", "A", ")", ":", "prev_unmask", "=", "self", ".", "_get_unmasked_polys", "(", ")", "if", "self", ".", "_deprecated_compression", "and", "np", ".", "ndim", "(", "A", ")", "==", "1", ":", "_api", ".", "warn_deprecated", "(", "\"3.8\"", ",", "message", "=", "\"Setting a PolyQuadMesh array using \"", "\"the compressed values is deprecated. \"", "\"Pass the full 2D shape of the original array \"", "f\"", "{", "prev_unmask", ".", "shape", "}", "\"", ")", "Afull", "=", "np", ".", "empty", "(", "self", ".", "_original_mask", ".", "shape", ")", "Afull", "[", "~", "self", ".", "_original_mask", "]", "=", "A", "mask", "=", "self", ".", "_original_mask", ".", "copy", "(", ")", "mask", "[", "~", "self", ".", "_original_mask", "]", "|=", "np", ".", "ma", ".", "getmask", "(", "A", ")", "A", "=", "np", ".", "ma", ".", "array", "(", "Afull", ",", "mask", "=", "mask", ")", "return", "super", "(", ")", ".", "set_array", "(", "A", ")", "self", ".", "_deprecated_compression", "=", "False", "super", "(", ")", ".", "set_array", "(", "A", ")", "if", "not", "np", ".", "array_equal", "(", "prev_unmask", ",", "self", ".", "_get_unmasked_polys", "(", ")", ")", ":", "self", ".", "_set_unmasked_verts", "(", ")"], "to_mask": {"VAR": ["A", "Afull", "_deprecated_compression", "mask", "prev_unmask", "self"], "METHOD": ["_get_unmasked_polys", "_set_unmasked_verts", "array", "array_equal", "copy", "empty", "getmask", "ndim", "set_array", "super", "warn_deprecated"]}, "attention_idx_tokens": [38, 38], "patch": "@@ -2344,9 +2313,9 @@\n         # elements and thus compression occurring.\n         if self._deprecated_compression and np.ndim(A) == 1:\n             _api.warn_deprecated(\"3.8\", message=\"Setting a PolyQuadMesh array using \"\n-                                                \"the compressed values is deprecated. \"\n-                                                \"Pass the full 2D shape of the original array \"\n-                                                f\"{prev_unmask.shape} including the masked elements.\")\n+                                 \"the compressed values is deprecated. \"", "ext_attention_idx_tokens": [38, 59], "uid": "6b3b085f", "question": "Were these changes intentional?", "code": "def set array self A # docstring inherited prev unmask self get unmasked polys # MPL <3 8 compressed the mask so we need to handle flattened 1d input # until the deprecation expires also only warning when there are masked # elements and thus compression occurring if self deprecated compression and np ndim A 1 api warn deprecated \"3 8\" message \"Setting a PolyQuadMesh array using \" \"the compressed values is deprecated \" \"Pass the full 2D shape of the original array \" f\"{prev unmask shape} including the masked elements \" Afull np empty self original mask shape Afull[~self original mask] A # We also want to update the mask with any potential # new masked elements that came in But we don t want # to update any of the compression from the original mask self original mask copy mask[~self original mask] | np ma getmask A A np ma array Afull mask mask return super set array A self deprecated compression False super set array A # If the mask has changed at all we need to update # the set of Polys that we are drawing if not np array equal prev unmask self get unmasked polys self set unmasked verts"}
{"message": "Looks like only one entry was changed?", "timestamp": "2023-10-04T23:39:02Z", "file_name": "lib/matplotlib/axis.py", "range": {"start_line": 1965, "end_line": 1965, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1346591542", "html_url": "https://github.com/matplotlib/matplotlib/pull/26951#discussion_r1346591542", "attention_area": "            locations. The labels are used as is, without further formatting.", "file_path": "files/24/14/00001424.py", "old_file_path": "files/25/14/00001425.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1962,7 +1962,7 @@ def set_ticklabels(self, labels, *, minor=False, fontdict=None, **kwargs):\n         labels : sequence of str or of `.Text`\\s\n             Texts for labeling each tick location in the sequence set by\n             `.Axis.set_ticks`; the number of labels must match the number of\n-            locations.\n+            locations. The labels are used as is, without further formatting.", "source": "def set_ticklabels(self, labels, *, minor=False, fontdict=None, **kwargs):\n        r\"\"\"\n        [*Discouraged*] Set this Axis' tick labels with list of string labels.\n\n        .. admonition:: Discouraged\n\n            The use of this method is discouraged, because of the dependency on\n            tick positions. In most cases, you'll want to use\n            ``Axes.set_[x/y/z]ticks(positions, labels)`` or ``Axis.set_ticks``\n            instead.\n\n            If you are using this method, you should always fix the tick\n            positions before, e.g. by using `.Axis.set_ticks` or by explicitly\n            setting a `~.ticker.FixedLocator`. Otherwise, ticks are free to\n            move and the labels may end up in unexpected positions.\n\n        Parameters\n        ----------\n        labels : sequence of str or of `.Text`\\s\n            Texts for labeling each tick location in the sequence set by\n            `.Axis.set_ticks`; the number of labels must match the number of\n            locations. The labels are used as is, without further formatting.\n\n        minor : bool\n            If True, set minor ticks instead of major ticks.\n\n        fontdict : dict, optional\n\n            .. admonition:: Discouraged\n\n               The use of *fontdict* is discouraged. Parameters should be passed as\n               individual keyword arguments or using dictionary-unpacking\n               ``set_ticklabels(..., **fontdict)``.\n\n            A dictionary controlling the appearance of the ticklabels.\n            The default *fontdict* is::\n\n               {'fontsize': rcParams['axes.titlesize'],\n                'fontweight': rcParams['axes.titleweight'],\n                'verticalalignment': 'baseline',\n                'horizontalalignment': loc}\n\n        **kwargs\n            Text properties.\n\n            .. warning::\n\n                This only sets the properties of the current ticks.\n                Ticks are not guaranteed to be persistent. Various operations\n                can create, delete and modify the Tick instances. There is an\n                imminent risk that these settings can get lost if you work on\n                the figure further (including also panning/zooming on a\n                displayed figure).\n\n                Use `.set_tick_params` instead if possible.\n\n        Returns\n        -------\n        list of `.Text`\\s\n            For each tick, includes ``tick.label1`` if it is visible, then\n            ``tick.label2`` if it is visible, in that order.\n        \"\"\"\n        try:\n            labels = [t.get_text() if hasattr(t, 'get_text') else t\n                      for t in labels]\n        except TypeError:\n            raise TypeError(f\"{labels:=} must be a sequence\") from None\n        locator = (self.get_minor_locator() if minor\n                   else self.get_major_locator())\n        if not labels:\n            # eg labels=[]:\n            formatter = mticker.NullFormatter()\n        elif isinstance(locator, mticker.FixedLocator):\n            # Passing [] as a list of labels is often used as a way to\n            # remove all tick labels, so only error for > 0 labels\n            if len(locator.locs) != len(labels) and len(labels) != 0:\n                raise ValueError(\n                    \"The number of FixedLocator locations\"\n                    f\" ({len(locator.locs)}), usually from a call to\"\n                    \" set_ticks, does not match\"\n                    f\" the number of labels ({len(labels)}).\")\n            tickd = {loc: lab for loc, lab in zip(locator.locs, labels)}\n            func = functools.partial(self._format_with_dict, tickd)\n            formatter = mticker.FuncFormatter(func)\n        else:\n            _api.warn_external(\n                 \"set_ticklabels() should only be used with a fixed number of \"\n                 \"ticks, i.e. after set_ticks() or using a FixedLocator.\")\n            formatter = mticker.FixedFormatter(labels)\n\n        with warnings.catch_warnings():\n            warnings.filterwarnings(\n                \"ignore\",\n                message=\"FixedFormatter should only be used together with FixedLocator\")\n            if minor:\n                self.set_minor_formatter(formatter)\n                locs = self.get_minorticklocs()\n                ticks = self.get_minor_ticks(len(locs))\n            else:\n                self.set_major_formatter(formatter)\n                locs = self.get_majorticklocs()\n                ticks = self.get_major_ticks(len(locs))\n\n        ret = []\n        if fontdict is not None:\n            kwargs.update(fontdict)\n        for pos, (loc, tick) in enumerate(zip(locs, ticks)):\n            tick.update_position(loc)\n            tick_label = formatter(loc, pos)\n            # deal with label1\n            tick.label1.set_text(tick_label)\n            tick.label1._internal_update(kwargs)\n            # deal with label2\n            tick.label2.set_text(tick_label)\n            tick.label2._internal_update(kwargs)\n            # only return visible tick labels\n            if tick.label1.get_visible():\n                ret.append(tick.label1)\n            if tick.label2.get_visible():\n                ret.append(tick.label2)\n\n        self.stale = True\n        return ret", "source_start_line": 1944, "tokens": ["def", "set_ticklabels", "(", "self", ",", "labels", ",", "*", ",", "minor", "=", "False", ",", "fontdict", "=", "None", ",", "**", "kwargs", ")", ":", "r\"\"\"        [*Discouraged*] Set this Axis' tick labels with list of string labels.        .. admonition:: Discouraged            The use of this method is discouraged, because of the dependency on            tick positions. In most cases, you'll want to use            ``Axes.set_[x/y/z]ticks(positions, labels)`` or ``Axis.set_ticks``            instead.            If you are using this method, you should always fix the tick            positions before, e.g. by using `.Axis.set_ticks` or by explicitly            setting a `~.ticker.FixedLocator`. Otherwise, ticks are free to            move and the labels may end up in unexpected positions.        Parameters        ----------        labels : sequence of str or of `.Text`\\s            Texts for labeling each tick location in the sequence set by            `.Axis.set_ticks`; the number of labels must match the number of            locations. The labels are used as is, without further formatting.        minor : bool            If True, set minor ticks instead of major ticks.        fontdict : dict, optional            .. admonition:: Discouraged               The use of *fontdict* is discouraged. Parameters should be passed as               individual keyword arguments or using dictionary-unpacking               ``set_ticklabels(..., **fontdict)``.            A dictionary controlling the appearance of the ticklabels.            The default *fontdict* is::               {'fontsize': rcParams['axes.titlesize'],                'fontweight': rcParams['axes.titleweight'],                'verticalalignment': 'baseline',                'horizontalalignment': loc}        **kwargs            Text properties.            .. warning::                This only sets the properties of the current ticks.                Ticks are not guaranteed to be persistent. Various operations                can create, delete and modify the Tick instances. There is an                imminent risk that these settings can get lost if you work on                the figure further (including also panning/zooming on a                displayed figure).                Use `.set_tick_params` instead if possible.        Returns        -------        list of `.Text`\\s            For each tick, includes ``tick.label1`` if it is visible, then            ``tick.label2`` if it is visible, in that order.        \"\"\"", "try", ":", "labels", "=", "[", "t", ".", "get_text", "(", ")", "if", "hasattr", "(", "t", ",", "'get_text'", ")", "else", "t", "for", "t", "in", "labels", "]", "except", "TypeError", ":", "raise", "TypeError", "(", "f\"", "{", "labels", ":=", "}", "\"", ")", "from", "None", "locator", "=", "(", "self", ".", "get_minor_locator", "(", ")", "if", "minor", "else", "self", ".", "get_major_locator", "(", ")", ")", "if", "not", "labels", ":", "formatter", "=", "mticker", ".", "NullFormatter", "(", ")", "elif", "isinstance", "(", "locator", ",", "mticker", ".", "FixedLocator", ")", ":", "if", "len", "(", "locator", ".", "locs", ")", "!=", "len", "(", "labels", ")", "and", "len", "(", "labels", ")", "!=", "0", ":", "raise", "ValueError", "(", "\"The number of FixedLocator locations\"", "f\"", "{", "len", "(", "locator", ".", "locs", ")", "}", "\"", "\" set_ticks, does not match\"", "f\"", "{", "len", "(", "labels", ")", "}", "\"", ")", "tickd", "=", "{", "loc", ":", "lab", "for", "loc", ",", "lab", "in", "zip", "(", "locator", ".", "locs", ",", "labels", ")", "}", "func", "=", "functools", ".", "partial", "(", "self", ".", "_format_with_dict", ",", "tickd", ")", "formatter", "=", "mticker", ".", "FuncFormatter", "(", "func", ")", "else", ":", "_api", ".", "warn_external", "(", "\"set_ticklabels() should only be used with a fixed number of \"", "\"ticks, i.e. after set_ticks() or using a FixedLocator.\"", ")", "formatter", "=", "mticker", ".", "FixedFormatter", "(", "labels", ")", "with", "warnings", ".", "catch_warnings", "(", ")", ":", "warnings", ".", "filterwarnings", "(", "\"ignore\"", ",", "message", "=", "\"FixedFormatter should only be used together with FixedLocator\"", ")", "if", "minor", ":", "self", ".", "set_minor_formatter", "(", "formatter", ")", "locs", "=", "self", ".", "get_minorticklocs", "(", ")", "ticks", "=", "self", ".", "get_minor_ticks", "(", "len", "(", "locs", ")", ")", "else", ":", "self", ".", "set_major_formatter", "(", "formatter", ")", "locs", "=", "self", ".", "get_majorticklocs", "(", ")", "ticks", "=", "self", ".", "get_major_ticks", "(", "len", "(", "locs", ")", ")", "ret", "=", "[", "]", "if", "fontdict", "is", "not", "None", ":", "kwargs", ".", "update", "(", "fontdict", ")", "for", "pos", ",", "(", "loc", ",", "tick", ")", "in", "enumerate", "(", "zip", "(", "locs", ",", "ticks", ")", ")", ":", "tick", ".", "update_position", "(", "loc", ")", "tick_label", "=", "formatter", "(", "loc", ",", "pos", ")", "tick", ".", "label1", ".", "set_text", "(", "tick_label", ")", "tick", ".", "label1", ".", "_internal_update", "(", "kwargs", ")", "tick", ".", "label2", ".", "set_text", "(", "tick_label", ")", "tick", ".", "label2", ".", "_internal_update", "(", "kwargs", ")", "if", "tick", ".", "label1", ".", "get_visible", "(", ")", ":", "ret", ".", "append", "(", "tick", ".", "label1", ")", "if", "tick", ".", "label2", ".", "get_visible", "(", ")", ":", "ret", ".", "append", "(", "tick", ".", "label2", ")", "self", ".", "stale", "=", "True", "return", "ret"], "to_mask": {"VAR": ["fontdict", "formatter", "func", "lab", "labels", "loc", "locator", "locs", "minor", "pos", "ret", "self", "stale", "tick_label", "tickd", "ticks"], "METHOD": ["FixedFormatter", "FuncFormatter", "NullFormatter", "TypeError", "ValueError", "_internal_update", "append", "catch_warnings", "enumerate", "filterwarnings", "formatter", "get_major_locator", "get_major_ticks", "get_majorticklocs", "get_minor_locator", "get_minor_ticks", "get_minorticklocs", "get_text", "get_visible", "hasattr", "isinstance", "len", "partial", "set_major_formatter", "set_minor_formatter", "set_text", "update", "update_position", "warn_external", "zip"]}, "attention_idx_tokens": [null, null], "patch": "@@ -1962,7 +1962,7 @@\n         labels : sequence of str or of `.Text`\\s\n             Texts for labeling each tick location in the sequence set by\n             `.Axis.set_ticks`; the number of labels must match the number of\n-            locations.\n+            locations. The labels are used as is, without further formatting.", "ext_attention_idx_tokens": [null, null], "uid": "2f6cc1ed", "question": "Looks like only one entry was changed?", "code": "def set ticklabels self labels * minor False fontdict None **kwargs r\"\"\" [*Discouraged*] Set this Axis tick labels with list of string labels admonition Discouraged The use of this method is discouraged because of the dependency on tick positions In most cases you ll want to use ``Axes set [x y z]ticks positions labels `` or ``Axis set ticks`` instead If you are using this method you should always fix the tick positions before e g by using ` Axis set ticks` or by explicitly setting a `~ ticker FixedLocator` Otherwise ticks are free to move and the labels may end up in unexpected positions Parameters ---------- labels sequence of str or of ` Text`\\s Texts for labeling each tick location in the sequence set by ` Axis set ticks`; the number of labels must match the number of locations The labels are used as is without further formatting minor bool If True set minor ticks instead of major ticks fontdict dict optional admonition Discouraged The use of *fontdict* is discouraged Parameters should be passed as individual keyword arguments or using dictionary-unpacking ``set ticklabels **fontdict `` A dictionary controlling the appearance of the ticklabels The default *fontdict* is { fontsize rcParams[ axes titlesize ] fontweight rcParams[ axes titleweight ] verticalalignment baseline horizontalalignment loc} **kwargs Text properties warning This only sets the properties of the current ticks Ticks are not guaranteed to be persistent Various operations can create delete and modify the Tick instances There is an imminent risk that these settings can get lost if you work on the figure further including also panning zooming on a displayed figure Use ` set tick params` instead if possible Returns ------- list of ` Text`\\s For each tick includes ``tick label1`` if it is visible then ``tick label2`` if it is visible in that order \"\"\" try labels [t get text if hasattr t get text else t for t in labels] except TypeError raise TypeError f\"{labels } must be a sequence\" from None locator self get minor locator if minor else self get major locator if not labels # eg labels [] formatter mticker NullFormatter elif isinstance locator mticker FixedLocator # Passing [] as a list of labels is often used as a way to # remove all tick labels so only error for > 0 labels if len locator locs ! len labels and len labels ! 0 raise ValueError \"The number of FixedLocator locations\" f\" {len locator locs } usually from a call to\" \" set ticks does not match\" f\" the number of labels {len labels } \" tickd {loc lab for loc lab in zip locator locs labels } func functools partial self format with dict tickd formatter mticker FuncFormatter func else api warn external \"set ticklabels should only be used with a fixed number of \" \"ticks i e after set ticks or using a FixedLocator \" formatter mticker FixedFormatter labels with warnings catch warnings warnings filterwarnings \"ignore\" message \"FixedFormatter should only be used together with FixedLocator\" if minor self set minor formatter formatter locs self get minorticklocs ticks self get minor ticks len locs else self set major formatter formatter locs self get majorticklocs ticks self get major ticks len locs ret [] if fontdict is not None kwargs update fontdict for pos loc tick in enumerate zip locs ticks tick update position loc tick label formatter loc pos # deal with label1 tick label1 set text tick label tick label1 internal update kwargs # deal with label2 tick label2 set text tick label tick label2 internal update kwargs # only return visible tick labels if tick label1 get visible ret append tick label1 if tick label2 get visible ret append tick label2 self stale True return ret"}
{"message": "Do we wish this single instance to warn if this returns `0`?\r\n\r\nOr are the desired warnings from this handled by the other parts of this PR?\r\n\r\n(All other instances had `warn=false` passed, but this one would have warned)", "timestamp": "2023-10-16T22:57:32Z", "file_name": "src/ft2font.cpp", "range": {"start_line": 582, "end_line": 582, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1361340834", "html_url": "https://github.com/matplotlib/matplotlib/pull/26989#discussion_r1361340834", "attention_area": "        FT_UInt glyph_index =  FT_Get_Char_Index(face, (FT_ULong) charcode);", "file_path": "files/74/14/00001474.cpp", "old_file_path": "files/75/14/00001475.cpp", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -592,8 +579,7 @@ void FT2Font::load_char(long charcode, FT_Int32 flags, FT2Font *&ft_object, bool\n         ft_object = ft_object_with_glyph;\n     } else {\n         ft_object = this;\n-        FT_UInt glyph_index = ft_get_char_index_or_warn(face, (FT_ULong)charcode);\n-\n+        FT_UInt glyph_index =  FT_Get_Char_Index(face, (FT_ULong) charcode);", "source": "void FT2Font::load_char(long charcode, FT_Int32 flags, FT2Font *&ft_object, bool fallback = false)\n{\n    // if this is parent FT2Font, cache will be filled in 2 ways:\n    // 1. set_text was previously called\n    // 2. set_text was not called and fallback was enabled\n    if (fallback && char_to_font.find(charcode) != char_to_font.end()) {\n        ft_object = char_to_font[charcode];\n        // since it will be assigned to ft_object anyway\n        FT2Font *throwaway = NULL;\n        ft_object->load_char(charcode, flags, throwaway, false);\n    } else if (fallback) {\n        FT_UInt final_glyph_index;\n        FT_Error charcode_error, glyph_error;\n        FT2Font *ft_object_with_glyph = this;\n        bool was_found = load_char_with_fallback(ft_object_with_glyph, final_glyph_index, glyphs, char_to_font,\n                                glyph_to_font, charcode, flags, charcode_error, glyph_error, true);\n        if (!was_found) {\n            if (charcode_error) {\n                throw_ft_error(\"Could not load charcode\", charcode_error);\n            }\n            else if (glyph_error) {\n                throw_ft_error(\"Could not load charcode\", glyph_error);\n            }\n        }\n        ft_object = ft_object_with_glyph;\n    } else {\n        ft_object = this;\n        FT_UInt glyph_index =  FT_Get_Char_Index(face, (FT_ULong) charcode);\n        if (FT_Error error = FT_Load_Glyph(face, glyph_index, flags)) {\n            throw_ft_error(\"Could not load charcode\", error);\n        }\n        FT_Glyph thisGlyph;\n        if (FT_Error error = FT_Get_Glyph(face->glyph, &thisGlyph)) {\n            throw_ft_error(\"Could not get glyph\", error);\n        }\n        glyphs.push_back(thisGlyph);\n    }\n}", "source_start_line": 555, "tokens": ["void", "FT2Font", "::", "load_char", "(", "long", "charcode", ",", "FT_Int32", "flags", ",", "FT2Font", "*", "&", "ft_object", ",", "bool", "fallback", "=", "false", ")", "{", "if", "(", "fallback", "&&", "char_to_font", ".", "find", "(", "charcode", ")", "!=", "char_to_font", ".", "end", "(", ")", ")", "{", "ft_object", "=", "char_to_font", "[", "charcode", "]", ";", "FT2Font", "*", "throwaway", "=", "NULL", ";", "ft_object", "->", "load_char", "(", "charcode", ",", "flags", ",", "throwaway", ",", "false", ")", ";", "}", "else", "if", "(", "fallback", ")", "{", "FT_UInt", "final_glyph_index", ";", "FT_Error", "charcode_error", ",", "glyph_error", ";", "FT2Font", "*", "ft_object_with_glyph", "=", "this", ";", "bool", "was_found", "=", "load_char_with_fallback", "(", "ft_object_with_glyph", ",", "final_glyph_index", ",", "glyphs", ",", "char_to_font", ",", "glyph_to_font", ",", "charcode", ",", "flags", ",", "charcode_error", ",", "glyph_error", ",", "true", ")", ";", "if", "(", "!", "was_found", ")", "{", "if", "(", "charcode_error", ")", "{", "throw_ft_error", "(", "\"", "\"", ",", "charcode_error", ")", ";", "}", "else", "if", "(", "glyph_error", ")", "{", "throw_ft_error", "(", "\"", "\"", ",", "glyph_error", ")", ";", "}", "}", "ft_object", "=", "ft_object_with_glyph", ";", "}", "else", "{", "ft_object", "=", "this", ";", "FT_UInt", "glyph_index", "=", "FT_Get_Char_Index", "(", "face", ",", "(", "FT_ULong", ")", "charcode", ")", ";", "if", "(", "FT_Error", "error", "=", "FT_Load_Glyph", "(", "face", ",", "glyph_index", ",", "flags", ")", ")", "{", "throw_ft_error", "(", "\"", "\"", ",", "error", ")", ";", "}", "FT_Glyph", "thisGlyph", ";", "if", "(", "FT_Error", "error", "=", "FT_Get_Glyph", "(", "face", "->", "glyph", ",", "&", "thisGlyph", ")", ")", "{", "throw_ft_error", "(", "\"", "\"", ",", "error", ")", ";", "}", "glyphs", ".", "push_back", "(", "thisGlyph", ")", ";", "}", "}"], "to_mask": {"VAR": ["charcode", "charcode_error", "error", "final_glyph_index", "flags", "ft_object", "ft_object_with_glyph", "glyph_error", "glyph_index", "thisGlyph", "throwaway", "was_found"], "METHOD": ["FT_Get_Char_Index", "FT_Get_Glyph", "FT_Load_Glyph", "end", "find", "load_char", "load_char_with_fallback", "push_back", "throw_ft_error"]}, "attention_idx_tokens": [160, 172], "patch": "@@ -592,8 +579,7 @@\n         ft_object = ft_object_with_glyph;\n     } else {\n         ft_object = this;\n-        FT_UInt glyph_index = ft_get_char_index_or_warn(face, (FT_ULong)charcode);\n-\n+        FT_UInt glyph_index =  FT_Get_Char_Index(face, (FT_ULong) charcode);", "ext_attention_idx_tokens": [160, 187], "uid": "8e7c02bd", "question": "Do we wish this single instance to warn if this returns `0`?    Or are the desired warnings from this handled by the other parts of this PR?    (All other instances had `warn=false` passed, but this one would have warned)", "code": "void FT2Font load char long charcode FT Int32 flags FT2Font *&ft object bool fallback false { if this is parent FT2Font cache will be filled in 2 ways 1 set text was previously called 2 set text was not called and fallback was enabled if fallback && char to font find charcode ! char to font end { ft object char to font[charcode]; since it will be assigned to ft object anyway FT2Font *throwaway NULL; ft object->load char charcode flags throwaway false ; } else if fallback { FT UInt final glyph index; FT Error charcode error glyph error; FT2Font *ft object with glyph this; bool was found load char with fallback ft object with glyph final glyph index glyphs char to font glyph to font charcode flags charcode error glyph error true ; if !was found { if charcode error { throw ft error \"Could not load charcode\" charcode error ; } else if glyph error { throw ft error \"Could not load charcode\" glyph error ; } } ft object ft object with glyph; } else { ft object this; FT UInt glyph index FT Get Char Index face FT ULong charcode ; if FT Error error FT Load Glyph face glyph index flags { throw ft error \"Could not load charcode\" error ; } FT Glyph thisGlyph; if FT Error error FT Get Glyph face->glyph &thisGlyph { throw ft error \"Could not get glyph\" error ; } glyphs push back thisGlyph ; } }"}
{"message": "At this point, shouldn't the deprecation warnings be eliminated?", "timestamp": "2023-10-18T10:30:46Z", "file_name": "lib/matplotlib/tests/test_contour.py", "range": {"start_line": 559, "end_line": 559, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1363638477", "html_url": "https://github.com/matplotlib/matplotlib/pull/27088#discussion_r1363638477", "attention_area": "    with pytest.warns(mpl._api.MatplotlibDeprecationWarning), \\", "file_path": "files/85/14/00001485.py", "old_file_path": "files/87/14/00001487.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -557,15 +557,15 @@ def test_find_nearest_contour_no_filled():\n     cs = plt.contourf(img, 10)\n \n     with pytest.warns(mpl._api.MatplotlibDeprecationWarning), \\", "source": "def test_find_nearest_contour_no_filled():\n    xy = np.indices((15, 15))\n    img = np.exp(-np.pi * (np.sum((xy - 5)**2, 0)/5.**2))\n    cs = plt.contourf(img, 10)\n\n    with pytest.warns(mpl._api.MatplotlibDeprecationWarning), \\\n         pytest.raises(ValueError, match=\"Method does not support filled contours\"):\n        cs.find_nearest_contour(1, 1, pixel=False)\n\n    with pytest.warns(mpl._api.MatplotlibDeprecationWarning), \\\n         pytest.raises(ValueError, match=\"Method does not support filled contours\"):\n        cs.find_nearest_contour(1, 10, indices=(5, 7), pixel=False)\n\n    with pytest.warns(mpl._api.MatplotlibDeprecationWarning), \\\n         pytest.raises(ValueError, match=\"Method does not support filled contours\"):\n        cs.find_nearest_contour(2, 5, indices=(2, 7), pixel=True)", "source_start_line": 554, "tokens": ["def", "test_find_nearest_contour_no_filled", "(", ")", ":", "xy", "=", "np", ".", "indices", "(", "(", "15", ",", "15", ")", ")", "img", "=", "np", ".", "exp", "(", "-", "np", ".", "pi", "*", "(", "np", ".", "sum", "(", "(", "xy", "-", "5", ")", "**", "2", ",", "0", ")", "/", "5.", "**", "2", ")", ")", "cs", "=", "plt", ".", "contourf", "(", "img", ",", "10", ")", "with", "pytest", ".", "warns", "(", "mpl", ".", "_api", ".", "MatplotlibDeprecationWarning", ")", ",", "pytest", ".", "raises", "(", "ValueError", ",", "match", "=", "\"Method does not support filled contours\"", ")", ":", "cs", ".", "find_nearest_contour", "(", "1", ",", "1", ",", "pixel", "=", "False", ")", "with", "pytest", ".", "warns", "(", "mpl", ".", "_api", ".", "MatplotlibDeprecationWarning", ")", ",", "pytest", ".", "raises", "(", "ValueError", ",", "match", "=", "\"Method does not support filled contours\"", ")", ":", "cs", ".", "find_nearest_contour", "(", "1", ",", "10", ",", "indices", "=", "(", "5", ",", "7", ")", ",", "pixel", "=", "False", ")", "with", "pytest", ".", "warns", "(", "mpl", ".", "_api", ".", "MatplotlibDeprecationWarning", ")", ",", "pytest", ".", "raises", "(", "ValueError", ",", "match", "=", "\"Method does not support filled contours\"", ")", ":", "cs", ".", "find_nearest_contour", "(", "2", ",", "5", ",", "indices", "=", "(", "2", ",", "7", ")", ",", "pixel", "=", "True", ")"], "to_mask": {"VAR": ["cs", "img", "xy"], "METHOD": ["contourf", "exp", "find_nearest_contour", "indices", "raises", "sum", "warns"]}, "attention_idx_tokens": [59, 70], "patch": "@@ -557,15 +557,15 @@\n     cs = plt.contourf(img, 10)\n \n     with pytest.warns(mpl._api.MatplotlibDeprecationWarning), \\\n-         pytest.raises(ValueError, match=\"Method does not support filled contours.\"):", "ext_attention_idx_tokens": [71, 179], "uid": "4a0d37d0", "question": "At this point, shouldn't the deprecation warnings be eliminated?", "code": "def test find nearest contour no filled xy np indices 15 15 img np exp -np pi * np sum xy - 5 **2 0 5 **2 cs plt contourf img 10 with pytest warns mpl api MatplotlibDeprecationWarning \\ pytest raises ValueError match \"Method does not support filled contours\" cs find nearest contour 1 1 pixel False with pytest warns mpl api MatplotlibDeprecationWarning \\ pytest raises ValueError match \"Method does not support filled contours\" cs find nearest contour 1 10 indices 5 7 pixel False with pytest warns mpl api MatplotlibDeprecationWarning \\ pytest raises ValueError match \"Method does not support filled contours\" cs find nearest contour 2 5 indices 2 7 pixel True"}
{"message": "Is this output portable across different system languages?", "timestamp": "2023-10-31T01:12:12Z", "file_name": "lib/matplotlib/font_manager.py", "range": {"start_line": 269, "end_line": 269, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1376946852", "html_url": "https://github.com/matplotlib/matplotlib/pull/27230#discussion_r1376946852", "attention_area": "        subprocess.check_output([\"system_profiler\", \"-xml\", \"SPFontsDataType\"]))", "file_path": "files/53/15/00001553.py", "old_file_path": "files/54/15/00001554.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -261,6 +262,14 @@ def _get_fontconfig_fonts():\n     return [Path(os.fsdecode(fname)) for fname in out.split(b'\\n')]\n \n \n+@lru_cache\n+def _get_macos_fonts():\n+    \"\"\"Cache and list the font paths known to ``system_profiler SPFontsDataType``.\"\"\"\n+    d, = plistlib.loads(\n+        subprocess.check_output([\"system_profiler\", \"-xml\", \"SPFontsDataType\"]))", "source": "def _get_macos_fonts():\n    \"\"\"Cache and list the font paths known to ``system_profiler SPFontsDataType``.\"\"\"\n    d, = plistlib.loads(\n        subprocess.check_output([\"system_profiler\", \"-xml\", \"SPFontsDataType\"]))\n    return [Path(entry[\"path\"]) for entry in d[\"_items\"]]", "source_start_line": 266, "tokens": ["def", "_get_macos_fonts", "(", ")", ":", "\"\"\"Cache and list the font paths known to ``system_profiler SPFontsDataType``.\"\"\"", "d", ",", "=", "plistlib", ".", "loads", "(", "subprocess", ".", "check_output", "(", "[", "\"system_profiler\"", ",", "\"-xml\"", ",", "\"SPFontsDataType\"", "]", ")", ")", "return", "[", "Path", "(", "entry", "[", "\"path\"", "]", ")", "for", "entry", "in", "d", "[", "\"_items\"", "]", "]"], "to_mask": {"VAR": ["d"], "METHOD": ["Path", "check_output", "loads"]}, "attention_idx_tokens": [13, 25], "patch": "@@ -261,6 +262,14 @@\n     return [Path(os.fsdecode(fname)) for fname in out.split(b'\\n')]\n \n \n+@lru_cache\n+def _get_macos_fonts():\n+    \"\"\"Cache and list the font paths known to ``system_profiler SPFontsDataType``.\"\"\"\n+    d, = plistlib.loads(\n+        subprocess.check_output([\"system_profiler\", \"-xml\", \"SPFontsDataType\"]))", "ext_attention_idx_tokens": [0, 42], "uid": "a0cb8b3f", "question": "Is this output portable across different system languages?", "code": "def get macos fonts \"\"\"Cache and list the font paths known to ``system profiler SPFontsDataType`` \"\"\" d plistlib loads subprocess check output [\"system profiler\" \"-xml\" \"SPFontsDataType\"] return [Path entry[\"path\"] for entry in d[\" items\"]]"}
{"message": "Can you walk through how this works?  Where did `_subplot_spec` come from and why is it defined on the parent gridspec?  ", "timestamp": "2023-11-22T16:05:30Z", "file_name": "lib/matplotlib/colorbar.py", "range": {"start_line": 1038, "end_line": 1038, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1402331630", "html_url": "https://github.com/matplotlib/matplotlib/pull/27360#discussion_r1402331630", "attention_area": "            subplotspec = self.ax.get_subplotspec().get_gridspec()._subplot_spec", "file_path": "files/35/16/00001635.py", "old_file_path": "files/36/16/00001636.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1035,14 +1035,11 @@ def remove(self):\n         except AttributeError:\n             return\n         try:\n-            gs = ax.get_subplotspec().get_gridspec()\n-            subplotspec = gs.get_topmost_subplotspec()\n-        except AttributeError:\n-            # use_gridspec was False\n+            subplotspec = self.ax.get_subplotspec().get_gridspec()._subplot_spec", "source": "def remove(self):\n        \"\"\"\n        Remove this colorbar from the figure.\n\n        If the colorbar was created with ``use_gridspec=True`` the previous\n        gridspec is restored.\n        \"\"\"\n        if hasattr(self.ax, '_colorbar_info'):\n            parents = self.ax._colorbar_info['parents']\n            for a in parents:\n                if self.ax in a._colorbars:\n                    a._colorbars.remove(self.ax)\n\n        self.ax.remove()\n\n        self.mappable.callbacks.disconnect(self.mappable.colorbar_cid)\n        self.mappable.colorbar = None\n        self.mappable.colorbar_cid = None\n        # Remove the extension callbacks\n        self.ax.callbacks.disconnect(self._extend_cid1)\n        self.ax.callbacks.disconnect(self._extend_cid2)\n\n        try:\n            ax = self.mappable.axes\n        except AttributeError:\n            return\n        try:\n            subplotspec = self.ax.get_subplotspec().get_gridspec()._subplot_spec\n        except AttributeError:  # use_gridspec was False\n            pos = ax.get_position(original=True)\n            ax._set_position(pos)\n        else:  # use_gridspec was True\n            ax.set_subplotspec(subplotspec)", "source_start_line": 1011, "tokens": ["def", "remove", "(", "self", ")", ":", "\"\"\"        Remove this colorbar from the figure.        If the colorbar was created with ``use_gridspec=True`` the previous        gridspec is restored.        \"\"\"", "if", "hasattr", "(", "self", ".", "ax", ",", "'_colorbar_info'", ")", ":", "parents", "=", "self", ".", "ax", ".", "_colorbar_info", "[", "'parents'", "]", "for", "a", "in", "parents", ":", "if", "self", ".", "ax", "in", "a", ".", "_colorbars", ":", "a", ".", "_colorbars", ".", "remove", "(", "self", ".", "ax", ")", "self", ".", "ax", ".", "remove", "(", ")", "self", ".", "mappable", ".", "callbacks", ".", "disconnect", "(", "self", ".", "mappable", ".", "colorbar_cid", ")", "self", ".", "mappable", ".", "colorbar", "=", "None", "self", ".", "mappable", ".", "colorbar_cid", "=", "None", "self", ".", "ax", ".", "callbacks", ".", "disconnect", "(", "self", ".", "_extend_cid1", ")", "self", ".", "ax", ".", "callbacks", ".", "disconnect", "(", "self", ".", "_extend_cid2", ")", "try", ":", "ax", "=", "self", ".", "mappable", ".", "axes", "except", "AttributeError", ":", "return", "try", ":", "subplotspec", "=", "self", ".", "ax", ".", "get_subplotspec", "(", ")", ".", "get_gridspec", "(", ")", ".", "_subplot_spec", "except", "AttributeError", ":", "pos", "=", "ax", ".", "get_position", "(", "original", "=", "True", ")", "ax", ".", "_set_position", "(", "pos", ")", "else", ":", "ax", ".", "set_subplotspec", "(", "subplotspec", ")"], "to_mask": {"VAR": ["a", "ax", "colorbar", "colorbar_cid", "parents", "pos", "self", "subplotspec"], "METHOD": ["_set_position", "disconnect", "get_gridspec", "get_position", "get_subplotspec", "hasattr", "remove", "set_subplotspec"]}, "attention_idx_tokens": [125, 139], "patch": "@@ -1035,14 +1035,11 @@\n         except AttributeError:\n             return\n         try:\n-            gs = ax.get_subplotspec().get_gridspec()\n-            subplotspec = gs.get_topmost_subplotspec()\n-        except AttributeError:\n-            # use_gridspec was False\n+            subplotspec = self.ax.get_subplotspec().get_gridspec()._subplot_spec", "ext_attention_idx_tokens": [125, 166], "uid": "8143e70e", "question": "Can you walk through how this works?  Where did `_subplot_spec` come from and why is it defined on the parent gridspec?  ", "code": "def remove self \"\"\" Remove this colorbar from the figure If the colorbar was created with ``use gridspec True`` the previous gridspec is restored \"\"\" if hasattr self ax colorbar info parents self ax colorbar info[ parents ] for a in parents if self ax in a colorbars a colorbars remove self ax self ax remove self mappable callbacks disconnect self mappable colorbar cid self mappable colorbar None self mappable colorbar cid None # Remove the extension callbacks self ax callbacks disconnect self extend cid1 self ax callbacks disconnect self extend cid2 try ax self mappable axes except AttributeError return try subplotspec self ax get subplotspec get gridspec subplot spec except AttributeError # use gridspec was False pos ax get position original True ax set position pos else # use gridspec was True ax set subplotspec subplotspec"}
{"message": "What are you trying to communicate w/ writable? ", "timestamp": "2023-11-30T15:22:05Z", "file_name": "lib/matplotlib/widgets.py", "range": {"start_line": 2698, "end_line": 2698, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1410834639", "html_url": "https://github.com/matplotlib/matplotlib/pull/27397#discussion_r1410834639", "attention_area": "        \"\"\"Direction of the span selector: 'vertical' or 'horizontal'. Writable.\"\"\"", "file_path": "files/47/16/00001647.py", "old_file_path": "files/43/16/00001643.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -2695,7 +2695,7 @@ def _press(self, event):\n \n     @property\n     def direction(self):\n-        \"\"\"Direction of the span selector: 'vertical' or 'horizontal'.\"\"\"\n+        \"\"\"Direction of the span selector: 'vertical' or 'horizontal'. Writable.\"\"\"", "source": "def direction(self):\n        \"\"\"Direction of the span selector: 'vertical' or 'horizontal'. Writable.\"\"\"\n        return self._direction", "source_start_line": 2697, "tokens": ["def", "direction", "(", "self", ")", ":", "\"\"\"Direction of the span selector: 'vertical' or 'horizontal'. Writable.\"\"\"", "return", "self", ".", "_direction"], "to_mask": {"VAR": ["self"], "METHOD": []}, "attention_idx_tokens": [6, 6], "patch": "@@ -2695,7 +2695,7 @@\n \n     @property\n     def direction(self):\n-        \"\"\"Direction of the span selector: 'vertical' or 'horizontal'.\"\"\"\n+        \"\"\"Direction of the span selector: 'vertical' or 'horizontal'. Writable.\"\"\"", "ext_attention_idx_tokens": [6, 10], "uid": "92b3721f", "question": "What are you trying to communicate w/ writable? ", "code": "def direction self \"\"\"Direction of the span selector vertical or horizontal Writable \"\"\" return self direction"}
{"message": "@judfs can you remove the writable? I don't think it's conveying what you intend to here and I don't want to hold up your PR longer ", "timestamp": "2023-12-05T19:09:43Z", "file_name": "lib/matplotlib/widgets.py", "range": {"start_line": 2698, "end_line": 2698, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1416164620", "html_url": "https://github.com/matplotlib/matplotlib/pull/27397#discussion_r1416164620", "attention_area": "        \"\"\"Direction of the span selector: 'vertical' or 'horizontal'. Writable.\"\"\"", "file_path": "files/47/16/00001647.py", "old_file_path": "files/81/16/00001681.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -2695,7 +2695,7 @@ def _press(self, event):\n \n     @property\n     def direction(self):\n-        \"\"\"Direction of the span selector: 'vertical' or 'horizontal'.\"\"\"\n+        \"\"\"Direction of the span selector: 'vertical' or 'horizontal'. Writable.\"\"\"", "source": "def direction(self):\n        \"\"\"Direction of the span selector: 'vertical' or 'horizontal'. Writable.\"\"\"\n        return self._direction", "source_start_line": 2697, "tokens": ["def", "direction", "(", "self", ")", ":", "\"\"\"Direction of the span selector: 'vertical' or 'horizontal'. Writable.\"\"\"", "return", "self", ".", "_direction"], "to_mask": {"VAR": ["self"], "METHOD": []}, "attention_idx_tokens": [6, 6], "patch": "@@ -2695,7 +2695,7 @@\n \n     @property\n     def direction(self):\n-        \"\"\"Direction of the span selector: 'vertical' or 'horizontal'.\"\"\"\n+        \"\"\"Direction of the span selector: 'vertical' or 'horizontal'. Writable.\"\"\"", "ext_attention_idx_tokens": [6, 10], "uid": "571cd685", "question": "@judfs can you remove the writable? I don't think it's conveying what you intend to here and I don't want to hold up your PR longer ", "code": "def direction self \"\"\"Direction of the span selector vertical or horizontal Writable \"\"\" return self direction"}
{"message": "Having a little bit of trouble following this - is there a more direct way of saying what this decorator does? \r\nMy reading is that the decorator stores documentation for the Artist property and the documentation stored on the decorator is what populates interpolated fields for that Artist?  ", "timestamp": "2023-12-21T02:52:46Z", "file_name": "lib/matplotlib/_docstring.py", "range": {"start_line": 9, "end_line": 9, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1433395050", "html_url": "https://github.com/matplotlib/matplotlib/pull/22699#discussion_r1433395050", "attention_area": "    passed through as keyword arguments.", "file_path": "files/36/17/00001736.py", "old_file_path": "files/37/17/00001737.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": true}, "language": "python", "replies": {}, "diff_hunk": "@@ -3,6 +3,31 @@\n from . import _api\n \n \n+def kwarg_doc(text):\n+    \"\"\"\n+    Decorator for defining the documentation used when artist properties are\n+    passed through as keyword arguments.", "source": "def kwarg_doc(text):\n    \"\"\"\n    Decorator for defining the documentation used when artist properties are\n    passed through as keyword arguments.\n\n    See e.g. the ``**kwargs`` section in `.Axes.text`.\n\n    The given text is stored in a privat variable ``_kwarg_doc`` on the method.\n    It is used for generating the kwdoc list for artists, which we\n    auto-generate through docstring interpolation, e.g. via\n    ``%(Line2D:kwdoc)s``.\n\n    The text should contain the supported types as well as the default value\n    if applicable, e.g.:\n\n        @_docstring.kwarg_doc(\"bool, default: :rc:`text.usetex`\")\n        def set_usetex(self, usetex):\n\n    \"\"\"\n    def decorator(func):\n        func._kwarg_doc = text\n        return func\n    return decorator", "source_start_line": 6, "tokens": ["def", "kwarg_doc", "(", "text", ")", ":", "\"\"\"    Decorator for defining the documentation used when artist properties are    passed through as keyword arguments.    See e.g. the ``**kwargs`` section in `.Axes.text`.    The given text is stored in a privat variable ``_kwarg_doc`` on the method.    It is used for generating the kwdoc list for artists, which we    auto-generate through docstring interpolation, e.g. via    ``%(Line2D:kwdoc)s``.    The text should contain the supported types as well as the default value    if applicable, e.g.:        @_docstring.kwarg_doc(\"bool, default: :rc:`text.usetex`\")        def set_usetex(self, usetex):    \"\"\"", "def", "decorator", "(", "func", ")", ":", "func", ".", "_kwarg_doc", "=", "text", "return", "func", "return", "decorator"], "to_mask": {"VAR": ["_kwarg_doc", "func", "text"], "METHOD": []}, "attention_idx_tokens": [null, null], "patch": "@@ -3,6 +3,31 @@\n from . import _api\n \n \n+def kwarg_doc(text):\n+    \"\"\"\n+    Decorator for defining the documentation used when artist properties are\n+    passed through as keyword arguments.", "ext_attention_idx_tokens": [0, 21], "uid": "eb649af3", "question": "Having a little bit of trouble following this - is there a more direct way of saying what this decorator does?   My reading is that the decorator stores documentation for the Artist property and the documentation stored on the decorator is what populates interpolated fields for that Artist?  ", "code": "def kwarg doc text \"\"\" Decorator for defining the documentation used when artist properties are passed through as keyword arguments See e g the ``**kwargs`` section in ` Axes text` The given text is stored in a privat variable `` kwarg doc`` on the method It is used for generating the kwdoc list for artists which we auto-generate through docstring interpolation e g via ``% Line2D kwdoc s`` The text should contain the supported types as well as the default value if applicable e g @ docstring kwarg doc \"bool default rc `text usetex`\" def set usetex self usetex \"\"\" def decorator func func kwarg doc text return func return decorator"}
{"message": "Is this comment from an earlier revision?  It says we allow, but then the code asserts an exception.", "timestamp": "2023-12-29T21:40:34Z", "file_name": "lib/matplotlib/tests/test_gridspec.py", "range": {"start_line": 47, "end_line": 47, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1438418164", "html_url": "https://github.com/matplotlib/matplotlib/pull/27565#discussion_r1438418164", "attention_area": "    # this is a mistake, and not what the type hints give, but we allow:", "file_path": "files/52/17/00001752.py", "old_file_path": "files/53/17/00001753.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -35,3 +36,16 @@ def test_repr():\n                            width_ratios=(1, 3))\n     assert repr(ss) == \\\n         \"GridSpec(2, 2, height_ratios=(3, 1), width_ratios=(1, 3))\"\n+\n+\n+def test_subplotspec_args():\n+    fig, axs = plt.subplots(1, 2)\n+    # should work:\n+    gs = gridspec.GridSpecFromSubplotSpec(2, 1,\n+                                          subplot_spec=axs[0].get_subplotspec())\n+    assert gs.get_topmost_subplotspec() == axs[0].get_subplotspec()\n+    # this is a mistake, and not what the type hints give, but we allow:", "source": "def test_subplotspec_args():\n    fig, axs = plt.subplots(1, 2)\n    # should work:\n    gs = gridspec.GridSpecFromSubplotSpec(2, 1,\n                                          subplot_spec=axs[0].get_subplotspec())\n    assert gs.get_topmost_subplotspec() == axs[0].get_subplotspec()\n    # this is a mistake, and not what the type hints give, but we allow:\n    with pytest.raises(TypeError, match=\"subplot_spec must be type SubplotSpec\"):\n        gs = gridspec.GridSpecFromSubplotSpec(2, 1, subplot_spec=axs[0])\n    with pytest.raises(TypeError, match=\"subplot_spec must be type SubplotSpec\"):\n        gs = gridspec.GridSpecFromSubplotSpec(2, 1, subplot_spec=axs)", "source_start_line": 41, "tokens": ["def", "test_subplotspec_args", "(", ")", ":", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "1", ",", "2", ")", "gs", "=", "gridspec", ".", "GridSpecFromSubplotSpec", "(", "2", ",", "1", ",", "subplot_spec", "=", "axs", "[", "0", "]", ".", "get_subplotspec", "(", ")", ")", "assert", "gs", ".", "get_topmost_subplotspec", "(", ")", "==", "axs", "[", "0", "]", ".", "get_subplotspec", "(", ")", "with", "pytest", ".", "raises", "(", "TypeError", ",", "match", "=", "\"subplot_spec must be type SubplotSpec\"", ")", ":", "gs", "=", "gridspec", ".", "GridSpecFromSubplotSpec", "(", "2", ",", "1", ",", "subplot_spec", "=", "axs", "[", "0", "]", ")", "with", "pytest", ".", "raises", "(", "TypeError", ",", "match", "=", "\"subplot_spec must be type SubplotSpec\"", ")", ":", "gs", "=", "gridspec", ".", "GridSpecFromSubplotSpec", "(", "2", ",", "1", ",", "subplot_spec", "=", "axs", ")"], "to_mask": {"VAR": ["axs", "fig", "gs"], "METHOD": ["GridSpecFromSubplotSpec", "get_subplotspec", "get_topmost_subplotspec", "raises", "subplots"]}, "attention_idx_tokens": [null, null], "patch": "@@ -35,3 +36,16 @@\n                            width_ratios=(1, 3))\n     assert repr(ss) == \\\n         \"GridSpec(2, 2, height_ratios=(3, 1), width_ratios=(1, 3))\"\n+\n+\n+def test_subplotspec_args():\n+    fig, axs = plt.subplots(1, 2)\n+    # should work:\n+    gs = gridspec.GridSpecFromSubplotSpec(2, 1,\n+                                          subplot_spec=axs[0].get_subplotspec())\n+    assert gs.get_topmost_subplotspec() == axs[0].get_subplotspec()\n+    # this is a mistake, and not what the type hints give, but we allow:", "ext_attention_idx_tokens": [0, 81], "uid": "50629cd0", "question": "Is this comment from an earlier revision?  It says we allow, but then the code asserts an exception.", "code": "def test subplotspec args fig axs plt subplots 1 2 # should work gs gridspec GridSpecFromSubplotSpec 2 1 subplot spec axs[0] get subplotspec assert gs get topmost subplotspec axs[0] get subplotspec # this is a mistake and not what the type hints give but we allow with pytest raises TypeError match \"subplot spec must be type SubplotSpec\" gs gridspec GridSpecFromSubplotSpec 2 1 subplot spec axs[0] with pytest raises TypeError match \"subplot spec must be type SubplotSpec\" gs gridspec GridSpecFromSubplotSpec 2 1 subplot spec axs"}
{"message": "1. Should this change be applied on main branch?\r\n2. why `= true`?", "timestamp": "2023-01-03T22:51:35Z", "file_name": "torch/csrc/onnx/init.cpp", "range": {"start_line": 137, "end_line": 137, "start_character": 0, "end_character": 0}, "project": "pytorch/pytorch", "api_url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/1061016614", "html_url": "https://github.com/pytorch/pytorch/pull/91596#discussion_r1061016614", "attention_area": "          py::arg(\"params_dict\") = true,", "file_path": "files/01/00/00000001.cpp", "old_file_path": "files/02/00/00000002.cpp", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -132,7 +132,10 @@ void initONNXBindings(PyObject* module) {\n                  std::map<std::string, IValue>& params_dict,\n                  int opset_version) {\n                 ONNXShapeTypeInference(graph, params_dict, opset_version);\n-              }))\n+              }),\n+          py::arg(\"graph\"),\n+          py::arg(\"params_dict\") = true,", "source": "void initONNXBindings(PyObject* module) {\n  auto m = py::handle(module).cast<py::module>();\n\n  // ONNX specific passes\n  m.def(\"_jit_pass_onnx_remove_print\", RemovePrintOps)\n      .def(\"_jit_pass_onnx_preprocess_caffe2\", PreprocessCaffe2Ops)\n      .def(\"_jit_pass_onnx\", ToONNX)\n      .def(\n          \"_jit_pass_onnx_assign_output_shape\",\n          ::torch::wrap_pybind_function(\n              [](std::shared_ptr<Graph>& graph,\n                 const std::vector<at::Tensor>& tensors,\n                 const python::IODescriptor& desc,\n                 bool onnx_shape_inference,\n                 bool is_script) {\n                ONNXAssignOutputShape(\n                    graph, tensors, desc, onnx_shape_inference, is_script);\n              }))\n      .def(\n          \"_jit_pass_onnx_function_substitution\",\n          wrap_pybind_function(ONNXFunctionCallSubstitution))\n      .def(\n          \"_jit_pass_onnx_autograd_function_process\",\n          wrap_pybind_function(ONNXAutogradFunctionProcess))\n      .def(\n          \"_jit_pass_onnx_peephole\",\n          ::torch::wrap_pybind_function([](std::shared_ptr<Graph>& graph,\n                                           int opset_version,\n                                           bool fixed_batch_size) {\n            return PeepholeOptimizeONNX(graph, opset_version, fixed_batch_size);\n          }))\n      .def(\n          \"_jit_pass_onnx_preprocess\",\n          ::torch::wrap_pybind_function(PreprocessForONNX))\n      .def(\n          \"_jit_pass_onnx_eval_peephole\",\n          ::torch::wrap_pybind_function(\n              [](std::shared_ptr<Graph>& graph,\n                 std::map<std::string, IValue>& paramsDict) {\n                EvalPeepholeONNX(graph, paramsDict);\n                return paramsDict;\n              }),\n          pybind11::return_value_policy::move)\n      .def(\n          \"_jit_pass_onnx_cast_all_constant_to_floating\",\n          ::torch::wrap_pybind_function(CastAllConstantToFloating))\n      .def(\n          \"_jit_pass_onnx_constant_fold\",\n          ::torch::wrap_pybind_function(\n              [](std::shared_ptr<Graph>& graph,\n                 std::map<std::string, IValue>& paramsDict,\n                 int opset_version) {\n                ConstantFoldONNX(\n                    graph,\n                    paramsDict,\n                    opset_version); // overload resolution\n                return paramsDict;\n              }),\n          pybind11::return_value_policy::move)\n      .def(\n          \"_jit_pass_onnx_eliminate_unused_items\",\n          ::torch::wrap_pybind_function(\n              [](std::shared_ptr<Graph>& graph,\n                 std::map<std::string, IValue>& paramsDict) {\n                EliminateUnusedItemsONNX(\n                    graph->block(),\n                    paramsDict); // overload resolution\n                return paramsDict;\n              }),\n          pybind11::return_value_policy::move)\n      .def(\n          \"_jit_pass_onnx_scalar_type_analysis\",\n          ::torch::wrap_pybind_function([](std::shared_ptr<Graph>& graph,\n                                           bool lowprecision_cast,\n                                           int opset_version) {\n            return ScalarTypeAnalysisForONNX(\n                graph, lowprecision_cast, opset_version);\n          }),\n          py::arg(\"graph\"),\n          py::arg(\"lowprecision_cast\") = true,\n          py::arg(\"opset_version\"))\n      .def(\n          \"_jit_pass_onnx_remove_inplace_ops_for_onnx\",\n          ::torch::wrap_pybind_function(RemoveInplaceOpsForONNX))\n      .def(\n          \"_jit_pass_onnx_node_shape_type_inference\",\n          ::torch::wrap_pybind_function(\n              [](Node* n,\n                 std::map<std::string, IValue>& params_dict,\n                 int opset_version) {\n                ONNXShapeTypeInference(n, params_dict, opset_version);\n              }))\n      .def(\n          \"_jit_pass_onnx_graph_shape_type_inference\",\n          ::torch::wrap_pybind_function(\n              [](std::shared_ptr<Graph>& graph,\n                 std::map<std::string, IValue>& params_dict,\n                 int opset_version) {\n                ONNXShapeTypeInference(graph, params_dict, opset_version);\n              }),\n          py::arg(\"graph\"),\n          py::arg(\"params_dict\") = true,\n          py::arg(\"opset_version\"))\n      .def(\n          \"_jit_pass_onnx_set_dynamic_input_shape\",\n          ::torch::wrap_pybind_function(ONNXSetDynamicInputShape))\n      .def(\"_jit_pass_onnx_lint\", torch::wrap_pybind_function(ONNXLintGraph))\n      .def(\n          \"_jit_pass_onnx_function_extraction\",\n          ::torch::wrap_pybind_function(\n              torch::jit::onnx::ONNXFunctionExtraction))\n      .def(\"_jit_pass_onnx_block\", torch::wrap_pybind_function(BlockToONNX))\n      .def(\n          \"_jit_pass_onnx_unpack_quantized_weights\",\n          ::torch::wrap_pybind_function(\n              [](std::shared_ptr<Graph>& graph,\n                 std::map<std::string, IValue>& paramsDict,\n                 bool caffe2) {\n                UnpackQuantizedWeights(graph, paramsDict, caffe2);\n                return paramsDict;\n              }),\n          pybind11::return_value_policy::move)\n      .def(\n          \"_jit_pass_onnx_quantization_insert_permutes\",\n          ::torch::wrap_pybind_function(\n              [](std::shared_ptr<Graph>& graph,\n                 std::map<std::string, IValue>& paramsDict) {\n                insertPermutes(graph, paramsDict);\n                return paramsDict;\n              }),\n          pybind11::return_value_policy::move)\n      .def(\n          \"_jit_onnx_list_model_parameters\",\n          ::torch::wrap_pybind_function(\n              [](Module& module) { return list_module_parameters(module); }))\n      .def(\n          \"_jit_pass_prepare_division_for_onnx\",\n          ::torch::wrap_pybind_function(PrepareDivisionForONNX))\n      .def(\n          \"_jit_onnx_convert_pattern_from_subblock\",\n          ::torch::wrap_pybind_function(ConvertPatternFromSubblock))\n      .def(\n          \"_jit_pass_fixup_onnx_controlflow_node\",\n          ::torch::wrap_pybind_function(FixupONNXControlflowNode))\n      .def(\n          \"_jit_pass_onnx_deduplicate_initializers\",\n          ::torch::wrap_pybind_function(\n              [](std::shared_ptr<Graph>& graph,\n                 std::map<std::string, IValue> params_dict,\n                 bool is_train) {\n                DeduplicateInitializers(graph, params_dict, is_train);\n                return params_dict;\n              }),\n          pybind11::return_value_policy::move)\n      .def(\n          \"_jit_pass_onnx_clear_scope_records\",\n          &torch::jit::onnx::ONNXClearScopeRecords)\n      .def(\n          \"_jit_pass_onnx_track_scope_attributes\",\n          &torch::jit::onnx::ONNXTrackScopeAttributes)\n      .def(\n          \"_jit_is_onnx_log_enabled\",\n          ::torch::jit::onnx::is_log_enabled,\n          \"Returns whether ONNX logging is enabled or disabled.\")\n      .def(\n          \"_jit_set_onnx_log_enabled\",\n          ::torch::jit::onnx::set_log_enabled,\n          \"Enables or disables ONNX logging.\")\n      .def(\n          \"_jit_set_onnx_log_output_stream\",\n          [](std::string stream_name = \"stdout\") -> void {\n            std::shared_ptr<std::ostream> out;\n            if (stream_name == \"stdout\") {\n              out = std::shared_ptr<std::ostream>(\n                  &std::cout, [](std::ostream*) {});\n            } else if (stream_name == \"stderr\") {\n              out = std::shared_ptr<std::ostream>(\n                  &std::cerr, [](std::ostream*) {});\n            } else {\n              std::cerr << \"ERROR: only `stdout` and `stderr`\"\n                        << \"are supported as `stream_name`\" << std::endl;\n            }\n            ::torch::jit::onnx::set_log_output_stream(out);\n          },\n          \"Set specific file stream for ONNX logging.\")\n      .def(\n          \"_jit_onnx_log\",\n          [](py::args args) -> void {\n            if (::torch::jit::onnx::is_log_enabled()) {\n              auto& out = ::torch::jit::onnx::_get_log_output_stream();\n              for (auto arg : args) {\n                out << ::c10::str(arg);\n              }\n              out << std::endl;\n            }\n          },\n          \"Write `args` to the previously specified ONNX log stream.\")\n      .def(\n          \"_jit_pass_onnx_assign_scoped_names_for_node_and_value\",\n          ::torch::wrap_pybind_function(\n              ::torch::jit::onnx::AssignScopedNamesForNodeAndValue),\n          \"Assign informative scoped names for nodes and values.\")\n      .def(\n          \"_jit_onnx_create_full_scope_name\",\n          ::torch::wrap_pybind_function(\n              ::torch::jit::onnx::ONNXScopeName::createFullScopeName),\n          \"Create a full scope name from class name and variable name.\");\n\n  m.def(\n      \"_check_onnx_proto\",\n      [](const std::string& proto_string, bool full_check) {\n        check_onnx_proto(proto_string, full_check);\n      },\n      py::arg(\"proto_string\"),\n      py::arg(\"full_check\") = false);\n\n  auto onnx = m.def_submodule(\"_onnx\");\n  py::enum_<::ONNX_NAMESPACE::TensorProto_DataType>(onnx, \"TensorProtoDataType\")\n      .value(\"UNDEFINED\", ::ONNX_NAMESPACE::TensorProto_DataType_UNDEFINED)\n      .value(\"FLOAT\", ::ONNX_NAMESPACE::TensorProto_DataType_FLOAT)\n      .value(\"UINT8\", ::ONNX_NAMESPACE::TensorProto_DataType_UINT8)\n      .value(\"INT8\", ::ONNX_NAMESPACE::TensorProto_DataType_INT8)\n      .value(\"UINT16\", ::ONNX_NAMESPACE::TensorProto_DataType_UINT16)\n      .value(\"INT16\", ::ONNX_NAMESPACE::TensorProto_DataType_INT16)\n      .value(\"INT32\", ::ONNX_NAMESPACE::TensorProto_DataType_INT32)\n      .value(\"INT64\", ::ONNX_NAMESPACE::TensorProto_DataType_INT64)\n      .value(\"STRING\", ::ONNX_NAMESPACE::TensorProto_DataType_STRING)\n      .value(\"BOOL\", ::ONNX_NAMESPACE::TensorProto_DataType_BOOL)\n      .value(\"FLOAT16\", ::ONNX_NAMESPACE::TensorProto_DataType_FLOAT16)\n      .value(\"DOUBLE\", ::ONNX_NAMESPACE::TensorProto_DataType_DOUBLE)\n      .value(\"UINT32\", ::ONNX_NAMESPACE::TensorProto_DataType_UINT32)\n      .value(\"UINT64\", ::ONNX_NAMESPACE::TensorProto_DataType_UINT64)\n      .value(\"COMPLEX64\", ::ONNX_NAMESPACE::TensorProto_DataType_COMPLEX64)\n      .value(\"COMPLEX128\", ::ONNX_NAMESPACE::TensorProto_DataType_COMPLEX128)\n      .value(\"BFLOAT16\", ::ONNX_NAMESPACE::TensorProto_DataType_BFLOAT16);\n\n  py::enum_<OperatorExportTypes>(onnx, \"OperatorExportTypes\")\n      .value(\"ONNX\", OperatorExportTypes::ONNX)\n      .value(\"ONNX_ATEN\", OperatorExportTypes::ONNX_ATEN)\n      .value(\"ONNX_ATEN_FALLBACK\", OperatorExportTypes::ONNX_ATEN_FALLBACK)\n      .value(\"ONNX_FALLTHROUGH\", OperatorExportTypes::ONNX_FALLTHROUGH);\n\n  py::enum_<TrainingMode>(onnx, \"TrainingMode\")\n      .value(\"EVAL\", TrainingMode::EVAL)\n      .value(\"PRESERVE\", TrainingMode::PRESERVE)\n      .value(\"TRAINING\", TrainingMode::TRAINING);\n\n  onnx.attr(\"PRODUCER_VERSION\") = py::str(TORCH_VERSION);\n\n#ifdef BUILD_CAFFE2\n  onnx.attr(\"_CAFFE2_ATEN_FALLBACK\") = true;\n#else\n  onnx.attr(\"_CAFFE2_ATEN_FALLBACK\") = false;\n#endif\n}", "source_start_line": 36, "tokens": ["void", "initONNXBindings", "(", "PyObject", "*", "module", ")", "{", "auto", "m", "=", "py", "::", "handle", "(", "module", ")", ".", "cast", "<", "py", "::", "module", ">", "(", ")", ";", "m", ".", "def", "(", "\"", "\"", ",", "RemovePrintOps", ")", ".", "def", "(", "\"", "\"", ",", "PreprocessCaffe2Ops", ")", ".", "def", "(", "\"", "\"", ",", "ToONNX", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "[", "]", "(", "std", "::", "shared_ptr", "<", "Graph", ">", "&", "graph", ",", "const", "std", "::", "vector", "<", "at", "::", "Tensor", ">", "&", "tensors", ",", "const", "python", "::", "IODescriptor", "&", "desc", ",", "bool", "onnx_shape_inference", ",", "bool", "is_script", ")", "{", "ONNXAssignOutputShape", "(", "graph", ",", "tensors", ",", "desc", ",", "onnx_shape_inference", ",", "is_script", ")", ";", "}", ")", ")", ".", "def", "(", "\"", "\"", ",", "wrap_pybind_function", "(", "ONNXFunctionCallSubstitution", ")", ")", ".", "def", "(", "\"", "\"", ",", "wrap_pybind_function", "(", "ONNXAutogradFunctionProcess", ")", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "[", "]", "(", "std", "::", "shared_ptr", "<", "Graph", ">", "&", "graph", ",", "int", "opset_version", ",", "bool", "fixed_batch_size", ")", "{", "return", "PeepholeOptimizeONNX", "(", "graph", ",", "opset_version", ",", "fixed_batch_size", ")", ";", "}", ")", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "PreprocessForONNX", ")", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "[", "]", "(", "std", "::", "shared_ptr", "<", "Graph", ">", "&", "graph", ",", "std", "::", "map", "<", "std", "::", "string", ",", "IValue", ">", "&", "paramsDict", ")", "{", "EvalPeepholeONNX", "(", "graph", ",", "paramsDict", ")", ";", "return", "paramsDict", ";", "}", ")", ",", "pybind11", "::", "return_value_policy", "::", "move", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "CastAllConstantToFloating", ")", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "[", "]", "(", "std", "::", "shared_ptr", "<", "Graph", ">", "&", "graph", ",", "std", "::", "map", "<", "std", "::", "string", ",", "IValue", ">", "&", "paramsDict", ",", "int", "opset_version", ")", "{", "ConstantFoldONNX", "(", "graph", ",", "paramsDict", ",", "opset_version", ")", ";", "return", "paramsDict", ";", "}", ")", ",", "pybind11", "::", "return_value_policy", "::", "move", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "[", "]", "(", "std", "::", "shared_ptr", "<", "Graph", ">", "&", "graph", ",", "std", "::", "map", "<", "std", "::", "string", ",", "IValue", ">", "&", "paramsDict", ")", "{", "EliminateUnusedItemsONNX", "(", "graph", "->", "block", "(", ")", ",", "paramsDict", ")", ";", "return", "paramsDict", ";", "}", ")", ",", "pybind11", "::", "return_value_policy", "::", "move", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "[", "]", "(", "std", "::", "shared_ptr", "<", "Graph", ">", "&", "graph", ",", "bool", "lowprecision_cast", ",", "int", "opset_version", ")", "{", "return", "ScalarTypeAnalysisForONNX", "(", "graph", ",", "lowprecision_cast", ",", "opset_version", ")", ";", "}", ")", ",", "py", "::", "arg", "(", "\"", "\"", ")", ",", "py", "::", "arg", "(", "\"", "\"", ")", "=", "true", ",", "py", "::", "arg", "(", "\"", "\"", ")", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "RemoveInplaceOpsForONNX", ")", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "[", "]", "(", "Node", "*", "n", ",", "std", "::", "map", "<", "std", "::", "string", ",", "IValue", ">", "&", "params_dict", ",", "int", "opset_version", ")", "{", "ONNXShapeTypeInference", "(", "n", ",", "params_dict", ",", "opset_version", ")", ";", "}", ")", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "[", "]", "(", "std", "::", "shared_ptr", "<", "Graph", ">", "&", "graph", ",", "std", "::", "map", "<", "std", "::", "string", ",", "IValue", ">", "&", "params_dict", ",", "int", "opset_version", ")", "{", "ONNXShapeTypeInference", "(", "graph", ",", "params_dict", ",", "opset_version", ")", ";", "}", ")", ",", "py", "::", "arg", "(", "\"", "\"", ")", ",", "py", "::", "arg", "(", "\"", "\"", ")", "=", "true", ",", "py", "::", "arg", "(", "\"", "\"", ")", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "ONNXSetDynamicInputShape", ")", ")", ".", "def", "(", "\"", "\"", ",", "torch", "::", "wrap_pybind_function", "(", "ONNXLintGraph", ")", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "torch", "::", "jit", "::", "onnx", "::", "ONNXFunctionExtraction", ")", ")", ".", "def", "(", "\"", "\"", ",", "torch", "::", "wrap_pybind_function", "(", "BlockToONNX", ")", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "[", "]", "(", "std", "::", "shared_ptr", "<", "Graph", ">", "&", "graph", ",", "std", "::", "map", "<", "std", "::", "string", ",", "IValue", ">", "&", "paramsDict", ",", "bool", "caffe2", ")", "{", "UnpackQuantizedWeights", "(", "graph", ",", "paramsDict", ",", "caffe2", ")", ";", "return", "paramsDict", ";", "}", ")", ",", "pybind11", "::", "return_value_policy", "::", "move", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "[", "]", "(", "std", "::", "shared_ptr", "<", "Graph", ">", "&", "graph", ",", "std", "::", "map", "<", "std", "::", "string", ",", "IValue", ">", "&", "paramsDict", ")", "{", "insertPermutes", "(", "graph", ",", "paramsDict", ")", ";", "return", "paramsDict", ";", "}", ")", ",", "pybind11", "::", "return_value_policy", "::", "move", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "[", "]", "(", "Module", "&", "module", ")", "{", "return", "list_module_parameters", "(", "module", ")", ";", "}", ")", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "PrepareDivisionForONNX", ")", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "ConvertPatternFromSubblock", ")", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "FixupONNXControlflowNode", ")", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "[", "]", "(", "std", "::", "shared_ptr", "<", "Graph", ">", "&", "graph", ",", "std", "::", "map", "<", "std", "::", "string", ",", "IValue", ">", "params_dict", ",", "bool", "is_train", ")", "{", "DeduplicateInitializers", "(", "graph", ",", "params_dict", ",", "is_train", ")", ";", "return", "params_dict", ";", "}", ")", ",", "pybind11", "::", "return_value_policy", "::", "move", ")", ".", "def", "(", "\"", "\"", ",", "&", "torch", "::", "jit", "::", "onnx", "::", "ONNXClearScopeRecords", ")", ".", "def", "(", "\"", "\"", ",", "&", "torch", "::", "jit", "::", "onnx", "::", "ONNXTrackScopeAttributes", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "jit", "::", "onnx", "::", "is_log_enabled", ",", "\"", "\"", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "jit", "::", "onnx", "::", "set_log_enabled", ",", "\"", "\"", ")", ".", "def", "(", "\"", "\"", ",", "[", "]", "(", "std", "::", "string", "stream_name", "=", "\"", "\"", ")", "->", "void", "{", "std", "::", "shared_ptr", "<", "std", "::", "ostream", ">", "out", ";", "if", "(", "stream_name", "==", "\"", "\"", ")", "{", "out", "=", "std", "::", "shared_ptr", "<", "std", "::", "ostream", ">", "(", "&", "std", "::", "cout", ",", "[", "]", "(", "std", "::", "ostream", "*", ")", "{", "}", ")", ";", "}", "else", "if", "(", "stream_name", "==", "\"", "\"", ")", "{", "out", "=", "std", "::", "shared_ptr", "<", "std", "::", "ostream", ">", "(", "&", "std", "::", "cerr", ",", "[", "]", "(", "std", "::", "ostream", "*", ")", "{", "}", ")", ";", "}", "else", "{", "std", "::", "cerr", "<<", "\"", "\"", "<<", "\"", "\"", "<<", "std", "::", "endl", ";", "}", "::", "torch", "::", "jit", "::", "onnx", "::", "set_log_output_stream", "(", "out", ")", ";", "}", ",", "\"", "\"", ")", ".", "def", "(", "\"", "\"", ",", "[", "]", "(", "py", "::", "args", "args", ")", "->", "void", "{", "if", "(", "::", "torch", "::", "jit", "::", "onnx", "::", "is_log_enabled", "(", ")", ")", "{", "auto", "&", "out", "=", "::", "torch", "::", "jit", "::", "onnx", "::", "_get_log_output_stream", "(", ")", ";", "for", "(", "auto", "arg", ":", "args", ")", "{", "out", "<<", "::", "c10", "::", "str", "(", "arg", ")", ";", "}", "out", "<<", "std", "::", "endl", ";", "}", "}", ",", "\"", "\"", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "::", "torch", "::", "jit", "::", "onnx", "::", "AssignScopedNamesForNodeAndValue", ")", ",", "\"", "\"", ")", ".", "def", "(", "\"", "\"", ",", "::", "torch", "::", "wrap_pybind_function", "(", "::", "torch", "::", "jit", "::", "onnx", "::", "ONNXScopeName", "::", "createFullScopeName", ")", ",", "\"", "\"", ")", ";", "m", ".", "def", "(", "\"", "\"", ",", "[", "]", "(", "const", "std", "::", "string", "&", "proto_string", ",", "bool", "full_check", ")", "{", "check_onnx_proto", "(", "proto_string", ",", "full_check", ")", ";", "}", ",", "py", "::", "arg", "(", "\"", "\"", ")", ",", "py", "::", "arg", "(", "\"", "\"", ")", "=", "false", ")", ";", "auto", "onnx", "=", "m", ".", "def_submodule", "(", "\"", "\"", ")", ";", "py", "::", "enum_", "<", "::", "ONNX_NAMESPACE", "::", "TensorProto_DataType", ">", "(", "onnx", ",", "\"", "\"", ")", ".", "value", "(", "\"", "\"", ",", "::", "ONNX_NAMESPACE", "::", "TensorProto_DataType_UNDEFINED", ")", ".", "value", "(", "\"", "\"", ",", "::", "ONNX_NAMESPACE", "::", "TensorProto_DataType_FLOAT", ")", ".", "value", "(", "\"", "\"", ",", "::", "ONNX_NAMESPACE", "::", "TensorProto_DataType_UINT8", ")", ".", "value", "(", "\"", "\"", ",", "::", "ONNX_NAMESPACE", "::", "TensorProto_DataType_INT8", ")", ".", "value", "(", "\"", "\"", ",", "::", "ONNX_NAMESPACE", "::", "TensorProto_DataType_UINT16", ")", ".", "value", "(", "\"", "\"", ",", "::", "ONNX_NAMESPACE", "::", "TensorProto_DataType_INT16", ")", ".", "value", "(", "\"", "\"", ",", "::", "ONNX_NAMESPACE", "::", "TensorProto_DataType_INT32", ")", ".", "value", "(", "\"", "\"", ",", "::", "ONNX_NAMESPACE", "::", "TensorProto_DataType_INT64", ")", ".", "value", "(", "\"", "\"", ",", "::", "ONNX_NAMESPACE", "::", "TensorProto_DataType_STRING", ")", ".", "value", "(", "\"", "\"", ",", "::", "ONNX_NAMESPACE", "::", "TensorProto_DataType_BOOL", ")", ".", "value", "(", "\"", "\"", ",", "::", "ONNX_NAMESPACE", "::", "TensorProto_DataType_FLOAT16", ")", ".", "value", "(", "\"", "\"", ",", "::", "ONNX_NAMESPACE", "::", "TensorProto_DataType_DOUBLE", ")", ".", "value", "(", "\"", "\"", ",", "::", "ONNX_NAMESPACE", "::", "TensorProto_DataType_UINT32", ")", ".", "value", "(", "\"", "\"", ",", "::", "ONNX_NAMESPACE", "::", "TensorProto_DataType_UINT64", ")", ".", "value", "(", "\"", "\"", ",", "::", "ONNX_NAMESPACE", "::", "TensorProto_DataType_COMPLEX64", ")", ".", "value", "(", "\"", "\"", ",", "::", "ONNX_NAMESPACE", "::", "TensorProto_DataType_COMPLEX128", ")", ".", "value", "(", "\"", "\"", ",", "::", "ONNX_NAMESPACE", "::", "TensorProto_DataType_BFLOAT16", ")", ";", "py", "::", "enum_", "<", "OperatorExportTypes", ">", "(", "onnx", ",", "\"", "\"", ")", ".", "value", "(", "\"", "\"", ",", "OperatorExportTypes", "::", "ONNX", ")", ".", "value", "(", "\"", "\"", ",", "OperatorExportTypes", "::", "ONNX_ATEN", ")", ".", "value", "(", "\"", "\"", ",", "OperatorExportTypes", "::", "ONNX_ATEN_FALLBACK", ")", ".", "value", "(", "\"", "\"", ",", "OperatorExportTypes", "::", "ONNX_FALLTHROUGH", ")", ";", "py", "::", "enum_", "<", "TrainingMode", ">", "(", "onnx", ",", "\"", "\"", ")", ".", "value", "(", "\"", "\"", ",", "TrainingMode", "::", "EVAL", ")", ".", "value", "(", "\"", "\"", ",", "TrainingMode", "::", "PRESERVE", ")", ".", "value", "(", "\"", "\"", ",", "TrainingMode", "::", "TRAINING", ")", ";", "onnx", ".", "attr", "(", "\"", "\"", ")", "=", "py", "::", "str", "(", "TORCH_VERSION", ")", ";", "#ifdef", "BUILD_CAFFE2", "onnx", ".", "attr", "(", "\"", "\"", ")", "=", "true", ";", "#else", "onnx", ".", "attr", "(", "\"", "\"", ")", "=", "false", ";", "#endif", "}"], "to_mask": {}, "attention_idx_tokens": [577, 586], "patch": "@@ -132,7 +132,10 @@\n                  std::map<std::string, IValue>& params_dict,\n                  int opset_version) {\n                 ONNXShapeTypeInference(graph, params_dict, opset_version);\n-              }))\n+              }),\n+          py::arg(\"graph\"),\n+          py::arg(\"params_dict\") = true,", "ext_attention_idx_tokens": [566, 597], "uid": "1b36ceea", "question": "1. Should this change be applied on main branch?  2. why `= true`?", "code": "void initONNXBindings PyObject* module { auto m py handle module cast<py module> ; ONNX specific passes m def \" jit pass onnx remove print\" RemovePrintOps def \" jit pass onnx preprocess caffe2\" PreprocessCaffe2Ops def \" jit pass onnx\" ToONNX def \" jit pass onnx assign output shape\" torch wrap pybind function [] std shared ptr<Graph>& graph const std vector<at Tensor>& tensors const python IODescriptor& desc bool onnx shape inference bool is script { ONNXAssignOutputShape graph tensors desc onnx shape inference is script ; } def \" jit pass onnx function substitution\" wrap pybind function ONNXFunctionCallSubstitution def \" jit pass onnx autograd function process\" wrap pybind function ONNXAutogradFunctionProcess def \" jit pass onnx peephole\" torch wrap pybind function [] std shared ptr<Graph>& graph int opset version bool fixed batch size { return PeepholeOptimizeONNX graph opset version fixed batch size ; } def \" jit pass onnx preprocess\" torch wrap pybind function PreprocessForONNX def \" jit pass onnx eval peephole\" torch wrap pybind function [] std shared ptr<Graph>& graph std map<std string IValue>& paramsDict { EvalPeepholeONNX graph paramsDict ; return paramsDict; } pybind11 return value policy move def \" jit pass onnx cast all constant to floating\" torch wrap pybind function CastAllConstantToFloating def \" jit pass onnx constant fold\" torch wrap pybind function [] std shared ptr<Graph>& graph std map<std string IValue>& paramsDict int opset version { ConstantFoldONNX graph paramsDict opset version ; overload resolution return paramsDict; } pybind11 return value policy move def \" jit pass onnx eliminate unused items\" torch wrap pybind function [] std shared ptr<Graph>& graph std map<std string IValue>& paramsDict { EliminateUnusedItemsONNX graph->block paramsDict ; overload resolution return paramsDict; } pybind11 return value policy move def \" jit pass onnx scalar type analysis\" torch wrap pybind function [] std shared ptr<Graph>& graph bool lowprecision cast int opset version { return ScalarTypeAnalysisForONNX graph lowprecision cast opset version ; } py arg \"graph\" py arg \"lowprecision cast\" true py arg \"opset version\" def \" jit pass onnx remove inplace ops for onnx\" torch wrap pybind function RemoveInplaceOpsForONNX def \" jit pass onnx node shape type inference\" torch wrap pybind function [] Node* n std map<std string IValue>& params dict int opset version { ONNXShapeTypeInference n params dict opset version ; } def \" jit pass onnx graph shape type inference\" torch wrap pybind function [] std shared ptr<Graph>& graph std map<std string IValue>& params dict int opset version { ONNXShapeTypeInference graph params dict opset version ; } py arg \"graph\" py arg \"params dict\" true py arg \"opset version\" def \" jit pass onnx set dynamic input shape\" torch wrap pybind function ONNXSetDynamicInputShape def \" jit pass onnx lint\" torch wrap pybind function ONNXLintGraph def \" jit pass onnx function extraction\" torch wrap pybind function torch jit onnx ONNXFunctionExtraction def \" jit pass onnx block\" torch wrap pybind function BlockToONNX def \" jit pass onnx unpack quantized weights\" torch wrap pybind function [] std shared ptr<Graph>& graph std map<std string IValue>& paramsDict bool caffe2 { UnpackQuantizedWeights graph paramsDict caffe2 ; return paramsDict; } pybind11 return value policy move def \" jit pass onnx quantization insert permutes\" torch wrap pybind function [] std shared ptr<Graph>& graph std map<std string IValue>& paramsDict { insertPermutes graph paramsDict ; return paramsDict; } pybind11 return value policy move def \" jit onnx list model parameters\" torch wrap pybind function [] Module& module { return list module parameters module ; } def \" jit pass prepare division for onnx\" torch wrap pybind function PrepareDivisionForONNX def \" jit onnx convert pattern from subblock\" torch wrap pybind function ConvertPatternFromSubblock def \" jit pass fixup onnx controlflow node\" torch wrap pybind function FixupONNXControlflowNode def \" jit pass onnx deduplicate initializers\" torch wrap pybind function [] std shared ptr<Graph>& graph std map<std string IValue> params dict bool is train { DeduplicateInitializers graph params dict is train ; return params dict; } pybind11 return value policy move def \" jit pass onnx clear scope records\" &torch jit onnx ONNXClearScopeRecords def \" jit pass onnx track scope attributes\" &torch jit onnx ONNXTrackScopeAttributes def \" jit is onnx log enabled\" torch jit onnx is log enabled \"Returns whether ONNX logging is enabled or disabled \" def \" jit set onnx log enabled\" torch jit onnx set log enabled \"Enables or disables ONNX logging \" def \" jit set onnx log output stream\" [] std string stream name \"stdout\" -> void { std shared ptr<std ostream> out; if stream name \"stdout\" { out std shared ptr<std ostream> &std cout [] std ostream* {} ; } else if stream name \"stderr\" { out std shared ptr<std ostream> &std cerr [] std ostream* {} ; } else { std cerr << \"ERROR only `stdout` and `stderr`\" << \"are supported as `stream name`\" << std endl; } torch jit onnx set log output stream out ; } \"Set specific file stream for ONNX logging \" def \" jit onnx log\" [] py args args -> void { if torch jit onnx is log enabled { auto& out torch jit onnx get log output stream ; for auto arg args { out << c10 str arg ; } out << std endl; } } \"Write `args` to the previously specified ONNX log stream \" def \" jit pass onnx assign scoped names for node and value\" torch wrap pybind function torch jit onnx AssignScopedNamesForNodeAndValue \"Assign informative scoped names for nodes and values \" def \" jit onnx create full scope name\" torch wrap pybind function torch jit onnx ONNXScopeName createFullScopeName \"Create a full scope name from class name and variable name \" ; m def \" check onnx proto\" [] const std string& proto string bool full check { check onnx proto proto string full check ; } py arg \"proto string\" py arg \"full check\" false ; auto onnx m def submodule \" onnx\" ; py enum < ONNX NAMESPACE TensorProto DataType> onnx \"TensorProtoDataType\" value \"UNDEFINED\" ONNX NAMESPACE TensorProto DataType UNDEFINED value \"FLOAT\" ONNX NAMESPACE TensorProto DataType FLOAT value \"UINT8\" ONNX NAMESPACE TensorProto DataType UINT8 value \"INT8\" ONNX NAMESPACE TensorProto DataType INT8 value \"UINT16\" ONNX NAMESPACE TensorProto DataType UINT16 value \"INT16\" ONNX NAMESPACE TensorProto DataType INT16 value \"INT32\" ONNX NAMESPACE TensorProto DataType INT32 value \"INT64\" ONNX NAMESPACE TensorProto DataType INT64 value \"STRING\" ONNX NAMESPACE TensorProto DataType STRING value \"BOOL\" ONNX NAMESPACE TensorProto DataType BOOL value \"FLOAT16\" ONNX NAMESPACE TensorProto DataType FLOAT16 value \"DOUBLE\" ONNX NAMESPACE TensorProto DataType DOUBLE value \"UINT32\" ONNX NAMESPACE TensorProto DataType UINT32 value \"UINT64\" ONNX NAMESPACE TensorProto DataType UINT64 value \"COMPLEX64\" ONNX NAMESPACE TensorProto DataType COMPLEX64 value \"COMPLEX128\" ONNX NAMESPACE TensorProto DataType COMPLEX128 value \"BFLOAT16\" ONNX NAMESPACE TensorProto DataType BFLOAT16 ; py enum <OperatorExportTypes> onnx \"OperatorExportTypes\" value \"ONNX\" OperatorExportTypes ONNX value \"ONNX ATEN\" OperatorExportTypes ONNX ATEN value \"ONNX ATEN FALLBACK\" OperatorExportTypes ONNX ATEN FALLBACK value \"ONNX FALLTHROUGH\" OperatorExportTypes ONNX FALLTHROUGH ; py enum <TrainingMode> onnx \"TrainingMode\" value \"EVAL\" TrainingMode EVAL value \"PRESERVE\" TrainingMode PRESERVE value \"TRAINING\" TrainingMode TRAINING ; onnx attr \"PRODUCER VERSION\" py str TORCH VERSION ; #ifdef BUILD CAFFE2 onnx attr \" CAFFE2 ATEN FALLBACK\" true; #else onnx attr \" CAFFE2 ATEN FALLBACK\" false; #endif }"}
{"message": "out of scope for this PR, but I'd love to hear your opinion on this. Which would you prefer?\r\n\r\n* optional, default to some default (same behavior as current exporter)\r\n* optional, default to latest\r\n* required\r\n* specified via a separate 'config.py' file (what dynamo and inductor does)\r\n* not configurable", "timestamp": "2023-01-19T17:58:08Z", "file_name": "torch/onnx/_internal/fx/export.py", "range": {"start_line": 473, "end_line": 473, "start_character": 0, "end_character": 0}, "project": "pytorch/pytorch", "api_url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/1081629521", "html_url": "https://github.com/pytorch/pytorch/pull/92366#discussion_r1081629521", "attention_area": "    opset_version,", "file_path": "files/14/00/00000014.py", "old_file_path": "files/15/00/00000015.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -470,6 +470,7 @@ def export(\n \n def export_without_kwargs(\n     fn: Union[torch.nn.Module, Callable],\n+    opset_version,", "source": "def export_without_kwargs(\n    fn: Union[torch.nn.Module, Callable],\n    opset_version,\n    *args,\n    use_binary_format: bool = True,\n    **kwargs,\n):\n    if isinstance(fn, torch.nn.Module):\n        signature = inspect.signature(fn.forward)\n    else:\n        signature = inspect.signature(fn)\n\n    # We hope the input kwargs will be mapped to bound.args after binding.\n    # If not, we will raise an error.\n    bound = signature.bind(*args, **kwargs)\n    bound.apply_defaults()\n    # kwargs are not handled.\n    assert not bound.kwargs\n\n    class Wrapper(torch.nn.Module):\n        def __init__(self, fn):\n            super().__init__()\n            self.fn = fn\n\n        def forward(self, *args):\n            result, _ = _pytree.tree_flatten(self.fn(*args))\n            return result\n\n    # args will be converted to symbolic tensor. Let's copy to avoid side effects.\n    bound_args = copy.deepcopy(bound.args)\n    # Translate callable to FX graph.\n    #\n    # TODO(wechi): There are several symbolic tracing mechanisms to convert\n    # nn.Module to FX graph. We should choose the right one after they are\n    # matured.\n\n    class GraphCaptureCompiler:\n        def __init__(self):\n            self.captured_graph: Optional[torch.fx.GraphModule] = None\n            self.captured_graph_count = 0\n\n        def compile(self, gm: torch.fx.GraphModule, _):\n            assert self.captured_graph_count == 0\n            self.captured_graph = gm\n            self.captured_graph_count += 1\n            return gm\n\n    compiler = GraphCaptureCompiler()\n    torch._dynamo.optimize(compiler.compile, nopython=True)(Wrapper(fn))(*bound_args)\n    torch._dynamo.reset()\n    assert compiler.captured_graph\n    # Export FX graph to ONNX ModelProto.\n    return _export(\n        compiler.captured_graph,\n        opset_version,\n        # Function optimized by _dynamo doesn't have None in args.\n        *tuple(arg for arg in bound_args if arg is not None),\n        decomposition_table=_ONNX_FRIENDLY_DECOMPOSITION_TABLE,\n        use_binary_format=use_binary_format,\n    )", "source_start_line": 471, "tokens": ["def", "export_without_kwargs", "(", "fn", ":", "Union", "[", "torch", ".", "nn", ".", "Module", ",", "Callable", "]", ",", "opset_version", ",", "*", "args", ",", "use_binary_format", ":", "bool", "=", "True", ",", "**", "kwargs", ",", ")", ":", "if", "isinstance", "(", "fn", ",", "torch", ".", "nn", ".", "Module", ")", ":", "signature", "=", "inspect", ".", "signature", "(", "fn", ".", "forward", ")", "else", ":", "signature", "=", "inspect", ".", "signature", "(", "fn", ")", "bound", "=", "signature", ".", "bind", "(", "*", "args", ",", "**", "kwargs", ")", "bound", ".", "apply_defaults", "(", ")", "assert", "not", "bound", ".", "kwargs", "class", "Wrapper", "(", "torch", ".", "nn", ".", "Module", ")", ":", "def", "__init__", "(", "self", ",", "fn", ")", ":", "super", "(", ")", ".", "__init__", "(", ")", "self", ".", "fn", "=", "fn", "def", "forward", "(", "self", ",", "*", "args", ")", ":", "result", ",", "_", "=", "_pytree", ".", "tree_flatten", "(", "self", ".", "fn", "(", "*", "args", ")", ")", "return", "result", "bound_args", "=", "copy", ".", "deepcopy", "(", "bound", ".", "args", ")", "class", "GraphCaptureCompiler", ":", "def", "__init__", "(", "self", ")", ":", "self", ".", "captured_graph", ":", "Optional", "[", "torch", ".", "fx", ".", "GraphModule", "]", "=", "None", "self", ".", "captured_graph_count", "=", "0", "def", "compile", "(", "self", ",", "gm", ":", "torch", ".", "fx", ".", "GraphModule", ",", "_", ")", ":", "assert", "self", ".", "captured_graph_count", "==", "0", "self", ".", "captured_graph", "=", "gm", "self", ".", "captured_graph_count", "+=", "1", "return", "gm", "compiler", "=", "GraphCaptureCompiler", "(", ")", "torch", ".", "_dynamo", ".", "optimize", "(", "compiler", ".", "compile", ",", "nopython", "=", "True", ")", "(", "Wrapper", "(", "fn", ")", ")", "(", "*", "bound_args", ")", "torch", ".", "_dynamo", ".", "reset", "(", ")", "assert", "compiler", ".", "captured_graph", "return", "_export", "(", "compiler", ".", "captured_graph", ",", "opset_version", ",", "*", "tuple", "(", "arg", "for", "arg", "in", "bound_args", "if", "arg", "is", "not", "None", ")", ",", "decomposition_table", "=", "_ONNX_FRIENDLY_DECOMPOSITION_TABLE", ",", "use_binary_format", "=", "use_binary_format", ",", ")"], "to_mask": {"VAR": ["_", "args", "bound", "bound_args", "captured_graph", "captured_graph_count", "compiler", "fn", "gm", "opset_version", "result", "self", "signature", "use_binary_format"], "METHOD": ["GraphCaptureCompiler", "Wrapper", "__init__", "_export", "apply_defaults", "bind", "deepcopy", "fn", "isinstance", "optimize", "reset", "signature", "super", "tree_flatten", "tuple"]}, "attention_idx_tokens": [16, 17], "patch": "@@ -470,6 +470,7 @@\n \n def export_without_kwargs(\n     fn: Union[torch.nn.Module, Callable],\n+    opset_version,", "ext_attention_idx_tokens": [16, 20], "uid": "47cdaffa", "question": "out of scope for this PR, but I'd love to hear your opinion on this. Which would you prefer?    * optional, default to some default (same behavior as current exporter)  * optional, default to latest  * required  * specified via a separate 'config.py' file (what dynamo and inductor does)  * not configurable", "code": "def export without kwargs fn Union[torch nn Module Callable] opset version *args use binary format bool True **kwargs if isinstance fn torch nn Module signature inspect signature fn forward else signature inspect signature fn # We hope the input kwargs will be mapped to bound args after binding # If not we will raise an error bound signature bind *args **kwargs bound apply defaults # kwargs are not handled assert not bound kwargs class Wrapper torch nn Module def init self fn super init self fn fn def forward self *args result pytree tree flatten self fn *args return result # args will be converted to symbolic tensor Let s copy to avoid side effects bound args copy deepcopy bound args # Translate callable to FX graph # # TODO wechi There are several symbolic tracing mechanisms to convert # nn Module to FX graph We should choose the right one after they are # matured class GraphCaptureCompiler def init self self captured graph Optional[torch fx GraphModule] None self captured graph count 0 def compile self gm torch fx GraphModule assert self captured graph count 0 self captured graph gm self captured graph count + 1 return gm compiler GraphCaptureCompiler torch dynamo optimize compiler compile nopython True Wrapper fn *bound args torch dynamo reset assert compiler captured graph # Export FX graph to ONNX ModelProto return export compiler captured graph opset version # Function optimized by dynamo doesn t have None in args *tuple arg for arg in bound args if arg is not None decomposition table ONNX FRIENDLY DECOMPOSITION TABLE use binary format use binary format"}
{"message": "Trying to understand, does it mean the data for the initializers is now stored in separate files? Does the call\r\n\r\n```\r\nonnx.save(onnx_model_with_initializers, os.path.join(basepath, model_location))\r\n```\r\n\r\nreflect that?", "timestamp": "2023-02-01T15:17:07Z", "file_name": "torch/onnx/_internal/fx/export.py", "range": {"start_line": 918, "end_line": 918, "start_character": 0, "end_character": 0}, "project": "pytorch/pytorch", "api_url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/1093364634", "html_url": "https://github.com/pytorch/pytorch/pull/92871#discussion_r1093364634", "attention_area": "    \"\"\"Load PyTorch tensors from files and add to \"onnx_model\" as external initializers.", "file_path": "files/44/00/00000044.py", "old_file_path": "files/38/00/00000038.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -541,3 +675,308 @@ def compile(self, gm: torch.fx.GraphModule, _):\n         decomposition_table=_ONNX_FRIENDLY_DECOMPOSITION_TABLE,\n         use_binary_format=use_binary_format,\n     )\n+\n+\n+@_beartype.beartype\n+def _move_placeholder_to_front(graph_module: \"torch.fx.GraphModule\") -> None:\n+    \"\"\"\n+    This function move all placeholder nodes to the front of the graph node list.\n+    In torch.fx.Graph, placeholder is a special assignment node. If it's not\n+    executed in the beginning, it could overwrite values computed by upstream\n+    nodes.\n+    \"\"\"\n+\n+    graph = graph_module.graph\n+    placeholders = []\n+    first_not_placeholder = None\n+    for node in graph.nodes:\n+        if node.op == \"placeholder\":\n+            placeholders.append(node)\n+        if first_not_placeholder is None and node.op != \"placeholder\":\n+            first_not_placeholder = node\n+    if first_not_placeholder is None:\n+        return\n+    for placeholder in placeholders:\n+        first_not_placeholder.prepend(placeholder)\n+\n+\n+@_beartype.beartype\n+def _replace_get_attr_with_placeholder(\n+    graph_module: \"torch.fx.GraphModule\",\n+) -> Tuple[torch.Tensor, ...]:\n+    \"\"\"\n+    Replace get_attr with placeholder.\n+    The parameters and buffers accessed by the original get_attr are returned;\n+    they are useful when creating random inputs for the modified graph_module.\n+    \"\"\"\n+    graph = graph_module.graph\n+    replaced_attrs: List[torch.Tensor] = []\n+    for node in graph.nodes:\n+        if node.op == \"get_attr\":\n+            replaced_attr: Optional[torch.Tensor] = None\n+            # get_attr could retrieve either parameter or buffer, so\n+            # we need to try both.\n+            try:\n+                replaced_attr = graph_module.get_parameter(node.target)\n+            except AttributeError:\n+                # It's possible that model author use buffer instead of\n+                # parameter to store trainable weights. In this case,\n+                # 1. get_parameter will throw something like\n+                #    AttributeError: `bias` is not an nn.Parameter.\n+                # 2. get_buffer should work.\n+                replaced_attr = graph_module.get_buffer(node.target)\n+\n+            # Reassign op type so that get_attr node becomes placeholder node.\n+            node.op = \"placeholder\"\n+            # The target name in placeholder must be a valid Python identifier.\n+            # Thus, we replace, e.g., \"module.submodule.weight\" with\n+            # \"module_submodule_weight\".\n+            node.target = node.target.replace(\".\", \"_\")\n+            # Default value is None. This is needed as long as the \"graph_module\"\n+            # has optional inputs. Assume the original forward signature is\n+            #  def forward(self, x, y=None)\n+            # and the replaced get_attr node has target \"z\". Then, the modified\n+            # signature should be\n+            #  def forward(self, x, y=None, z=None)\n+            # Without the following line, the signature will be\n+            #  def forward(self, x, y=None, z)\n+            # , which is not valid Python code.\n+            node.args = (None,)\n+\n+            replaced_attrs.append(replaced_attr)\n+\n+    return tuple(replaced_attrs)\n+\n+\n+@_beartype.beartype\n+def _trace_into_fx_graph_via_fx_symbolic_trace(\n+    module: torch.nn.Module,\n+    *args,\n+    # kwargs are the keyword arguments to call \"module\"; that is,\n+    # module(*args, **kwargs) must run.\n+    **kwargs,\n+) -> Tuple[\"torch.fx.GraphModule\", Tuple[Any, ...]]:\n+    signature = inspect.signature(module.forward)\n+\n+    # We hope the input kwargs will be mapped to bound.args after binding.\n+    # If not, we will raise an error.\n+    bound = signature.bind(*args, **kwargs)\n+    bound.apply_defaults()\n+    # After apply_defaults, all non keyword-only arguments are in bound.args.\n+    # Because below code do not support keyword-word arguments, bound.kwargs\n+    # must be empty.\n+    assert len(bound.kwargs) == 0, bound.kwargs\n+\n+    # Create inputs to call symbolic trace (torch.fx.symbolic_trace)\n+    # Example content of concrete_args:\n+    #  concrete_args[\"x\"] = torch.fx._symbolic_trace.PH\n+    #  concrete_args[\"b\"] = 1\n+    # where \"x\" and \"b\" are argument names in \"signature\".\n+    concrete_args = {}\n+    for param_name, param_value in bound.arguments.items():\n+        if isinstance(param_value, torch.Tensor):\n+            # param_value can be, e.g., a real tensor or a fake tensor.\n+            # param_value is treated as substitutable tensor symbol (aka placeholder).\n+            concrete_args[param_name] = torch.fx._symbolic_trace.PH\n+        else:\n+            concrete_args[param_name] = param_value\n+\n+    return (\n+        module_expansion_symbolic_trace(module, concrete_args=concrete_args),\n+        bound.args,\n+    )\n+\n+\n+@_beartype.beartype\n+def export_without_parameters_and_buffers(\n+    module: torch.nn.Module,\n+    *args,\n+    decomposition_table: Optional[Dict[torch._ops.OpOverload, Callable]] = None,\n+    use_binary_format: bool = True,\n+    opset_version: int = None,\n+    # kwargs are the keyword arguments to call \"module\"; that is,\n+    # module(*args, **kwargs) must run.\n+    **kwargs,\n+) -> Tuple[\n+    Union[\"onnx.ModelProto\", bytes],\n+    \"torch.fx.GraphModule\",\n+    Tuple[Any, ...],\n+    Tuple[Any, ...],\n+]:\n+    if opset_version is None:\n+        opset_version = torch.onnx._constants.ONNX_DEFAULT_OPSET\n+\n+    graph_module, bound_args = _trace_into_fx_graph_via_fx_symbolic_trace(\n+        module, *args, **kwargs\n+    )\n+\n+    # Make sure all placeholder nodes are executed before get_attr nodes.\n+    # Otherwise, inputs can interleave with initializers in the final ModeoProto.graph.input.\n+    # Basically, we want\n+    #  ModeoProto.graph.input =\n+    #   [input_0, input_1, ..., input_n, weight_0, weight_1, ..., weight_m]\n+    # and we don't want\n+    #  ModeoProto.graph.input =\n+    #   [input_0, weight_0, input_1, weight_1, ..., input_n, weight_0, weight_1, ..., weight_m]\n+    _move_placeholder_to_front(graph_module)\n+    # To save memory, move get_attr to input so that the generated model doesn't\n+    # have weigh tensors. \"replaced_attrs\" are the list of replaced weight tensors.\n+    replaced_attrs = _replace_get_attr_with_placeholder(graph_module)\n+    # Move all newly created placeholder nodes to the front of the graph.\n+    _move_placeholder_to_front(graph_module)\n+    # Finalize the graph editing.\n+    graph_module.recompile()\n+\n+    return (\n+        _export(\n+            graph_module,\n+            opset_version,\n+            *bound_args,\n+            *replaced_attrs,\n+            decomposition_table=decomposition_table,\n+            use_binary_format=use_binary_format,\n+        ),\n+        graph_module,\n+        bound_args,\n+        replaced_attrs,\n+    )\n+\n+\n+@_beartype.beartype\n+def _create_tensor_proto_with_external_data(\n+    tensor: torch.Tensor, name: str, location: str, basepath: str\n+) -> \"onnx.TensorProto\":\n+    \"\"\"Create a TensorProto with external data from a PyTorch tensor.\n+    The external data is saved to os.path.join(basepath, location).\n+\n+    Args:\n+        tensor: Tensor to be saved.\n+        name: Name of the tensor (i.e., initializer name in ONNX graph).\n+        location: Relative location of the external data file\n+            (e.g., \"/tmp/initializers/weight_0\" when model is \"/tmp/model_name.onnx\").\n+        basepath: Base path of the external data file (e.g., \"/tmp/external_data\" while model must be in \"/tmp\").\n+\n+\n+    Reference for ONNX's external data format:\n+        How to load?\n+        https://github.com/onnx/onnx/blob/5dac81ac0707bdf88f56c35c0a5e8855d3534673/onnx/external_data_helper.py#L187\n+        How to save?\n+        https://github.com/onnx/onnx/blob/5dac81ac0707bdf88f56c35c0a5e8855d3534673/onnx/external_data_helper.py#L43\n+        How to set ONNX fields?\n+        https://github.com/onnx/onnx/blob/5dac81ac0707bdf88f56c35c0a5e8855d3534673/onnx/external_data_helper.py#L88\n+    \"\"\"\n+    tensor_proto = onnx.TensorProto()\n+    tensor_proto.name = name\n+    tensor_proto.data_type = torch.onnx._type_utils._SCALAR_TYPE_TO_ONNX[  # type: ignore[assignment]\n+        torch.onnx._type_utils._DTYPE_TO_SCALAR_TYPE[tensor.dtype]\n+    ]\n+    tensor_proto.dims.extend(tensor.shape)\n+    tensor_proto.data_location = onnx.TensorProto.EXTERNAL\n+\n+    # Settings for saving one tensor per file.\n+    # Offset is zero because there is no other tensor in the same file.\n+    key_value_pairs = {\n+        \"location\": location,\n+        \"offset\": 0,\n+        \"length\": tensor.untyped_storage().nbytes(),\n+    }\n+    for k, v in key_value_pairs.items():\n+        entry = tensor_proto.external_data.add()\n+        entry.key = k\n+        entry.value = str(v)\n+\n+    # Actual path to write content of tensor.\n+    external_data_file_path = os.path.join(basepath, location)\n+    if os.path.exists(external_data_file_path):\n+        os.remove(external_data_file_path)\n+\n+    # Create external data's folder if not exists.\n+    external_data_dir_path = os.path.dirname(external_data_file_path)\n+    if not os.path.exists(external_data_dir_path):\n+        # if the demo_folder directory is not present\n+        # then create it.\n+        os.makedirs(external_data_dir_path)\n+\n+    # Create a fresh file.\n+    with open(external_data_file_path, \"xb\") as data_file:\n+        # No need to call \"seek\" because offset is 0.\n+        # data_file.seek(0)\n+        # Write tensor content to the file.\n+        data_file.write(tensor.numpy().tobytes())\n+\n+    return tensor_proto\n+\n+\n+@_beartype.beartype\n+def save_model_with_external_data(\n+    basepath: str,\n+    model_location: str,\n+    initializer_location: str,\n+    torch_load_paths: Tuple[str, ...],\n+    onnx_model: \"onnx.ModelProto\",\n+) -> None:\n+    \"\"\"Load PyTorch tensors from files and add to \"onnx_model\" as external initializers.", "source": "def save_model_with_external_data(\n    basepath: str,\n    model_location: str,\n    initializer_location: str,\n    torch_load_paths: Tuple[str, ...],\n    onnx_model: \"onnx.ModelProto\",\n) -> None:\n    \"\"\"Load PyTorch tensors from files and add to \"onnx_model\" as external initializers.\n\n    Output files:\n        ONNX model file path:\n        ONNX initializer folder: os.path.join(basepath, initializer_location)\n\n    After running this function, you can do\n        ort_sess = onnxruntime.InferenceSession(os.path.join(basepath, model_location))\n    to execute the model.\n\n    Arguments:\n        basepath: Base path of the external data file (e.g., \"/tmp/large-onnx-model\").\n        model_location: Relative location of the ONNX model file.\n            E.g., \"model.onnx\" so that the model file is saved to\n            \"/tmp/large-onnx-model/model.onnx\".\n        initializer_location: Relative location of the ONNX initializer folder.\n            E.g., \"initializers\" so that the initializers are saved to\n            \"/tmp/large-onnx-model/initializers\".\n        torch_load_paths: Files which containing serialized PyTorch tensors to be saved\n            as ONNX initializers. They are loaded by torch.load.\n        onnx_model: ONNX model to be saved with external initializers.\n            If an input name matches a tensor loaded from \"torch_load_paths\",\n            the tensor will be saved as that input's external initializer.\n    \"\"\"\n    onnx_model_with_initializers = onnx.ModelProto()\n    onnx_model_with_initializers.CopyFrom(onnx_model)\n    onnx_input_names = [input.name for input in onnx_model.graph.input]\n\n    for path in torch_load_paths:\n        state_ditc = torch.load(path)\n        for name, tensor in state_ditc.items():\n            # Basically, \"transformer.attention.self.query.weight\" is mapped\n            # to \"transformer_attention_self_query_weight\" for mimicking the\n            # name-modifying code in FX-to-ONNX exporter.\n            # See function _replace_get_attr_with_placeholder for details.\n            refined_name = name.replace(\".\", \"_\")\n\n            # For each refined PyTorch tensor name loaded by torch.load,\n            #  1.  Search its best match in ONNX model. E.g., the match of\n            #       \"transformer_attention_weight\" could be \"attention_weight\".\n            #  2.  Set \"tensor\" as the initializer of the matched ONNX input.\n            #      E.g., \"tensor\" is stored as the initializer of \"attention_weight\".\n            # Step 1 is required because sometimes, tensor names are stored with prefix the dictionary\n            # loaded by torch.load.\n            for onnx_input_name in onnx_input_names:\n                if onnx_input_name.endswith(refined_name) or refined_name.endswith(\n                    onnx_input_name\n                ):\n                    # Find a match. Change refined_name to the matched ONNX input name, so that we\n                    # create initializer with the right ONNX name.\n                    refined_name = onnx_input_name\n                    break\n\n            relative_tensor_file_path = os.path.join(initializer_location, refined_name)\n            # Create one file per tensor.\n            # tensor_proto.raw_data is stored to external file at\n            # os.path.join(basepath, relative_tensor_file_path).\n            tensor_proto = _create_tensor_proto_with_external_data(\n                tensor, refined_name, relative_tensor_file_path, basepath\n            )\n            # Add the tensor_proto to the ONNX model as an initializer with external data.\n            onnx_model_with_initializers.graph.initializer.append(tensor_proto)\n\n    # model_location should be a pure file name such as \"file_name.onnx\", not \"folder/file_name.onnx\".\n    onnx.save(onnx_model_with_initializers, os.path.join(basepath, model_location))", "source_start_line": 911, "tokens": ["def", "save_model_with_external_data", "(", "basepath", ":", "str", ",", "model_location", ":", "str", ",", "initializer_location", ":", "str", ",", "torch_load_paths", ":", "Tuple", "[", "str", ",", "...", "]", ",", "onnx_model", ":", "\"onnx.ModelProto\"", ",", ")", "->", "None", ":", "\"\"\"Load PyTorch tensors from files and add to \"onnx_model\" as external initializers.    Output files:        ONNX model file path:        ONNX initializer folder: os.path.join(basepath, initializer_location)    After running this function, you can do        ort_sess = onnxruntime.InferenceSession(os.path.join(basepath, model_location))    to execute the model.    Arguments:        basepath: Base path of the external data file (e.g., \"/tmp/large-onnx-model\").        model_location: Relative location of the ONNX model file.            E.g., \"model.onnx\" so that the model file is saved to            \"/tmp/large-onnx-model/model.onnx\".        initializer_location: Relative location of the ONNX initializer folder.            E.g., \"initializers\" so that the initializers are saved to            \"/tmp/large-onnx-model/initializers\".        torch_load_paths: Files which containing serialized PyTorch tensors to be saved            as ONNX initializers. They are loaded by torch.load.        onnx_model: ONNX model to be saved with external initializers.            If an input name matches a tensor loaded from \"torch_load_paths\",            the tensor will be saved as that input's external initializer.    \"\"\"", "onnx_model_with_initializers", "=", "onnx", ".", "ModelProto", "(", ")", "onnx_model_with_initializers", ".", "CopyFrom", "(", "onnx_model", ")", "onnx_input_names", "=", "[", "input", ".", "name", "for", "input", "in", "onnx_model", ".", "graph", ".", "input", "]", "for", "path", "in", "torch_load_paths", ":", "state_ditc", "=", "torch", ".", "load", "(", "path", ")", "for", "name", ",", "tensor", "in", "state_ditc", ".", "items", "(", ")", ":", "refined_name", "=", "name", ".", "replace", "(", "\".\"", ",", "\"_\"", ")", "for", "onnx_input_name", "in", "onnx_input_names", ":", "if", "onnx_input_name", ".", "endswith", "(", "refined_name", ")", "or", "refined_name", ".", "endswith", "(", "onnx_input_name", ")", ":", "refined_name", "=", "onnx_input_name", "break", "relative_tensor_file_path", "=", "os", ".", "path", ".", "join", "(", "initializer_location", ",", "refined_name", ")", "tensor_proto", "=", "_create_tensor_proto_with_external_data", "(", "tensor", ",", "refined_name", ",", "relative_tensor_file_path", ",", "basepath", ")", "onnx_model_with_initializers", ".", "graph", ".", "initializer", ".", "append", "(", "tensor_proto", ")", "onnx", ".", "save", "(", "onnx_model_with_initializers", ",", "os", ".", "path", ".", "join", "(", "basepath", ",", "model_location", ")", ")"], "to_mask": {"VAR": ["basepath", "initializer_location", "model_location", "name", "onnx_input_name", "onnx_input_names", "onnx_model", "onnx_model_with_initializers", "path", "refined_name", "relative_tensor_file_path", "state_ditc", "tensor", "tensor_proto", "torch_load_paths"], "METHOD": ["CopyFrom", "ModelProto", "_create_tensor_proto_with_external_data", "append", "endswith", "items", "join", "load", "replace", "save"]}, "attention_idx_tokens": [32, 32], "patch": "@@ -541,3 +675,308 @@\n         decomposition_table=_ONNX_FRIENDLY_DECOMPOSITION_TABLE,\n         use_binary_format=use_binary_format,\n     )\n+\n+\n+@_beartype.beartype\n+def _move_placeholder_to_front(graph_module: \"torch.fx.GraphModule\") -> None:\n+    \"\"\"\n+    This function move all placeholder nodes to the front of the graph node list.\n+    In torch.fx.Graph, placeholder is a special assignment node. If it's not\n+    executed in the beginning, it could overwrite values computed by upstream\n+    nodes.\n+    \"\"\"\n+\n+    graph = graph_module.graph\n+    placeholders = []\n+    first_not_placeholder = None\n+    for node in graph.nodes:\n+        if node.op == \"placeholder\":\n+            placeholders.append(node)\n+        if first_not_placeholder is None and node.op != \"placeholder\":\n+            first_not_placeholder = node\n+    if first_not_placeholder is None:\n+        return\n+    for placeholder in placeholders:\n+        first_not_placeholder.prepend(placeholder)\n+\n+\n+@_beartype.beartype\n+def _replace_get_attr_with_placeholder(\n+    graph_module: \"torch.fx.GraphModule\",\n+) -> Tuple[torch.Tensor, ...]:\n+    \"\"\"\n+    Replace get_attr with placeholder.\n+    The parameters and buffers accessed by the original get_attr are returned;\n+    they are useful when creating random inputs for the modified graph_module.\n+    \"\"\"\n+    graph = graph_module.graph\n+    replaced_attrs: List[torch.Tensor] = []\n+    for node in graph.nodes:\n+        if node.op == \"get_attr\":\n+            replaced_attr: Optional[torch.Tensor] = None\n+            # get_attr could retrieve either parameter or buffer, so\n+            # we need to try both.\n+            try:\n+                replaced_attr = graph_module.get_parameter(node.target)\n+            except AttributeError:\n+                # It's possible that model author use buffer instead of\n+                # parameter to store trainable weights. In this case,\n+                # 1. get_parameter will throw something like\n+                #    AttributeError: `bias` is not an nn.Parameter.\n+                # 2. get_buffer should work.\n+                replaced_attr = graph_module.get_buffer(node.target)\n+\n+            # Reassign op type so that get_attr node becomes placeholder node.\n+            node.op = \"placeholder\"\n+            # The target name in placeholder must be a valid Python identifier.\n+            # Thus, we replace, e.g., \"module.submodule.weight\" with\n+            # \"module_submodule_weight\".\n+            node.target = node.target.replace(\".\", \"_\")\n+            # Default value is None. This is needed as long as the \"graph_module\"\n+            # has optional inputs. Assume the original forward signature is\n+            #  def forward(self, x, y=None)\n+            # and the replaced get_attr node has target \"z\". Then, the modified\n+            # signature should be\n+            #  def forward(self, x, y=None, z=None)\n+            # Without the following line, the signature will be\n+            #  def forward(self, x, y=None, z)\n+            # , which is not valid Python code.\n+            node.args = (None,)\n+\n+            replaced_attrs.append(replaced_attr)\n+\n+    return tuple(replaced_attrs)\n+\n+\n+@_beartype.beartype\n+def _trace_into_fx_graph_via_fx_symbolic_trace(\n+    module: torch.nn.Module,\n+    *args,\n+    # kwargs are the keyword arguments to call \"module\"; that is,\n+    # module(*args, **kwargs) must run.\n+    **kwargs,\n+) -> Tuple[\"torch.fx.GraphModule\", Tuple[Any, ...]]:\n+    signature = inspect.signature(module.forward)\n+\n+    # We hope the input kwargs will be mapped to bound.args after binding.\n+    # If not, we will raise an error.\n+    bound = signature.bind(*args, **kwargs)\n+    bound.apply_defaults()\n+    # After apply_defaults, all non keyword-only arguments are in bound.args.\n+    # Because below code do not support keyword-word arguments, bound.kwargs\n+    # must be empty.\n+    assert len(bound.kwargs) == 0, bound.kwargs\n+\n+    # Create inputs to call symbolic trace (torch.fx.symbolic_trace)\n+    # Example content of concrete_args:\n+    #  concrete_args[\"x\"] = torch.fx._symbolic_trace.PH\n+    #  concrete_args[\"b\"] = 1\n+    # where \"x\" and \"b\" are argument names in \"signature\".\n+    concrete_args = {}\n+    for param_name, param_value in bound.arguments.items():\n+        if isinstance(param_value, torch.Tensor):\n+            # param_value can be, e.g., a real tensor or a fake tensor.\n+            # param_value is treated as substitutable tensor symbol (aka placeholder).\n+            concrete_args[param_name] = torch.fx._symbolic_trace.PH\n+        else:\n+            concrete_args[param_name] = param_value\n+\n+    return (\n+        module_expansion_symbolic_trace(module, concrete_args=concrete_args),\n+        bound.args,\n+    )\n+\n+\n+@_beartype.beartype\n+def export_without_parameters_and_buffers(\n+    module: torch.nn.Module,\n+    *args,\n+    decomposition_table: Optional[Dict[torch._ops.OpOverload, Callable]] = None,\n+    use_binary_format: bool = True,\n+    opset_version: int = None,\n+    # kwargs are the keyword arguments to call \"module\"; that is,\n+    # module(*args, **kwargs) must run.\n+    **kwargs,\n+) -> Tuple[\n+    Union[\"onnx.ModelProto\", bytes],\n+    \"torch.fx.GraphModule\",\n+    Tuple[Any, ...],\n+    Tuple[Any, ...],\n+]:\n+    if opset_version is None:\n+        opset_version = torch.onnx._constants.ONNX_DEFAULT_OPSET\n+\n+    graph_module, bound_args = _trace_into_fx_graph_via_fx_symbolic_trace(\n+        module, *args, **kwargs\n+    )\n+\n+    # Make sure all placeholder nodes are executed before get_attr nodes.\n+    # Otherwise, inputs can interleave with initializers in the final ModeoProto.graph.input.\n+    # Basically, we want\n+    #  ModeoProto.graph.input =\n+    #   [input_0, input_1, ..., input_n, weight_0, weight_1, ..., weight_m]\n+    # and we don't want\n+    #  ModeoProto.graph.input =\n+    #   [input_0, weight_0, input_1, weight_1, ..., input_n, weight_0, weight_1, ..., weight_m]\n+    _move_placeholder_to_front(graph_module)\n+    # To save memory, move get_attr to input so that the generated model doesn't\n+    # have weigh tensors. \"replaced_attrs\" are the list of replaced weight tensors.\n+    replaced_attrs = _replace_get_attr_with_placeholder(graph_module)\n+    # Move all newly created placeholder nodes to the front of the graph.\n+    _move_placeholder_to_front(graph_module)\n+    # Finalize the graph editing.\n+    graph_module.recompile()\n+\n+    return (\n+        _export(\n+            graph_module,\n+            opset_version,\n+            *bound_args,\n+            *replaced_attrs,\n+            decomposition_table=decomposition_table,\n+            use_binary_format=use_binary_format,\n+        ),\n+        graph_module,\n+        bound_args,\n+        replaced_attrs,\n+    )\n+\n+\n+@_beartype.beartype\n+def _create_tensor_proto_with_external_data(\n+    tensor: torch.Tensor, name: str, location: str, basepath: str\n+) -> \"onnx.TensorProto\":\n+    \"\"\"Create a TensorProto with external data from a PyTorch tensor.\n+    The external data is saved to os.path.join(basepath, location).\n+\n+    Args:\n+        tensor: Tensor to be saved.\n+        name: Name of the tensor (i.e., initializer name in ONNX graph).\n+        location: Relative location of the external data file\n+            (e.g., \"/tmp/initializers/weight_0\" when model is \"/tmp/model_name.onnx\").\n+        basepath: Base path of the external data file (e.g., \"/tmp/external_data\" while model must be in \"/tmp\").\n+\n+\n+    Reference for ONNX's external data format:\n+        How to load?\n+        https://github.com/onnx/onnx/blob/5dac81ac0707bdf88f56c35c0a5e8855d3534673/onnx/external_data_helper.py#L187\n+        How to save?\n+        https://github.com/onnx/onnx/blob/5dac81ac0707bdf88f56c35c0a5e8855d3534673/onnx/external_data_helper.py#L43\n+        How to set ONNX fields?\n+        https://github.com/onnx/onnx/blob/5dac81ac0707bdf88f56c35c0a5e8855d3534673/onnx/external_data_helper.py#L88\n+    \"\"\"\n+    tensor_proto = onnx.TensorProto()\n+    tensor_proto.name = name\n+    tensor_proto.data_type = torch.onnx._type_utils._SCALAR_TYPE_TO_ONNX[  # type: ignore[assignment]\n+        torch.onnx._type_utils._DTYPE_TO_SCALAR_TYPE[tensor.dtype]\n+    ]\n+    tensor_proto.dims.extend(tensor.shape)\n+    tensor_proto.data_location = onnx.TensorProto.EXTERNAL\n+\n+    # Settings for saving one tensor per file.\n+    # Offset is zero because there is no other tensor in the same file.\n+    key_value_pairs = {\n+        \"location\": location,\n+        \"offset\": 0,\n+        \"length\": tensor.untyped_storage().nbytes(),\n+    }\n+    for k, v in key_value_pairs.items():\n+        entry = tensor_proto.external_data.add()\n+        entry.key = k\n+        entry.value = str(v)\n+\n+    # Actual path to write content of tensor.\n+    external_data_file_path = os.path.join(basepath, location)\n+    if os.path.exists(external_data_file_path):\n+        os.remove(external_data_file_path)\n+\n+    # Create external data's folder if not exists.\n+    external_data_dir_path = os.path.dirname(external_data_file_path)\n+    if not os.path.exists(external_data_dir_path):\n+        # if the demo_folder directory is not present\n+        # then create it.\n+        os.makedirs(external_data_dir_path)\n+\n+    # Create a fresh file.\n+    with open(external_data_file_path, \"xb\") as data_file:\n+        # No need to call \"seek\" because offset is 0.\n+        # data_file.seek(0)\n+        # Write tensor content to the file.\n+        data_file.write(tensor.numpy().tobytes())\n+\n+    return tensor_proto\n+\n+\n+@_beartype.beartype\n+def save_model_with_external_data(\n+    basepath: str,\n+    model_location: str,\n+    initializer_location: str,\n+    torch_load_paths: Tuple[str, ...],\n+    onnx_model: \"onnx.ModelProto\",\n+) -> None:\n+    \"\"\"Load PyTorch tensors from files and add to \"onnx_model\" as external initializers.", "ext_attention_idx_tokens": [0, 152], "uid": "c4bb8db8", "question": "Trying to understand, does it mean the data for the initializers is now stored in separate files? Does the call    ```  onnx.save(onnx_model_with_initializers, os.path.join(basepath, model_location))  ```    reflect that?", "code": "def save model with external data basepath str model location str initializer location str torch load paths Tuple[str ] onnx model \"onnx ModelProto\" -> None \"\"\"Load PyTorch tensors from files and add to \"onnx model\" as external initializers Output files ONNX model file path ONNX initializer folder os path join basepath initializer location After running this function you can do ort sess onnxruntime InferenceSession os path join basepath model location to execute the model Arguments basepath Base path of the external data file e g \" tmp large-onnx-model\" model location Relative location of the ONNX model file E g \"model onnx\" so that the model file is saved to \" tmp large-onnx-model model onnx\" initializer location Relative location of the ONNX initializer folder E g \"initializers\" so that the initializers are saved to \" tmp large-onnx-model initializers\" torch load paths Files which containing serialized PyTorch tensors to be saved as ONNX initializers They are loaded by torch load onnx model ONNX model to be saved with external initializers If an input name matches a tensor loaded from \"torch load paths\" the tensor will be saved as that input s external initializer \"\"\" onnx model with initializers onnx ModelProto onnx model with initializers CopyFrom onnx model onnx input names [input name for input in onnx model graph input] for path in torch load paths state ditc torch load path for name tensor in state ditc items # Basically \"transformer attention self query weight\" is mapped # to \"transformer attention self query weight\" for mimicking the # name-modifying code in FX-to-ONNX exporter # See function replace get attr with placeholder for details refined name name replace \" \" \" \" # For each refined PyTorch tensor name loaded by torch load # 1 Search its best match in ONNX model E g the match of # \"transformer attention weight\" could be \"attention weight\" # 2 Set \"tensor\" as the initializer of the matched ONNX input # E g \"tensor\" is stored as the initializer of \"attention weight\" # Step 1 is required because sometimes tensor names are stored with prefix the dictionary # loaded by torch load for onnx input name in onnx input names if onnx input name endswith refined name or refined name endswith onnx input name # Find a match Change refined name to the matched ONNX input name so that we # create initializer with the right ONNX name refined name onnx input name break relative tensor file path os path join initializer location refined name # Create one file per tensor # tensor proto raw data is stored to external file at # os path join basepath relative tensor file path tensor proto create tensor proto with external data tensor refined name relative tensor file path basepath # Add the tensor proto to the ONNX model as an initializer with external data onnx model with initializers graph initializer append tensor proto # model location should be a pure file name such as \"file name onnx\" not \"folder file name onnx\" onnx save onnx model with initializers os path join basepath model location"}
{"message": "How do we guarantee the passed-in output buffers are valid? So basically what is our protocol with the runtime?", "timestamp": "2023-06-23T20:33:51Z", "file_name": "torch/_inductor/codegen/wrapper.py", "range": {"start_line": 1176, "end_line": 1176, "start_character": 0, "end_character": 0}, "project": "pytorch/pytorch", "api_url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/1240351633", "html_url": "https://github.com/pytorch/pytorch/pull/103922#discussion_r1240351633", "attention_area": "                f\"at::Tensor {buffer.get_name()} = outputs[{output_idx}]{self.ending}\"", "file_path": "files/75/00/00000075.py", "old_file_path": "files/76/00/00000076.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1086,19 +1163,31 @@ def codegen_device(self, device):\n     def make_buffer_allocation(self, buffer):\n         from .cpp import DTYPE_TO_ATEN\n \n-        # TODO: map layout here\n-        device = buffer.get_device()\n-        dtype = buffer.get_dtype()\n-        shape = tuple(buffer.get_size())\n-        stride = tuple(buffer.get_stride())\n-        device_str = self.codegen_device\n-        return (\n-            f\"{self.declare}{buffer.get_name()} = {self.namespace}empty_strided(\"\n-            f\"{self.codegen_shape_tuple(shape)}, \"\n-            f\"{self.codegen_shape_tuple(stride)}, \"\n-            f\"{self.codegen_device(device)}\"\n-            f\".dtype({DTYPE_TO_ATEN[dtype]})){self.ending}\"\n-        )\n+        output_idx = None\n+        for idx, output in enumerate(V.graph.graph_outputs):\n+            if isinstance(output, (ir.NoneAsConstantBuffer, ir.ShapeAsConstantBuffer)):\n+                continue\n+            if buffer == output.data:\n+                output_idx = idx\n+                break\n+        if output_idx is not None and V.graph.aot_mode:\n+            # In aot_mode, output buffers are managed by the AOT runtime.\n+            return (\n+                f\"at::Tensor {buffer.get_name()} = outputs[{output_idx}]{self.ending}\"", "source": "def make_buffer_allocation(self, buffer):\n        from .cpp import DTYPE_TO_ATEN\n\n        output_idx = None\n        for idx, output in enumerate(V.graph.graph_outputs):\n            if isinstance(output, (ir.NoneAsConstantBuffer, ir.ShapeAsConstantBuffer)):\n                continue\n            if buffer == output.data:\n                output_idx = idx\n                break\n        if output_idx is not None and V.graph.aot_mode:\n            # In aot_mode, output buffers are managed by the AOT runtime.\n            return (\n                f\"at::Tensor {buffer.get_name()} = outputs[{output_idx}]{self.ending}\"\n            )\n        else:\n            # TODO: map layout here.\n            device = buffer.get_device()\n            dtype = buffer.get_dtype()\n            shape = tuple(buffer.get_size())\n            stride = tuple(buffer.get_stride())\n            return (\n                f\"{self.declare}{buffer.get_name()} = {self.namespace}empty_strided(\"\n                f\"{self.codegen_shape_tuple(shape)}, \"\n                f\"{self.codegen_shape_tuple(stride)}, \"\n                f\"{self.codegen_device(device)}\"\n                f\".dtype({DTYPE_TO_ATEN[dtype]})){self.ending}\"\n            )", "source_start_line": 1163, "tokens": ["def", "make_buffer_allocation", "(", "self", ",", "buffer", ")", ":", "from", ".", "cpp", "import", "DTYPE_TO_ATEN", "output_idx", "=", "None", "for", "idx", ",", "output", "in", "enumerate", "(", "V", ".", "graph", ".", "graph_outputs", ")", ":", "if", "isinstance", "(", "output", ",", "(", "ir", ".", "NoneAsConstantBuffer", ",", "ir", ".", "ShapeAsConstantBuffer", ")", ")", ":", "continue", "if", "buffer", "==", "output", ".", "data", ":", "output_idx", "=", "idx", "break", "if", "output_idx", "is", "not", "None", "and", "V", ".", "graph", ".", "aot_mode", ":", "return", "(", "f\"", "{", "buffer", ".", "get_name", "(", ")", "}", "{", "output_idx", "}", "{", "self", ".", "ending", "}", "\"", ")", "else", ":", "device", "=", "buffer", ".", "get_device", "(", ")", "dtype", "=", "buffer", ".", "get_dtype", "(", ")", "shape", "=", "tuple", "(", "buffer", ".", "get_size", "(", ")", ")", "stride", "=", "tuple", "(", "buffer", ".", "get_stride", "(", ")", ")", "return", "(", "f\"", "{", "self", ".", "declare", "}", "{", "buffer", ".", "get_name", "(", ")", "}", "{", "self", ".", "namespace", "}", "\"", "f\"", "{", "self", ".", "codegen_shape_tuple", "(", "shape", ")", "}", "\"", "f\"", "{", "self", ".", "codegen_shape_tuple", "(", "stride", ")", "}", "\"", "f\"", "{", "self", ".", "codegen_device", "(", "device", ")", "}", "\"", "f\"", "{", "DTYPE_TO_ATEN", "[", "dtype", "]", "}", "{", "self", ".", "ending", "}", "\"", ")"], "to_mask": {"VAR": ["buffer", "device", "dtype", "idx", "output", "output_idx", "self", "shape", "stride"], "METHOD": ["codegen_device", "codegen_shape_tuple", "enumerate", "get_device", "get_dtype", "get_name", "get_size", "get_stride", "isinstance", "tuple"]}, "attention_idx_tokens": [72, 88], "patch": "@@ -1086,19 +1163,31 @@\n     def make_buffer_allocation(self, buffer):\n         from .cpp import DTYPE_TO_ATEN\n \n-        # TODO: map layout here\n-        device = buffer.get_device()\n-        dtype = buffer.get_dtype()\n-        shape = tuple(buffer.get_size())\n-        stride = tuple(buffer.get_stride())\n-        device_str = self.codegen_device\n-        return (\n-            f\"{self.declare}{buffer.get_name()} = {self.namespace}empty_strided(\"\n-            f\"{self.codegen_shape_tuple(shape)}, \"\n-            f\"{self.codegen_shape_tuple(stride)}, \"\n-            f\"{self.codegen_device(device)}\"\n-            f\".dtype({DTYPE_TO_ATEN[dtype]})){self.ending}\"\n-        )\n+        output_idx = None\n+        for idx, output in enumerate(V.graph.graph_outputs):\n+            if isinstance(output, (ir.NoneAsConstantBuffer, ir.ShapeAsConstantBuffer)):\n+                continue\n+            if buffer == output.data:\n+                output_idx = idx\n+                break\n+        if output_idx is not None and V.graph.aot_mode:\n+            # In aot_mode, output buffers are managed by the AOT runtime.\n+            return (\n+                f\"at::Tensor {buffer.get_name()} = outputs[{output_idx}]{self.ending}\"", "ext_attention_idx_tokens": [13, 190], "uid": "e25aa90d", "question": "How do we guarantee the passed-in output buffers are valid? So basically what is our protocol with the runtime?", "code": "def make buffer allocation self buffer from cpp import DTYPE TO ATEN output idx None for idx output in enumerate V graph graph outputs if isinstance output ir NoneAsConstantBuffer ir ShapeAsConstantBuffer continue if buffer output data output idx idx break if output idx is not None and V graph aot mode # In aot mode output buffers are managed by the AOT runtime return f\"at Tensor {buffer get name } outputs[{output idx}]{self ending}\" else # TODO map layout here device buffer get device dtype buffer get dtype shape tuple buffer get size stride tuple buffer get stride return f\"{self declare}{buffer get name } {self namespace}empty strided \" f\"{self codegen shape tuple shape } \" f\"{self codegen shape tuple stride } \" f\"{self codegen device device }\" f\" dtype {DTYPE TO ATEN[dtype]} {self ending}\""}
{"message": "Is this just a refactor?", "timestamp": "2023-08-02T14:20:02Z", "file_name": "torch/_dynamo/variables/tensor.py", "range": {"start_line": 491, "end_line": 491, "start_character": 0, "end_character": 0}, "project": "pytorch/pytorch", "api_url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/1281978421", "html_url": "https://github.com/pytorch/pytorch/pull/106431#discussion_r1281978421", "attention_area": "            return NumpyNdarrayVariable.create(tx, proxy, **options)", "file_path": "files/85/00/00000085.py", "old_file_path": "files/86/00/00000086.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -479,23 +479,17 @@ def make_const_size_variable(x, **options):\n                 )\n             return constant_result\n         elif name == \"numpy\":\n-            from .builder import wrap_fx_proxy_cls\n-\n             assert not args, \"Tensor.numpy() doesn't take args.\"\n             # TODO: support force\n             if kwargs and \"force\" in kwargs:\n                 unimplemented(f\"Tensor.numpy(force={kwargs['force']})\")\n-            return wrap_fx_proxy_cls(\n-                target_cls=NumpyNdarrayVariable,\n-                tx=tx,\n-                proxy=tx.output.create_proxy(\n-                    \"call_function\",\n-                    torch.detach,\n-                    *proxy_args_kwargs([self], {}),\n-                ),\n-                example_value=None,\n-                **options,\n+            proxy = tx.output.create_proxy(\n+                \"call_function\",\n+                torch.detach,\n+                *proxy_args_kwargs([self], {}),\n             )\n+            return NumpyNdarrayVariable.create(tx, proxy, **options)", "source": "def call_method(\n        self,\n        tx,\n        name,\n        args: \"List[VariableTracker]\",\n        kwargs: \"Dict[str, VariableTracker]\",\n    ) -> \"VariableTracker\":\n        if tx.strict_checks_enabled:\n            if name in self._strict_mode_banned_ops():\n                unimplemented(f\"Illegal method invocation {name} in strict mode\")\n        from . import ConstantVariable, TorchVariable, TupleVariable\n        from .builder import wrap_fx_proxy\n\n        kwargs = dict(kwargs)\n        options = VariableTracker.propagate(self, args, kwargs.values())\n\n        if name in (\"stride\", \"size\"):\n            dim_var = None\n            if len(args) == 1:\n                dim_var = args[0]\n            elif \"dim\" in kwargs:\n                dim_var = kwargs[\"dim\"]\n            else:\n                assert not args and not kwargs, f\"Tensor.{name}() unhandled args/kwargs\"\n\n            dim = guard_if_dyn(dim_var)\n\n            def make_const_size_variable(x, **options):\n                return SizeVariable(\n                    [ConstantVariable(y, **options) for y in x], **options\n                )\n\n            RetVariable = (\n                make_const_size_variable if name == \"size\" else ConstantVariable\n            )\n\n            # Technically, this should not be necessary, but I'm including it\n            # for enhanced BC, in case example_value is sometimes not set\n            # (it really should always be set though!)\n            if (r := getattr(self, name)) is not None:\n                if dim is None:\n                    return RetVariable(r, **options)\n                else:\n                    return ConstantVariable(r[dim], **options)\n\n            # It might still be constant!  Consult the fake tensor and see\n            if (fake := self.proxy.node.meta.get(\"example_value\")) is not None:\n                if dim is None:\n                    fake_r = getattr(fake, name)()\n                    if not free_symbols(fake_r):\n                        # int conversion for safety, in case a SymInt refined\n                        # to constant\n                        return RetVariable(tuple(int(r) for r in fake_r), **options)\n                else:\n                    fake_r = getattr(fake, name)(dim)\n                    if not free_symbols(fake_r):\n                        return ConstantVariable(int(fake_r), **options)\n\n            # Oops, it's not constant.  Do the dynamic shapes path.\n            return wrap_fx_proxy(\n                tx,\n                tx.output.create_proxy(\n                    \"call_method\",\n                    name,\n                    *proxy_args_kwargs([self] + list(args), kwargs),\n                ),\n                **options,\n            )\n\n        elif name in (\"numel\", \"nelement\"):\n            if self.size is not None:\n                return ConstantVariable(product(self.size), **options)\n\n            # It might still be constant!  Consult the fake tensor and see\n            if (fake := self.proxy.node.meta.get(\"example_value\")) is not None:\n                fake_r = fake.numel()\n                if not free_symbols(fake_r):\n                    return ConstantVariable(int(fake_r), **options)\n\n            assert not kwargs, f\"Tensor.{name}() unhandled kwargs\"\n\n            # Oops, it's not constant.  Do the dynamic shapes path.\n            return wrap_fx_proxy(\n                tx,\n                tx.output.create_proxy(\n                    \"call_method\",\n                    \"numel\",\n                    *proxy_args_kwargs([self] + list(args), kwargs),\n                ),\n                **options,\n            )\n\n        elif name in (\"ndimension\", \"dim\") and self.ndim is not None:\n            constant_result = ConstantVariable(self.ndim, **options)\n        elif name == \"is_floating_point\" and self.dtype is not None:\n            constant_result = ConstantVariable(self.dtype.is_floating_point, **options)\n        elif name == \"is_contiguous\" and self.is_contiguous is not None:\n            if \"memory_format\" in kwargs:\n                memory_format = kwargs.pop(\"memory_format\").as_python_constant()\n            else:\n                memory_format = torch.contiguous_format\n            constant_result = ConstantVariable(\n                memory_format in self.is_contiguous, **options\n            )\n        elif (\n            name == \"type\"\n            and self.dtype is not None\n            and len(args) == 0\n            and isinstance(self.device, torch.device)\n        ):\n            tensortype = [k for k, v in tensortype_to_dtype.items() if self.dtype in v][\n                0\n            ]\n            if self.device.type == \"cuda\":\n                constant_result = ConstantVariable(\n                    f\"torch.cuda.{tensortype.__name__}\", **options\n                )\n            else:\n                constant_result = ConstantVariable(\n                    f\"torch.{tensortype.__name__}\", **options\n                )\n        elif (\n            name == \"type\"\n            and len(args) == 1\n            and fqn(type(args[0].as_python_constant())) == \"torch.tensortype\"\n        ):\n            # torch.FloatTensor, etc. are all of type \"torch.tensortype\".\n            # torch.fx's tracer fails on these types, because it doesn't support arguments of torch.tensortype type.\n            # So, we pass it in as a string (which is also supported, see above implementation for .type() with 0 args)\n            tensor_type = args[0].as_python_constant()\n            tensor_type_const = ConstantVariable(fqn(tensor_type), **options)\n            return wrap_fx_proxy(\n                tx,\n                tx.output.create_proxy(\n                    \"call_method\",\n                    name,\n                    *proxy_args_kwargs([self, tensor_type_const], kwargs),\n                ),\n                **options,\n            )\n        elif name == \"get_device\" and isinstance(self.device, torch.device):\n            index = self.device.index if self.device.type != \"cpu\" else -1\n            constant_result = ConstantVariable(index, **options)\n        else:\n            constant_result = None\n\n        if constant_result:\n            assert not kwargs, f\"Tensor.{name}() unhandled kwargs\"\n            # TODO: I think this branch is dead\n            if len(args) == 1:\n                return constant_result.getitem_const(args[0])\n            elif args:\n                return TupleVariable(\n                    [constant_result.getitem_const(a) for a in args], **options\n                )\n            return constant_result\n        elif name == \"numpy\":\n            assert not args, \"Tensor.numpy() doesn't take args.\"\n            # TODO: support force\n            if kwargs and \"force\" in kwargs:\n                unimplemented(f\"Tensor.numpy(force={kwargs['force']})\")\n            proxy = tx.output.create_proxy(\n                \"call_function\",\n                torch.detach,\n                *proxy_args_kwargs([self], {}),\n            )\n            return NumpyNdarrayVariable.create(tx, proxy, **options)\n\n        elif name == \"tolist\":\n            from .builder import SourcelessBuilder\n\n            def tolist(tensor, sub_proxy):\n                def wrap(i, sub_proxy):\n                    return SymNodeVariable.create(\n                        tx,\n                        sub_proxy.item(),\n                        sym_num=tx.output.shape_env.create_unbacked_symint(),\n                    )\n\n                if tensor.dtype not in [\n                    torch.int8,\n                    torch.int16,\n                    torch.int32,\n                    torch.int64,\n                ]:\n                    unimplemented(\"Input tensor for tolist must be an integer tensor\")\n\n                if tensor.dim() == 0:\n                    return wrap(tensor, sub_proxy)\n\n                if tensor.dim() == 1:\n                    return [wrap(val, sub_proxy[i]) for i, val in enumerate(tensor)]\n\n                return [\n                    tolist(sub_tensor, sub_proxy=sub_proxy[i])\n                    for i, sub_tensor in enumerate(tensor)\n                ]\n\n            tensor = self.as_proxy().node.meta[\"example_value\"]\n            out = tolist(tensor, self.as_proxy())\n            return SourcelessBuilder()(tx, out).add_options(options)\n        elif name in (\"backward\", \"data_ptr\"):\n            unimplemented(f\"Tensor.{name}\")\n        elif name == \"item\" and not config.capture_scalar_outputs:\n            unimplemented(f\"Tensor.{name}\")\n        elif name == \"__len__\":\n            return self.call_method(tx, \"size\", [ConstantVariable(0, **options)], {})\n        elif name == \"__setitem__\":\n            key, value = args\n\n            def has_bool_key(v):\n                if isinstance(v, TensorVariable):\n                    return v.dtype in (torch.bool, torch.int8)\n                elif isinstance(v, TupleVariable):\n                    return any(has_bool_key(item) for item in v.items)\n                else:\n                    return False\n\n            if (\n                not config.capture_dynamic_output_shape_ops\n                and has_bool_key(key)\n                and isinstance(value, TensorVariable)\n                and value.requires_grad\n            ):\n                unimplemented(\n                    \"boolean masking setitem backwards requires dynamic shapes\"\n                )\n            tx.output.guards.update(options[\"guards\"])\n            tx.output.create_proxy(\n                \"call_function\",\n                operator.setitem,\n                *proxy_args_kwargs([self] + list(args), kwargs),\n            )\n            return ConstantVariable(None, **options)\n        elif name in (\"resize_\", \"resize_as_\"):\n            if \"memory_format\" in kwargs:\n                memory_format = kwargs[\"memory_format\"].as_python_constant()\n            else:\n                memory_format = torch.contiguous_format\n\n            if name == \"resize_\":\n                self.size = args[0].as_python_constant()\n                self.is_contiguous = (memory_format,)\n            else:\n                assert isinstance(args[0], TensorVariable)\n                if self.size and args[0].size:\n                    if (\n                        self.size == args[0].size\n                        or memory_format is torch.preserve_format\n                    ):\n                        self.is_contiguous = args[0].is_contiguous\n                    else:\n                        self.size = args[0].size\n                        self.stride = args[0].stride\n                        self.ndim = args[0].ndim\n                        self.is_contiguous = (memory_format,)\n\n            return wrap_fx_proxy(\n                tx,\n                tx.output.create_proxy(\n                    \"call_method\",\n                    name,\n                    *proxy_args_kwargs([self] + list(args), kwargs),\n                ),\n                **options,\n            )\n        elif (\n            name == \"add_\" and len(args) == 1 and len(kwargs) == 1 and \"alpha\" in kwargs\n        ):\n            result = TorchVariable(torch.mul, **options).call_function(\n                tx, args + [kwargs[\"alpha\"]], {}\n            )\n            return self.call_method(tx, \"add_\", [result], {})\n        elif (\n            name == \"addcdiv_\"\n            and len(args) == 2\n            and len(kwargs) == 1\n            and \"value\" in kwargs\n        ):\n            result = TorchVariable(torch.div, **options).call_function(tx, args, {})\n            result = TorchVariable(torch.mul, **options).call_function(\n                tx, [result, kwargs[\"value\"]], {}\n            )\n            return self.call_method(tx, \"add_\", [result], {})\n        elif name == \"__contains__\":\n            # Rewrite __contains__ here so that downstream passes can trace through\n            # without dealing with unbacked symbool. Roughly the code we translate is:\n            # def __contains__(self, x):\n            #     return (x == self).any().item()\n            result = TorchVariable(torch.eq, **options).call_function(\n                tx, [self, args[0]], {}\n            )\n            result = TorchVariable(torch.any, **options).call_function(tx, [result], {})\n            return result.call_method(tx, \"item\", [], {})\n        elif name == \"redistribute\":\n            # rewrite non-primitive args/kwargs to be included in the on-the-fly prim function\n            # and rewrite args to have only proxyable args, then insert call_function\n            args_as_value = [x.as_python_constant() for x in args]\n\n            def redistribute_fn_with_prim_types(x):\n                return x.redistribute(*args_as_value)\n\n            # attach the same function name for better debugging\n            redistribute_fn_with_prim_types.__name__ = f\"prim_{name}\"\n\n            return wrap_fx_proxy(\n                tx=tx,\n                proxy=tx.output.create_proxy(\n                    \"call_function\",\n                    redistribute_fn_with_prim_types,\n                    *proxy_args_kwargs([self], {}),\n                ),\n                **options,\n            )\n        else:\n            # Convert x.new(torch.Size) into x.new_empty(torch.Size),\n            # as Tensor.new acts differently with a Size input versus a tuple input.\n            if (\n                name == \"new\"\n                and len(args) == 1\n                and isinstance(args[0], (SizeVariable, ShapeVariable))\n            ):\n                name = \"new_empty\"\n            return wrap_fx_proxy(\n                tx,\n                tx.output.create_proxy(\n                    \"call_method\",\n                    name,\n                    *proxy_args_kwargs([self] + list(args), kwargs),\n                ),\n                **options,\n            )", "source_start_line": 325, "tokens": ["def", "call_method", "(", "self", ",", "tx", ",", "name", ",", "args", ":", "\"List[VariableTracker]\"", ",", "kwargs", ":", "\"Dict[str, VariableTracker]\"", ",", ")", "->", "\"VariableTracker\"", ":", "if", "tx", ".", "strict_checks_enabled", ":", "if", "name", "in", "self", ".", "_strict_mode_banned_ops", "(", ")", ":", "unimplemented", "(", "f\"", "{", "name", "}", "\"", ")", "from", ".", "import", "ConstantVariable", ",", "TorchVariable", ",", "TupleVariable", "from", ".", "builder", "import", "wrap_fx_proxy", "kwargs", "=", "dict", "(", "kwargs", ")", "options", "=", "VariableTracker", ".", "propagate", "(", "self", ",", "args", ",", "kwargs", ".", "values", "(", ")", ")", "if", "name", "in", "(", "\"stride\"", ",", "\"size\"", ")", ":", "dim_var", "=", "None", "if", "len", "(", "args", ")", "==", "1", ":", "dim_var", "=", "args", "[", "0", "]", "elif", "\"dim\"", "in", "kwargs", ":", "dim_var", "=", "kwargs", "[", "\"dim\"", "]", "else", ":", "assert", "not", "args", "and", "not", "kwargs", ",", "f\"", "{", "name", "}", "\"", "dim", "=", "guard_if_dyn", "(", "dim_var", ")", "def", "make_const_size_variable", "(", "x", ",", "**", "options", ")", ":", "return", "SizeVariable", "(", "[", "ConstantVariable", "(", "y", ",", "**", "options", ")", "for", "y", "in", "x", "]", ",", "**", "options", ")", "RetVariable", "=", "(", "make_const_size_variable", "if", "name", "==", "\"size\"", "else", "ConstantVariable", ")", "if", "(", "r", ":=", "getattr", "(", "self", ",", "name", ")", ")", "is", "not", "None", ":", "if", "dim", "is", "None", ":", "return", "RetVariable", "(", "r", ",", "**", "options", ")", "else", ":", "return", "ConstantVariable", "(", "r", "[", "dim", "]", ",", "**", "options", ")", "if", "(", "fake", ":=", "self", ".", "proxy", ".", "node", ".", "meta", ".", "get", "(", "\"example_value\"", ")", ")", "is", "not", "None", ":", "if", "dim", "is", "None", ":", "fake_r", "=", "getattr", "(", "fake", ",", "name", ")", "(", ")", "if", "not", "free_symbols", "(", "fake_r", ")", ":", "return", "RetVariable", "(", "tuple", "(", "int", "(", "r", ")", "for", "r", "in", "fake_r", ")", ",", "**", "options", ")", "else", ":", "fake_r", "=", "getattr", "(", "fake", ",", "name", ")", "(", "dim", ")", "if", "not", "free_symbols", "(", "fake_r", ")", ":", "return", "ConstantVariable", "(", "int", "(", "fake_r", ")", ",", "**", "options", ")", "return", "wrap_fx_proxy", "(", "tx", ",", "tx", ".", "output", ".", "create_proxy", "(", "\"call_method\"", ",", "name", ",", "*", "proxy_args_kwargs", "(", "[", "self", "]", "+", "list", "(", "args", ")", ",", "kwargs", ")", ",", ")", ",", "**", "options", ",", ")", "elif", "name", "in", "(", "\"numel\"", ",", "\"nelement\"", ")", ":", "if", "self", ".", "size", "is", "not", "None", ":", "return", "ConstantVariable", "(", "product", "(", "self", ".", "size", ")", ",", "**", "options", ")", "if", "(", "fake", ":=", "self", ".", "proxy", ".", "node", ".", "meta", ".", "get", "(", "\"example_value\"", ")", ")", "is", "not", "None", ":", "fake_r", "=", "fake", ".", "numel", "(", ")", "if", "not", "free_symbols", "(", "fake_r", ")", ":", "return", "ConstantVariable", "(", "int", "(", "fake_r", ")", ",", "**", "options", ")", "assert", "not", "kwargs", ",", "f\"", "{", "name", "}", "\"", "return", "wrap_fx_proxy", "(", "tx", ",", "tx", ".", "output", ".", "create_proxy", "(", "\"call_method\"", ",", "\"numel\"", ",", "*", "proxy_args_kwargs", "(", "[", "self", "]", "+", "list", "(", "args", ")", ",", "kwargs", ")", ",", ")", ",", "**", "options", ",", ")", "elif", "name", "in", "(", "\"ndimension\"", ",", "\"dim\"", ")", "and", "self", ".", "ndim", "is", "not", "None", ":", "constant_result", "=", "ConstantVariable", "(", "self", ".", "ndim", ",", "**", "options", ")", "elif", "name", "==", "\"is_floating_point\"", "and", "self", ".", "dtype", "is", "not", "None", ":", "constant_result", "=", "ConstantVariable", "(", "self", ".", "dtype", ".", "is_floating_point", ",", "**", "options", ")", "elif", "name", "==", "\"is_contiguous\"", "and", "self", ".", "is_contiguous", "is", "not", "None", ":", "if", "\"memory_format\"", "in", "kwargs", ":", "memory_format", "=", "kwargs", ".", "pop", "(", "\"memory_format\"", ")", ".", "as_python_constant", "(", ")", "else", ":", "memory_format", "=", "torch", ".", "contiguous_format", "constant_result", "=", "ConstantVariable", "(", "memory_format", "in", "self", ".", "is_contiguous", ",", "**", "options", ")", "elif", "(", "name", "==", "\"type\"", "and", "self", ".", "dtype", "is", "not", "None", "and", "len", "(", "args", ")", "==", "0", "and", "isinstance", "(", "self", ".", "device", ",", "torch", ".", "device", ")", ")", ":", "tensortype", "=", "[", "k", "for", "k", ",", "v", "in", "tensortype_to_dtype", ".", "items", "(", ")", "if", "self", ".", "dtype", "in", "v", "]", "[", "0", "]", "if", "self", ".", "device", ".", "type", "==", "\"cuda\"", ":", "constant_result", "=", "ConstantVariable", "(", "f\"", "{", "tensortype", ".", "__name__", "}", "\"", ",", "**", "options", ")", "else", ":", "constant_result", "=", "ConstantVariable", "(", "f\"", "{", "tensortype", ".", "__name__", "}", "\"", ",", "**", "options", ")", "elif", "(", "name", "==", "\"type\"", "and", "len", "(", "args", ")", "==", "1", "and", "fqn", "(", "type", "(", "args", "[", "0", "]", ".", "as_python_constant", "(", ")", ")", ")", "==", "\"torch.tensortype\"", ")", ":", "tensor_type", "=", "args", "[", "0", "]", ".", "as_python_constant", "(", ")", "tensor_type_const", "=", "ConstantVariable", "(", "fqn", "(", "tensor_type", ")", ",", "**", "options", ")", "return", "wrap_fx_proxy", "(", "tx", ",", "tx", ".", "output", ".", "create_proxy", "(", "\"call_method\"", ",", "name", ",", "*", "proxy_args_kwargs", "(", "[", "self", ",", "tensor_type_const", "]", ",", "kwargs", ")", ",", ")", ",", "**", "options", ",", ")", "elif", "name", "==", "\"get_device\"", "and", "isinstance", "(", "self", ".", "device", ",", "torch", ".", "device", ")", ":", "index", "=", "self", ".", "device", ".", "index", "if", "self", ".", "device", ".", "type", "!=", "\"cpu\"", "else", "-", "1", "constant_result", "=", "ConstantVariable", "(", "index", ",", "**", "options", ")", "else", ":", "constant_result", "=", "None", "if", "constant_result", ":", "assert", "not", "kwargs", ",", "f\"", "{", "name", "}", "\"", "if", "len", "(", "args", ")", "==", "1", ":", "return", "constant_result", ".", "getitem_const", "(", "args", "[", "0", "]", ")", "elif", "args", ":", "return", "TupleVariable", "(", "[", "constant_result", ".", "getitem_const", "(", "a", ")", "for", "a", "in", "args", "]", ",", "**", "options", ")", "return", "constant_result", "elif", "name", "==", "\"numpy\"", ":", "assert", "not", "args", ",", "\"Tensor.numpy() doesn't take args.\"", "if", "kwargs", "and", "\"force\"", "in", "kwargs", ":", "unimplemented", "(", "f\"", "{", "kwargs", "[", "'force'", "]", "}", "\"", ")", "proxy", "=", "tx", ".", "output", ".", "create_proxy", "(", "\"call_function\"", ",", "torch", ".", "detach", ",", "*", "proxy_args_kwargs", "(", "[", "self", "]", ",", "{", "}", ")", ",", ")", "return", "NumpyNdarrayVariable", ".", "create", "(", "tx", ",", "proxy", ",", "**", "options", ")", "elif", "name", "==", "\"tolist\"", ":", "from", ".", "builder", "import", "SourcelessBuilder", "def", "tolist", "(", "tensor", ",", "sub_proxy", ")", ":", "def", "wrap", "(", "i", ",", "sub_proxy", ")", ":", "return", "SymNodeVariable", ".", "create", "(", "tx", ",", "sub_proxy", ".", "item", "(", ")", ",", "sym_num", "=", "tx", ".", "output", ".", "shape_env", ".", "create_unbacked_symint", "(", ")", ",", ")", "if", "tensor", ".", "dtype", "not", "in", "[", "torch", ".", "int8", ",", "torch", ".", "int16", ",", "torch", ".", "int32", ",", "torch", ".", "int64", ",", "]", ":", "unimplemented", "(", "\"Input tensor for tolist must be an integer tensor\"", ")", "if", "tensor", ".", "dim", "(", ")", "==", "0", ":", "return", "wrap", "(", "tensor", ",", "sub_proxy", ")", "if", "tensor", ".", "dim", "(", ")", "==", "1", ":", "return", "[", "wrap", "(", "val", ",", "sub_proxy", "[", "i", "]", ")", "for", "i", ",", "val", "in", "enumerate", "(", "tensor", ")", "]", "return", "[", "tolist", "(", "sub_tensor", ",", "sub_proxy", "=", "sub_proxy", "[", "i", "]", ")", "for", "i", ",", "sub_tensor", "in", "enumerate", "(", "tensor", ")", "]", "tensor", "=", "self", ".", "as_proxy", "(", ")", ".", "node", ".", "meta", "[", "\"example_value\"", "]", "out", "=", "tolist", "(", "tensor", ",", "self", ".", "as_proxy", "(", ")", ")", "return", "SourcelessBuilder", "(", ")", "(", "tx", ",", "out", ")", ".", "add_options", "(", "options", ")", "elif", "name", "in", "(", "\"backward\"", ",", "\"data_ptr\"", ")", ":", "unimplemented", "(", "f\"", "{", "name", "}", "\"", ")", "elif", "name", "==", "\"item\"", "and", "not", "config", ".", "capture_scalar_outputs", ":", "unimplemented", "(", "f\"", "{", "name", "}", "\"", ")", "elif", "name", "==", "\"__len__\"", ":", "return", "self", ".", "call_method", "(", "tx", ",", "\"size\"", ",", "[", "ConstantVariable", "(", "0", ",", "**", "options", ")", "]", ",", "{", "}", ")", "elif", "name", "==", "\"__setitem__\"", ":", "key", ",", "value", "=", "args", "def", "has_bool_key", "(", "v", ")", ":", "if", "isinstance", "(", "v", ",", "TensorVariable", ")", ":", "return", "v", ".", "dtype", "in", "(", "torch", ".", "bool", ",", "torch", ".", "int8", ")", "elif", "isinstance", "(", "v", ",", "TupleVariable", ")", ":", "return", "any", "(", "has_bool_key", "(", "item", ")", "for", "item", "in", "v", ".", "items", ")", "else", ":", "return", "False", "if", "(", "not", "config", ".", "capture_dynamic_output_shape_ops", "and", "has_bool_key", "(", "key", ")", "and", "isinstance", "(", "value", ",", "TensorVariable", ")", "and", "value", ".", "requires_grad", ")", ":", "unimplemented", "(", "\"boolean masking setitem backwards requires dynamic shapes\"", ")", "tx", ".", "output", ".", "guards", ".", "update", "(", "options", "[", "\"guards\"", "]", ")", "tx", ".", "output", ".", "create_proxy", "(", "\"call_function\"", ",", "operator", ".", "setitem", ",", "*", "proxy_args_kwargs", "(", "[", "self", "]", "+", "list", "(", "args", ")", ",", "kwargs", ")", ",", ")", "return", "ConstantVariable", "(", "None", ",", "**", "options", ")", "elif", "name", "in", "(", "\"resize_\"", ",", "\"resize_as_\"", ")", ":", "if", "\"memory_format\"", "in", "kwargs", ":", "memory_format", "=", "kwargs", "[", "\"memory_format\"", "]", ".", "as_python_constant", "(", ")", "else", ":", "memory_format", "=", "torch", ".", "contiguous_format", "if", "name", "==", "\"resize_\"", ":", "self", ".", "size", "=", "args", "[", "0", "]", ".", "as_python_constant", "(", ")", "self", ".", "is_contiguous", "=", "(", "memory_format", ",", ")", "else", ":", "assert", "isinstance", "(", "args", "[", "0", "]", ",", "TensorVariable", ")", "if", "self", ".", "size", "and", "args", "[", "0", "]", ".", "size", ":", "if", "(", "self", ".", "size", "==", "args", "[", "0", "]", ".", "size", "or", "memory_format", "is", "torch", ".", "preserve_format", ")", ":", "self", ".", "is_contiguous", "=", "args", "[", "0", "]", ".", "is_contiguous", "else", ":", "self", ".", "size", "=", "args", "[", "0", "]", ".", "size", "self", ".", "stride", "=", "args", "[", "0", "]", ".", "stride", "self", ".", "ndim", "=", "args", "[", "0", "]", ".", "ndim", "self", ".", "is_contiguous", "=", "(", "memory_format", ",", ")", "return", "wrap_fx_proxy", "(", "tx", ",", "tx", ".", "output", ".", "create_proxy", "(", "\"call_method\"", ",", "name", ",", "*", "proxy_args_kwargs", "(", "[", "self", "]", "+", "list", "(", "args", ")", ",", "kwargs", ")", ",", ")", ",", "**", "options", ",", ")", "elif", "(", "name", "==", "\"add_\"", "and", "len", "(", "args", ")", "==", "1", "and", "len", "(", "kwargs", ")", "==", "1", "and", "\"alpha\"", "in", "kwargs", ")", ":", "result", "=", "TorchVariable", "(", "torch", ".", "mul", ",", "**", "options", ")", ".", "call_function", "(", "tx", ",", "args", "+", "[", "kwargs", "[", "\"alpha\"", "]", "]", ",", "{", "}", ")", "return", "self", ".", "call_method", "(", "tx", ",", "\"add_\"", ",", "[", "result", "]", ",", "{", "}", ")", "elif", "(", "name", "==", "\"addcdiv_\"", "and", "len", "(", "args", ")", "==", "2", "and", "len", "(", "kwargs", ")", "==", "1", "and", "\"value\"", "in", "kwargs", ")", ":", "result", "=", "TorchVariable", "(", "torch", ".", "div", ",", "**", "options", ")", ".", "call_function", "(", "tx", ",", "args", ",", "{", "}", ")", "result", "=", "TorchVariable", "(", "torch", ".", "mul", ",", "**", "options", ")", ".", "call_function", "(", "tx", ",", "[", "result", ",", "kwargs", "[", "\"value\"", "]", "]", ",", "{", "}", ")", "return", "self", ".", "call_method", "(", "tx", ",", "\"add_\"", ",", "[", "result", "]", ",", "{", "}", ")", "elif", "name", "==", "\"__contains__\"", ":", "result", "=", "TorchVariable", "(", "torch", ".", "eq", ",", "**", "options", ")", ".", "call_function", "(", "tx", ",", "[", "self", ",", "args", "[", "0", "]", "]", ",", "{", "}", ")", "result", "=", "TorchVariable", "(", "torch", ".", "any", ",", "**", "options", ")", ".", "call_function", "(", "tx", ",", "[", "result", "]", ",", "{", "}", ")", "return", "result", ".", "call_method", "(", "tx", ",", "\"item\"", ",", "[", "]", ",", "{", "}", ")", "elif", "name", "==", "\"redistribute\"", ":", "args_as_value", "=", "[", "x", ".", "as_python_constant", "(", ")", "for", "x", "in", "args", "]", "def", "redistribute_fn_with_prim_types", "(", "x", ")", ":", "return", "x", ".", "redistribute", "(", "*", "args_as_value", ")", "redistribute_fn_with_prim_types", ".", "__name__", "=", "f\"", "{", "name", "}", "\"", "return", "wrap_fx_proxy", "(", "tx", "=", "tx", ",", "proxy", "=", "tx", ".", "output", ".", "create_proxy", "(", "\"call_function\"", ",", "redistribute_fn_with_prim_types", ",", "*", "proxy_args_kwargs", "(", "[", "self", "]", ",", "{", "}", ")", ",", ")", ",", "**", "options", ",", ")", "else", ":", "if", "(", "name", "==", "\"new\"", "and", "len", "(", "args", ")", "==", "1", "and", "isinstance", "(", "args", "[", "0", "]", ",", "(", "SizeVariable", ",", "ShapeVariable", ")", ")", ")", ":", "name", "=", "\"new_empty\"", "return", "wrap_fx_proxy", "(", "tx", ",", "tx", ".", "output", ".", "create_proxy", "(", "\"call_method\"", ",", "name", ",", "*", "proxy_args_kwargs", "(", "[", "self", "]", "+", "list", "(", "args", ")", ",", "kwargs", ")", ",", ")", ",", "**", "options", ",", ")"], "to_mask": {"VAR": ["RetVariable", "__name__", "args", "args_as_value", "constant_result", "dim", "dim_var", "fake_r", "i", "index", "is_contiguous", "k", "key", "kwargs", "memory_format", "name", "ndim", "options", "out", "proxy", "result", "self", "size", "stride", "sub_proxy", "sub_tensor", "tensor", "tensor_type", "tensor_type_const", "tensortype", "tx", "v", "val", "value", "x"], "METHOD": ["ConstantVariable", "RetVariable", "SizeVariable", "SourcelessBuilder", "TorchVariable", "TupleVariable", "_strict_mode_banned_ops", "add_options", "any", "as_proxy", "as_python_constant", "call_function", "call_method", "create", "create_proxy", "create_unbacked_symint", "dict", "dim", "enumerate", "fqn", "free_symbols", "get", "getattr", "getitem_const", "guard_if_dyn", "has_bool_key", "int", "isinstance", "item", "items", "len", "list", "numel", "pop", "product", "propagate", "proxy_args_kwargs", "redistribute", "tolist", "tuple", "type", "unimplemented", "update", "values", "wrap", "wrap_fx_proxy"]}, "attention_idx_tokens": [905, 916], "patch": "@@ -479,23 +479,17 @@\n                 )\n             return constant_result\n         elif name == \"numpy\":\n-            from .builder import wrap_fx_proxy_cls\n-\n             assert not args, \"Tensor.numpy() doesn't take args.\"\n             # TODO: support force\n             if kwargs and \"force\" in kwargs:\n                 unimplemented(f\"Tensor.numpy(force={kwargs['force']})\")\n-            return wrap_fx_proxy_cls(\n-                target_cls=NumpyNdarrayVariable,\n-                tx=tx,\n-                proxy=tx.output.create_proxy(\n-                    \"call_function\",\n-                    torch.detach,\n-                    *proxy_args_kwargs([self], {}),\n-                ),\n-                example_value=None,\n-                **options,\n+            proxy = tx.output.create_proxy(\n+                \"call_function\",\n+                torch.detach,\n+                *proxy_args_kwargs([self], {}),\n             )\n+            return NumpyNdarrayVariable.create(tx, proxy, **options)", "ext_attention_idx_tokens": [856, 921], "uid": "79e85397", "question": "Is this just a refactor?", "code": "def call method self tx name args \"List[VariableTracker]\" kwargs \"Dict[str VariableTracker]\" -> \"VariableTracker\" if tx strict checks enabled if name in self strict mode banned ops unimplemented f\"Illegal method invocation {name} in strict mode\" from import ConstantVariable TorchVariable TupleVariable from builder import wrap fx proxy kwargs dict kwargs options VariableTracker propagate self args kwargs values if name in \"stride\" \"size\" dim var None if len args 1 dim var args[0] elif \"dim\" in kwargs dim var kwargs[\"dim\"] else assert not args and not kwargs f\"Tensor {name} unhandled args kwargs\" dim guard if dyn dim var def make const size variable x **options return SizeVariable [ConstantVariable y **options for y in x] **options RetVariable make const size variable if name \"size\" else ConstantVariable # Technically this should not be necessary but I m including it # for enhanced BC in case example value is sometimes not set # it really should always be set though! if r getattr self name is not None if dim is None return RetVariable r **options else return ConstantVariable r[dim] **options # It might still be constant! Consult the fake tensor and see if fake self proxy node meta get \"example value\" is not None if dim is None fake r getattr fake name if not free symbols fake r # int conversion for safety in case a SymInt refined # to constant return RetVariable tuple int r for r in fake r **options else fake r getattr fake name dim if not free symbols fake r return ConstantVariable int fake r **options # Oops it s not constant Do the dynamic shapes path return wrap fx proxy tx tx output create proxy \"call method\" name *proxy args kwargs [self] + list args kwargs **options elif name in \"numel\" \"nelement\" if self size is not None return ConstantVariable product self size **options # It might still be constant! Consult the fake tensor and see if fake self proxy node meta get \"example value\" is not None fake r fake numel if not free symbols fake r return ConstantVariable int fake r **options assert not kwargs f\"Tensor {name} unhandled kwargs\" # Oops it s not constant Do the dynamic shapes path return wrap fx proxy tx tx output create proxy \"call method\" \"numel\" *proxy args kwargs [self] + list args kwargs **options elif name in \"ndimension\" \"dim\" and self ndim is not None constant result ConstantVariable self ndim **options elif name \"is floating point\" and self dtype is not None constant result ConstantVariable self dtype is floating point **options elif name \"is contiguous\" and self is contiguous is not None if \"memory format\" in kwargs memory format kwargs pop \"memory format\" as python constant else memory format torch contiguous format constant result ConstantVariable memory format in self is contiguous **options elif name \"type\" and self dtype is not None and len args 0 and isinstance self device torch device tensortype [k for k v in tensortype to dtype items if self dtype in v][ 0 ] if self device type \"cuda\" constant result ConstantVariable f\"torch cuda {tensortype name }\" **options else constant result ConstantVariable f\"torch {tensortype name }\" **options elif name \"type\" and len args 1 and fqn type args[0] as python constant \"torch tensortype\" # torch FloatTensor etc are all of type \"torch tensortype\" # torch fx s tracer fails on these types because it doesn t support arguments of torch tensortype type # So we pass it in as a string which is also supported see above implementation for type with 0 args tensor type args[0] as python constant tensor type const ConstantVariable fqn tensor type **options return wrap fx proxy tx tx output create proxy \"call method\" name *proxy args kwargs [self tensor type const] kwargs **options elif name \"get device\" and isinstance self device torch device index self device index if self device type ! \"cpu\" else -1 constant result ConstantVariable index **options else constant result None if constant result assert not kwargs f\"Tensor {name} unhandled kwargs\" # TODO I think this branch is dead if len args 1 return constant result getitem const args[0] elif args return TupleVariable [constant result getitem const a for a in args] **options return constant result elif name \"numpy\" assert not args \"Tensor numpy doesn t take args \" # TODO support force if kwargs and \"force\" in kwargs unimplemented f\"Tensor numpy force {kwargs[ force ]} \" proxy tx output create proxy \"call function\" torch detach *proxy args kwargs [self] {} return NumpyNdarrayVariable create tx proxy **options elif name \"tolist\" from builder import SourcelessBuilder def tolist tensor sub proxy def wrap i sub proxy return SymNodeVariable create tx sub proxy item sym num tx output shape env create unbacked symint if tensor dtype not in [ torch int8 torch int16 torch int32 torch int64 ] unimplemented \"Input tensor for tolist must be an integer tensor\" if tensor dim 0 return wrap tensor sub proxy if tensor dim 1 return [wrap val sub proxy[i] for i val in enumerate tensor ] return [ tolist sub tensor sub proxy sub proxy[i] for i sub tensor in enumerate tensor ] tensor self as proxy node meta[\"example value\"] out tolist tensor self as proxy return SourcelessBuilder tx out add options options elif name in \"backward\" \"data ptr\" unimplemented f\"Tensor {name}\" elif name \"item\" and not config capture scalar outputs unimplemented f\"Tensor {name}\" elif name \" len \" return self call method tx \"size\" [ConstantVariable 0 **options ] {} elif name \" setitem \" key value args def has bool key v if isinstance v TensorVariable return v dtype in torch bool torch int8 elif isinstance v TupleVariable return any has bool key item for item in v items else return False if not config capture dynamic output shape ops and has bool key key and isinstance value TensorVariable and value requires grad unimplemented \"boolean masking setitem backwards requires dynamic shapes\" tx output guards update options[\"guards\"] tx output create proxy \"call function\" operator setitem *proxy args kwargs [self] + list args kwargs return ConstantVariable None **options elif name in \"resize \" \"resize as \" if \"memory format\" in kwargs memory format kwargs[\"memory format\"] as python constant else memory format torch contiguous format if name \"resize \" self size args[0] as python constant self is contiguous memory format else assert isinstance args[0] TensorVariable if self size and args[0] size if self size args[0] size or memory format is torch preserve format self is contiguous args[0] is contiguous else self size args[0] size self stride args[0] stride self ndim args[0] ndim self is contiguous memory format return wrap fx proxy tx tx output create proxy \"call method\" name *proxy args kwargs [self] + list args kwargs **options elif name \"add \" and len args 1 and len kwargs 1 and \"alpha\" in kwargs result TorchVariable torch mul **options call function tx args + [kwargs[\"alpha\"]] {} return self call method tx \"add \" [result] {} elif name \"addcdiv \" and len args 2 and len kwargs 1 and \"value\" in kwargs result TorchVariable torch div **options call function tx args {} result TorchVariable torch mul **options call function tx [result kwargs[\"value\"]] {} return self call method tx \"add \" [result] {} elif name \" contains \" # Rewrite contains here so that downstream passes can trace through # without dealing with unbacked symbool Roughly the code we translate is # def contains self x # return x self any item result TorchVariable torch eq **options call function tx [self args[0]] {} result TorchVariable torch any **options call function tx [result] {} return result call method tx \"item\" [] {} elif name \"redistribute\" # rewrite non-primitive args kwargs to be included in the on-the-fly prim function # and rewrite args to have only proxyable args then insert call function args as value [x as python constant for x in args] def redistribute fn with prim types x return x redistribute *args as value # attach the same function name for better debugging redistribute fn with prim types name f\"prim {name}\" return wrap fx proxy tx tx proxy tx output create proxy \"call function\" redistribute fn with prim types *proxy args kwargs [self] {} **options else # Convert x new torch Size into x new empty torch Size # as Tensor new acts differently with a Size input versus a tuple input if name \"new\" and len args 1 and isinstance args[0] SizeVariable ShapeVariable name \"new empty\" return wrap fx proxy tx tx output create proxy \"call method\" name *proxy args kwargs [self] + list args kwargs **options"}
{"message": "Why does this util exist then? Can we collapse them?", "timestamp": "2023-08-02T20:20:47Z", "file_name": "torch/_dynamo/utils.py", "range": {"start_line": 1649, "end_line": 1649, "start_character": 0, "end_character": 0}, "project": "pytorch/pytorch", "api_url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/1282381532", "html_url": "https://github.com/pytorch/pytorch/pull/106431#discussion_r1282381532", "attention_area": "        return numpy_to_tensor(tnp.array(value, dtype=str(value.dtype)))", "file_path": "files/81/00/00000081.py", "old_file_path": "files/82/00/00000082.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1645,6 +1645,8 @@ def to_numpy_helper(value):\n \n def numpy_to_tensor(value):\n     \"\"\"Convert tnp.ndarray to tensor, leave other types intact. If a list/tuple, loop through it to convert.\"\"\"\n+    if isinstance(value, np.ndarray):\n+        return numpy_to_tensor(tnp.array(value, dtype=str(value.dtype)))", "source": "def numpy_to_tensor(value):\n    \"\"\"Convert tnp.ndarray to tensor, leave other types intact. If a list/tuple, loop through it to convert.\"\"\"\n    if isinstance(value, np.ndarray):\n        return numpy_to_tensor(tnp.array(value, dtype=str(value.dtype)))\n    if isinstance(value, tnp.ndarray):\n        return value.tensor\n    elif isinstance(value, (tuple, list)):\n        return type(value)(numpy_to_tensor(obj) for obj in value)\n    else:\n        return value", "source_start_line": 1646, "tokens": ["def", "numpy_to_tensor", "(", "value", ")", ":", "\"\"\"Convert tnp.ndarray to tensor, leave other types intact. If a list/tuple, loop through it to convert.\"\"\"", "if", "isinstance", "(", "value", ",", "np", ".", "ndarray", ")", ":", "return", "numpy_to_tensor", "(", "tnp", ".", "array", "(", "value", ",", "dtype", "=", "str", "(", "value", ".", "dtype", ")", ")", ")", "if", "isinstance", "(", "value", ",", "tnp", ".", "ndarray", ")", ":", "return", "value", ".", "tensor", "elif", "isinstance", "(", "value", ",", "(", "tuple", ",", "list", ")", ")", ":", "return", "type", "(", "value", ")", "(", "numpy_to_tensor", "(", "obj", ")", "for", "obj", "in", "value", ")", "else", ":", "return", "value"], "to_mask": {"VAR": ["value"], "METHOD": ["array", "isinstance", "numpy_to_tensor", "str", "type"]}, "attention_idx_tokens": [17, 35], "patch": "@@ -1645,6 +1645,8 @@\n \n def numpy_to_tensor(value):\n     \"\"\"Convert tnp.ndarray to tensor, leave other types intact. If a list/tuple, loop through it to convert.\"\"\"\n+    if isinstance(value, np.ndarray):\n+        return numpy_to_tensor(tnp.array(value, dtype=str(value.dtype)))", "ext_attention_idx_tokens": [7, 45], "uid": "e230dffb", "question": "Why does this util exist then? Can we collapse them?", "code": "def numpy to tensor value \"\"\"Convert tnp ndarray to tensor leave other types intact If a list tuple loop through it to convert \"\"\" if isinstance value np ndarray return numpy to tensor tnp array value dtype str value dtype if isinstance value tnp ndarray return value tensor elif isinstance value tuple list return type value numpy to tensor obj for obj in value else return value"}
{"message": "does this... do anything lol", "timestamp": "2023-08-02T20:57:03Z", "file_name": "torch/_dynamo/codegen.py", "range": {"start_line": 160, "end_line": 160, "start_character": 0, "end_character": 0}, "project": "pytorch/pytorch", "api_url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/1282411879", "html_url": "https://github.com/pytorch/pytorch/pull/106431#discussion_r1282411879", "attention_area": "        graph_outputs_key = id(value.as_proxy())", "file_path": "files/87/00/00000087.py", "old_file_path": "files/88/00/00000088.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -157,7 +157,7 @@ def __call__(self, value, allow_cache=True):\n         self.top_of_stack = value\n \n     def add_graph_output(self, value):\n-        graph_outputs_key = id(value.proxy)\n+        graph_outputs_key = id(value.as_proxy())", "source": "def add_graph_output(self, value):\n        graph_outputs_key = id(value.as_proxy())\n        if graph_outputs_key not in self.graph_outputs:\n            self.graph_outputs[graph_outputs_key] = GraphOutputEntry(\n                len(self.graph_outputs), value\n            )\n        else:\n            self.graph_outputs[graph_outputs_key].merge(value)\n\n        return graph_outputs_key", "source_start_line": 159, "tokens": ["def", "add_graph_output", "(", "self", ",", "value", ")", ":", "graph_outputs_key", "=", "id", "(", "value", ".", "as_proxy", "(", ")", ")", "if", "graph_outputs_key", "not", "in", "self", ".", "graph_outputs", ":", "self", ".", "graph_outputs", "[", "graph_outputs_key", "]", "=", "GraphOutputEntry", "(", "len", "(", "self", ".", "graph_outputs", ")", ",", "value", ")", "else", ":", "self", ".", "graph_outputs", "[", "graph_outputs_key", "]", ".", "merge", "(", "value", ")", "return", "graph_outputs_key"], "to_mask": {"VAR": ["graph_outputs_key", "self", "value"], "METHOD": ["GraphOutputEntry", "as_proxy", "id", "len", "merge"]}, "attention_idx_tokens": [8, 17], "patch": "@@ -157,7 +157,7 @@\n         self.top_of_stack = value\n \n     def add_graph_output(self, value):\n-        graph_outputs_key = id(value.proxy)\n+        graph_outputs_key = id(value.as_proxy())", "ext_attention_idx_tokens": [8, 25], "uid": "2db7128b", "question": "does this... do anything lol", "code": "def add graph output self value graph outputs key id value as proxy if graph outputs key not in self graph outputs self graph outputs[graph outputs key] GraphOutputEntry len self graph outputs value else self graph outputs[graph outputs key] merge value return graph outputs key"}
{"message": "Let me double check, I am pretty certain we do hit this, and that is why I added it. Why would you expect us to not get here? ", "timestamp": "2023-08-07T02:07:55Z", "file_name": "torch/_dynamo/utils.py", "range": {"start_line": 1649, "end_line": 1649, "start_character": 0, "end_character": 0}, "project": "pytorch/pytorch", "api_url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/1285314180", "html_url": "https://github.com/pytorch/pytorch/pull/106431#discussion_r1285314180", "attention_area": "        return torch.as_tensor(value)", "file_path": "files/94/00/00000094.py", "old_file_path": "files/82/00/00000082.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1645,6 +1645,8 @@ def to_numpy_helper(value):\n \n def numpy_to_tensor(value):\n     \"\"\"Convert tnp.ndarray to tensor, leave other types intact. If a list/tuple, loop through it to convert.\"\"\"\n+    if isinstance(value, np.ndarray):\n+        return torch.as_tensor(value)", "source": "def numpy_to_tensor(value):\n    \"\"\"Convert tnp.ndarray to tensor, leave other types intact. If a list/tuple, loop through it to convert.\"\"\"\n    if isinstance(value, np.ndarray):\n        return torch.as_tensor(value)\n    if isinstance(value, tnp.ndarray):\n        return value.tensor\n    elif isinstance(value, (tuple, list)):\n        return type(value)(numpy_to_tensor(obj) for obj in value)\n    else:\n        return value", "source_start_line": 1646, "tokens": ["def", "numpy_to_tensor", "(", "value", ")", ":", "\"\"\"Convert tnp.ndarray to tensor, leave other types intact. If a list/tuple, loop through it to convert.\"\"\"", "if", "isinstance", "(", "value", ",", "np", ".", "ndarray", ")", ":", "return", "torch", ".", "as_tensor", "(", "value", ")", "if", "isinstance", "(", "value", ",", "tnp", ".", "ndarray", ")", ":", "return", "value", ".", "tensor", "elif", "isinstance", "(", "value", ",", "(", "tuple", ",", "list", ")", ")", ":", "return", "type", "(", "value", ")", "(", "numpy_to_tensor", "(", "obj", ")", "for", "obj", "in", "value", ")", "else", ":", "return", "value"], "to_mask": {"VAR": ["value"], "METHOD": ["as_tensor", "isinstance", "numpy_to_tensor", "type"]}, "attention_idx_tokens": [17, 23], "patch": "@@ -1645,6 +1645,8 @@\n \n def numpy_to_tensor(value):\n     \"\"\"Convert tnp.ndarray to tensor, leave other types intact. If a list/tuple, loop through it to convert.\"\"\"\n+    if isinstance(value, np.ndarray):\n+        return torch.as_tensor(value)", "ext_attention_idx_tokens": [7, 33], "uid": "35b0ceb1", "question": "Let me double check, I am pretty certain we do hit this, and that is why I added it. Why would you expect us to not get here? ", "code": "def numpy to tensor value \"\"\"Convert tnp ndarray to tensor leave other types intact If a list tuple loop through it to convert \"\"\" if isinstance value np ndarray return torch as tensor value if isinstance value tnp ndarray return value tensor elif isinstance value tuple list return type value numpy to tensor obj for obj in value else return value"}
{"message": "What is the difference before and after? Or is this just refactoring.", "timestamp": "2023-08-07T18:54:04Z", "file_name": "torch/_dynamo/variables/misc.py", "range": {"start_line": 846, "end_line": 846, "start_character": 0, "end_character": 0}, "project": "pytorch/pytorch", "api_url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/1286276678", "html_url": "https://github.com/pytorch/pytorch/pull/106431#discussion_r1286276678", "attention_area": "            return NumpyNdarrayVariable.create(tx, proxy, **options)", "file_path": "files/95/00/00000095.py", "old_file_path": "files/96/00/00000096.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -839,17 +838,12 @@ def call_function(\n \n             # TODO(larryliu0820): currently assuming all numpy.* functions are returning a ndarray that can be\n             #  wrapped by NumpyNdarrayVariable which is wrong!\n-            return wrap_fx_proxy_cls(\n-                target_cls=NumpyNdarrayVariable,\n-                tx=tx,\n-                proxy=tx.output.create_proxy(\n-                    \"call_function\",\n-                    numpy_to_tensor_wrapper(func),\n-                    *proxy_args_kwargs(args, kwargs),\n-                ),\n-                example_value=None,\n-                **options,\n+            proxy = tx.output.create_proxy(\n+                \"call_function\",\n+                numpy_to_tensor_wrapper(func),\n+                *proxy_args_kwargs(args, kwargs),\n             )\n+            return NumpyNdarrayVariable.create(tx, proxy, **options)", "source": "def call_function(\n        self, tx, args: \"List[VariableTracker]\", kwargs: \"Dict[str, VariableTracker]\"\n    ) -> \"VariableTracker\":\n        from ..utils import numpy_to_tensor_wrapper\n\n        from .tensor import NumpyNdarrayVariable\n\n        options = VariableTracker.propagate([[self]], [args], [list(kwargs.values())])\n        # lookup method name in tnp. Things like np.dtype(float) are not supported yet.\n        if self.value.__name__ == \"dtype\":\n            unimplemented(\n                f\"numpy dtype function is not supported yet. Got type {type(self.value)}.\"\n            )\n        else:  # We are dealing with a callable.\n            func = get_np_to_tnp_map().get(self.value)\n            if func is None:\n                unimplemented(\n                    f\"Can't find numpy function {self.value} in torch._numpy. \"\n                    \" Please file an issue to request support for this function.\"\n                )\n\n            # TODO(larryliu0820): currently assuming all numpy.* functions are returning a ndarray that can be\n            #  wrapped by NumpyNdarrayVariable which is wrong!\n            proxy = tx.output.create_proxy(\n                \"call_function\",\n                numpy_to_tensor_wrapper(func),\n                *proxy_args_kwargs(args, kwargs),\n            )\n            return NumpyNdarrayVariable.create(tx, proxy, **options)", "source_start_line": 818, "tokens": ["def", "call_function", "(", "self", ",", "tx", ",", "args", ":", "\"List[VariableTracker]\"", ",", "kwargs", ":", "\"Dict[str, VariableTracker]\"", ")", "->", "\"VariableTracker\"", ":", "from", ".", ".", "utils", "import", "numpy_to_tensor_wrapper", "from", ".", "tensor", "import", "NumpyNdarrayVariable", "options", "=", "VariableTracker", ".", "propagate", "(", "[", "[", "self", "]", "]", ",", "[", "args", "]", ",", "[", "list", "(", "kwargs", ".", "values", "(", ")", ")", "]", ")", "if", "self", ".", "value", ".", "__name__", "==", "\"dtype\"", ":", "unimplemented", "(", "f\"", "{", "type", "(", "self", ".", "value", ")", "}", "\"", ")", "else", ":", "func", "=", "get_np_to_tnp_map", "(", ")", ".", "get", "(", "self", ".", "value", ")", "if", "func", "is", "None", ":", "unimplemented", "(", "f\"", "{", "self", ".", "value", "}", "\"", "\" Please file an issue to request support for this function.\"", ")", "proxy", "=", "tx", ".", "output", ".", "create_proxy", "(", "\"call_function\"", ",", "numpy_to_tensor_wrapper", "(", "func", ")", ",", "*", "proxy_args_kwargs", "(", "args", ",", "kwargs", ")", ",", ")", "return", "NumpyNdarrayVariable", ".", "create", "(", "tx", ",", "proxy", ",", "**", "options", ")"], "to_mask": {"VAR": ["args", "func", "kwargs", "options", "proxy", "self", "tx"], "METHOD": ["create", "create_proxy", "get", "get_np_to_tnp_map", "list", "numpy_to_tensor_wrapper", "propagate", "proxy_args_kwargs", "type", "unimplemented", "values"]}, "attention_idx_tokens": [132, 143], "patch": "@@ -839,17 +838,12 @@\n \n             # TODO(larryliu0820): currently assuming all numpy.* functions are returning a ndarray that can be\n             #  wrapped by NumpyNdarrayVariable which is wrong!\n-            return wrap_fx_proxy_cls(\n-                target_cls=NumpyNdarrayVariable,\n-                tx=tx,\n-                proxy=tx.output.create_proxy(\n-                    \"call_function\",\n-                    numpy_to_tensor_wrapper(func),\n-                    *proxy_args_kwargs(args, kwargs),\n-                ),\n-                example_value=None,\n-                **options,\n+            proxy = tx.output.create_proxy(\n+                \"call_function\",\n+                numpy_to_tensor_wrapper(func),\n+                *proxy_args_kwargs(args, kwargs),\n             )\n+            return NumpyNdarrayVariable.create(tx, proxy, **options)", "ext_attention_idx_tokens": [108, 143], "uid": "53461e31", "question": "What is the difference before and after? Or is this just refactoring.", "code": "def call function self tx args \"List[VariableTracker]\" kwargs \"Dict[str VariableTracker]\" -> \"VariableTracker\" from utils import numpy to tensor wrapper from tensor import NumpyNdarrayVariable options VariableTracker propagate [[self]] [args] [list kwargs values ] # lookup method name in tnp Things like np dtype float are not supported yet if self value name \"dtype\" unimplemented f\"numpy dtype function is not supported yet Got type {type self value } \" else # We are dealing with a callable func get np to tnp map get self value if func is None unimplemented f\"Can t find numpy function {self value} in torch numpy \" \" Please file an issue to request support for this function \" # TODO larryliu0820 currently assuming all numpy * functions are returning a ndarray that can be # wrapped by NumpyNdarrayVariable which is wrong! proxy tx output create proxy \"call function\" numpy to tensor wrapper func *proxy args kwargs args kwargs return NumpyNdarrayVariable create tx proxy **options"}
{"message": "Why increment max version by 2?", "timestamp": "2022-12-06T08:33:30Z", "file_name": "tensorflow/lite/core/kernels/register.cc", "range": {"start_line": 60, "end_line": 60, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1040650205", "html_url": "https://github.com/tensorflow/tensorflow/pull/58400#discussion_r1040650205", "attention_area": "             /* max_version = */ 8);", "file_path": "files/03/00/00000003.cc", "old_file_path": "files/02/00/00000002.cc", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -57,7 +57,7 @@ BuiltinOpResolver::BuiltinOpResolver() {\n   AddBuiltin(BuiltinOperator_L2_POOL_2D, Register_L2_POOL_2D());\n   AddBuiltin(BuiltinOperator_CONV_2D, Register_CONV_2D(),\n              /* min_version = */ 1,\n-             /* max_version = */ 6);\n+             /* max_version = */ 8);", "source": "BuiltinOpResolver::BuiltinOpResolver() {\n  AddBuiltin(BuiltinOperator_ABS, Register_ABS(), /* min_version = */ 1,\n             /* max_version = */ 5);\n  AddBuiltin(BuiltinOperator_HARD_SWISH, Register_HARD_SWISH());\n  AddBuiltin(BuiltinOperator_RELU, Register_RELU(), /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_RELU_N1_TO_1, Register_RELU_N1_TO_1());\n  AddBuiltin(BuiltinOperator_RELU_0_TO_1, Register_RELU_0_TO_1());\n  AddBuiltin(BuiltinOperator_RELU6, Register_RELU6(), /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_TANH, Register_TANH(), /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_LOGISTIC, Register_LOGISTIC(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_AVERAGE_POOL_2D, Register_AVERAGE_POOL_2D(),\n             /* min_version */ 1,\n             /* max_version */ 3);\n  AddBuiltin(BuiltinOperator_MAX_POOL_2D, Register_MAX_POOL_2D(),\n             /* min_version */ 1,\n             /* max_version */ 3);\n  AddBuiltin(BuiltinOperator_L2_POOL_2D, Register_L2_POOL_2D());\n  AddBuiltin(BuiltinOperator_CONV_2D, Register_CONV_2D(),\n             /* min_version = */ 1,\n             /* max_version = */ 8);\n  AddBuiltin(BuiltinOperator_DEPTHWISE_CONV_2D, Register_DEPTHWISE_CONV_2D(),\n             /* min_version = */ 1,\n             /* max_version = */ 7);\n  AddBuiltin(BuiltinOperator_SVDF, Register_SVDF(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_RNN, Register_RNN(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_BIDIRECTIONAL_SEQUENCE_RNN,\n             Register_BIDIRECTIONAL_SEQUENCE_RNN(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_UNIDIRECTIONAL_SEQUENCE_RNN,\n             Register_UNIDIRECTIONAL_SEQUENCE_RNN(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_EMBEDDING_LOOKUP, Register_EMBEDDING_LOOKUP(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_EMBEDDING_LOOKUP_SPARSE,\n             Register_EMBEDDING_LOOKUP_SPARSE());\n  AddBuiltin(BuiltinOperator_FULLY_CONNECTED, Register_FULLY_CONNECTED(),\n             /* min_version = */ 1,\n             /* max_version = */ 11);\n  AddBuiltin(BuiltinOperator_LSH_PROJECTION, Register_LSH_PROJECTION());\n  AddBuiltin(BuiltinOperator_HASHTABLE_LOOKUP, Register_HASHTABLE_LOOKUP());\n  AddBuiltin(BuiltinOperator_SOFTMAX, Register_SOFTMAX(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_CONCATENATION, Register_CONCATENATION(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_ADD, Register_ADD(),\n             /* min_version */ 1,\n             /* max_version */ 5);\n  AddBuiltin(BuiltinOperator_SPACE_TO_BATCH_ND, Register_SPACE_TO_BATCH_ND(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_BATCH_TO_SPACE_ND, Register_BATCH_TO_SPACE_ND(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_MUL, Register_MUL(), /* min_version = */ 1,\n             /* max_version = */ 7);\n  AddBuiltin(BuiltinOperator_L2_NORMALIZATION, Register_L2_NORMALIZATION(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_LOCAL_RESPONSE_NORMALIZATION,\n             Register_LOCAL_RESPONSE_NORMALIZATION());\n  AddBuiltin(BuiltinOperator_LSTM, Register_LSTM(), /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_BIDIRECTIONAL_SEQUENCE_LSTM,\n             Register_BIDIRECTIONAL_SEQUENCE_LSTM(), /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_UNIDIRECTIONAL_SEQUENCE_LSTM,\n             Register_UNIDIRECTIONAL_SEQUENCE_LSTM(), /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_PAD, Register_PAD(), /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_PADV2, Register_PADV2(), /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_RESHAPE, Register_RESHAPE());\n  AddBuiltin(BuiltinOperator_RESIZE_BILINEAR, Register_RESIZE_BILINEAR(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_RESIZE_NEAREST_NEIGHBOR,\n             Register_RESIZE_NEAREST_NEIGHBOR(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_SKIP_GRAM, Register_SKIP_GRAM());\n  AddBuiltin(BuiltinOperator_SPACE_TO_DEPTH, Register_SPACE_TO_DEPTH(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_DEPTH_TO_SPACE, Register_DEPTH_TO_SPACE(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_GATHER, Register_GATHER(),\n             /* min_version = */ 1,\n             /* max_version = */ 6);\n  AddBuiltin(BuiltinOperator_TRANSPOSE, Register_TRANSPOSE(),\n             /* min_version = */ 1,\n             /* max_version = */ 6);\n  AddBuiltin(BuiltinOperator_MEAN, Register_MEAN(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_DIV, Register_DIV(),\n             /* min_version */ 1,\n             /* max_version */ 2);\n  AddBuiltin(BuiltinOperator_SUB, Register_SUB(),\n             /* min_version = */ 1,\n             /* max_version = */ 5);\n  AddBuiltin(BuiltinOperator_SPLIT, Register_SPLIT(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_SPLIT_V, Register_SPLIT_V(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_SQUEEZE, Register_SQUEEZE(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_STRIDED_SLICE, Register_STRIDED_SLICE(),\n             /* min_version = */ 1,\n             /* max_version = */ 8);\n  AddBuiltin(BuiltinOperator_EXP, Register_EXP(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_TOPK_V2, Register_TOPK_V2(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_LOG, Register_LOG(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_LOG_SOFTMAX, Register_LOG_SOFTMAX(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_CAST, Register_CAST(),\n             /* min_version = */ 1,\n             /* max_version = */ 5);\n  AddBuiltin(BuiltinOperator_DEQUANTIZE, Register_DEQUANTIZE(),\n             /* min_version = */ 1,\n             /* max_version = */ 5);\n  AddBuiltin(BuiltinOperator_PRELU, Register_PRELU());\n  AddBuiltin(BuiltinOperator_MAXIMUM, Register_MAXIMUM(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_MINIMUM, Register_MINIMUM(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_ARG_MAX, Register_ARG_MAX(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_ARG_MIN, Register_ARG_MIN(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_GREATER, Register_GREATER(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_GREATER_EQUAL, Register_GREATER_EQUAL(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_LESS, Register_LESS(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_LESS_EQUAL, Register_LESS_EQUAL(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_FLOOR, Register_FLOOR());\n  AddBuiltin(BuiltinOperator_CEIL, Register_CEIL());\n  AddBuiltin(BuiltinOperator_ROUND, Register_ROUND());\n  AddBuiltin(BuiltinOperator_NEG, Register_NEG());\n  AddBuiltin(BuiltinOperator_SELECT, Register_SELECT(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_SELECT_V2, Register_SELECT_V2(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_SLICE, Register_SLICE(),\n             /* min_version = */ 1,\n             /* max_version = */ 6);\n  AddBuiltin(BuiltinOperator_SIN, Register_SIN());\n  AddBuiltin(BuiltinOperator_COS, Register_COS());\n  AddBuiltin(BuiltinOperator_TRANSPOSE_CONV, Register_TRANSPOSE_CONV(),\n             /* min_version = */ 1,\n             /* max_version = */ 5);\n  AddBuiltin(BuiltinOperator_TILE, Register_TILE(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_SUM, Register_SUM(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_REDUCE_PROD, Register_REDUCE_PROD(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_REDUCE_MAX, Register_REDUCE_MAX(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_REDUCE_MIN, Register_REDUCE_MIN(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_REDUCE_ANY, Register_REDUCE_ANY());\n  AddBuiltin(BuiltinOperator_REDUCE_ALL, Register_REDUCE_ALL());\n  AddBuiltin(BuiltinOperator_EXPAND_DIMS, Register_EXPAND_DIMS());\n  AddBuiltin(BuiltinOperator_SPARSE_TO_DENSE, Register_SPARSE_TO_DENSE(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_EQUAL, Register_EQUAL(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_NOT_EQUAL, Register_NOT_EQUAL(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_SQRT, Register_SQRT());\n  AddBuiltin(BuiltinOperator_RSQRT, Register_RSQRT(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_SHAPE, Register_SHAPE());\n  AddBuiltin(BuiltinOperator_RANK, Register_RANK());\n  AddBuiltin(BuiltinOperator_POW, Register_POW());\n  AddBuiltin(BuiltinOperator_FAKE_QUANT, Register_FAKE_QUANT(), 1, 2);\n  AddBuiltin(BuiltinOperator_PACK, Register_PACK(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_ONE_HOT, Register_ONE_HOT());\n  AddBuiltin(BuiltinOperator_LOGICAL_OR, Register_LOGICAL_OR());\n  AddBuiltin(BuiltinOperator_LOGICAL_AND, Register_LOGICAL_AND());\n  AddBuiltin(BuiltinOperator_LOGICAL_NOT, Register_LOGICAL_NOT());\n  AddBuiltin(BuiltinOperator_UNPACK, Register_UNPACK(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_FLOOR_DIV, Register_FLOOR_DIV(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_SQUARE, Register_SQUARE());\n  AddBuiltin(BuiltinOperator_ZEROS_LIKE, Register_ZEROS_LIKE());\n  AddBuiltin(BuiltinOperator_FLOOR_MOD, Register_FLOOR_MOD(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_RANGE, Register_RANGE(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_LEAKY_RELU, Register_LEAKY_RELU(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_SQUARED_DIFFERENCE, Register_SQUARED_DIFFERENCE(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_FILL, Register_FILL(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_MIRROR_PAD, Register_MIRROR_PAD(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_UNIQUE, Register_UNIQUE());\n  AddBuiltin(BuiltinOperator_REVERSE_V2, Register_REVERSE_V2(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_ADD_N, Register_ADD_N());\n  AddBuiltin(BuiltinOperator_GATHER_ND, Register_GATHER_ND(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_WHERE, Register_WHERE(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_ELU, Register_ELU());\n  AddBuiltin(BuiltinOperator_REVERSE_SEQUENCE, Register_REVERSE_SEQUENCE());\n  AddBuiltin(BuiltinOperator_MATRIX_DIAG, Register_MATRIX_DIAG());\n  AddBuiltin(BuiltinOperator_QUANTIZE, Register_QUANTIZE(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_MATRIX_SET_DIAG, Register_MATRIX_SET_DIAG());\n  AddBuiltin(BuiltinOperator_IF, tflite::ops::builtin::Register_IF());\n  AddBuiltin(BuiltinOperator_WHILE, tflite::ops::builtin::Register_WHILE());\n  AddBuiltin(BuiltinOperator_NON_MAX_SUPPRESSION_V4,\n             Register_NON_MAX_SUPPRESSION_V4());\n  AddBuiltin(BuiltinOperator_NON_MAX_SUPPRESSION_V5,\n             Register_NON_MAX_SUPPRESSION_V5());\n  AddBuiltin(BuiltinOperator_SCATTER_ND, Register_SCATTER_ND());\n  AddBuiltin(BuiltinOperator_DENSIFY, Register_DENSIFY());\n  AddBuiltin(BuiltinOperator_SEGMENT_SUM, Register_SEGMENT_SUM());\n  AddBuiltin(BuiltinOperator_BATCH_MATMUL, Register_BATCH_MATMUL(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_CUMSUM, Register_CUMSUM());\n  // The version one of broadcast to op won't be not supported since the version\n  // one was rollbacked and the builtin op code number has been changed because\n  // of builtin op code shortage problem.\n  AddBuiltin(BuiltinOperator_BROADCAST_TO, Register_BROADCAST_TO(),\n             /* min_version = */ 2,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_CALL_ONCE,\n             tflite::ops::builtin::Register_CALL_ONCE());\n  AddBuiltin(BuiltinOperator_RFFT2D, Register_RFFT2D());\n  AddBuiltin(BuiltinOperator_CONV_3D, Register_CONV_3D());\n  AddBuiltin(BuiltinOperator_IMAG, Register_IMAG());\n  AddBuiltin(BuiltinOperator_REAL, Register_REAL());\n  AddBuiltin(BuiltinOperator_COMPLEX_ABS, Register_COMPLEX_ABS());\n  AddBuiltin(BuiltinOperator_BROADCAST_ARGS, Register_BROADCAST_ARGS());\n  AddBuiltin(BuiltinOperator_HASHTABLE, Register_HASHTABLE());\n  AddBuiltin(BuiltinOperator_HASHTABLE_FIND, Register_HASHTABLE_FIND());\n  AddBuiltin(BuiltinOperator_HASHTABLE_IMPORT, Register_HASHTABLE_IMPORT());\n  AddBuiltin(BuiltinOperator_HASHTABLE_SIZE, Register_HASHTABLE_SIZE());\n  AddBuiltin(BuiltinOperator_CONV_3D_TRANSPOSE, Register_CONV_3D_TRANSPOSE());\n  AddBuiltin(BuiltinOperator_VAR_HANDLE, Register_VAR_HANDLE());\n  AddBuiltin(BuiltinOperator_READ_VARIABLE, Register_READ_VARIABLE());\n  AddBuiltin(BuiltinOperator_ASSIGN_VARIABLE, Register_ASSIGN_VARIABLE());\n  AddBuiltin(BuiltinOperator_MULTINOMIAL, Register_MULTINOMIAL());\n  AddBuiltin(BuiltinOperator_RANDOM_STANDARD_NORMAL,\n             Register_RANDOM_STANDARD_NORMAL());\n  AddBuiltin(BuiltinOperator_BUCKETIZE, Register_BUCKETIZE());\n  AddBuiltin(BuiltinOperator_RANDOM_UNIFORM, Register_RANDOM_UNIFORM());\n  AddBuiltin(BuiltinOperator_GELU, Register_GELU(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_DYNAMIC_UPDATE_SLICE,\n             Register_DYNAMIC_UPDATE_SLICE());\n  AddBuiltin(BuiltinOperator_UNSORTED_SEGMENT_PROD,\n             Register_UNSORTED_SEGMENT_PROD());\n  AddBuiltin(BuiltinOperator_UNSORTED_SEGMENT_MAX,\n             Register_UNSORTED_SEGMENT_MAX());\n  AddBuiltin(BuiltinOperator_UNSORTED_SEGMENT_MIN,\n             Register_UNSORTED_SEGMENT_MIN());\n  AddBuiltin(BuiltinOperator_UNSORTED_SEGMENT_SUM,\n             Register_UNSORTED_SEGMENT_SUM());\n  AddBuiltin(BuiltinOperator_ATAN2, Register_ATAN2());\n  AddBuiltin(BuiltinOperator_SIGN, Register_SIGN(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_BITCAST, Register_BITCAST());\n  AddBuiltin(BuiltinOperator_BITWISE_XOR, Register_BITWISE_XOR());\n  AddBuiltin(BuiltinOperator_RIGHT_SHIFT, Register_RIGHT_SHIFT());\n  AddBuiltin(BuiltinOperator_STABLEHLO_SCATTER, Register_STABLEHLO_SCATTER());\n  AddCustom(\"NumericVerify\", tflite::ops::custom::Register_NUMERIC_VERIFY());\n  // TODO(andrewharp, ahentz): Move these somewhere more appropriate so that\n  // custom ops aren't always included by default.\n  AddCustom(\"Mfcc\", tflite::ops::custom::Register_MFCC());\n  AddCustom(\"AudioSpectrogram\",\n            tflite::ops::custom::Register_AUDIO_SPECTROGRAM());\n  AddCustom(\"TFLite_Detection_PostProcess\",\n            tflite::ops::custom::Register_DETECTION_POSTPROCESS());\n  // By definition, all of the ops added above are not user-defined ops,\n  // since they are supported by BuiltinOpResolver.\n  may_directly_contain_user_defined_ops_ = false;\n\n  // Populate the list of TF Lite delegate creators. The created delegates could\n  // be applied to the model graph by default at runtime.\n  delegate_creators_.push_back([](TfLiteContext* context) {\n    return tflite::MaybeCreateXNNPACKDelegate(context,\n                                              XNNPackQS8Options::default_value);\n  });\n}", "source_start_line": 36, "tokens": ["BuiltinOpResolver", "::", "BuiltinOpResolver", "(", ")", "{", "AddBuiltin", "(", "BuiltinOperator_ABS", ",", "Register_ABS", "(", ")", ",", "1", ",", "5", ")", ";", "AddBuiltin", "(", "BuiltinOperator_HARD_SWISH", ",", "Register_HARD_SWISH", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RELU", ",", "Register_RELU", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RELU_N1_TO_1", ",", "Register_RELU_N1_TO_1", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RELU_0_TO_1", ",", "Register_RELU_0_TO_1", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RELU6", ",", "Register_RELU6", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_TANH", ",", "Register_TANH", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LOGISTIC", ",", "Register_LOGISTIC", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_AVERAGE_POOL_2D", ",", "Register_AVERAGE_POOL_2D", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_MAX_POOL_2D", ",", "Register_MAX_POOL_2D", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_L2_POOL_2D", ",", "Register_L2_POOL_2D", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_CONV_2D", ",", "Register_CONV_2D", "(", ")", ",", "1", ",", "8", ")", ";", "AddBuiltin", "(", "BuiltinOperator_DEPTHWISE_CONV_2D", ",", "Register_DEPTHWISE_CONV_2D", "(", ")", ",", "1", ",", "7", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SVDF", ",", "Register_SVDF", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RNN", ",", "Register_RNN", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_BIDIRECTIONAL_SEQUENCE_RNN", ",", "Register_BIDIRECTIONAL_SEQUENCE_RNN", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_UNIDIRECTIONAL_SEQUENCE_RNN", ",", "Register_UNIDIRECTIONAL_SEQUENCE_RNN", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_EMBEDDING_LOOKUP", ",", "Register_EMBEDDING_LOOKUP", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_EMBEDDING_LOOKUP_SPARSE", ",", "Register_EMBEDDING_LOOKUP_SPARSE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_FULLY_CONNECTED", ",", "Register_FULLY_CONNECTED", "(", ")", ",", "1", ",", "11", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LSH_PROJECTION", ",", "Register_LSH_PROJECTION", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_HASHTABLE_LOOKUP", ",", "Register_HASHTABLE_LOOKUP", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SOFTMAX", ",", "Register_SOFTMAX", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_CONCATENATION", ",", "Register_CONCATENATION", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ADD", ",", "Register_ADD", "(", ")", ",", "1", ",", "5", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SPACE_TO_BATCH_ND", ",", "Register_SPACE_TO_BATCH_ND", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_BATCH_TO_SPACE_ND", ",", "Register_BATCH_TO_SPACE_ND", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_MUL", ",", "Register_MUL", "(", ")", ",", "1", ",", "7", ")", ";", "AddBuiltin", "(", "BuiltinOperator_L2_NORMALIZATION", ",", "Register_L2_NORMALIZATION", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LOCAL_RESPONSE_NORMALIZATION", ",", "Register_LOCAL_RESPONSE_NORMALIZATION", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LSTM", ",", "Register_LSTM", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_BIDIRECTIONAL_SEQUENCE_LSTM", ",", "Register_BIDIRECTIONAL_SEQUENCE_LSTM", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_UNIDIRECTIONAL_SEQUENCE_LSTM", ",", "Register_UNIDIRECTIONAL_SEQUENCE_LSTM", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_PAD", ",", "Register_PAD", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_PADV2", ",", "Register_PADV2", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RESHAPE", ",", "Register_RESHAPE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RESIZE_BILINEAR", ",", "Register_RESIZE_BILINEAR", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RESIZE_NEAREST_NEIGHBOR", ",", "Register_RESIZE_NEAREST_NEIGHBOR", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SKIP_GRAM", ",", "Register_SKIP_GRAM", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SPACE_TO_DEPTH", ",", "Register_SPACE_TO_DEPTH", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_DEPTH_TO_SPACE", ",", "Register_DEPTH_TO_SPACE", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_GATHER", ",", "Register_GATHER", "(", ")", ",", "1", ",", "6", ")", ";", "AddBuiltin", "(", "BuiltinOperator_TRANSPOSE", ",", "Register_TRANSPOSE", "(", ")", ",", "1", ",", "6", ")", ";", "AddBuiltin", "(", "BuiltinOperator_MEAN", ",", "Register_MEAN", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_DIV", ",", "Register_DIV", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SUB", ",", "Register_SUB", "(", ")", ",", "1", ",", "5", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SPLIT", ",", "Register_SPLIT", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SPLIT_V", ",", "Register_SPLIT_V", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SQUEEZE", ",", "Register_SQUEEZE", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_STRIDED_SLICE", ",", "Register_STRIDED_SLICE", "(", ")", ",", "1", ",", "8", ")", ";", "AddBuiltin", "(", "BuiltinOperator_EXP", ",", "Register_EXP", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_TOPK_V2", ",", "Register_TOPK_V2", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LOG", ",", "Register_LOG", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LOG_SOFTMAX", ",", "Register_LOG_SOFTMAX", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_CAST", ",", "Register_CAST", "(", ")", ",", "1", ",", "5", ")", ";", "AddBuiltin", "(", "BuiltinOperator_DEQUANTIZE", ",", "Register_DEQUANTIZE", "(", ")", ",", "1", ",", "5", ")", ";", "AddBuiltin", "(", "BuiltinOperator_PRELU", ",", "Register_PRELU", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_MAXIMUM", ",", "Register_MAXIMUM", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_MINIMUM", ",", "Register_MINIMUM", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ARG_MAX", ",", "Register_ARG_MAX", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ARG_MIN", ",", "Register_ARG_MIN", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_GREATER", ",", "Register_GREATER", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_GREATER_EQUAL", ",", "Register_GREATER_EQUAL", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LESS", ",", "Register_LESS", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LESS_EQUAL", ",", "Register_LESS_EQUAL", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_FLOOR", ",", "Register_FLOOR", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_CEIL", ",", "Register_CEIL", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ROUND", ",", "Register_ROUND", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_NEG", ",", "Register_NEG", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SELECT", ",", "Register_SELECT", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SELECT_V2", ",", "Register_SELECT_V2", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SLICE", ",", "Register_SLICE", "(", ")", ",", "1", ",", "6", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SIN", ",", "Register_SIN", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_COS", ",", "Register_COS", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_TRANSPOSE_CONV", ",", "Register_TRANSPOSE_CONV", "(", ")", ",", "1", ",", "5", ")", ";", "AddBuiltin", "(", "BuiltinOperator_TILE", ",", "Register_TILE", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SUM", ",", "Register_SUM", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_REDUCE_PROD", ",", "Register_REDUCE_PROD", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_REDUCE_MAX", ",", "Register_REDUCE_MAX", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_REDUCE_MIN", ",", "Register_REDUCE_MIN", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_REDUCE_ANY", ",", "Register_REDUCE_ANY", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_REDUCE_ALL", ",", "Register_REDUCE_ALL", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_EXPAND_DIMS", ",", "Register_EXPAND_DIMS", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SPARSE_TO_DENSE", ",", "Register_SPARSE_TO_DENSE", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_EQUAL", ",", "Register_EQUAL", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_NOT_EQUAL", ",", "Register_NOT_EQUAL", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SQRT", ",", "Register_SQRT", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RSQRT", ",", "Register_RSQRT", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SHAPE", ",", "Register_SHAPE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RANK", ",", "Register_RANK", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_POW", ",", "Register_POW", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_FAKE_QUANT", ",", "Register_FAKE_QUANT", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_PACK", ",", "Register_PACK", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ONE_HOT", ",", "Register_ONE_HOT", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LOGICAL_OR", ",", "Register_LOGICAL_OR", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LOGICAL_AND", ",", "Register_LOGICAL_AND", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LOGICAL_NOT", ",", "Register_LOGICAL_NOT", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_UNPACK", ",", "Register_UNPACK", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_FLOOR_DIV", ",", "Register_FLOOR_DIV", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SQUARE", ",", "Register_SQUARE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ZEROS_LIKE", ",", "Register_ZEROS_LIKE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_FLOOR_MOD", ",", "Register_FLOOR_MOD", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RANGE", ",", "Register_RANGE", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LEAKY_RELU", ",", "Register_LEAKY_RELU", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SQUARED_DIFFERENCE", ",", "Register_SQUARED_DIFFERENCE", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_FILL", ",", "Register_FILL", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_MIRROR_PAD", ",", "Register_MIRROR_PAD", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_UNIQUE", ",", "Register_UNIQUE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_REVERSE_V2", ",", "Register_REVERSE_V2", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ADD_N", ",", "Register_ADD_N", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_GATHER_ND", ",", "Register_GATHER_ND", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_WHERE", ",", "Register_WHERE", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ELU", ",", "Register_ELU", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_REVERSE_SEQUENCE", ",", "Register_REVERSE_SEQUENCE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_MATRIX_DIAG", ",", "Register_MATRIX_DIAG", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_QUANTIZE", ",", "Register_QUANTIZE", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_MATRIX_SET_DIAG", ",", "Register_MATRIX_SET_DIAG", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_IF", ",", "tflite", "::", "ops", "::", "builtin", "::", "Register_IF", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_WHILE", ",", "tflite", "::", "ops", "::", "builtin", "::", "Register_WHILE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_NON_MAX_SUPPRESSION_V4", ",", "Register_NON_MAX_SUPPRESSION_V4", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_NON_MAX_SUPPRESSION_V5", ",", "Register_NON_MAX_SUPPRESSION_V5", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SCATTER_ND", ",", "Register_SCATTER_ND", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_DENSIFY", ",", "Register_DENSIFY", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SEGMENT_SUM", ",", "Register_SEGMENT_SUM", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_BATCH_MATMUL", ",", "Register_BATCH_MATMUL", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_CUMSUM", ",", "Register_CUMSUM", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_BROADCAST_TO", ",", "Register_BROADCAST_TO", "(", ")", ",", "2", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_CALL_ONCE", ",", "tflite", "::", "ops", "::", "builtin", "::", "Register_CALL_ONCE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RFFT2D", ",", "Register_RFFT2D", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_CONV_3D", ",", "Register_CONV_3D", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_IMAG", ",", "Register_IMAG", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_REAL", ",", "Register_REAL", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_COMPLEX_ABS", ",", "Register_COMPLEX_ABS", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_BROADCAST_ARGS", ",", "Register_BROADCAST_ARGS", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_HASHTABLE", ",", "Register_HASHTABLE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_HASHTABLE_FIND", ",", "Register_HASHTABLE_FIND", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_HASHTABLE_IMPORT", ",", "Register_HASHTABLE_IMPORT", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_HASHTABLE_SIZE", ",", "Register_HASHTABLE_SIZE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_CONV_3D_TRANSPOSE", ",", "Register_CONV_3D_TRANSPOSE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_VAR_HANDLE", ",", "Register_VAR_HANDLE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_READ_VARIABLE", ",", "Register_READ_VARIABLE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ASSIGN_VARIABLE", ",", "Register_ASSIGN_VARIABLE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_MULTINOMIAL", ",", "Register_MULTINOMIAL", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RANDOM_STANDARD_NORMAL", ",", "Register_RANDOM_STANDARD_NORMAL", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_BUCKETIZE", ",", "Register_BUCKETIZE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RANDOM_UNIFORM", ",", "Register_RANDOM_UNIFORM", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_GELU", ",", "Register_GELU", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_DYNAMIC_UPDATE_SLICE", ",", "Register_DYNAMIC_UPDATE_SLICE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_UNSORTED_SEGMENT_PROD", ",", "Register_UNSORTED_SEGMENT_PROD", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_UNSORTED_SEGMENT_MAX", ",", "Register_UNSORTED_SEGMENT_MAX", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_UNSORTED_SEGMENT_MIN", ",", "Register_UNSORTED_SEGMENT_MIN", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_UNSORTED_SEGMENT_SUM", ",", "Register_UNSORTED_SEGMENT_SUM", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ATAN2", ",", "Register_ATAN2", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SIGN", ",", "Register_SIGN", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_BITCAST", ",", "Register_BITCAST", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_BITWISE_XOR", ",", "Register_BITWISE_XOR", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RIGHT_SHIFT", ",", "Register_RIGHT_SHIFT", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_STABLEHLO_SCATTER", ",", "Register_STABLEHLO_SCATTER", "(", ")", ")", ";", "AddCustom", "(", "\"", "\"", ",", "tflite", "::", "ops", "::", "custom", "::", "Register_NUMERIC_VERIFY", "(", ")", ")", ";", "AddCustom", "(", "\"", "\"", ",", "tflite", "::", "ops", "::", "custom", "::", "Register_MFCC", "(", ")", ")", ";", "AddCustom", "(", "\"", "\"", ",", "tflite", "::", "ops", "::", "custom", "::", "Register_AUDIO_SPECTROGRAM", "(", ")", ")", ";", "AddCustom", "(", "\"", "\"", ",", "tflite", "::", "ops", "::", "custom", "::", "Register_DETECTION_POSTPROCESS", "(", ")", ")", ";", "may_directly_contain_user_defined_ops_", "=", "false", ";", "delegate_creators_", ".", "push_back", "(", "[", "]", "(", "TfLiteContext", "*", "context", ")", "{", "return", "tflite", "::", "MaybeCreateXNNPACKDelegate", "(", "context", ",", "XNNPackQS8Options", "::", "default_value", ")", ";", "}", ")", ";", "}"], "to_mask": {"VAR": ["context"], "METHOD": ["AddBuiltin", "AddCustom", "MaybeCreateXNNPACKDelegate", "Register_ABS", "Register_ADD", "Register_ADD_N", "Register_ARG_MAX", "Register_ARG_MIN", "Register_ASSIGN_VARIABLE", "Register_ATAN2", "Register_AUDIO_SPECTROGRAM", "Register_AVERAGE_POOL_2D", "Register_BATCH_MATMUL", "Register_BATCH_TO_SPACE_ND", "Register_BIDIRECTIONAL_SEQUENCE_LSTM", "Register_BIDIRECTIONAL_SEQUENCE_RNN", "Register_BITCAST", "Register_BITWISE_XOR", "Register_BROADCAST_ARGS", "Register_BROADCAST_TO", "Register_BUCKETIZE", "Register_CALL_ONCE", "Register_CAST", "Register_CEIL", "Register_COMPLEX_ABS", "Register_CONCATENATION", "Register_CONV_2D", "Register_CONV_3D", "Register_CONV_3D_TRANSPOSE", "Register_COS", "Register_CUMSUM", "Register_DENSIFY", "Register_DEPTHWISE_CONV_2D", "Register_DEPTH_TO_SPACE", "Register_DEQUANTIZE", "Register_DETECTION_POSTPROCESS", "Register_DIV", "Register_DYNAMIC_UPDATE_SLICE", "Register_ELU", "Register_EMBEDDING_LOOKUP", "Register_EMBEDDING_LOOKUP_SPARSE", "Register_EQUAL", "Register_EXP", "Register_EXPAND_DIMS", "Register_FAKE_QUANT", "Register_FILL", "Register_FLOOR", "Register_FLOOR_DIV", "Register_FLOOR_MOD", "Register_FULLY_CONNECTED", "Register_GATHER", "Register_GATHER_ND", "Register_GELU", "Register_GREATER", "Register_GREATER_EQUAL", "Register_HARD_SWISH", "Register_HASHTABLE", "Register_HASHTABLE_FIND", "Register_HASHTABLE_IMPORT", "Register_HASHTABLE_LOOKUP", "Register_HASHTABLE_SIZE", "Register_IF", "Register_IMAG", "Register_L2_NORMALIZATION", "Register_L2_POOL_2D", "Register_LEAKY_RELU", "Register_LESS", "Register_LESS_EQUAL", "Register_LOCAL_RESPONSE_NORMALIZATION", "Register_LOG", "Register_LOGICAL_AND", "Register_LOGICAL_NOT", "Register_LOGICAL_OR", "Register_LOGISTIC", "Register_LOG_SOFTMAX", "Register_LSH_PROJECTION", "Register_LSTM", "Register_MATRIX_DIAG", "Register_MATRIX_SET_DIAG", "Register_MAXIMUM", "Register_MAX_POOL_2D", "Register_MEAN", "Register_MFCC", "Register_MINIMUM", "Register_MIRROR_PAD", "Register_MUL", "Register_MULTINOMIAL", "Register_NEG", "Register_NON_MAX_SUPPRESSION_V4", "Register_NON_MAX_SUPPRESSION_V5", "Register_NOT_EQUAL", "Register_NUMERIC_VERIFY", "Register_ONE_HOT", "Register_PACK", "Register_PAD", "Register_PADV2", "Register_POW", "Register_PRELU", "Register_QUANTIZE", "Register_RANDOM_STANDARD_NORMAL", "Register_RANDOM_UNIFORM", "Register_RANGE", "Register_RANK", "Register_READ_VARIABLE", "Register_REAL", "Register_REDUCE_ALL", "Register_REDUCE_ANY", "Register_REDUCE_MAX", "Register_REDUCE_MIN", "Register_REDUCE_PROD", "Register_RELU", "Register_RELU6", "Register_RELU_0_TO_1", "Register_RELU_N1_TO_1", "Register_RESHAPE", "Register_RESIZE_BILINEAR", "Register_RESIZE_NEAREST_NEIGHBOR", "Register_REVERSE_SEQUENCE", "Register_REVERSE_V2", "Register_RFFT2D", "Register_RIGHT_SHIFT", "Register_RNN", "Register_ROUND", "Register_RSQRT", "Register_SCATTER_ND", "Register_SEGMENT_SUM", "Register_SELECT", "Register_SELECT_V2", "Register_SHAPE", "Register_SIGN", "Register_SIN", "Register_SKIP_GRAM", "Register_SLICE", "Register_SOFTMAX", "Register_SPACE_TO_BATCH_ND", "Register_SPACE_TO_DEPTH", "Register_SPARSE_TO_DENSE", "Register_SPLIT", "Register_SPLIT_V", "Register_SQRT", "Register_SQUARE", "Register_SQUARED_DIFFERENCE", "Register_SQUEEZE", "Register_STABLEHLO_SCATTER", "Register_STRIDED_SLICE", "Register_SUB", "Register_SUM", "Register_SVDF", "Register_TANH", "Register_TILE", "Register_TOPK_V2", "Register_TRANSPOSE", "Register_TRANSPOSE_CONV", "Register_UNIDIRECTIONAL_SEQUENCE_LSTM", "Register_UNIDIRECTIONAL_SEQUENCE_RNN", "Register_UNIQUE", "Register_UNPACK", "Register_UNSORTED_SEGMENT_MAX", "Register_UNSORTED_SEGMENT_MIN", "Register_UNSORTED_SEGMENT_PROD", "Register_UNSORTED_SEGMENT_SUM", "Register_VAR_HANDLE", "Register_WHERE", "Register_WHILE", "Register_ZEROS_LIKE", "push_back"]}, "attention_idx_tokens": [143, 145], "patch": "@@ -57,7 +57,7 @@\n   AddBuiltin(BuiltinOperator_L2_POOL_2D, Register_L2_POOL_2D());\n   AddBuiltin(BuiltinOperator_CONV_2D, Register_CONV_2D(),\n              /* min_version = */ 1,\n-             /* max_version = */ 7);\n+             /* max_version = */ 8);", "ext_attention_idx_tokens": [143, 153], "uid": "184e803e", "question": "Why increment max version by 2?", "code": "BuiltinOpResolver BuiltinOpResolver { AddBuiltin BuiltinOperator ABS Register ABS * min version * 1 * max version * 5 ; AddBuiltin BuiltinOperator HARD SWISH Register HARD SWISH ; AddBuiltin BuiltinOperator RELU Register RELU * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator RELU N1 TO 1 Register RELU N1 TO 1 ; AddBuiltin BuiltinOperator RELU 0 TO 1 Register RELU 0 TO 1 ; AddBuiltin BuiltinOperator RELU6 Register RELU6 * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator TANH Register TANH * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator LOGISTIC Register LOGISTIC * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator AVERAGE POOL 2D Register AVERAGE POOL 2D * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator MAX POOL 2D Register MAX POOL 2D * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator L2 POOL 2D Register L2 POOL 2D ; AddBuiltin BuiltinOperator CONV 2D Register CONV 2D * min version * 1 * max version * 8 ; AddBuiltin BuiltinOperator DEPTHWISE CONV 2D Register DEPTHWISE CONV 2D * min version * 1 * max version * 7 ; AddBuiltin BuiltinOperator SVDF Register SVDF * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator RNN Register RNN * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator BIDIRECTIONAL SEQUENCE RNN Register BIDIRECTIONAL SEQUENCE RNN * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator UNIDIRECTIONAL SEQUENCE RNN Register UNIDIRECTIONAL SEQUENCE RNN * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator EMBEDDING LOOKUP Register EMBEDDING LOOKUP * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator EMBEDDING LOOKUP SPARSE Register EMBEDDING LOOKUP SPARSE ; AddBuiltin BuiltinOperator FULLY CONNECTED Register FULLY CONNECTED * min version * 1 * max version * 11 ; AddBuiltin BuiltinOperator LSH PROJECTION Register LSH PROJECTION ; AddBuiltin BuiltinOperator HASHTABLE LOOKUP Register HASHTABLE LOOKUP ; AddBuiltin BuiltinOperator SOFTMAX Register SOFTMAX * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator CONCATENATION Register CONCATENATION * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator ADD Register ADD * min version * 1 * max version * 5 ; AddBuiltin BuiltinOperator SPACE TO BATCH ND Register SPACE TO BATCH ND * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator BATCH TO SPACE ND Register BATCH TO SPACE ND * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator MUL Register MUL * min version * 1 * max version * 7 ; AddBuiltin BuiltinOperator L2 NORMALIZATION Register L2 NORMALIZATION * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator LOCAL RESPONSE NORMALIZATION Register LOCAL RESPONSE NORMALIZATION ; AddBuiltin BuiltinOperator LSTM Register LSTM * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator BIDIRECTIONAL SEQUENCE LSTM Register BIDIRECTIONAL SEQUENCE LSTM * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator UNIDIRECTIONAL SEQUENCE LSTM Register UNIDIRECTIONAL SEQUENCE LSTM * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator PAD Register PAD * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator PADV2 Register PADV2 * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator RESHAPE Register RESHAPE ; AddBuiltin BuiltinOperator RESIZE BILINEAR Register RESIZE BILINEAR * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator RESIZE NEAREST NEIGHBOR Register RESIZE NEAREST NEIGHBOR * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator SKIP GRAM Register SKIP GRAM ; AddBuiltin BuiltinOperator SPACE TO DEPTH Register SPACE TO DEPTH * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator DEPTH TO SPACE Register DEPTH TO SPACE * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator GATHER Register GATHER * min version * 1 * max version * 6 ; AddBuiltin BuiltinOperator TRANSPOSE Register TRANSPOSE * min version * 1 * max version * 6 ; AddBuiltin BuiltinOperator MEAN Register MEAN * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator DIV Register DIV * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator SUB Register SUB * min version * 1 * max version * 5 ; AddBuiltin BuiltinOperator SPLIT Register SPLIT * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator SPLIT V Register SPLIT V * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator SQUEEZE Register SQUEEZE * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator STRIDED SLICE Register STRIDED SLICE * min version * 1 * max version * 8 ; AddBuiltin BuiltinOperator EXP Register EXP * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator TOPK V2 Register TOPK V2 * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator LOG Register LOG * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator LOG SOFTMAX Register LOG SOFTMAX * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator CAST Register CAST * min version * 1 * max version * 5 ; AddBuiltin BuiltinOperator DEQUANTIZE Register DEQUANTIZE * min version * 1 * max version * 5 ; AddBuiltin BuiltinOperator PRELU Register PRELU ; AddBuiltin BuiltinOperator MAXIMUM Register MAXIMUM * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator MINIMUM Register MINIMUM * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator ARG MAX Register ARG MAX * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator ARG MIN Register ARG MIN * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator GREATER Register GREATER * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator GREATER EQUAL Register GREATER EQUAL * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator LESS Register LESS * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator LESS EQUAL Register LESS EQUAL * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator FLOOR Register FLOOR ; AddBuiltin BuiltinOperator CEIL Register CEIL ; AddBuiltin BuiltinOperator ROUND Register ROUND ; AddBuiltin BuiltinOperator NEG Register NEG ; AddBuiltin BuiltinOperator SELECT Register SELECT * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator SELECT V2 Register SELECT V2 * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator SLICE Register SLICE * min version * 1 * max version * 6 ; AddBuiltin BuiltinOperator SIN Register SIN ; AddBuiltin BuiltinOperator COS Register COS ; AddBuiltin BuiltinOperator TRANSPOSE CONV Register TRANSPOSE CONV * min version * 1 * max version * 5 ; AddBuiltin BuiltinOperator TILE Register TILE * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator SUM Register SUM * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator REDUCE PROD Register REDUCE PROD * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator REDUCE MAX Register REDUCE MAX * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator REDUCE MIN Register REDUCE MIN * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator REDUCE ANY Register REDUCE ANY ; AddBuiltin BuiltinOperator REDUCE ALL Register REDUCE ALL ; AddBuiltin BuiltinOperator EXPAND DIMS Register EXPAND DIMS ; AddBuiltin BuiltinOperator SPARSE TO DENSE Register SPARSE TO DENSE * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator EQUAL Register EQUAL * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator NOT EQUAL Register NOT EQUAL * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator SQRT Register SQRT ; AddBuiltin BuiltinOperator RSQRT Register RSQRT * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator SHAPE Register SHAPE ; AddBuiltin BuiltinOperator RANK Register RANK ; AddBuiltin BuiltinOperator POW Register POW ; AddBuiltin BuiltinOperator FAKE QUANT Register FAKE QUANT 1 2 ; AddBuiltin BuiltinOperator PACK Register PACK * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator ONE HOT Register ONE HOT ; AddBuiltin BuiltinOperator LOGICAL OR Register LOGICAL OR ; AddBuiltin BuiltinOperator LOGICAL AND Register LOGICAL AND ; AddBuiltin BuiltinOperator LOGICAL NOT Register LOGICAL NOT ; AddBuiltin BuiltinOperator UNPACK Register UNPACK * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator FLOOR DIV Register FLOOR DIV * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator SQUARE Register SQUARE ; AddBuiltin BuiltinOperator ZEROS LIKE Register ZEROS LIKE ; AddBuiltin BuiltinOperator FLOOR MOD Register FLOOR MOD * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator RANGE Register RANGE * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator LEAKY RELU Register LEAKY RELU * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator SQUARED DIFFERENCE Register SQUARED DIFFERENCE * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator FILL Register FILL * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator MIRROR PAD Register MIRROR PAD * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator UNIQUE Register UNIQUE ; AddBuiltin BuiltinOperator REVERSE V2 Register REVERSE V2 * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator ADD N Register ADD N ; AddBuiltin BuiltinOperator GATHER ND Register GATHER ND * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator WHERE Register WHERE * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator ELU Register ELU ; AddBuiltin BuiltinOperator REVERSE SEQUENCE Register REVERSE SEQUENCE ; AddBuiltin BuiltinOperator MATRIX DIAG Register MATRIX DIAG ; AddBuiltin BuiltinOperator QUANTIZE Register QUANTIZE * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator MATRIX SET DIAG Register MATRIX SET DIAG ; AddBuiltin BuiltinOperator IF tflite ops builtin Register IF ; AddBuiltin BuiltinOperator WHILE tflite ops builtin Register WHILE ; AddBuiltin BuiltinOperator NON MAX SUPPRESSION V4 Register NON MAX SUPPRESSION V4 ; AddBuiltin BuiltinOperator NON MAX SUPPRESSION V5 Register NON MAX SUPPRESSION V5 ; AddBuiltin BuiltinOperator SCATTER ND Register SCATTER ND ; AddBuiltin BuiltinOperator DENSIFY Register DENSIFY ; AddBuiltin BuiltinOperator SEGMENT SUM Register SEGMENT SUM ; AddBuiltin BuiltinOperator BATCH MATMUL Register BATCH MATMUL * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator CUMSUM Register CUMSUM ; The version one of broadcast to op won t be not supported since the version one was rollbacked and the builtin op code number has been changed because of builtin op code shortage problem AddBuiltin BuiltinOperator BROADCAST TO Register BROADCAST TO * min version * 2 * max version * 3 ; AddBuiltin BuiltinOperator CALL ONCE tflite ops builtin Register CALL ONCE ; AddBuiltin BuiltinOperator RFFT2D Register RFFT2D ; AddBuiltin BuiltinOperator CONV 3D Register CONV 3D ; AddBuiltin BuiltinOperator IMAG Register IMAG ; AddBuiltin BuiltinOperator REAL Register REAL ; AddBuiltin BuiltinOperator COMPLEX ABS Register COMPLEX ABS ; AddBuiltin BuiltinOperator BROADCAST ARGS Register BROADCAST ARGS ; AddBuiltin BuiltinOperator HASHTABLE Register HASHTABLE ; AddBuiltin BuiltinOperator HASHTABLE FIND Register HASHTABLE FIND ; AddBuiltin BuiltinOperator HASHTABLE IMPORT Register HASHTABLE IMPORT ; AddBuiltin BuiltinOperator HASHTABLE SIZE Register HASHTABLE SIZE ; AddBuiltin BuiltinOperator CONV 3D TRANSPOSE Register CONV 3D TRANSPOSE ; AddBuiltin BuiltinOperator VAR HANDLE Register VAR HANDLE ; AddBuiltin BuiltinOperator READ VARIABLE Register READ VARIABLE ; AddBuiltin BuiltinOperator ASSIGN VARIABLE Register ASSIGN VARIABLE ; AddBuiltin BuiltinOperator MULTINOMIAL Register MULTINOMIAL ; AddBuiltin BuiltinOperator RANDOM STANDARD NORMAL Register RANDOM STANDARD NORMAL ; AddBuiltin BuiltinOperator BUCKETIZE Register BUCKETIZE ; AddBuiltin BuiltinOperator RANDOM UNIFORM Register RANDOM UNIFORM ; AddBuiltin BuiltinOperator GELU Register GELU * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator DYNAMIC UPDATE SLICE Register DYNAMIC UPDATE SLICE ; AddBuiltin BuiltinOperator UNSORTED SEGMENT PROD Register UNSORTED SEGMENT PROD ; AddBuiltin BuiltinOperator UNSORTED SEGMENT MAX Register UNSORTED SEGMENT MAX ; AddBuiltin BuiltinOperator UNSORTED SEGMENT MIN Register UNSORTED SEGMENT MIN ; AddBuiltin BuiltinOperator UNSORTED SEGMENT SUM Register UNSORTED SEGMENT SUM ; AddBuiltin BuiltinOperator ATAN2 Register ATAN2 ; AddBuiltin BuiltinOperator SIGN Register SIGN * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator BITCAST Register BITCAST ; AddBuiltin BuiltinOperator BITWISE XOR Register BITWISE XOR ; AddBuiltin BuiltinOperator RIGHT SHIFT Register RIGHT SHIFT ; AddBuiltin BuiltinOperator STABLEHLO SCATTER Register STABLEHLO SCATTER ; AddCustom \"NumericVerify\" tflite ops custom Register NUMERIC VERIFY ; TODO andrewharp ahentz Move these somewhere more appropriate so that custom ops aren t always included by default AddCustom \"Mfcc\" tflite ops custom Register MFCC ; AddCustom \"AudioSpectrogram\" tflite ops custom Register AUDIO SPECTROGRAM ; AddCustom \"TFLite Detection PostProcess\" tflite ops custom Register DETECTION POSTPROCESS ; By definition all of the ops added above are not user-defined ops since they are supported by BuiltinOpResolver may directly contain user defined ops false; Populate the list of TF Lite delegate creators The created delegates could be applied to the model graph by default at runtime delegate creators push back [] TfLiteContext* context { return tflite MaybeCreateXNNPACKDelegate context XNNPackQS8Options default value ; } ; }"}
{"message": "Why increment max version by 2?", "timestamp": "2022-12-06T08:33:47Z", "file_name": "tensorflow/lite/core/kernels/register.cc", "range": {"start_line": 85, "end_line": 85, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1040650438", "html_url": "https://github.com/tensorflow/tensorflow/pull/58400#discussion_r1040650438", "attention_area": "             /* max_version = */ 11);", "file_path": "files/01/00/00000001.cc", "old_file_path": "files/02/00/00000002.cc", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -82,7 +82,7 @@ BuiltinOpResolver::BuiltinOpResolver() {\n              Register_EMBEDDING_LOOKUP_SPARSE());\n   AddBuiltin(BuiltinOperator_FULLY_CONNECTED, Register_FULLY_CONNECTED(),\n              /* min_version = */ 1,\n-             /* max_version = */ 9);\n+             /* max_version = */ 11);", "source": "BuiltinOpResolver::BuiltinOpResolver() {\n  AddBuiltin(BuiltinOperator_ABS, Register_ABS(), /* min_version = */ 1,\n             /* max_version = */ 5);\n  AddBuiltin(BuiltinOperator_HARD_SWISH, Register_HARD_SWISH());\n  AddBuiltin(BuiltinOperator_RELU, Register_RELU(), /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_RELU_N1_TO_1, Register_RELU_N1_TO_1());\n  AddBuiltin(BuiltinOperator_RELU_0_TO_1, Register_RELU_0_TO_1());\n  AddBuiltin(BuiltinOperator_RELU6, Register_RELU6(), /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_TANH, Register_TANH(), /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_LOGISTIC, Register_LOGISTIC(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_AVERAGE_POOL_2D, Register_AVERAGE_POOL_2D(),\n             /* min_version */ 1,\n             /* max_version */ 3);\n  AddBuiltin(BuiltinOperator_MAX_POOL_2D, Register_MAX_POOL_2D(),\n             /* min_version */ 1,\n             /* max_version */ 3);\n  AddBuiltin(BuiltinOperator_L2_POOL_2D, Register_L2_POOL_2D());\n  AddBuiltin(BuiltinOperator_CONV_2D, Register_CONV_2D(),\n             /* min_version = */ 1,\n             /* max_version = */ 8);\n  AddBuiltin(BuiltinOperator_DEPTHWISE_CONV_2D, Register_DEPTHWISE_CONV_2D(),\n             /* min_version = */ 1,\n             /* max_version = */ 6);\n  AddBuiltin(BuiltinOperator_SVDF, Register_SVDF(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_RNN, Register_RNN(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_BIDIRECTIONAL_SEQUENCE_RNN,\n             Register_BIDIRECTIONAL_SEQUENCE_RNN(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_UNIDIRECTIONAL_SEQUENCE_RNN,\n             Register_UNIDIRECTIONAL_SEQUENCE_RNN(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_EMBEDDING_LOOKUP, Register_EMBEDDING_LOOKUP(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_EMBEDDING_LOOKUP_SPARSE,\n             Register_EMBEDDING_LOOKUP_SPARSE());\n  AddBuiltin(BuiltinOperator_FULLY_CONNECTED, Register_FULLY_CONNECTED(),\n             /* min_version = */ 1,\n             /* max_version = */ 11);\n  AddBuiltin(BuiltinOperator_LSH_PROJECTION, Register_LSH_PROJECTION());\n  AddBuiltin(BuiltinOperator_HASHTABLE_LOOKUP, Register_HASHTABLE_LOOKUP());\n  AddBuiltin(BuiltinOperator_SOFTMAX, Register_SOFTMAX(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_CONCATENATION, Register_CONCATENATION(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_ADD, Register_ADD(),\n             /* min_version */ 1,\n             /* max_version */ 4);\n  AddBuiltin(BuiltinOperator_SPACE_TO_BATCH_ND, Register_SPACE_TO_BATCH_ND(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_BATCH_TO_SPACE_ND, Register_BATCH_TO_SPACE_ND(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_MUL, Register_MUL(), /* min_version = */ 1,\n             /* max_version = */ 6);\n  AddBuiltin(BuiltinOperator_L2_NORMALIZATION, Register_L2_NORMALIZATION(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_LOCAL_RESPONSE_NORMALIZATION,\n             Register_LOCAL_RESPONSE_NORMALIZATION());\n  AddBuiltin(BuiltinOperator_LSTM, Register_LSTM(), /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_BIDIRECTIONAL_SEQUENCE_LSTM,\n             Register_BIDIRECTIONAL_SEQUENCE_LSTM(), /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_UNIDIRECTIONAL_SEQUENCE_LSTM,\n             Register_UNIDIRECTIONAL_SEQUENCE_LSTM(), /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_PAD, Register_PAD(), /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_PADV2, Register_PADV2(), /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_RESHAPE, Register_RESHAPE());\n  AddBuiltin(BuiltinOperator_RESIZE_BILINEAR, Register_RESIZE_BILINEAR(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_RESIZE_NEAREST_NEIGHBOR,\n             Register_RESIZE_NEAREST_NEIGHBOR(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_SKIP_GRAM, Register_SKIP_GRAM());\n  AddBuiltin(BuiltinOperator_SPACE_TO_DEPTH, Register_SPACE_TO_DEPTH(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_DEPTH_TO_SPACE, Register_DEPTH_TO_SPACE(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_GATHER, Register_GATHER(),\n             /* min_version = */ 1,\n             /* max_version = */ 5);\n  AddBuiltin(BuiltinOperator_TRANSPOSE, Register_TRANSPOSE(),\n             /* min_version = */ 1,\n             /* max_version = */ 6);\n  AddBuiltin(BuiltinOperator_MEAN, Register_MEAN(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_DIV, Register_DIV(),\n             /* min_version */ 1,\n             /* max_version */ 2);\n  AddBuiltin(BuiltinOperator_SUB, Register_SUB(),\n             /* min_version = */ 1,\n             /* max_version = */ 5);\n  AddBuiltin(BuiltinOperator_SPLIT, Register_SPLIT(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_SPLIT_V, Register_SPLIT_V(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_SQUEEZE, Register_SQUEEZE(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_STRIDED_SLICE, Register_STRIDED_SLICE(),\n             /* min_version = */ 1,\n             /* max_version = */ 6);\n  AddBuiltin(BuiltinOperator_EXP, Register_EXP());\n  AddBuiltin(BuiltinOperator_TOPK_V2, Register_TOPK_V2(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_LOG, Register_LOG());\n  AddBuiltin(BuiltinOperator_LOG_SOFTMAX, Register_LOG_SOFTMAX(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_CAST, Register_CAST(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_DEQUANTIZE, Register_DEQUANTIZE(),\n             /* min_version = */ 1,\n             /* max_version = */ 5);\n  AddBuiltin(BuiltinOperator_PRELU, Register_PRELU());\n  AddBuiltin(BuiltinOperator_MAXIMUM, Register_MAXIMUM(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_MINIMUM, Register_MINIMUM(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_ARG_MAX, Register_ARG_MAX(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_ARG_MIN, Register_ARG_MIN(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_GREATER, Register_GREATER(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_GREATER_EQUAL, Register_GREATER_EQUAL(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_LESS, Register_LESS(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_LESS_EQUAL, Register_LESS_EQUAL(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_FLOOR, Register_FLOOR());\n  AddBuiltin(BuiltinOperator_CEIL, Register_CEIL());\n  AddBuiltin(BuiltinOperator_ROUND, Register_ROUND());\n  AddBuiltin(BuiltinOperator_NEG, Register_NEG());\n  AddBuiltin(BuiltinOperator_SELECT, Register_SELECT(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_SELECT_V2, Register_SELECT_V2());\n  AddBuiltin(BuiltinOperator_SLICE, Register_SLICE(),\n             /* min_version = */ 1,\n             /* max_version = */ 5);\n  AddBuiltin(BuiltinOperator_SIN, Register_SIN());\n  AddBuiltin(BuiltinOperator_COS, Register_COS());\n  AddBuiltin(BuiltinOperator_TRANSPOSE_CONV, Register_TRANSPOSE_CONV(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_TILE, Register_TILE(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_SUM, Register_SUM(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_REDUCE_PROD, Register_REDUCE_PROD(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_REDUCE_MAX, Register_REDUCE_MAX(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_REDUCE_MIN, Register_REDUCE_MIN(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_REDUCE_ANY, Register_REDUCE_ANY());\n  AddBuiltin(BuiltinOperator_REDUCE_ALL, Register_REDUCE_ALL());\n  AddBuiltin(BuiltinOperator_EXPAND_DIMS, Register_EXPAND_DIMS());\n  AddBuiltin(BuiltinOperator_SPARSE_TO_DENSE, Register_SPARSE_TO_DENSE(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_EQUAL, Register_EQUAL(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_NOT_EQUAL, Register_NOT_EQUAL(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_SQRT, Register_SQRT());\n  AddBuiltin(BuiltinOperator_RSQRT, Register_RSQRT(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_SHAPE, Register_SHAPE());\n  AddBuiltin(BuiltinOperator_RANK, Register_RANK());\n  AddBuiltin(BuiltinOperator_POW, Register_POW());\n  AddBuiltin(BuiltinOperator_FAKE_QUANT, Register_FAKE_QUANT(), 1, 2);\n  AddBuiltin(BuiltinOperator_PACK, Register_PACK(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_ONE_HOT, Register_ONE_HOT());\n  AddBuiltin(BuiltinOperator_LOGICAL_OR, Register_LOGICAL_OR());\n  AddBuiltin(BuiltinOperator_LOGICAL_AND, Register_LOGICAL_AND());\n  AddBuiltin(BuiltinOperator_LOGICAL_NOT, Register_LOGICAL_NOT());\n  AddBuiltin(BuiltinOperator_UNPACK, Register_UNPACK(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_FLOOR_DIV, Register_FLOOR_DIV(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_SQUARE, Register_SQUARE());\n  AddBuiltin(BuiltinOperator_ZEROS_LIKE, Register_ZEROS_LIKE());\n  AddBuiltin(BuiltinOperator_FLOOR_MOD, Register_FLOOR_MOD());\n  AddBuiltin(BuiltinOperator_RANGE, Register_RANGE());\n  AddBuiltin(BuiltinOperator_LEAKY_RELU, Register_LEAKY_RELU(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_SQUARED_DIFFERENCE, Register_SQUARED_DIFFERENCE(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_FILL, Register_FILL(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_MIRROR_PAD, Register_MIRROR_PAD(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_UNIQUE, Register_UNIQUE());\n  AddBuiltin(BuiltinOperator_REVERSE_V2, Register_REVERSE_V2(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_ADD_N, Register_ADD_N());\n  AddBuiltin(BuiltinOperator_GATHER_ND, Register_GATHER_ND(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_WHERE, Register_WHERE(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_ELU, Register_ELU());\n  AddBuiltin(BuiltinOperator_REVERSE_SEQUENCE, Register_REVERSE_SEQUENCE());\n  AddBuiltin(BuiltinOperator_MATRIX_DIAG, Register_MATRIX_DIAG());\n  AddBuiltin(BuiltinOperator_QUANTIZE, Register_QUANTIZE(),\n             /* min_version = */ 1,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_MATRIX_SET_DIAG, Register_MATRIX_SET_DIAG());\n  AddBuiltin(BuiltinOperator_IF, tflite::ops::builtin::Register_IF());\n  AddBuiltin(BuiltinOperator_WHILE, tflite::ops::builtin::Register_WHILE());\n  AddBuiltin(BuiltinOperator_NON_MAX_SUPPRESSION_V4,\n             Register_NON_MAX_SUPPRESSION_V4());\n  AddBuiltin(BuiltinOperator_NON_MAX_SUPPRESSION_V5,\n             Register_NON_MAX_SUPPRESSION_V5());\n  AddBuiltin(BuiltinOperator_SCATTER_ND, Register_SCATTER_ND());\n  AddBuiltin(BuiltinOperator_DENSIFY, Register_DENSIFY());\n  AddBuiltin(BuiltinOperator_SEGMENT_SUM, Register_SEGMENT_SUM());\n  AddBuiltin(BuiltinOperator_BATCH_MATMUL, Register_BATCH_MATMUL(),\n             /* min_version = */ 1,\n             /* max_version = */ 4);\n  AddBuiltin(BuiltinOperator_CUMSUM, Register_CUMSUM());\n  // The version one of broadcast to op won't be not supported since the version\n  // one was rollbacked and the builtin op code number has been changed because\n  // of builtin op code shortage problem.\n  AddBuiltin(BuiltinOperator_BROADCAST_TO, Register_BROADCAST_TO(),\n             /* min_version = */ 2,\n             /* max_version = */ 3);\n  AddBuiltin(BuiltinOperator_CALL_ONCE,\n             tflite::ops::builtin::Register_CALL_ONCE());\n  AddBuiltin(BuiltinOperator_RFFT2D, Register_RFFT2D());\n  AddBuiltin(BuiltinOperator_CONV_3D, Register_CONV_3D());\n  AddBuiltin(BuiltinOperator_IMAG, Register_IMAG());\n  AddBuiltin(BuiltinOperator_REAL, Register_REAL());\n  AddBuiltin(BuiltinOperator_COMPLEX_ABS, Register_COMPLEX_ABS());\n  AddBuiltin(BuiltinOperator_BROADCAST_ARGS, Register_BROADCAST_ARGS());\n  AddBuiltin(BuiltinOperator_HASHTABLE, Register_HASHTABLE());\n  AddBuiltin(BuiltinOperator_HASHTABLE_FIND, Register_HASHTABLE_FIND());\n  AddBuiltin(BuiltinOperator_HASHTABLE_IMPORT, Register_HASHTABLE_IMPORT());\n  AddBuiltin(BuiltinOperator_HASHTABLE_SIZE, Register_HASHTABLE_SIZE());\n  AddBuiltin(BuiltinOperator_CONV_3D_TRANSPOSE, Register_CONV_3D_TRANSPOSE());\n  AddBuiltin(BuiltinOperator_VAR_HANDLE, Register_VAR_HANDLE());\n  AddBuiltin(BuiltinOperator_READ_VARIABLE, Register_READ_VARIABLE());\n  AddBuiltin(BuiltinOperator_ASSIGN_VARIABLE, Register_ASSIGN_VARIABLE());\n  AddBuiltin(BuiltinOperator_MULTINOMIAL, Register_MULTINOMIAL());\n  AddBuiltin(BuiltinOperator_RANDOM_STANDARD_NORMAL,\n             Register_RANDOM_STANDARD_NORMAL());\n  AddBuiltin(BuiltinOperator_BUCKETIZE, Register_BUCKETIZE());\n  AddBuiltin(BuiltinOperator_RANDOM_UNIFORM, Register_RANDOM_UNIFORM());\n  AddBuiltin(BuiltinOperator_GELU, Register_GELU(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddBuiltin(BuiltinOperator_DYNAMIC_UPDATE_SLICE,\n             Register_DYNAMIC_UPDATE_SLICE());\n  AddBuiltin(BuiltinOperator_UNSORTED_SEGMENT_PROD,\n             Register_UNSORTED_SEGMENT_PROD());\n  AddBuiltin(BuiltinOperator_UNSORTED_SEGMENT_MAX,\n             Register_UNSORTED_SEGMENT_MAX());\n  AddBuiltin(BuiltinOperator_UNSORTED_SEGMENT_MIN,\n             Register_UNSORTED_SEGMENT_MIN());\n  AddBuiltin(BuiltinOperator_UNSORTED_SEGMENT_SUM,\n             Register_UNSORTED_SEGMENT_SUM());\n  AddBuiltin(BuiltinOperator_ATAN2, Register_ATAN2());\n  AddBuiltin(BuiltinOperator_SIGN, Register_SIGN(),\n             /* min_version = */ 1,\n             /* max_version = */ 2);\n  AddCustom(\"NumericVerify\", tflite::ops::custom::Register_NUMERIC_VERIFY());\n  // TODO(andrewharp, ahentz): Move these somewhere more appropriate so that\n  // custom ops aren't always included by default.\n  AddCustom(\"Mfcc\", tflite::ops::custom::Register_MFCC());\n  AddCustom(\"AudioSpectrogram\",\n            tflite::ops::custom::Register_AUDIO_SPECTROGRAM());\n  AddCustom(\"TFLite_Detection_PostProcess\",\n            tflite::ops::custom::Register_DETECTION_POSTPROCESS());\n  // By definition, all of the ops added above are not user-defined ops,\n  // since they are supported by BuiltinOpResolver.\n  may_directly_contain_user_defined_ops_ = false;\n\n  // Populate the list of TF Lite delegate creators. The created delegates could\n  // be applied to the model graph by default at runtime.\n  delegate_creators_.push_back([](TfLiteContext* context) {\n    return tflite::MaybeCreateXNNPACKDelegate(\n        context, /*enable_xnnpack_unsigned_quantized=*/false);\n  });\n}", "source_start_line": 36, "tokens": ["BuiltinOpResolver", "::", "BuiltinOpResolver", "(", ")", "{", "AddBuiltin", "(", "BuiltinOperator_ABS", ",", "Register_ABS", "(", ")", ",", "1", ",", "5", ")", ";", "AddBuiltin", "(", "BuiltinOperator_HARD_SWISH", ",", "Register_HARD_SWISH", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RELU", ",", "Register_RELU", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RELU_N1_TO_1", ",", "Register_RELU_N1_TO_1", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RELU_0_TO_1", ",", "Register_RELU_0_TO_1", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RELU6", ",", "Register_RELU6", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_TANH", ",", "Register_TANH", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LOGISTIC", ",", "Register_LOGISTIC", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_AVERAGE_POOL_2D", ",", "Register_AVERAGE_POOL_2D", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_MAX_POOL_2D", ",", "Register_MAX_POOL_2D", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_L2_POOL_2D", ",", "Register_L2_POOL_2D", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_CONV_2D", ",", "Register_CONV_2D", "(", ")", ",", "1", ",", "8", ")", ";", "AddBuiltin", "(", "BuiltinOperator_DEPTHWISE_CONV_2D", ",", "Register_DEPTHWISE_CONV_2D", "(", ")", ",", "1", ",", "6", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SVDF", ",", "Register_SVDF", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RNN", ",", "Register_RNN", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_BIDIRECTIONAL_SEQUENCE_RNN", ",", "Register_BIDIRECTIONAL_SEQUENCE_RNN", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_UNIDIRECTIONAL_SEQUENCE_RNN", ",", "Register_UNIDIRECTIONAL_SEQUENCE_RNN", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_EMBEDDING_LOOKUP", ",", "Register_EMBEDDING_LOOKUP", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_EMBEDDING_LOOKUP_SPARSE", ",", "Register_EMBEDDING_LOOKUP_SPARSE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_FULLY_CONNECTED", ",", "Register_FULLY_CONNECTED", "(", ")", ",", "1", ",", "11", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LSH_PROJECTION", ",", "Register_LSH_PROJECTION", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_HASHTABLE_LOOKUP", ",", "Register_HASHTABLE_LOOKUP", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SOFTMAX", ",", "Register_SOFTMAX", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_CONCATENATION", ",", "Register_CONCATENATION", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ADD", ",", "Register_ADD", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SPACE_TO_BATCH_ND", ",", "Register_SPACE_TO_BATCH_ND", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_BATCH_TO_SPACE_ND", ",", "Register_BATCH_TO_SPACE_ND", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_MUL", ",", "Register_MUL", "(", ")", ",", "1", ",", "6", ")", ";", "AddBuiltin", "(", "BuiltinOperator_L2_NORMALIZATION", ",", "Register_L2_NORMALIZATION", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LOCAL_RESPONSE_NORMALIZATION", ",", "Register_LOCAL_RESPONSE_NORMALIZATION", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LSTM", ",", "Register_LSTM", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_BIDIRECTIONAL_SEQUENCE_LSTM", ",", "Register_BIDIRECTIONAL_SEQUENCE_LSTM", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_UNIDIRECTIONAL_SEQUENCE_LSTM", ",", "Register_UNIDIRECTIONAL_SEQUENCE_LSTM", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_PAD", ",", "Register_PAD", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_PADV2", ",", "Register_PADV2", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RESHAPE", ",", "Register_RESHAPE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RESIZE_BILINEAR", ",", "Register_RESIZE_BILINEAR", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RESIZE_NEAREST_NEIGHBOR", ",", "Register_RESIZE_NEAREST_NEIGHBOR", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SKIP_GRAM", ",", "Register_SKIP_GRAM", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SPACE_TO_DEPTH", ",", "Register_SPACE_TO_DEPTH", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_DEPTH_TO_SPACE", ",", "Register_DEPTH_TO_SPACE", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_GATHER", ",", "Register_GATHER", "(", ")", ",", "1", ",", "5", ")", ";", "AddBuiltin", "(", "BuiltinOperator_TRANSPOSE", ",", "Register_TRANSPOSE", "(", ")", ",", "1", ",", "6", ")", ";", "AddBuiltin", "(", "BuiltinOperator_MEAN", ",", "Register_MEAN", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_DIV", ",", "Register_DIV", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SUB", ",", "Register_SUB", "(", ")", ",", "1", ",", "5", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SPLIT", ",", "Register_SPLIT", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SPLIT_V", ",", "Register_SPLIT_V", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SQUEEZE", ",", "Register_SQUEEZE", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_STRIDED_SLICE", ",", "Register_STRIDED_SLICE", "(", ")", ",", "1", ",", "6", ")", ";", "AddBuiltin", "(", "BuiltinOperator_EXP", ",", "Register_EXP", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_TOPK_V2", ",", "Register_TOPK_V2", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LOG", ",", "Register_LOG", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LOG_SOFTMAX", ",", "Register_LOG_SOFTMAX", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_CAST", ",", "Register_CAST", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_DEQUANTIZE", ",", "Register_DEQUANTIZE", "(", ")", ",", "1", ",", "5", ")", ";", "AddBuiltin", "(", "BuiltinOperator_PRELU", ",", "Register_PRELU", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_MAXIMUM", ",", "Register_MAXIMUM", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_MINIMUM", ",", "Register_MINIMUM", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ARG_MAX", ",", "Register_ARG_MAX", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ARG_MIN", ",", "Register_ARG_MIN", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_GREATER", ",", "Register_GREATER", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_GREATER_EQUAL", ",", "Register_GREATER_EQUAL", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LESS", ",", "Register_LESS", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LESS_EQUAL", ",", "Register_LESS_EQUAL", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_FLOOR", ",", "Register_FLOOR", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_CEIL", ",", "Register_CEIL", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ROUND", ",", "Register_ROUND", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_NEG", ",", "Register_NEG", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SELECT", ",", "Register_SELECT", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SELECT_V2", ",", "Register_SELECT_V2", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SLICE", ",", "Register_SLICE", "(", ")", ",", "1", ",", "5", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SIN", ",", "Register_SIN", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_COS", ",", "Register_COS", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_TRANSPOSE_CONV", ",", "Register_TRANSPOSE_CONV", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_TILE", ",", "Register_TILE", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SUM", ",", "Register_SUM", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_REDUCE_PROD", ",", "Register_REDUCE_PROD", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_REDUCE_MAX", ",", "Register_REDUCE_MAX", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_REDUCE_MIN", ",", "Register_REDUCE_MIN", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_REDUCE_ANY", ",", "Register_REDUCE_ANY", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_REDUCE_ALL", ",", "Register_REDUCE_ALL", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_EXPAND_DIMS", ",", "Register_EXPAND_DIMS", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SPARSE_TO_DENSE", ",", "Register_SPARSE_TO_DENSE", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_EQUAL", ",", "Register_EQUAL", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_NOT_EQUAL", ",", "Register_NOT_EQUAL", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SQRT", ",", "Register_SQRT", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RSQRT", ",", "Register_RSQRT", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SHAPE", ",", "Register_SHAPE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RANK", ",", "Register_RANK", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_POW", ",", "Register_POW", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_FAKE_QUANT", ",", "Register_FAKE_QUANT", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_PACK", ",", "Register_PACK", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ONE_HOT", ",", "Register_ONE_HOT", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LOGICAL_OR", ",", "Register_LOGICAL_OR", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LOGICAL_AND", ",", "Register_LOGICAL_AND", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LOGICAL_NOT", ",", "Register_LOGICAL_NOT", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_UNPACK", ",", "Register_UNPACK", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_FLOOR_DIV", ",", "Register_FLOOR_DIV", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SQUARE", ",", "Register_SQUARE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ZEROS_LIKE", ",", "Register_ZEROS_LIKE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_FLOOR_MOD", ",", "Register_FLOOR_MOD", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RANGE", ",", "Register_RANGE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_LEAKY_RELU", ",", "Register_LEAKY_RELU", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SQUARED_DIFFERENCE", ",", "Register_SQUARED_DIFFERENCE", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_FILL", ",", "Register_FILL", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_MIRROR_PAD", ",", "Register_MIRROR_PAD", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_UNIQUE", ",", "Register_UNIQUE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_REVERSE_V2", ",", "Register_REVERSE_V2", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ADD_N", ",", "Register_ADD_N", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_GATHER_ND", ",", "Register_GATHER_ND", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_WHERE", ",", "Register_WHERE", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ELU", ",", "Register_ELU", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_REVERSE_SEQUENCE", ",", "Register_REVERSE_SEQUENCE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_MATRIX_DIAG", ",", "Register_MATRIX_DIAG", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_QUANTIZE", ",", "Register_QUANTIZE", "(", ")", ",", "1", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_MATRIX_SET_DIAG", ",", "Register_MATRIX_SET_DIAG", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_IF", ",", "tflite", "::", "ops", "::", "builtin", "::", "Register_IF", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_WHILE", ",", "tflite", "::", "ops", "::", "builtin", "::", "Register_WHILE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_NON_MAX_SUPPRESSION_V4", ",", "Register_NON_MAX_SUPPRESSION_V4", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_NON_MAX_SUPPRESSION_V5", ",", "Register_NON_MAX_SUPPRESSION_V5", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SCATTER_ND", ",", "Register_SCATTER_ND", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_DENSIFY", ",", "Register_DENSIFY", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SEGMENT_SUM", ",", "Register_SEGMENT_SUM", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_BATCH_MATMUL", ",", "Register_BATCH_MATMUL", "(", ")", ",", "1", ",", "4", ")", ";", "AddBuiltin", "(", "BuiltinOperator_CUMSUM", ",", "Register_CUMSUM", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_BROADCAST_TO", ",", "Register_BROADCAST_TO", "(", ")", ",", "2", ",", "3", ")", ";", "AddBuiltin", "(", "BuiltinOperator_CALL_ONCE", ",", "tflite", "::", "ops", "::", "builtin", "::", "Register_CALL_ONCE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RFFT2D", ",", "Register_RFFT2D", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_CONV_3D", ",", "Register_CONV_3D", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_IMAG", ",", "Register_IMAG", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_REAL", ",", "Register_REAL", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_COMPLEX_ABS", ",", "Register_COMPLEX_ABS", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_BROADCAST_ARGS", ",", "Register_BROADCAST_ARGS", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_HASHTABLE", ",", "Register_HASHTABLE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_HASHTABLE_FIND", ",", "Register_HASHTABLE_FIND", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_HASHTABLE_IMPORT", ",", "Register_HASHTABLE_IMPORT", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_HASHTABLE_SIZE", ",", "Register_HASHTABLE_SIZE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_CONV_3D_TRANSPOSE", ",", "Register_CONV_3D_TRANSPOSE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_VAR_HANDLE", ",", "Register_VAR_HANDLE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_READ_VARIABLE", ",", "Register_READ_VARIABLE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ASSIGN_VARIABLE", ",", "Register_ASSIGN_VARIABLE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_MULTINOMIAL", ",", "Register_MULTINOMIAL", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RANDOM_STANDARD_NORMAL", ",", "Register_RANDOM_STANDARD_NORMAL", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_BUCKETIZE", ",", "Register_BUCKETIZE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_RANDOM_UNIFORM", ",", "Register_RANDOM_UNIFORM", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_GELU", ",", "Register_GELU", "(", ")", ",", "1", ",", "2", ")", ";", "AddBuiltin", "(", "BuiltinOperator_DYNAMIC_UPDATE_SLICE", ",", "Register_DYNAMIC_UPDATE_SLICE", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_UNSORTED_SEGMENT_PROD", ",", "Register_UNSORTED_SEGMENT_PROD", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_UNSORTED_SEGMENT_MAX", ",", "Register_UNSORTED_SEGMENT_MAX", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_UNSORTED_SEGMENT_MIN", ",", "Register_UNSORTED_SEGMENT_MIN", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_UNSORTED_SEGMENT_SUM", ",", "Register_UNSORTED_SEGMENT_SUM", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_ATAN2", ",", "Register_ATAN2", "(", ")", ")", ";", "AddBuiltin", "(", "BuiltinOperator_SIGN", ",", "Register_SIGN", "(", ")", ",", "1", ",", "2", ")", ";", "AddCustom", "(", "\"", "\"", ",", "tflite", "::", "ops", "::", "custom", "::", "Register_NUMERIC_VERIFY", "(", ")", ")", ";", "AddCustom", "(", "\"", "\"", ",", "tflite", "::", "ops", "::", "custom", "::", "Register_MFCC", "(", ")", ")", ";", "AddCustom", "(", "\"", "\"", ",", "tflite", "::", "ops", "::", "custom", "::", "Register_AUDIO_SPECTROGRAM", "(", ")", ")", ";", "AddCustom", "(", "\"", "\"", ",", "tflite", "::", "ops", "::", "custom", "::", "Register_DETECTION_POSTPROCESS", "(", ")", ")", ";", "may_directly_contain_user_defined_ops_", "=", "false", ";", "delegate_creators_", ".", "push_back", "(", "[", "]", "(", "TfLiteContext", "*", "context", ")", "{", "return", "tflite", "::", "MaybeCreateXNNPACKDelegate", "(", "context", ",", "false", ")", ";", "}", ")", ";", "}"], "to_mask": {"VAR": ["context"], "METHOD": ["AddBuiltin", "AddCustom", "MaybeCreateXNNPACKDelegate", "Register_ABS", "Register_ADD", "Register_ADD_N", "Register_ARG_MAX", "Register_ARG_MIN", "Register_ASSIGN_VARIABLE", "Register_ATAN2", "Register_AUDIO_SPECTROGRAM", "Register_AVERAGE_POOL_2D", "Register_BATCH_MATMUL", "Register_BATCH_TO_SPACE_ND", "Register_BIDIRECTIONAL_SEQUENCE_LSTM", "Register_BIDIRECTIONAL_SEQUENCE_RNN", "Register_BROADCAST_ARGS", "Register_BROADCAST_TO", "Register_BUCKETIZE", "Register_CALL_ONCE", "Register_CAST", "Register_CEIL", "Register_COMPLEX_ABS", "Register_CONCATENATION", "Register_CONV_2D", "Register_CONV_3D", "Register_CONV_3D_TRANSPOSE", "Register_COS", "Register_CUMSUM", "Register_DENSIFY", "Register_DEPTHWISE_CONV_2D", "Register_DEPTH_TO_SPACE", "Register_DEQUANTIZE", "Register_DETECTION_POSTPROCESS", "Register_DIV", "Register_DYNAMIC_UPDATE_SLICE", "Register_ELU", "Register_EMBEDDING_LOOKUP", "Register_EMBEDDING_LOOKUP_SPARSE", "Register_EQUAL", "Register_EXP", "Register_EXPAND_DIMS", "Register_FAKE_QUANT", "Register_FILL", "Register_FLOOR", "Register_FLOOR_DIV", "Register_FLOOR_MOD", "Register_FULLY_CONNECTED", "Register_GATHER", "Register_GATHER_ND", "Register_GELU", "Register_GREATER", "Register_GREATER_EQUAL", "Register_HARD_SWISH", "Register_HASHTABLE", "Register_HASHTABLE_FIND", "Register_HASHTABLE_IMPORT", "Register_HASHTABLE_LOOKUP", "Register_HASHTABLE_SIZE", "Register_IF", "Register_IMAG", "Register_L2_NORMALIZATION", "Register_L2_POOL_2D", "Register_LEAKY_RELU", "Register_LESS", "Register_LESS_EQUAL", "Register_LOCAL_RESPONSE_NORMALIZATION", "Register_LOG", "Register_LOGICAL_AND", "Register_LOGICAL_NOT", "Register_LOGICAL_OR", "Register_LOGISTIC", "Register_LOG_SOFTMAX", "Register_LSH_PROJECTION", "Register_LSTM", "Register_MATRIX_DIAG", "Register_MATRIX_SET_DIAG", "Register_MAXIMUM", "Register_MAX_POOL_2D", "Register_MEAN", "Register_MFCC", "Register_MINIMUM", "Register_MIRROR_PAD", "Register_MUL", "Register_MULTINOMIAL", "Register_NEG", "Register_NON_MAX_SUPPRESSION_V4", "Register_NON_MAX_SUPPRESSION_V5", "Register_NOT_EQUAL", "Register_NUMERIC_VERIFY", "Register_ONE_HOT", "Register_PACK", "Register_PAD", "Register_PADV2", "Register_POW", "Register_PRELU", "Register_QUANTIZE", "Register_RANDOM_STANDARD_NORMAL", "Register_RANDOM_UNIFORM", "Register_RANGE", "Register_RANK", "Register_READ_VARIABLE", "Register_REAL", "Register_REDUCE_ALL", "Register_REDUCE_ANY", "Register_REDUCE_MAX", "Register_REDUCE_MIN", "Register_REDUCE_PROD", "Register_RELU", "Register_RELU6", "Register_RELU_0_TO_1", "Register_RELU_N1_TO_1", "Register_RESHAPE", "Register_RESIZE_BILINEAR", "Register_RESIZE_NEAREST_NEIGHBOR", "Register_REVERSE_SEQUENCE", "Register_REVERSE_V2", "Register_RFFT2D", "Register_RNN", "Register_ROUND", "Register_RSQRT", "Register_SCATTER_ND", "Register_SEGMENT_SUM", "Register_SELECT", "Register_SELECT_V2", "Register_SHAPE", "Register_SIGN", "Register_SIN", "Register_SKIP_GRAM", "Register_SLICE", "Register_SOFTMAX", "Register_SPACE_TO_BATCH_ND", "Register_SPACE_TO_DEPTH", "Register_SPARSE_TO_DENSE", "Register_SPLIT", "Register_SPLIT_V", "Register_SQRT", "Register_SQUARE", "Register_SQUARED_DIFFERENCE", "Register_SQUEEZE", "Register_STRIDED_SLICE", "Register_SUB", "Register_SUM", "Register_SVDF", "Register_TANH", "Register_TILE", "Register_TOPK_V2", "Register_TRANSPOSE", "Register_TRANSPOSE_CONV", "Register_UNIDIRECTIONAL_SEQUENCE_LSTM", "Register_UNIDIRECTIONAL_SEQUENCE_RNN", "Register_UNIQUE", "Register_UNPACK", "Register_UNSORTED_SEGMENT_MAX", "Register_UNSORTED_SEGMENT_MIN", "Register_UNSORTED_SEGMENT_PROD", "Register_UNSORTED_SEGMENT_SUM", "Register_VAR_HANDLE", "Register_WHERE", "Register_WHILE", "Register_ZEROS_LIKE", "push_back"]}, "attention_idx_tokens": [243, 245], "patch": "@@ -82,7 +82,7 @@\n              Register_EMBEDDING_LOOKUP_SPARSE());\n   AddBuiltin(BuiltinOperator_FULLY_CONNECTED, Register_FULLY_CONNECTED(),\n              /* min_version = */ 1,\n-             /* max_version = */ 10);\n+             /* max_version = */ 11);", "ext_attention_idx_tokens": [243, 254], "uid": "6c5c160e", "question": "Why increment max version by 2?", "code": "BuiltinOpResolver BuiltinOpResolver { AddBuiltin BuiltinOperator ABS Register ABS * min version * 1 * max version * 5 ; AddBuiltin BuiltinOperator HARD SWISH Register HARD SWISH ; AddBuiltin BuiltinOperator RELU Register RELU * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator RELU N1 TO 1 Register RELU N1 TO 1 ; AddBuiltin BuiltinOperator RELU 0 TO 1 Register RELU 0 TO 1 ; AddBuiltin BuiltinOperator RELU6 Register RELU6 * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator TANH Register TANH * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator LOGISTIC Register LOGISTIC * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator AVERAGE POOL 2D Register AVERAGE POOL 2D * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator MAX POOL 2D Register MAX POOL 2D * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator L2 POOL 2D Register L2 POOL 2D ; AddBuiltin BuiltinOperator CONV 2D Register CONV 2D * min version * 1 * max version * 8 ; AddBuiltin BuiltinOperator DEPTHWISE CONV 2D Register DEPTHWISE CONV 2D * min version * 1 * max version * 6 ; AddBuiltin BuiltinOperator SVDF Register SVDF * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator RNN Register RNN * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator BIDIRECTIONAL SEQUENCE RNN Register BIDIRECTIONAL SEQUENCE RNN * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator UNIDIRECTIONAL SEQUENCE RNN Register UNIDIRECTIONAL SEQUENCE RNN * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator EMBEDDING LOOKUP Register EMBEDDING LOOKUP * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator EMBEDDING LOOKUP SPARSE Register EMBEDDING LOOKUP SPARSE ; AddBuiltin BuiltinOperator FULLY CONNECTED Register FULLY CONNECTED * min version * 1 * max version * 11 ; AddBuiltin BuiltinOperator LSH PROJECTION Register LSH PROJECTION ; AddBuiltin BuiltinOperator HASHTABLE LOOKUP Register HASHTABLE LOOKUP ; AddBuiltin BuiltinOperator SOFTMAX Register SOFTMAX * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator CONCATENATION Register CONCATENATION * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator ADD Register ADD * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator SPACE TO BATCH ND Register SPACE TO BATCH ND * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator BATCH TO SPACE ND Register BATCH TO SPACE ND * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator MUL Register MUL * min version * 1 * max version * 6 ; AddBuiltin BuiltinOperator L2 NORMALIZATION Register L2 NORMALIZATION * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator LOCAL RESPONSE NORMALIZATION Register LOCAL RESPONSE NORMALIZATION ; AddBuiltin BuiltinOperator LSTM Register LSTM * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator BIDIRECTIONAL SEQUENCE LSTM Register BIDIRECTIONAL SEQUENCE LSTM * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator UNIDIRECTIONAL SEQUENCE LSTM Register UNIDIRECTIONAL SEQUENCE LSTM * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator PAD Register PAD * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator PADV2 Register PADV2 * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator RESHAPE Register RESHAPE ; AddBuiltin BuiltinOperator RESIZE BILINEAR Register RESIZE BILINEAR * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator RESIZE NEAREST NEIGHBOR Register RESIZE NEAREST NEIGHBOR * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator SKIP GRAM Register SKIP GRAM ; AddBuiltin BuiltinOperator SPACE TO DEPTH Register SPACE TO DEPTH * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator DEPTH TO SPACE Register DEPTH TO SPACE * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator GATHER Register GATHER * min version * 1 * max version * 5 ; AddBuiltin BuiltinOperator TRANSPOSE Register TRANSPOSE * min version * 1 * max version * 6 ; AddBuiltin BuiltinOperator MEAN Register MEAN * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator DIV Register DIV * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator SUB Register SUB * min version * 1 * max version * 5 ; AddBuiltin BuiltinOperator SPLIT Register SPLIT * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator SPLIT V Register SPLIT V * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator SQUEEZE Register SQUEEZE * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator STRIDED SLICE Register STRIDED SLICE * min version * 1 * max version * 6 ; AddBuiltin BuiltinOperator EXP Register EXP ; AddBuiltin BuiltinOperator TOPK V2 Register TOPK V2 * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator LOG Register LOG ; AddBuiltin BuiltinOperator LOG SOFTMAX Register LOG SOFTMAX * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator CAST Register CAST * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator DEQUANTIZE Register DEQUANTIZE * min version * 1 * max version * 5 ; AddBuiltin BuiltinOperator PRELU Register PRELU ; AddBuiltin BuiltinOperator MAXIMUM Register MAXIMUM * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator MINIMUM Register MINIMUM * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator ARG MAX Register ARG MAX * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator ARG MIN Register ARG MIN * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator GREATER Register GREATER * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator GREATER EQUAL Register GREATER EQUAL * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator LESS Register LESS * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator LESS EQUAL Register LESS EQUAL * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator FLOOR Register FLOOR ; AddBuiltin BuiltinOperator CEIL Register CEIL ; AddBuiltin BuiltinOperator ROUND Register ROUND ; AddBuiltin BuiltinOperator NEG Register NEG ; AddBuiltin BuiltinOperator SELECT Register SELECT * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator SELECT V2 Register SELECT V2 ; AddBuiltin BuiltinOperator SLICE Register SLICE * min version * 1 * max version * 5 ; AddBuiltin BuiltinOperator SIN Register SIN ; AddBuiltin BuiltinOperator COS Register COS ; AddBuiltin BuiltinOperator TRANSPOSE CONV Register TRANSPOSE CONV * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator TILE Register TILE * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator SUM Register SUM * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator REDUCE PROD Register REDUCE PROD * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator REDUCE MAX Register REDUCE MAX * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator REDUCE MIN Register REDUCE MIN * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator REDUCE ANY Register REDUCE ANY ; AddBuiltin BuiltinOperator REDUCE ALL Register REDUCE ALL ; AddBuiltin BuiltinOperator EXPAND DIMS Register EXPAND DIMS ; AddBuiltin BuiltinOperator SPARSE TO DENSE Register SPARSE TO DENSE * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator EQUAL Register EQUAL * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator NOT EQUAL Register NOT EQUAL * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator SQRT Register SQRT ; AddBuiltin BuiltinOperator RSQRT Register RSQRT * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator SHAPE Register SHAPE ; AddBuiltin BuiltinOperator RANK Register RANK ; AddBuiltin BuiltinOperator POW Register POW ; AddBuiltin BuiltinOperator FAKE QUANT Register FAKE QUANT 1 2 ; AddBuiltin BuiltinOperator PACK Register PACK * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator ONE HOT Register ONE HOT ; AddBuiltin BuiltinOperator LOGICAL OR Register LOGICAL OR ; AddBuiltin BuiltinOperator LOGICAL AND Register LOGICAL AND ; AddBuiltin BuiltinOperator LOGICAL NOT Register LOGICAL NOT ; AddBuiltin BuiltinOperator UNPACK Register UNPACK * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator FLOOR DIV Register FLOOR DIV * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator SQUARE Register SQUARE ; AddBuiltin BuiltinOperator ZEROS LIKE Register ZEROS LIKE ; AddBuiltin BuiltinOperator FLOOR MOD Register FLOOR MOD ; AddBuiltin BuiltinOperator RANGE Register RANGE ; AddBuiltin BuiltinOperator LEAKY RELU Register LEAKY RELU * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator SQUARED DIFFERENCE Register SQUARED DIFFERENCE * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator FILL Register FILL * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator MIRROR PAD Register MIRROR PAD * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator UNIQUE Register UNIQUE ; AddBuiltin BuiltinOperator REVERSE V2 Register REVERSE V2 * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator ADD N Register ADD N ; AddBuiltin BuiltinOperator GATHER ND Register GATHER ND * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator WHERE Register WHERE * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator ELU Register ELU ; AddBuiltin BuiltinOperator REVERSE SEQUENCE Register REVERSE SEQUENCE ; AddBuiltin BuiltinOperator MATRIX DIAG Register MATRIX DIAG ; AddBuiltin BuiltinOperator QUANTIZE Register QUANTIZE * min version * 1 * max version * 3 ; AddBuiltin BuiltinOperator MATRIX SET DIAG Register MATRIX SET DIAG ; AddBuiltin BuiltinOperator IF tflite ops builtin Register IF ; AddBuiltin BuiltinOperator WHILE tflite ops builtin Register WHILE ; AddBuiltin BuiltinOperator NON MAX SUPPRESSION V4 Register NON MAX SUPPRESSION V4 ; AddBuiltin BuiltinOperator NON MAX SUPPRESSION V5 Register NON MAX SUPPRESSION V5 ; AddBuiltin BuiltinOperator SCATTER ND Register SCATTER ND ; AddBuiltin BuiltinOperator DENSIFY Register DENSIFY ; AddBuiltin BuiltinOperator SEGMENT SUM Register SEGMENT SUM ; AddBuiltin BuiltinOperator BATCH MATMUL Register BATCH MATMUL * min version * 1 * max version * 4 ; AddBuiltin BuiltinOperator CUMSUM Register CUMSUM ; The version one of broadcast to op won t be not supported since the version one was rollbacked and the builtin op code number has been changed because of builtin op code shortage problem AddBuiltin BuiltinOperator BROADCAST TO Register BROADCAST TO * min version * 2 * max version * 3 ; AddBuiltin BuiltinOperator CALL ONCE tflite ops builtin Register CALL ONCE ; AddBuiltin BuiltinOperator RFFT2D Register RFFT2D ; AddBuiltin BuiltinOperator CONV 3D Register CONV 3D ; AddBuiltin BuiltinOperator IMAG Register IMAG ; AddBuiltin BuiltinOperator REAL Register REAL ; AddBuiltin BuiltinOperator COMPLEX ABS Register COMPLEX ABS ; AddBuiltin BuiltinOperator BROADCAST ARGS Register BROADCAST ARGS ; AddBuiltin BuiltinOperator HASHTABLE Register HASHTABLE ; AddBuiltin BuiltinOperator HASHTABLE FIND Register HASHTABLE FIND ; AddBuiltin BuiltinOperator HASHTABLE IMPORT Register HASHTABLE IMPORT ; AddBuiltin BuiltinOperator HASHTABLE SIZE Register HASHTABLE SIZE ; AddBuiltin BuiltinOperator CONV 3D TRANSPOSE Register CONV 3D TRANSPOSE ; AddBuiltin BuiltinOperator VAR HANDLE Register VAR HANDLE ; AddBuiltin BuiltinOperator READ VARIABLE Register READ VARIABLE ; AddBuiltin BuiltinOperator ASSIGN VARIABLE Register ASSIGN VARIABLE ; AddBuiltin BuiltinOperator MULTINOMIAL Register MULTINOMIAL ; AddBuiltin BuiltinOperator RANDOM STANDARD NORMAL Register RANDOM STANDARD NORMAL ; AddBuiltin BuiltinOperator BUCKETIZE Register BUCKETIZE ; AddBuiltin BuiltinOperator RANDOM UNIFORM Register RANDOM UNIFORM ; AddBuiltin BuiltinOperator GELU Register GELU * min version * 1 * max version * 2 ; AddBuiltin BuiltinOperator DYNAMIC UPDATE SLICE Register DYNAMIC UPDATE SLICE ; AddBuiltin BuiltinOperator UNSORTED SEGMENT PROD Register UNSORTED SEGMENT PROD ; AddBuiltin BuiltinOperator UNSORTED SEGMENT MAX Register UNSORTED SEGMENT MAX ; AddBuiltin BuiltinOperator UNSORTED SEGMENT MIN Register UNSORTED SEGMENT MIN ; AddBuiltin BuiltinOperator UNSORTED SEGMENT SUM Register UNSORTED SEGMENT SUM ; AddBuiltin BuiltinOperator ATAN2 Register ATAN2 ; AddBuiltin BuiltinOperator SIGN Register SIGN * min version * 1 * max version * 2 ; AddCustom \"NumericVerify\" tflite ops custom Register NUMERIC VERIFY ; TODO andrewharp ahentz Move these somewhere more appropriate so that custom ops aren t always included by default AddCustom \"Mfcc\" tflite ops custom Register MFCC ; AddCustom \"AudioSpectrogram\" tflite ops custom Register AUDIO SPECTROGRAM ; AddCustom \"TFLite Detection PostProcess\" tflite ops custom Register DETECTION POSTPROCESS ; By definition all of the ops added above are not user-defined ops since they are supported by BuiltinOpResolver may directly contain user defined ops false; Populate the list of TF Lite delegate creators The created delegates could be applied to the model graph by default at runtime delegate creators push back [] TfLiteContext* context { return tflite MaybeCreateXNNPACKDelegate context *enable xnnpack unsigned quantized * false ; } ; }"}
{"message": "Ok I suppose we don't have this coverage in the OSS CI?", "timestamp": "2023-01-03T23:24:21Z", "file_name": "tensorflow/core/kernels/range_sampler_test.cc", "range": {"start_line": 179, "end_line": 179, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1061031117", "html_url": "https://github.com/tensorflow/tensorflow/pull/58358#discussion_r1061031117", "attention_area": "  FixedUnigramSampler* test_sampler = new FixedUnigramSampler(8, 0.8, 0, 1, 0);", "file_path": "files/22/00/00000022.cc", "old_file_path": "files/23/00/00000023.cc", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -157,32 +157,54 @@ TEST_F(RangeSamplerTest, FixedUnigramProbabilities) {\n   Env* env = Env::Default();\n   string fname = io::JoinPath(testing::TmpDir(), \"vocab_file\");\n   TF_CHECK_OK(WriteStringToFile(env, fname, kVocabContent));\n-  sampler_.reset(new FixedUnigramSampler(env, 9, fname, 0.8, 0, 1, 0));\n+  FixedUnigramSampler* test_sampler = new FixedUnigramSampler(9, 0.8, 0, 1, 0);\n+  TF_CHECK_OK(test_sampler->SetDistributionSampler(env, fname));\n+  sampler_.reset(test_sampler);\n   // 1^0.8+2^0.8+4^0.8+...+256^0.8=197.05\n   for (int i = 0; i < 9; i++) {\n     ASSERT_NEAR(sampler_->Probability(i), pow(2, i * 0.8) / 197.05, 1e-4);\n   }\n }\n+TEST_F(RangeSamplerTest, FixedUnigramNoExistingFilename) {\n+  Env* env = Env::Default();\n+  string fname = \"NoExistingFile\";\n+  FixedUnigramSampler* test_sampler = new FixedUnigramSampler(9, 0.8, 0, 1, 0);\n+  Status s = test_sampler->SetDistributionSampler(env, fname);\n+  EXPECT_TRUE(errors::IsNotFound(s)) << s;\n+}\n+TEST_F(RangeSamplerTest, FixedUnigramNoMatchingRangeWeights) {\n+  Env* env = Env::Default();\n+  string fname = io::JoinPath(testing::TmpDir(), \"vocab_file\");\n+  TF_CHECK_OK(WriteStringToFile(env, fname, kVocabContent));\n+  FixedUnigramSampler* test_sampler = new FixedUnigramSampler(8, 0.8, 0, 1, 0);", "source": "TEST_F(RangeSamplerTest, FixedUnigramNoMatchingRangeWeights) {\n  Env* env = Env::Default();\n  string fname = io::JoinPath(testing::TmpDir(), \"vocab_file\");\n  TF_CHECK_OK(WriteStringToFile(env, fname, kVocabContent));\n  FixedUnigramSampler* test_sampler = new FixedUnigramSampler(8, 0.8, 0, 1, 0);\n  Status s = test_sampler->SetDistributionSampler(env, fname);\n  EXPECT_TRUE(errors::IsInvalidArgument(s)) << s;\n}", "source_start_line": 175, "tokens": ["TEST_F", "(", "RangeSamplerTest", ",", "FixedUnigramNoMatchingRangeWeights", ")", "{", "Env", "*", "env", "=", "Env", "::", "Default", "(", ")", ";", "string", "fname", "=", "io", "::", "JoinPath", "(", "testing", "::", "TmpDir", "(", ")", ",", "\"", "\"", ")", ";", "TF_CHECK_OK", "(", "WriteStringToFile", "(", "env", ",", "fname", ",", "kVocabContent", ")", ")", ";", "FixedUnigramSampler", "*", "test_sampler", "=", "new", "FixedUnigramSampler", "(", "8", ",", "0.8", ",", "0", ",", "1", ",", "0", ")", ";", "Status", "s", "=", "test_sampler", "->", "SetDistributionSampler", "(", "env", ",", "fname", ")", ";", "EXPECT_TRUE", "(", "errors", "::", "IsInvalidArgument", "(", "s", ")", ")", "<<", "s", ";", "}"], "to_mask": {"VAR": ["env", "fname", "s", "test_sampler"], "METHOD": ["Default", "EXPECT_TRUE", "IsInvalidArgument", "JoinPath", "SetDistributionSampler", "TF_CHECK_OK", "TmpDir", "WriteStringToFile"]}, "attention_idx_tokens": [46, 63], "patch": "@@ -157,32 +157,54 @@\n   Env* env = Env::Default();\n   string fname = io::JoinPath(testing::TmpDir(), \"vocab_file\");\n   TF_CHECK_OK(WriteStringToFile(env, fname, kVocabContent));\n-  sampler_.reset(new FixedUnigramSampler(env, 9, fname, 0.8, 0, 1, 0));\n+  FixedUnigramSampler* test_sampler = new FixedUnigramSampler(9, 0.8, 0, 1, 0);\n+  TF_CHECK_OK(test_sampler->SetDistributionSampler(env, fname));\n+  sampler_.reset(test_sampler);\n   // 1^0.8+2^0.8+4^0.8+...+256^0.8=197.05\n   for (int i = 0; i < 9; i++) {\n     ASSERT_NEAR(sampler_->Probability(i), pow(2, i * 0.8) / 197.05, 1e-4);\n   }\n }\n+TEST_F(RangeSamplerTest, FixedUnigramNoExistingFilename) {\n+  Env* env = Env::Default();\n+  string fname = \"NoExistingFile\";\n+  FixedUnigramSampler* test_sampler = new FixedUnigramSampler(9, 0.8, 0, 1, 0);\n+  Status s = test_sampler->SetDistributionSampler(env, fname);\n+  EXPECT_TRUE(errors::IsNotFound(s)) << s;\n+}\n+TEST_F(RangeSamplerTest, FixedUnigramNoMatchingRangeWeights) {\n+  Env* env = Env::Default();\n+  string fname = io::JoinPath(testing::TmpDir(), \"vocab_file\");\n+  TF_CHECK_OK(WriteStringToFile(env, fname, kVocabContent));\n+  FixedUnigramSampler* test_sampler = new FixedUnigramSampler(8, 0.8, 0, 1, 0);", "ext_attention_idx_tokens": [0, 88], "uid": "37e153e1", "question": "Ok I suppose we don't have this coverage in the OSS CI?", "code": "TEST F RangeSamplerTest FixedUnigramNoMatchingRangeWeights { Env* env Env Default ; string fname io JoinPath testing TmpDir \"vocab file\" ; TF CHECK OK WriteStringToFile env fname kVocabContent ; FixedUnigramSampler* test sampler new FixedUnigramSampler 8 0 8 0 1 0 ; Status s test sampler->SetDistributionSampler env fname ; EXPECT TRUE errors IsInvalidArgument s << s; }"}
{"message": "what does \"#125091515651\" mean here?", "timestamp": "2023-01-12T00:51:17Z", "file_name": "tensorflow/python/kernel_tests/random/random_binomial_test.py", "range": {"start_line": 213, "end_line": 213, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1067599881", "html_url": "https://github.com/tensorflow/tensorflow/pull/59233#discussion_r1067599881", "attention_area": "    shape_0 = constant_op.constant(1, dtype=dtypes.int64) #125091515651", "file_path": "files/98/00/00000098.py", "old_file_path": "files/99/00/00000099.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -207,6 +208,24 @@ def moment(self, i):\n         )\n         self.assertAllLess(z_scores, z_limit)\n \n+  def testStatelessDtypes(self):\n+    # Test case for GitHub issue 59160\n+    shape_0 = constant_op.constant(1, dtype=dtypes.int64) #125091515651", "source": "def testStatelessDtypes(self):\n    # Test case for GitHub issue 59160\n    shape_0 = constant_op.constant(1, dtype=dtypes.int64) #125091515651\n    shape = [shape_0,]\n    seed_0 = 12\n    seed_1 = 34\n    seed = [seed_0,seed_1,]\n    counts = 10.0\n    probs = 0.4\n    output_dtype = dtypes.float16\n    out = stateless_random_ops.stateless_random_binomial(\n        shape=shape,\n        seed=seed,\n        counts=counts,\n        probs=probs,\n        output_dtype=output_dtype)\n    self.evaluate(out)", "source_start_line": 211, "tokens": ["def", "testStatelessDtypes", "(", "self", ")", ":", "shape_0", "=", "constant_op", ".", "constant", "(", "1", ",", "dtype", "=", "dtypes", ".", "int64", ")", "shape", "=", "[", "shape_0", ",", "]", "seed_0", "=", "12", "seed_1", "=", "34", "seed", "=", "[", "seed_0", ",", "seed_1", ",", "]", "counts", "=", "10.0", "probs", "=", "0.4", "output_dtype", "=", "dtypes", ".", "float16", "out", "=", "stateless_random_ops", ".", "stateless_random_binomial", "(", "shape", "=", "shape", ",", "seed", "=", "seed", ",", "counts", "=", "counts", ",", "probs", "=", "probs", ",", "output_dtype", "=", "output_dtype", ")", "self", ".", "evaluate", "(", "out", ")"], "to_mask": {"VAR": ["counts", "out", "output_dtype", "probs", "seed", "seed_0", "seed_1", "self", "shape", "shape_0"], "METHOD": ["constant", "evaluate", "stateless_random_binomial"]}, "attention_idx_tokens": [6, 19], "patch": "@@ -207,6 +208,24 @@\n         )\n         self.assertAllLess(z_scores, z_limit)\n \n+  def testStatelessDtypes(self):\n+    # Test case for GitHub issue 59160\n+    shape_0 = constant_op.constant(1, dtype=dtypes.int64) #125091515651", "ext_attention_idx_tokens": [0, 82], "uid": "08e77afb", "question": "what does \"#125091515651\" mean here?", "code": "def testStatelessDtypes self # Test case for GitHub issue 59160 shape 0 constant op constant 1 dtype dtypes int64 #125091515651 shape [shape 0 ] seed 0 12 seed 1 34 seed [seed 0 seed 1 ] counts 10 0 probs 0 4 output dtype dtypes float16 out stateless random ops stateless random binomial shape shape seed seed counts counts probs probs output dtype output dtype self evaluate out"}
{"message": "Why was this change needed?", "timestamp": "2023-01-17T16:46:32Z", "file_name": "tensorflow/compiler/mlir/tosa/transforms/legalize_utils.cc", "range": {"start_line": 316, "end_line": 316, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1072452510", "html_url": "https://github.com/tensorflow/tensorflow/pull/59100#discussion_r1072452510", "attention_area": "  auto const_type = tensorflow::GetTypeFromTFTensorShape({513}, rewriter.getIntegerType(16));", "file_path": "files/22/01/00000122.cc", "old_file_path": "files/23/01/00000123.cc", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -313,13 +313,9 @@ Value getTosaConst16bitTable(PatternRewriter& rewriter, Operation* op,\n   table.push_back(\n       static_cast<int16_t>(std::min(std::max(max_val, -32768), 32767)));\n \n-  auto element_qtype =\n-      UniformQuantizedType::get(true, rewriter.getIntegerType(16),\n-                                rewriter.getF32Type(), 1.0f, 0, -32768, 32767);\n-  auto const_type = tensorflow::GetTypeFromTFTensorShape({513}, element_qtype);\n-  auto storage_type = tensorflow::GetTypeFromTFTensorShape(\n-      {513}, element_qtype.getStorageType());\n-  auto const_attr = DenseElementsAttr::get(storage_type, llvm::ArrayRef(table));\n+  auto const_type = tensorflow::GetTypeFromTFTensorShape({513}, rewriter.getIntegerType(16));", "source": "Value getTosaConst16bitTable(PatternRewriter& rewriter, Operation* op,\n                             std::function<double(double)> func, double min,\n                             double max) {\n  SmallVector<int16_t, 513> table;\n\n  double step = (max - min) / 512.0f;\n  double half_step = step / 2.0f;\n  for (int32_t i = 0; i < 512; i++) {\n    int32_t sample_val = std::llround(func(min + (i * step)) * 32768.0);\n    double midpoint_interp_val =\n        std::round(((func(min + (i + 1) * step) * 32768.0) +\n                    std::round(func(min + (i * step)) * 32768.0)) /\n                   2.0);\n    double midpoint_val =\n        std::round(func(min + (i * step) + half_step) * 32768.0);\n    double midpoint_err = midpoint_interp_val - midpoint_val;\n    int32_t bias = std::llround(midpoint_err / 2.0);\n\n    table.push_back(static_cast<int16_t>(\n        std::min(std::max(sample_val - bias, -32768), 32767)));\n  }\n\n  int32_t max_val = std::llround(func(max) * 32768.0);\n  table.push_back(\n      static_cast<int16_t>(std::min(std::max(max_val, -32768), 32767)));\n\n  auto const_type = tensorflow::GetTypeFromTFTensorShape({513}, rewriter.getIntegerType(16));\n  auto const_attr =\n      DenseElementsAttr::get(const_type, llvm::ArrayRef(table));\n\n  auto const_op =\n      rewriter.create<tosa::ConstOp>(op->getLoc(), const_type, const_attr);\n  return const_op.getResult();\n}", "source_start_line": 290, "tokens": ["Value", "getTosaConst16bitTable", "(", "PatternRewriter", "&", "rewriter", ",", "Operation", "*", "op", ",", "std", "::", "function", "<", "double", "(", "double", ")", ">", "func", ",", "double", "min", ",", "double", "max", ")", "{", "SmallVector", "<", "int16_t", ",", "513", ">", "table", ";", "double", "step", "=", "(", "max", "-", "min", ")", "/", "512.0f", ";", "double", "half_step", "=", "step", "/", "2.0f", ";", "for", "(", "int32_t", "i", "=", "0", ";", "i", "<", "512", ";", "i", "++", ")", "{", "int32_t", "sample_val", "=", "std", "::", "llround", "(", "func", "(", "min", "+", "(", "i", "*", "step", ")", ")", "*", "32768.0", ")", ";", "double", "midpoint_interp_val", "=", "std", "::", "round", "(", "(", "(", "func", "(", "min", "+", "(", "i", "+", "1", ")", "*", "step", ")", "*", "32768.0", ")", "+", "std", "::", "round", "(", "func", "(", "min", "+", "(", "i", "*", "step", ")", ")", "*", "32768.0", ")", ")", "/", "2.0", ")", ";", "double", "midpoint_val", "=", "std", "::", "round", "(", "func", "(", "min", "+", "(", "i", "*", "step", ")", "+", "half_step", ")", "*", "32768.0", ")", ";", "double", "midpoint_err", "=", "midpoint_interp_val", "-", "midpoint_val", ";", "int32_t", "bias", "=", "std", "::", "llround", "(", "midpoint_err", "/", "2.0", ")", ";", "table", ".", "push_back", "(", "static_cast", "<", "int16_t", ">", "(", "std", "::", "min", "(", "std", "::", "max", "(", "sample_val", "-", "bias", ",", "-32768", ")", ",", "32767", ")", ")", ")", ";", "}", "int32_t", "max_val", "=", "std", "::", "llround", "(", "func", "(", "max", ")", "*", "32768.0", ")", ";", "table", ".", "push_back", "(", "static_cast", "<", "int16_t", ">", "(", "std", "::", "min", "(", "std", "::", "max", "(", "max_val", ",", "-32768", ")", ",", "32767", ")", ")", ")", ";", "auto", "const_type", "=", "tensorflow", "::", "GetTypeFromTFTensorShape", "(", "{", "513", "}", ",", "rewriter", ".", "getIntegerType", "(", "16", ")", ")", ";", "auto", "const_attr", "=", "DenseElementsAttr", "::", "get", "(", "const_type", ",", "llvm", "::", "ArrayRef", "(", "table", ")", ")", ";", "auto", "const_op", "=", "rewriter", ".", "create", "<", "tosa", "::", "ConstOp", ">", "(", "op", "->", "getLoc", "(", ")", ",", "const_type", ",", "const_attr", ")", ";", "return", "const_op", ".", "getResult", "(", ")", ";", "}"], "to_mask": {"VAR": ["bias", "const_attr", "const_op", "const_type", "func", "half_step", "i", "max", "max_val", "midpoint_err", "midpoint_interp_val", "midpoint_val", "min", "op", "rewriter", "sample_val", "step", "table"], "METHOD": ["ArrayRef", "GetTypeFromTFTensorShape", "func", "get", "getIntegerType", "getLoc", "getResult", "llround", "max", "min", "push_back", "rewriter", "round", "static_cast"]}, "attention_idx_tokens": [252, 270], "patch": "@@ -313,13 +313,9 @@\n   table.push_back(\n       static_cast<int16_t>(std::min(std::max(max_val, -32768), 32767)));\n \n-  auto element_qtype =\n-      UniformQuantizedType::get(true, rewriter.getIntegerType(16),\n-                                rewriter.getF32Type(), 1.0f, 0, -32768, 32767);\n-  auto const_type = tensorflow::GetTypeFromTFTensorShape({513}, element_qtype);\n-  auto storage_type = tensorflow::GetTypeFromTFTensorShape(\n-      {513}, element_qtype.getStorageType());\n-  auto const_attr = DenseElementsAttr::get(storage_type, llvm::ArrayRef(table));\n+  auto const_type = tensorflow::GetTypeFromTFTensorShape({513}, rewriter.getIntegerType(16));", "ext_attention_idx_tokens": [252, 287], "uid": "e98c89a6", "question": "Why was this change needed?", "code": "Value getTosaConst16bitTable PatternRewriter& rewriter Operation* op std function<double double > func double min double max { SmallVector<int16 t 513> table; double step max - min 512 0f; double half step step 2 0f; for int32 t i 0; i < 512; i++ { int32 t sample val std llround func min + i * step * 32768 0 ; double midpoint interp val std round func min + i + 1 * step * 32768 0 + std round func min + i * step * 32768 0 2 0 ; double midpoint val std round func min + i * step + half step * 32768 0 ; double midpoint err midpoint interp val - midpoint val; int32 t bias std llround midpoint err 2 0 ; table push back static cast<int16 t> std min std max sample val - bias -32768 32767 ; } int32 t max val std llround func max * 32768 0 ; table push back static cast<int16 t> std min std max max val -32768 32767 ; auto const type tensorflow GetTypeFromTFTensorShape {513} rewriter getIntegerType 16 ; auto const attr DenseElementsAttr get const type llvm ArrayRef table ; auto const op rewriter create<tosa ConstOp> op->getLoc const type const attr ; return const op getResult ; }"}
{"message": "ROCM 5.0 should be OK. However, I didn't pay attention to the fact that the error message looked more like a linker error, not a compiler error. I also didn't notice that the other API calls for rocblas go through a wrapper, most likely with the intent to support loading the rocblas library dynamically at runtime. Therefore, I have updated the call to `rocblas_set_atomics_mode` to also use this wrapper, hopefully that will resolve the problem. Could you please rerun the CI?", "timestamp": "2023-01-18T17:59:04Z", "file_name": "tensorflow/compiler/xla/stream_executor/rocm/rocm_blas.cc", "range": {"start_line": 204, "end_line": 204, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1073885422", "html_url": "https://github.com/tensorflow/tensorflow/pull/58284#discussion_r1073885422", "attention_area": "    ret = rocblas_set_atomics_mode(blas_, rocblas_atomics_not_allowed);", "file_path": "files/12/01/00000112.cc", "old_file_path": "files/13/01/00000113.cc", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -193,7 +196,19 @@ bool ROCMBlas::DoBlasInternalImpl(FuncT rocblas_func, Stream *stream,\n   }\n \n   gpu::ScopedActivateExecutorContext sac{parent_};\n-  rocblas_status ret = rocblas_func(blas_, args...);\n+\n+  // set the atomics mode, leaving default to library\n+  bool allow_atomics = !OpDeterminismRequired();\n+  rocblas_status ret;\n+  if (!allow_atomics) {\n+    ret = rocblas_set_atomics_mode(blas_, rocblas_atomics_not_allowed);", "source": "bool ROCMBlas::DoBlasInternalImpl(FuncT rocblas_func, Stream *stream,\n                                  bool pointer_mode_host, bool err_on_failure,\n                                  Args... args) {\n  absl::MutexLock lock{&mu_};\n\n  CHECK(blas_ != nullptr);\n  if (!SetStream(stream)) {\n    return false;\n  }\n\n  gpu::ScopedActivateExecutorContext sac{parent_};\n\n  // set the atomics mode, leaving default to library\n  bool allow_atomics = !OpDeterminismRequired();\n  rocblas_status ret;\n  if (!allow_atomics) {\n    ret = rocblas_set_atomics_mode(blas_, rocblas_atomics_not_allowed);\n    if (err_on_failure && ret != rocblas_status_success) {\n      LOG(ERROR) << \"failed to to set atomics mode before \" << rocblas_func.kName << \": \"\n                 << ToString(ret);\n    }\n  }\n\n  ret = rocblas_func(blas_, args...);\n  if (err_on_failure && ret != rocblas_status_success) {\n    LOG(ERROR) << \"failed to run ROCBLAS routine \" << rocblas_func.kName << \": \"\n               << ToString(ret);\n  }\n  return ret == rocblas_status_success;\n}", "source_start_line": 188, "tokens": ["bool", "ROCMBlas", "::", "DoBlasInternalImpl", "(", "FuncT", "rocblas_func", ",", "Stream", "*", "stream", ",", "bool", "pointer_mode_host", ",", "bool", "err_on_failure", ",", "Args", "...", "args", ")", "{", "absl", "::", "MutexLock", "lock", "{", "&", "mu_", "}", ";", "CHECK", "(", "blas_", "!=", "nullptr", ")", ";", "if", "(", "!", "SetStream", "(", "stream", ")", ")", "{", "return", "false", ";", "}", "gpu", "::", "ScopedActivateExecutorContext", "sac", "{", "parent_", "}", ";", "bool", "allow_atomics", "=", "!", "OpDeterminismRequired", "(", ")", ";", "rocblas_status", "ret", ";", "if", "(", "!", "allow_atomics", ")", "{", "ret", "=", "rocblas_set_atomics_mode", "(", "blas_", ",", "rocblas_atomics_not_allowed", ")", ";", "if", "(", "err_on_failure", "&&", "ret", "!=", "rocblas_status_success", ")", "{", "LOG", "(", "ERROR", ")", "<<", "\"", "\"", "<<", "rocblas_func", ".", "kName", "<<", "\"", "\"", "<<", "ToString", "(", "ret", ")", ";", "}", "}", "ret", "=", "rocblas_func", "(", "blas_", ",", "args", "...", ")", ";", "if", "(", "err_on_failure", "&&", "ret", "!=", "rocblas_status_success", ")", "{", "LOG", "(", "ERROR", ")", "<<", "\"", "\"", "<<", "rocblas_func", ".", "kName", "<<", "\"", "\"", "<<", "ToString", "(", "ret", ")", ";", "}", "return", "ret", "==", "rocblas_status_success", ";", "}"], "to_mask": {"VAR": ["allow_atomics", "err_on_failure", "lock", "pointer_mode_host", "ret", "rocblas_func", "sac", "stream"], "METHOD": ["CHECK", "LOG", "OpDeterminismRequired", "SetStream", "ToString", "rocblas_func", "rocblas_set_atomics_mode"]}, "attention_idx_tokens": [77, 85], "patch": "@@ -193,7 +196,19 @@\n   }\n \n   gpu::ScopedActivateExecutorContext sac{parent_};\n-  rocblas_status ret = rocblas_func(blas_, args...);\n+\n+  // set the atomics mode, leaving default to library\n+  bool allow_atomics = !OpDeterminismRequired();\n+  rocblas_status ret;\n+  if (!allow_atomics) {\n+    ret = rocblas_set_atomics_mode(blas_, rocblas_atomics_not_allowed);", "ext_attention_idx_tokens": [60, 135], "uid": "8baa26a3", "question": "ROCM 5.0 should be OK. However, I didn't pay attention to the fact that the error message looked more like a linker error, not a compiler error. I also didn't notice that the other API calls for rocblas go through a wrapper, most likely with the intent to support loading the rocblas library dynamically at runtime. Therefore, I have updated the call to `rocblas_set_atomics_mode` to also use this wrapper, hopefully that will resolve the problem. Could you please rerun the CI?", "code": "bool ROCMBlas DoBlasInternalImpl FuncT rocblas func Stream *stream bool pointer mode host bool err on failure Args args { absl MutexLock lock{&mu }; CHECK blas ! nullptr ; if !SetStream stream { return false; } gpu ScopedActivateExecutorContext sac{parent }; set the atomics mode leaving default to library bool allow atomics !OpDeterminismRequired ; rocblas status ret; if !allow atomics { ret rocblas set atomics mode blas rocblas atomics not allowed ; if err on failure && ret ! rocblas status success { LOG ERROR << \"failed to to set atomics mode before \" << rocblas func kName << \" \" << ToString ret ; } } ret rocblas func blas args ; if err on failure && ret ! rocblas status success { LOG ERROR << \"failed to run ROCBLAS routine \" << rocblas func kName << \" \" << ToString ret ; } return ret rocblas status success; }"}
{"message": "Maybe users just installed it to the wrong path. How about \"Could not find TensorRT.\" ?\r\n\r\n@reedwm What do you think?", "timestamp": "2023-01-18T18:17:57Z", "file_name": "tensorflow/compiler/tf2tensorrt/utils/py_utils.cc", "range": {"start_line": 38, "end_line": 38, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1073908868", "html_url": "https://github.com/tensorflow/tensorflow/pull/59256#discussion_r1073908868", "attention_area": "    LOG_WARNING_WITH_PREFIX << \"TensorRT is not installed.\";", "file_path": "files/30/01/00000130.cc", "old_file_path": "files/31/01/00000131.cc", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -35,10 +35,7 @@ bool IsGoogleTensorRTEnabled() {\n #else   // TF_USE_TENSORRT_STATIC\n   auto handle_or = se::internal::DsoLoader::TryDlopenTensorRTLibraries();\n   if (!handle_or.ok()) {\n-    LOG_WARNING_WITH_PREFIX\n-        << \"Cannot dlopen some TensorRT libraries. If you would like \"\n-           \"to use Nvidia GPU with TensorRT, please make sure the \"\n-           \"missing libraries mentioned above are installed properly.\";\n+    LOG_WARNING_WITH_PREFIX << \"TensorRT is not installed.\";", "source": "bool IsGoogleTensorRTEnabled() {\n#if GOOGLE_CUDA && GOOGLE_TENSORRT\n#if TF_USE_TENSORRT_STATIC\n  LOG(INFO) << \"TensorRT libraries are statically linked, skip dlopen check\";\n  return true;\n#else   // TF_USE_TENSORRT_STATIC\n  auto handle_or = se::internal::DsoLoader::TryDlopenTensorRTLibraries();\n  if (!handle_or.ok()) {\n    LOG_WARNING_WITH_PREFIX << \"TensorRT is not installed.\";\n  }\n  return handle_or.ok();\n#endif  // TF_USE_TENSORRT_STATIC\n#else   // GOOGLE_CUDA && GOOGLE_TENSORRT\n  return false;\n#endif  // GOOGLE_CUDA && GOOGLE_TENSORRT\n}", "source_start_line": 30, "tokens": ["bool", "IsGoogleTensorRTEnabled", "(", ")", "{", "#if", "GOOGLE_CUDA", "&&", "GOOGLE_TENSORRT", "", "#if", "TF_USE_TENSORRT_STATIC", "", "LOG", "(", "INFO", ")", "<<", "\"", "\"", ";", "return", "true", ";", "#else", "auto", "handle_or", "=", "se", "::", "internal", "::", "DsoLoader", "::", "TryDlopenTensorRTLibraries", "(", ")", ";", "if", "(", "!", "handle_or", ".", "ok", "(", ")", ")", "{", "LOG_WARNING_WITH_PREFIX", "<<", "\"", "\"", ";", "}", "return", "handle_or", ".", "ok", "(", ")", ";", "#endif", "#else", "return", "false", ";", "#endif", "}"], "to_mask": {"VAR": ["handle_or"], "METHOD": ["LOG", "TryDlopenTensorRTLibraries", "ok"]}, "attention_idx_tokens": [48, 52], "patch": "@@ -35,10 +35,7 @@\n #else   // TF_USE_TENSORRT_STATIC\n   auto handle_or = se::internal::DsoLoader::TryDlopenTensorRTLibraries();\n   if (!handle_or.ok()) {\n-    LOG_WARNING_WITH_PREFIX\n-        << \"Cannot dlopen some TensorRT libraries. If you would like \"\n-           \"to use Nvidia GPU with TensorRT, please make sure the \"\n-           \"missing libraries mentioned above are installed properly.\";\n+    LOG_WARNING_WITH_PREFIX << \"TensorRT is not installed.\";", "ext_attention_idx_tokens": [48, 53], "uid": "b5205519", "question": "Maybe users just installed it to the wrong path. How about \"Could not find TensorRT.\" ?    @reedwm What do you think?", "code": "bool IsGoogleTensorRTEnabled { #if GOOGLE CUDA && GOOGLE TENSORRT #if TF USE TENSORRT STATIC LOG INFO << \"TensorRT libraries are statically linked skip dlopen check\"; return true; #else TF USE TENSORRT STATIC auto handle or se internal DsoLoader TryDlopenTensorRTLibraries ; if !handle or ok { LOG WARNING WITH PREFIX << \"TensorRT is not installed \"; } return handle or ok ; #endif TF USE TENSORRT STATIC #else GOOGLE CUDA && GOOGLE TENSORRT return false; #endif GOOGLE CUDA && GOOGLE TENSORRT }"}
{"message": "Fixed. Can you please let us know the reason behind this suggestion?", "timestamp": "2023-01-20T15:02:13Z", "file_name": "tensorflow/core/common_runtime/zen_layout_pass.cc", "range": {"start_line": 352, "end_line": 352, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1082670638", "html_url": "https://github.com/tensorflow/tensorflow/pull/59137#discussion_r1082670638", "attention_area": "  CHECK_NOTNULL(n);", "file_path": "files/38/01/00000138.cc", "old_file_path": null, "filters": {"comment_message": false, "patchset": true, "first_in_thread": false, "valid_patch": true}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -0,0 +1,1292 @@\n+/* Copyright 2023 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifdef AMD_ZENDNN\n+\n+#include <algorithm>\n+#include <functional>\n+#include <iterator>\n+#include <memory>\n+#include <queue>\n+#include <set>\n+#include <stack>\n+#include <string>\n+#include <tuple>\n+#include <unordered_map>\n+#include <unordered_set>\n+#include <utility>\n+#include <vector>\n+\n+#include \"tensorflow/core/common_runtime/function.h\"\n+#include \"tensorflow/core/common_runtime/layout_pass_util.h\"\n+#include \"tensorflow/core/common_runtime/optimization_registry.h\"\n+#include \"tensorflow/core/framework/node_def_util.h\"\n+#include \"tensorflow/core/framework/tensor.pb.h\"\n+#include \"tensorflow/core/graph/algorithm.h\"\n+#include \"tensorflow/core/graph/graph.h\"\n+#include \"tensorflow/core/graph/zen_graph_util.h\"\n+#include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/lib/core/status.h\"\n+#include \"tensorflow/core/lib/gtl/array_slice.h\"\n+#include \"tensorflow/core/lib/gtl/map_util.h\"\n+#include \"tensorflow/core/lib/hash/hash.h\"\n+#include \"tensorflow/core/util/port.h\"\n+#include \"tensorflow/core/util/tensor_format.h\"\n+#include \"tensorflow/core/util/zen_util.h\"\n+\n+namespace tensorflow {\n+\n+// This pass implements rewriting of graph to support following scenarios:\n+// (A) Merging nodes in the graph\n+// (B) Updating nodes in graph\n+//\n+// Example of A : Merging nodes in the graph\n+// -----------------------------------------\n+// Currently, we merge Pad + Conv2D together.\n+// Consider the subgraph below :\n+//\n+//        [Const Op]\n+//                  \\\n+//  [Sub-Graph 1]-->[Pad Op]-->[Conv2D_1]-->[Sub-Graph 2]\n+//\n+// As part of fusion, the graph gets transformed to\n+//\n+// [Sub-Graph 1]-->[Conv2D_2]-->[Sub-Graph 2]\n+//\n+// This fusion is valid provided Conv2D op supports EXPLICIT padding\n+//\n+// The padding value from the Pad op is added up to the existing pad value of\n+// the Conv op and the Pad op is removed.\n+//\n+// Only the padding values of the Conv op is updated and the sub-graph linked\n+// to Pad op is now linked with the Conv op.\n+//\n+// Example of B : Rewriting nodes to Zen nodes\n+// -------------------------------------------\n+// Consider a Relu node. Current definition of Relu node looks like:\n+//\n+//              O = Relu(A)\n+//\n+// Relu has 1 input (A), and 1 output (O).\n+//\n+// This rewrite pass will generate a new graph node for Relu (new node is\n+// called ZenRelu) as:\n+//\n+//             O = ZenRelu(A)\n+//\n+// Rewriting prerequisites:\n+//  - Rewrite pass requires that op is registered. If the op type is not\n+//    registered, then any node of this op type will not be rewritten.\n+//\n+// Graph rewrite algorithm:\n+//      Algorithm: Graph Rewrite\n+//      Input: Graph G, Names of the nodes to rewrite and their new names\n+//      Output: Modified Graph G' if the nodes are modified, G otherwise.\n+//      Start:\n+//        N = TopologicalSort(G)  // N is a set of nodes in toposort order.\n+//        foreach node n in N\n+//        do\n+//          if (ZenOpNodeRewrite(n))  // Can this node be rewritten with Zen op.\n+//          then\n+//            E = set of <incoming edge and its src_output slot> of n\n+//            E' = {}   // a new set of edges for rewritten node\n+//            foreach <e,s> in E\n+//            do\n+//              E' U {<e,s>}  // Copy edges which generate tensors\n+//            done\n+//            n' = BuildNewNode(G, new_name, E')\n+//            MarkRewritten(n')  // Mark the new node as being rewritten.\n+//          fi\n+//        done\n+//\n+//      Explanation:\n+//        For graph rewrite, we visit nodes of the input graph in the\n+//        topological sort order (top-to-bottom fashion). We need this order\n+//        because while visiting a node we want that all of its input nodes are\n+//        visited and rewritten if applicable. This is because if we need to\n+//        rewrite a given node then all of its input nodes need to be fixed (in\n+//        other words they cannot be deleted later.)\n+//\n+class ZenLayoutRewritePass : public GraphOptimizationPass {\n+ public:\n+  ZenLayoutRewritePass() {\n+    // Zen op rewrite information records\n+    zen_rewrite_db_.push_back({\"Conv2D\", \"_ZenConv2D\",\n+                               CheckValidityForDTypeSupported,\n+                               UpdateZenOpAttrsConv2D});\n+    zen_rewrite_db_.push_back({\"_FusedConv2D\", \"_ZenFusedConv2D\",\n+                               CheckValidityFusedConv2D,\n+                               UpdateZenOpAttrsFusedConv2D});\n+    zen_rewrite_db_.push_back(\n+        {\"DepthwiseConv2dNative\", \"_ZenDepthwiseConv2dNative\",\n+         CheckValidityForDTypeSupported, UpdateZenOpAttrsConv2D});\n+    zen_rewrite_db_.push_back(\n+        {\"_FusedDepthwiseConv2dNative\", \"_ZenFusedDepthwiseConv2dNative\",\n+         CheckValidityFusedConv2D, UpdateZenOpAttrsFusedConv2D});\n+    zen_rewrite_db_.push_back({\"MatMul\", \"_ZenMatMul\",\n+                               CheckValidityForDTypeSupported,\n+                               UpdateZenOpAttrs});\n+    zen_rewrite_db_.push_back({\"_FusedMatMul\", \"_ZenFusedMatMul\",\n+                               CheckValidityForDTypeSupported,\n+                               UpdateZenOpAttrs});\n+    zen_rewrite_db_.push_back({\"BatchMatMul\", \"_ZenBatchMatMul\",\n+                               CheckValidityForDTypeSupported,\n+                               UpdateZenOpAttrs});\n+    zen_rewrite_db_.push_back({\"BatchMatMulV2\", \"_ZenBatchMatMulV2\",\n+                               CheckValidityForDTypeSupported,\n+                               UpdateZenOpAttrs});\n+    zen_rewrite_db_.push_back({\"MaxPool\", \"_ZenMaxPool\",\n+                               CheckValidityForDTypeSupported,\n+                               UpdateZenOpAttrs});\n+    zen_rewrite_db_.push_back({\"AvgPool\", \"_ZenAvgPool\",\n+                               CheckValidityForDTypeSupported,\n+                               UpdateZenOpAttrs});\n+    // TF-ZenDNN supports NHWC and blocked format execution. For blocked format,\n+    // following rewrites are not supported.\n+    if (!IsBlockedFormatEnabled()) {\n+      zen_rewrite_db_.push_back({\"Softmax\", \"_ZenSoftmax\",\n+                                 CheckValidityForDTypeSupported,\n+                                 UpdateZenOpAttrs});\n+      zen_rewrite_db_.push_back({\"ConjugateTranspose\", \"_ZenConjugateTranspose\",\n+                                 RewriteValid, UpdateZenOpAttrs});\n+      zen_rewrite_db_.push_back(\n+          {\"Transpose\", \"_ZenTranspose\", RewriteValid, UpdateZenOpAttrs});\n+      zen_rewrite_db_.push_back({\"InvertPermutation\", \"_ZenInvertPermutation\",\n+                                 RewriteValid, UpdateZenOpAttrs});\n+      zen_rewrite_db_.push_back({\"FusedBatchNorm\", \"_ZenFusedBatchNorm\",\n+                                 RewriteValid, UpdateZenOpAttrs});\n+      zen_rewrite_db_.push_back({\"FusedBatchNormV2\", \"_ZenFusedBatchNormV2\",\n+                                 RewriteValid, UpdateZenOpAttrs});\n+      zen_rewrite_db_.push_back({\"FusedBatchNormV3\", \"_ZenFusedBatchNormV3\",\n+                                 RewriteValid, UpdateZenOpAttrs});\n+    }\n+    // TF-ZenDNN currently only supports inference. The graph must not have\n+    // any of the training ops in tensorflow/core/kernels/training_ops.cc\n+    tf_training_ops_.push_back(\"ApplyGradientDescent\");\n+    tf_training_ops_.push_back(\"ApplyAdadelta\");\n+    tf_training_ops_.push_back(\"ResourceSparseApplyAdadelta\");\n+    tf_training_ops_.push_back(\"ApplyProximalGradientDescent\");\n+    tf_training_ops_.push_back(\"SparseApplyProximalGradientDescent\");\n+    tf_training_ops_.push_back(\"ApplyAdagrad\");\n+    tf_training_ops_.push_back(\"ApplyAdagradV2\");\n+    tf_training_ops_.push_back(\"ApplyProximalAdagrad\");\n+    tf_training_ops_.push_back(\"SparseApplyAdagrad\");\n+    tf_training_ops_.push_back(\"SparseApplyAdagradV2\");\n+    tf_training_ops_.push_back(\"SparseApplyProximalAdagrad\");\n+    tf_training_ops_.push_back(\"ApplyAdagradDA\");\n+    tf_training_ops_.push_back(\"SparseApplyAdagradDA\");\n+    tf_training_ops_.push_back(\"ApplyFtrl\");\n+    tf_training_ops_.push_back(\"ApplyFtrlV2\");\n+    tf_training_ops_.push_back(\"SparseApplyFtrl\");\n+    tf_training_ops_.push_back(\"SparseApplyFtrlV2\");\n+    tf_training_ops_.push_back(\"ApplyMomentum\");\n+    tf_training_ops_.push_back(\"ApplyKerasMomentum\");\n+    tf_training_ops_.push_back(\"ApplyAdam\");\n+    tf_training_ops_.push_back(\"ApplyAdaMax\");\n+    tf_training_ops_.push_back(\"ApplyRMSProp\");\n+    tf_training_ops_.push_back(\"ApplyCenteredRMSProp\");\n+    tf_training_ops_.push_back(\"ApplyAddSign\");\n+    tf_training_ops_.push_back(\"ApplyPowerSign\");\n+  }\n+\n+  // Standard interface to run optimization passes.\n+  Status Run(const GraphOptimizationPassOptions &options);\n+\n+  // Executes fusion and rewrite passes on the graph. Has an option to dump\n+  // graph before and after rewrite. Returns true if and only if the graph\n+  // mutated, false otherwise.\n+  bool ZenOpRewritePass(std::unique_ptr<Graph> *g);\n+\n+  // Replaces TF-Vanilla ops with Zen ops\n+  // Returns true if one or more rewrites are successful, false otherwise.\n+  bool ZenOpUpdate(std::unique_ptr<Graph> *g);\n+\n+  // Stores Zen op rewrite rules.\n+  typedef struct {\n+    string tf_op_name;   // Original name of op of the node in the graph\n+    string zen_op_name;  // New name of the op\n+    // A function handler to copy attributes from an old node to a new node.\n+    std::function<bool(const Node *)> check_validity;\n+    // Returns true if we should rewrite the node.\n+    std::function<void(const Node *, NodeBuilder *)> update_zen_op_attr;\n+  } ZenOpRewriteRecord;\n+\n+ private:\n+  // Maintain record about nodes to rewrite\n+  std::vector<ZenOpRewriteRecord> zen_rewrite_db_;\n+\n+  // TF training ops list from tensorflow/core/kernels/training_ops.cc\n+  std::vector<string> tf_training_ops_;\n+\n+  inline bool HasSubstr(const std::string primary,\n+                        const std::string sub) const {\n+    return primary.find(sub) != std::string::npos;\n+  }\n+\n+  // Check if the node 'n' has any applicable rewrite rule\n+  //\n+  // @return RewriteInfo* for the applicable rewrite rule\n+  const ZenOpRewriteRecord *CheckNodeForZenOpRewrite(const Node *n) const;\n+\n+  // Get nodes that will feed a list of TF tensors to the new\n+  // node that we are constructing.\n+  //\n+  // @input inputs - inputs to old node that we are using for constructing\n+  //                 new inputs,\n+  // @input input_idx - the index in the 'inputs' vector pointing to the\n+  //                    current input that we have processed so far\n+  // @output input_idx - index will be incremented by the number of nodes\n+  //                     from 'inputs' that are processed\n+  // @input list_length - The expected length of list of TF tensors\n+  // @output output_nodes - the list of new nodes creating TF tensors\n+  //\n+  // @return None\n+  void GetNodesProducingTFTensorList(\n+      const gtl::InlinedVector<std::pair<Node *, int>, 4> &inputs,\n+      int *input_idx, int list_length,\n+      std::vector<NodeBuilder::NodeOut> *output_nodes);\n+\n+  // ZenDNN currently does not support all fusions that grappler performs\n+  // together with Conv2D and DepthwiseConv2D. We rewrite\n+  // _FusedConv2D and _FusedDepthwiseConv2dNative only if it includes those\n+  // we support\n+  static bool CheckValidityFusedConv2D(const Node *n) {\n+    // Return false if the node is not with data type supported by Zen\n+    // inference. Currently Zen supports inference in float only.\n+    if (!CheckValidityForDTypeSupported(n)) {\n+      return false;\n+    }\n+    std::vector<string> fused_ops;\n+    TF_CHECK_OK(GetNodeAttr(n->def(), \"fused_ops\", &fused_ops));\n+\n+    return (fused_ops == std::vector<string>{\"BiasAdd\"} ||\n+            fused_ops == std::vector<string>{\"FusedBatchNorm\"} ||\n+            fused_ops == std::vector<string>{\"Relu\"} ||\n+            fused_ops == std::vector<string>{\"BiasAdd\", \"Relu\"} ||\n+            fused_ops == std::vector<string>{\"BiasAdd\", \"Relu6\"} ||\n+            fused_ops == std::vector<string>{\"BiasAdd\", \"Add\"} ||\n+            fused_ops == std::vector<string>{\"BiasAdd\", \"Add\", \"Relu\"} ||\n+            fused_ops == std::vector<string>{\"FusedBatchNorm\", \"Relu\"});\n+  }\n+\n+  // Currently TF-ZenDNN supports FP32 inference only.\n+  // Returns, true if node is of float dataype, false otherwise\n+  static bool CheckValidityForDTypeSupported(const Node *n) {\n+    DataType data_type;\n+    TF_CHECK_OK(GetNodeAttr(n->def(), \"T\", &data_type));\n+    return (data_type == DT_FLOAT);\n+  }\n+\n+  // Method to provide a 'valid' status for nodes that don't require any check.\n+  // This method is used in ZenLayoutRewritePass() for creating the\n+  // record/entry for rewriting native ops with Zen ops.\n+  static bool RewriteValid(const Node *n) { return true; }\n+\n+  // Method to find whether the graph has inference ops only. It returns\n+  // error status if the graph has training ops.\n+  Status AreAllInferenceOps(std::unique_ptr<Graph> *g);\n+\n+  // Rewrites input node to a new node specified by its matching rewrite record.\n+  //\n+  // Input node may be deleted in case of rewrite. Attempt to use the node\n+  // after the call can result in undefined behaviors.\n+  //\n+  // @input  g - input graph, n - Node to be rewritten,\n+  //         ri - matching rewrite record,\n+  //         reorder_flags - flags to populate reorder attributes of Zen op.\n+  // @return OkStatus(), if the input node is rewritten;\n+  //         Returns appropriate Status error code otherwise.\n+  //         Graph is updated in case the input node is rewritten.\n+  //         Otherwise, it is not updated.\n+  Status ZenOpNodeRewrite(std::unique_ptr<Graph> *g, Node *n,\n+                          const ZenOpRewriteRecord *ri,\n+                          std::pair<bool, bool> reorder_flags);\n+\n+  // Functions specific to operators to copy attributes\n+  // We need operator-specific function to copy attributes because the framework\n+  // does not provide any generic function for it.\n+  static void UpdateZenOpAttrs(const Node *orig_node, NodeBuilder *nb);\n+\n+  static void UpdateZenOpAttrsConv2D(const Node *orig_node, NodeBuilder *nb);\n+\n+  static void UpdateZenOpAttrsFusedConv2D(const Node *orig_node,\n+                                          NodeBuilder *nb);\n+\n+  // Examines the input and output nodes of each node, for Zen nodes and\n+  // determines reorder flags.\n+  //\n+  // @input   nodes - A list of nodes\n+  // @return  An unordered map with nodes as key and\n+  //          value as a pair of reorder flags\n+  std::unordered_map<Node *, std::pair<bool, bool>> GetReorderFlags(\n+      std::vector<Node *> &nodes);\n+\n+  // Update reorder information of all Zen nodes\n+  //\n+  // @input g - input graph\n+  // @return true, if one or more updates are successful; false otherwise.\n+  bool AddReorderAttrs(std::unique_ptr<Graph> *g);\n+};\n+\n+// ZenLayoutRewritePass is executed in phase 0, to make sure it is executed\n+// before MklLayoutRewritePass(Phase 1).\n+REGISTER_OPTIMIZATION(OptimizationPassRegistry::POST_PARTITIONING, 0,\n+                      ZenLayoutRewritePass);\n+\n+void DeleteNodeAndUpdateLinks(std::unique_ptr<Graph> *, Node *, Node *, int);\n+\n+const ZenLayoutRewritePass::ZenOpRewriteRecord *\n+ZenLayoutRewritePass::CheckNodeForZenOpRewrite(const Node *n) const {\n+  CHECK_NOTNULL(n);", "source": "const ZenLayoutRewritePass::ZenOpRewriteRecord *\nZenLayoutRewritePass::CheckNodeForZenOpRewrite(const Node *n) const {\n  CHECK_NOTNULL(n);\n\n  DataType data_type;\n\n  for (auto rewrite_record = zen_rewrite_db_.cbegin();\n       rewrite_record != zen_rewrite_db_.cend(); ++rewrite_record) {\n    if (n->type_string().compare(rewrite_record->tf_op_name) == 0 &&\n        rewrite_record->check_validity(n)) {\n      TF_CHECK_OK(GetNodeAttr(n->def(), \"T\", &data_type));\n      if (!zen_op_registry::IsZenOpKernelRegistered(rewrite_record->zen_op_name,\n                                                    data_type)) {\n        // No Zen kernel is registered for op\n        return nullptr;\n      }\n      return &*rewrite_record;\n    }\n  }\n  return nullptr;\n}", "source_start_line": 350, "tokens": ["const", "ZenLayoutRewritePass", "::", "ZenOpRewriteRecord", "*", "ZenLayoutRewritePass", "::", "CheckNodeForZenOpRewrite", "(", "const", "Node", "*", "n", ")", "const", "{", "CHECK_NOTNULL", "(", "n", ")", ";", "DataType", "data_type", ";", "for", "(", "auto", "rewrite_record", "=", "zen_rewrite_db_", ".", "cbegin", "(", ")", ";", "rewrite_record", "!=", "zen_rewrite_db_", ".", "cend", "(", ")", ";", "++", "rewrite_record", ")", "{", "if", "(", "n", "->", "type_string", "(", ")", ".", "compare", "(", "rewrite_record", "->", "tf_op_name", ")", "==", "0", "&&", "rewrite_record", "->", "check_validity", "(", "n", ")", ")", "{", "TF_CHECK_OK", "(", "GetNodeAttr", "(", "n", "->", "def", "(", ")", ",", "\"", "\"", ",", "&", "data_type", ")", ")", ";", "if", "(", "!", "zen_op_registry", "::", "IsZenOpKernelRegistered", "(", "rewrite_record", "->", "zen_op_name", ",", "data_type", ")", ")", "{", "return", "nullptr", ";", "}", "return", "&", "*", "rewrite_record", ";", "}", "}", "return", "nullptr", ";", "}"], "to_mask": {"VAR": ["data_type", "n", "rewrite_record"], "METHOD": ["CHECK_NOTNULL", "GetNodeAttr", "IsZenOpKernelRegistered", "TF_CHECK_OK", "cbegin", "cend", "check_validity", "compare", "def", "type_string"]}, "attention_idx_tokens": [16, 20], "patch": "@@ -0,0 +1,1292 @@\n+/* Copyright 2023 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifdef AMD_ZENDNN\n+\n+#include <algorithm>\n+#include <functional>\n+#include <iterator>\n+#include <memory>\n+#include <queue>\n+#include <set>\n+#include <stack>\n+#include <string>\n+#include <tuple>\n+#include <unordered_map>\n+#include <unordered_set>\n+#include <utility>\n+#include <vector>\n+\n+#include \"tensorflow/core/common_runtime/function.h\"\n+#include \"tensorflow/core/common_runtime/layout_pass_util.h\"\n+#include \"tensorflow/core/common_runtime/optimization_registry.h\"\n+#include \"tensorflow/core/framework/node_def_util.h\"\n+#include \"tensorflow/core/framework/tensor.pb.h\"\n+#include \"tensorflow/core/graph/algorithm.h\"\n+#include \"tensorflow/core/graph/graph.h\"\n+#include \"tensorflow/core/graph/zen_graph_util.h\"\n+#include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/lib/core/status.h\"\n+#include \"tensorflow/core/lib/gtl/array_slice.h\"\n+#include \"tensorflow/core/lib/gtl/map_util.h\"\n+#include \"tensorflow/core/lib/hash/hash.h\"\n+#include \"tensorflow/core/util/port.h\"\n+#include \"tensorflow/core/util/tensor_format.h\"\n+#include \"tensorflow/core/util/zen_util.h\"\n+\n+namespace tensorflow {\n+\n+// This pass implements rewriting of graph to support following scenarios:\n+// (A) Merging nodes in the graph\n+// (B) Updating nodes in graph\n+//\n+// Example of A : Merging nodes in the graph\n+// -----------------------------------------\n+// Currently, we merge Pad + Conv2D together.\n+// Consider the subgraph below :\n+//\n+//        [Const Op]\n+//                  \\\n+//  [Sub-Graph 1]-->[Pad Op]-->[Conv2D_1]-->[Sub-Graph 2]\n+//\n+// As part of fusion, the graph gets transformed to\n+//\n+// [Sub-Graph 1]-->[Conv2D_2]-->[Sub-Graph 2]\n+//\n+// This fusion is valid provided Conv2D op supports EXPLICIT padding\n+//\n+// The padding value from the Pad op is added up to the existing pad value of\n+// the Conv op and the Pad op is removed.\n+//\n+// Only the padding values of the Conv op is updated and the sub-graph linked\n+// to Pad op is now linked with the Conv op.\n+//\n+// Example of B : Rewriting nodes to Zen nodes\n+// -------------------------------------------\n+// Consider a Relu node. Current definition of Relu node looks like:\n+//\n+//              O = Relu(A)\n+//\n+// Relu has 1 input (A), and 1 output (O).\n+//\n+// This rewrite pass will generate a new graph node for Relu (new node is\n+// called ZenRelu) as:\n+//\n+//             O = ZenRelu(A)\n+//\n+// Rewriting prerequisites:\n+//  - Rewrite pass requires that op is registered. If the op type is not\n+//    registered, then any node of this op type will not be rewritten.\n+//\n+// Graph rewrite algorithm:\n+//      Algorithm: Graph Rewrite\n+//      Input: Graph G, Names of the nodes to rewrite and their new names\n+//      Output: Modified Graph G' if the nodes are modified, G otherwise.\n+//      Start:\n+//        N = TopologicalSort(G)  // N is a set of nodes in toposort order.\n+//        foreach node n in N\n+//        do\n+//          if (ZenOpNodeRewrite(n))  // Can this node be rewritten with Zen op.\n+//          then\n+//            E = set of <incoming edge and its src_output slot> of n\n+//            E' = {}   // a new set of edges for rewritten node\n+//            foreach <e,s> in E\n+//            do\n+//              E' U {<e,s>}  // Copy edges which generate tensors\n+//            done\n+//            n' = BuildNewNode(G, new_name, E')\n+//            MarkRewritten(n')  // Mark the new node as being rewritten.\n+//          fi\n+//        done\n+//\n+//      Explanation:\n+//        For graph rewrite, we visit nodes of the input graph in the\n+//        topological sort order (top-to-bottom fashion). We need this order\n+//        because while visiting a node we want that all of its input nodes are\n+//        visited and rewritten if applicable. This is because if we need to\n+//        rewrite a given node then all of its input nodes need to be fixed (in\n+//        other words they cannot be deleted later.)\n+//\n+class ZenLayoutRewritePass : public GraphOptimizationPass {\n+ public:\n+  ZenLayoutRewritePass() {\n+    // Zen op rewrite information records\n+    zen_rewrite_db_.push_back({\"Conv2D\", \"_ZenConv2D\",\n+                               CheckValidityForDTypeSupported,\n+                               UpdateZenOpAttrsConv2D});\n+    zen_rewrite_db_.push_back({\"_FusedConv2D\", \"_ZenFusedConv2D\",\n+                               CheckValidityFusedConv2D,\n+                               UpdateZenOpAttrsFusedConv2D});\n+    zen_rewrite_db_.push_back(\n+        {\"DepthwiseConv2dNative\", \"_ZenDepthwiseConv2dNative\",\n+         CheckValidityForDTypeSupported, UpdateZenOpAttrsConv2D});\n+    zen_rewrite_db_.push_back(\n+        {\"_FusedDepthwiseConv2dNative\", \"_ZenFusedDepthwiseConv2dNative\",\n+         CheckValidityFusedConv2D, UpdateZenOpAttrsFusedConv2D});\n+    zen_rewrite_db_.push_back({\"MatMul\", \"_ZenMatMul\",\n+                               CheckValidityForDTypeSupported,\n+                               UpdateZenOpAttrs});\n+    zen_rewrite_db_.push_back({\"_FusedMatMul\", \"_ZenFusedMatMul\",\n+                               CheckValidityForDTypeSupported,\n+                               UpdateZenOpAttrs});\n+    zen_rewrite_db_.push_back({\"BatchMatMul\", \"_ZenBatchMatMul\",\n+                               CheckValidityForDTypeSupported,\n+                               UpdateZenOpAttrs});\n+    zen_rewrite_db_.push_back({\"BatchMatMulV2\", \"_ZenBatchMatMulV2\",\n+                               CheckValidityForDTypeSupported,\n+                               UpdateZenOpAttrs});\n+    zen_rewrite_db_.push_back({\"MaxPool\", \"_ZenMaxPool\",\n+                               CheckValidityForDTypeSupported,\n+                               UpdateZenOpAttrs});\n+    zen_rewrite_db_.push_back({\"AvgPool\", \"_ZenAvgPool\",\n+                               CheckValidityForDTypeSupported,\n+                               UpdateZenOpAttrs});\n+    // TF-ZenDNN supports NHWC and blocked format execution. For blocked format,\n+    // following rewrites are not supported.\n+    if (!IsBlockedFormatEnabled()) {\n+      zen_rewrite_db_.push_back({\"Softmax\", \"_ZenSoftmax\",\n+                                 CheckValidityForDTypeSupported,\n+                                 UpdateZenOpAttrs});\n+      zen_rewrite_db_.push_back({\"ConjugateTranspose\", \"_ZenConjugateTranspose\",\n+                                 RewriteValid, UpdateZenOpAttrs});\n+      zen_rewrite_db_.push_back(\n+          {\"Transpose\", \"_ZenTranspose\", RewriteValid, UpdateZenOpAttrs});\n+      zen_rewrite_db_.push_back({\"InvertPermutation\", \"_ZenInvertPermutation\",\n+                                 RewriteValid, UpdateZenOpAttrs});\n+      zen_rewrite_db_.push_back({\"FusedBatchNorm\", \"_ZenFusedBatchNorm\",\n+                                 RewriteValid, UpdateZenOpAttrs});\n+      zen_rewrite_db_.push_back({\"FusedBatchNormV2\", \"_ZenFusedBatchNormV2\",\n+                                 RewriteValid, UpdateZenOpAttrs});\n+      zen_rewrite_db_.push_back({\"FusedBatchNormV3\", \"_ZenFusedBatchNormV3\",\n+                                 RewriteValid, UpdateZenOpAttrs});\n+    }\n+    // TF-ZenDNN currently only supports inference. The graph must not have\n+    // any of the training ops in tensorflow/core/kernels/training_ops.cc\n+    tf_training_ops_.push_back(\"ApplyGradientDescent\");\n+    tf_training_ops_.push_back(\"ApplyAdadelta\");\n+    tf_training_ops_.push_back(\"ResourceSparseApplyAdadelta\");\n+    tf_training_ops_.push_back(\"ApplyProximalGradientDescent\");\n+    tf_training_ops_.push_back(\"SparseApplyProximalGradientDescent\");\n+    tf_training_ops_.push_back(\"ApplyAdagrad\");\n+    tf_training_ops_.push_back(\"ApplyAdagradV2\");\n+    tf_training_ops_.push_back(\"ApplyProximalAdagrad\");\n+    tf_training_ops_.push_back(\"SparseApplyAdagrad\");\n+    tf_training_ops_.push_back(\"SparseApplyAdagradV2\");\n+    tf_training_ops_.push_back(\"SparseApplyProximalAdagrad\");\n+    tf_training_ops_.push_back(\"ApplyAdagradDA\");\n+    tf_training_ops_.push_back(\"SparseApplyAdagradDA\");\n+    tf_training_ops_.push_back(\"ApplyFtrl\");\n+    tf_training_ops_.push_back(\"ApplyFtrlV2\");\n+    tf_training_ops_.push_back(\"SparseApplyFtrl\");\n+    tf_training_ops_.push_back(\"SparseApplyFtrlV2\");\n+    tf_training_ops_.push_back(\"ApplyMomentum\");\n+    tf_training_ops_.push_back(\"ApplyKerasMomentum\");\n+    tf_training_ops_.push_back(\"ApplyAdam\");\n+    tf_training_ops_.push_back(\"ApplyAdaMax\");\n+    tf_training_ops_.push_back(\"ApplyRMSProp\");\n+    tf_training_ops_.push_back(\"ApplyCenteredRMSProp\");\n+    tf_training_ops_.push_back(\"ApplyAddSign\");\n+    tf_training_ops_.push_back(\"ApplyPowerSign\");\n+  }\n+\n+  // Standard interface to run optimization passes.\n+  Status Run(const GraphOptimizationPassOptions &options);\n+\n+  // Executes fusion and rewrite passes on the graph. Has an option to dump\n+  // graph before and after rewrite. Returns true if and only if the graph\n+  // mutated, false otherwise.\n+  bool ZenOpRewritePass(std::unique_ptr<Graph> *g);\n+\n+  // Replaces TF-Vanilla ops with Zen ops\n+  // Returns true if one or more rewrites are successful, false otherwise.\n+  bool ZenOpUpdate(std::unique_ptr<Graph> *g);\n+\n+  // Stores Zen op rewrite rules.\n+  typedef struct {\n+    string tf_op_name;   // Original name of op of the node in the graph\n+    string zen_op_name;  // New name of the op\n+    // A function handler to copy attributes from an old node to a new node.\n+    std::function<bool(const Node *)> check_validity;\n+    // Returns true if we should rewrite the node.\n+    std::function<void(const Node *, NodeBuilder *)> update_zen_op_attr;\n+  } ZenOpRewriteRecord;\n+\n+ private:\n+  // Maintain record about nodes to rewrite\n+  std::vector<ZenOpRewriteRecord> zen_rewrite_db_;\n+\n+  // TF training ops list from tensorflow/core/kernels/training_ops.cc\n+  std::vector<string> tf_training_ops_;\n+\n+  inline bool HasSubstr(const std::string primary,\n+                        const std::string sub) const {\n+    return primary.find(sub) != std::string::npos;\n+  }\n+\n+  // Check if the node 'n' has any applicable rewrite rule\n+  //\n+  // @return RewriteInfo* for the applicable rewrite rule\n+  const ZenOpRewriteRecord *CheckNodeForZenOpRewrite(const Node *n) const;\n+\n+  // Get nodes that will feed a list of TF tensors to the new\n+  // node that we are constructing.\n+  //\n+  // @input inputs - inputs to old node that we are using for constructing\n+  //                 new inputs,\n+  // @input input_idx - the index in the 'inputs' vector pointing to the\n+  //                    current input that we have processed so far\n+  // @output input_idx - index will be incremented by the number of nodes\n+  //                     from 'inputs' that are processed\n+  // @input list_length - The expected length of list of TF tensors\n+  // @output output_nodes - the list of new nodes creating TF tensors\n+  //\n+  // @return None\n+  void GetNodesProducingTFTensorList(\n+      const gtl::InlinedVector<std::pair<Node *, int>, 4> &inputs,\n+      int *input_idx, int list_length,\n+      std::vector<NodeBuilder::NodeOut> *output_nodes);\n+\n+  // ZenDNN currently does not support all fusions that grappler performs\n+  // together with Conv2D and DepthwiseConv2D. We rewrite\n+  // _FusedConv2D and _FusedDepthwiseConv2dNative only if it includes those\n+  // we support\n+  static bool CheckValidityFusedConv2D(const Node *n) {\n+    // Return false if the node is not with data type supported by Zen\n+    // inference. Currently Zen supports inference in float only.\n+    if (!CheckValidityForDTypeSupported(n)) {\n+      return false;\n+    }\n+    std::vector<string> fused_ops;\n+    TF_CHECK_OK(GetNodeAttr(n->def(), \"fused_ops\", &fused_ops));\n+\n+    return (fused_ops == std::vector<string>{\"BiasAdd\"} ||\n+            fused_ops == std::vector<string>{\"FusedBatchNorm\"} ||\n+            fused_ops == std::vector<string>{\"Relu\"} ||\n+            fused_ops == std::vector<string>{\"BiasAdd\", \"Relu\"} ||\n+            fused_ops == std::vector<string>{\"BiasAdd\", \"Relu6\"} ||\n+            fused_ops == std::vector<string>{\"BiasAdd\", \"Add\"} ||\n+            fused_ops == std::vector<string>{\"BiasAdd\", \"Add\", \"Relu\"} ||\n+            fused_ops == std::vector<string>{\"FusedBatchNorm\", \"Relu\"});\n+  }\n+\n+  // Currently TF-ZenDNN supports FP32 inference only.\n+  // Returns, true if node is of float dataype, false otherwise\n+  static bool CheckValidityForDTypeSupported(const Node *n) {\n+    DataType data_type;\n+    TF_CHECK_OK(GetNodeAttr(n->def(), \"T\", &data_type));\n+    return (data_type == DT_FLOAT);\n+  }\n+\n+  // Method to provide a 'valid' status for nodes that don't require any check.\n+  // This method is used in ZenLayoutRewritePass() for creating the\n+  // record/entry for rewriting native ops with Zen ops.\n+  static bool RewriteValid(const Node *n) { return true; }\n+\n+  // Method to find whether the graph has inference ops only. It returns\n+  // error status if the graph has training ops.\n+  Status AreAllInferenceOps(std::unique_ptr<Graph> *g);\n+\n+  // Rewrites input node to a new node specified by its matching rewrite record.\n+  //\n+  // Input node may be deleted in case of rewrite. Attempt to use the node\n+  // after the call can result in undefined behaviors.\n+  //\n+  // @input  g - input graph, n - Node to be rewritten,\n+  //         ri - matching rewrite record,\n+  //         reorder_flags - flags to populate reorder attributes of Zen op.\n+  // @return OkStatus(), if the input node is rewritten;\n+  //         Returns appropriate Status error code otherwise.\n+  //         Graph is updated in case the input node is rewritten.\n+  //         Otherwise, it is not updated.\n+  Status ZenOpNodeRewrite(std::unique_ptr<Graph> *g, Node *n,\n+                          const ZenOpRewriteRecord *ri,\n+                          std::pair<bool, bool> reorder_flags);\n+\n+  // Functions specific to operators to copy attributes\n+  // We need operator-specific function to copy attributes because the framework\n+  // does not provide any generic function for it.\n+  static void UpdateZenOpAttrs(const Node *orig_node, NodeBuilder *nb);\n+\n+  static void UpdateZenOpAttrsConv2D(const Node *orig_node, NodeBuilder *nb);\n+\n+  static void UpdateZenOpAttrsFusedConv2D(const Node *orig_node,\n+                                          NodeBuilder *nb);\n+\n+  // Examines the input and output nodes of each node, for Zen nodes and\n+  // determines reorder flags.\n+  //\n+  // @input   nodes - A list of nodes\n+  // @return  An unordered map with nodes as key and\n+  //          value as a pair of reorder flags\n+  std::unordered_map<Node *, std::pair<bool, bool>> GetReorderFlags(\n+      std::vector<Node *> &nodes);\n+\n+  // Update reorder information of all Zen nodes\n+  //\n+  // @input g - input graph\n+  // @return true, if one or more updates are successful; false otherwise.\n+  bool AddReorderAttrs(std::unique_ptr<Graph> *g);\n+};\n+\n+// ZenLayoutRewritePass is executed in phase 0, to make sure it is executed\n+// before MklLayoutRewritePass(Phase 1).\n+REGISTER_OPTIMIZATION(OptimizationPassRegistry::POST_PARTITIONING, 0,\n+                      ZenLayoutRewritePass);\n+\n+void DeleteNodeAndUpdateLinks(std::unique_ptr<Graph> *, Node *, Node *, int);\n+\n+const ZenLayoutRewritePass::ZenOpRewriteRecord *\n+ZenLayoutRewritePass::CheckNodeForZenOpRewrite(const Node *n) const {\n+  CHECK_NOTNULL(n);", "ext_attention_idx_tokens": [0, 119], "uid": "c427a87c", "question": "Fixed. Can you please let us know the reason behind this suggestion?", "code": "const ZenLayoutRewritePass ZenOpRewriteRecord * ZenLayoutRewritePass CheckNodeForZenOpRewrite const Node *n const { CHECK NOTNULL n ; DataType data type; for auto rewrite record zen rewrite db cbegin ; rewrite record ! zen rewrite db cend ; ++rewrite record { if n->type string compare rewrite record->tf op name 0 && rewrite record->check validity n { TF CHECK OK GetNodeAttr n->def \"T\" &data type ; if !zen op registry IsZenOpKernelRegistered rewrite record->zen op name data type { No Zen kernel is registered for op return nullptr; } return &*rewrite record; } } return nullptr; }"}
{"message": "Without this change there's a crash generating the lookup table while creating the `UniformQuantizedType`. Honestly, I didn't investigate too much because this change seems to simplify the code and fix the issue. Happy to take another look if you feel it would be worth investigating?", "timestamp": "2023-01-24T09:17:47Z", "file_name": "tensorflow/compiler/mlir/tosa/transforms/legalize_utils.cc", "range": {"start_line": 316, "end_line": 316, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1084996919", "html_url": "https://github.com/tensorflow/tensorflow/pull/59100#discussion_r1084996919", "attention_area": "  auto const_type = tensorflow::GetTypeFromTFTensorShape({513}, rewriter.getIntegerType(16));", "file_path": "files/22/01/00000122.cc", "old_file_path": "files/59/01/00000159.cc", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -313,13 +313,9 @@ Value getTosaConst16bitTable(PatternRewriter& rewriter, Operation* op,\n   table.push_back(\n       static_cast<int16_t>(std::min(std::max(max_val, -32768), 32767)));\n \n-  auto element_qtype =\n-      UniformQuantizedType::get(true, rewriter.getIntegerType(16),\n-                                rewriter.getF32Type(), 1.0f, 0, -32768, 32767);\n-  auto const_type = tensorflow::GetTypeFromTFTensorShape({513}, element_qtype);\n-  auto storage_type = tensorflow::GetTypeFromTFTensorShape(\n-      {513}, element_qtype.getStorageType());\n-  auto const_attr = DenseElementsAttr::get(storage_type, llvm::ArrayRef(table));\n+  auto const_type = tensorflow::GetTypeFromTFTensorShape({513}, rewriter.getIntegerType(16));", "source": "Value getTosaConst16bitTable(PatternRewriter& rewriter, Operation* op,\n                             std::function<double(double)> func, double min,\n                             double max) {\n  SmallVector<int16_t, 513> table;\n\n  double step = (max - min) / 512.0f;\n  double half_step = step / 2.0f;\n  for (int32_t i = 0; i < 512; i++) {\n    int32_t sample_val = std::llround(func(min + (i * step)) * 32768.0);\n    double midpoint_interp_val =\n        std::round(((func(min + (i + 1) * step) * 32768.0) +\n                    std::round(func(min + (i * step)) * 32768.0)) /\n                   2.0);\n    double midpoint_val =\n        std::round(func(min + (i * step) + half_step) * 32768.0);\n    double midpoint_err = midpoint_interp_val - midpoint_val;\n    int32_t bias = std::llround(midpoint_err / 2.0);\n\n    table.push_back(static_cast<int16_t>(\n        std::min(std::max(sample_val - bias, -32768), 32767)));\n  }\n\n  int32_t max_val = std::llround(func(max) * 32768.0);\n  table.push_back(\n      static_cast<int16_t>(std::min(std::max(max_val, -32768), 32767)));\n\n  auto const_type = tensorflow::GetTypeFromTFTensorShape({513}, rewriter.getIntegerType(16));\n  auto const_attr =\n      DenseElementsAttr::get(const_type, llvm::ArrayRef(table));\n\n  auto const_op =\n      rewriter.create<tosa::ConstOp>(op->getLoc(), const_type, const_attr);\n  return const_op.getResult();\n}", "source_start_line": 290, "tokens": ["Value", "getTosaConst16bitTable", "(", "PatternRewriter", "&", "rewriter", ",", "Operation", "*", "op", ",", "std", "::", "function", "<", "double", "(", "double", ")", ">", "func", ",", "double", "min", ",", "double", "max", ")", "{", "SmallVector", "<", "int16_t", ",", "513", ">", "table", ";", "double", "step", "=", "(", "max", "-", "min", ")", "/", "512.0f", ";", "double", "half_step", "=", "step", "/", "2.0f", ";", "for", "(", "int32_t", "i", "=", "0", ";", "i", "<", "512", ";", "i", "++", ")", "{", "int32_t", "sample_val", "=", "std", "::", "llround", "(", "func", "(", "min", "+", "(", "i", "*", "step", ")", ")", "*", "32768.0", ")", ";", "double", "midpoint_interp_val", "=", "std", "::", "round", "(", "(", "(", "func", "(", "min", "+", "(", "i", "+", "1", ")", "*", "step", ")", "*", "32768.0", ")", "+", "std", "::", "round", "(", "func", "(", "min", "+", "(", "i", "*", "step", ")", ")", "*", "32768.0", ")", ")", "/", "2.0", ")", ";", "double", "midpoint_val", "=", "std", "::", "round", "(", "func", "(", "min", "+", "(", "i", "*", "step", ")", "+", "half_step", ")", "*", "32768.0", ")", ";", "double", "midpoint_err", "=", "midpoint_interp_val", "-", "midpoint_val", ";", "int32_t", "bias", "=", "std", "::", "llround", "(", "midpoint_err", "/", "2.0", ")", ";", "table", ".", "push_back", "(", "static_cast", "<", "int16_t", ">", "(", "std", "::", "min", "(", "std", "::", "max", "(", "sample_val", "-", "bias", ",", "-32768", ")", ",", "32767", ")", ")", ")", ";", "}", "int32_t", "max_val", "=", "std", "::", "llround", "(", "func", "(", "max", ")", "*", "32768.0", ")", ";", "table", ".", "push_back", "(", "static_cast", "<", "int16_t", ">", "(", "std", "::", "min", "(", "std", "::", "max", "(", "max_val", ",", "-32768", ")", ",", "32767", ")", ")", ")", ";", "auto", "const_type", "=", "tensorflow", "::", "GetTypeFromTFTensorShape", "(", "{", "513", "}", ",", "rewriter", ".", "getIntegerType", "(", "16", ")", ")", ";", "auto", "const_attr", "=", "DenseElementsAttr", "::", "get", "(", "const_type", ",", "llvm", "::", "ArrayRef", "(", "table", ")", ")", ";", "auto", "const_op", "=", "rewriter", ".", "create", "<", "tosa", "::", "ConstOp", ">", "(", "op", "->", "getLoc", "(", ")", ",", "const_type", ",", "const_attr", ")", ";", "return", "const_op", ".", "getResult", "(", ")", ";", "}"], "to_mask": {"VAR": ["bias", "const_attr", "const_op", "const_type", "func", "half_step", "i", "max", "max_val", "midpoint_err", "midpoint_interp_val", "midpoint_val", "min", "op", "rewriter", "sample_val", "step", "table"], "METHOD": ["ArrayRef", "GetTypeFromTFTensorShape", "func", "get", "getIntegerType", "getLoc", "getResult", "llround", "max", "min", "push_back", "rewriter", "round", "static_cast"]}, "attention_idx_tokens": [252, 270], "patch": "@@ -313,13 +313,9 @@\n   table.push_back(\n       static_cast<int16_t>(std::min(std::max(max_val, -32768), 32767)));\n \n-  auto element_qtype =\n-      UniformQuantizedType::get(true, rewriter.getIntegerType(16),\n-                                rewriter.getF32Type(), 1.0f, 0, -32768, 32767);\n-  auto const_type = tensorflow::GetTypeFromTFTensorShape({513}, element_qtype);\n-  auto storage_type = tensorflow::GetTypeFromTFTensorShape(\n-      {513}, element_qtype.getStorageType());\n-  auto const_attr = DenseElementsAttr::get(storage_type, llvm::ArrayRef(table));\n+  auto const_type = tensorflow::GetTypeFromTFTensorShape({513}, rewriter.getIntegerType(16));", "ext_attention_idx_tokens": [252, 287], "uid": "130a3807", "question": "Without this change there's a crash generating the lookup table while creating the `UniformQuantizedType`. Honestly, I didn't investigate too much because this change seems to simplify the code and fix the issue. Happy to take another look if you feel it would be worth investigating?", "code": "Value getTosaConst16bitTable PatternRewriter& rewriter Operation* op std function<double double > func double min double max { SmallVector<int16 t 513> table; double step max - min 512 0f; double half step step 2 0f; for int32 t i 0; i < 512; i++ { int32 t sample val std llround func min + i * step * 32768 0 ; double midpoint interp val std round func min + i + 1 * step * 32768 0 + std round func min + i * step * 32768 0 2 0 ; double midpoint val std round func min + i * step + half step * 32768 0 ; double midpoint err midpoint interp val - midpoint val; int32 t bias std llround midpoint err 2 0 ; table push back static cast<int16 t> std min std max sample val - bias -32768 32767 ; } int32 t max val std llround func max * 32768 0 ; table push back static cast<int16 t> std min std max max val -32768 32767 ; auto const type tensorflow GetTypeFromTFTensorShape {513} rewriter getIntegerType 16 ; auto const attr DenseElementsAttr get const type llvm ArrayRef table ; auto const op rewriter create<tosa ConstOp> op->getLoc const type const attr ; return const op getResult ; }"}
{"message": "How is alpha used?", "timestamp": "2023-02-08T20:13:59Z", "file_name": "tensorflow/compiler/xla/service/gpu/cudnn_fused_conv_rewriter.cc", "range": {"start_line": 707, "end_line": 707, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1100632664", "html_url": "https://github.com/tensorflow/tensorflow/pull/59614#discussion_r1100632664", "attention_area": "                         m::Multiply(gte_pattern, m::Broadcast(m::ConstantEffectiveScalar(&alpha)))))) {", "file_path": "files/06/02/00000206.cc", "old_file_path": "files/07/02/00000207.cc", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -633,6 +633,100 @@ StatusOr<bool> FuseRelu(HloComputation* comp) {\n   return changed;\n }\n \n+StatusOr<bool> FuseRelu6(HloComputation* comp, se::CudaComputeCapability cc) {\n+  bool changed = false;\n+  for (HloInstruction* instr : comp->MakeInstructionPostOrder()) {\n+    const DebugOptions& debug_options =\n+    instr->GetModule()->config().debug_options();\n+    if (!debug_options.xla_gpu_use_runtime_fusion() ||\n+        !cc.IsAtLeast(se::CudaComputeCapability::AMPERE)) {\n+      return false;\n+    }\n+    HloInstruction* gte;\n+    HloInstruction* conv;\n+    // We don't want to upgrade depthwise convolutions to ConvBiasActivation,\n+    // because the fused CUDNN functions are slower for some of those.\n+    if (!Match(instr,\n+               m::Clamp(\n+                   m::Broadcast(m::ConstantEffectiveScalar(0)),\n+                   m::GetTupleElement(\n+                       &gte, m::Op(&conv)\n+                                 .WithPredicate(IsNonDepthwiseConvCustomCall)\n+                                 .WithOneUse())\n+                       .WithOneUse(),\n+                       m::Broadcast(m::ConstantEffectiveScalar(6))))) {\n+      continue;\n+    }\n+    TF_ASSIGN_OR_RETURN(CudnnConvBackendConfig config,\n+                        conv->backend_config<CudnnConvBackendConfig>());\n+    if (config.activation_mode() != se::dnn::kNone) {\n+      continue;\n+    }\n+\n+    if (!ConsumeFuel(\"cudnn-fused-convolution-rewriter\", [&] {\n+          return absl::StrCat(\"FuseRelu6: \", conv->ToString());\n+        })) {\n+      continue;\n+    }\n+    TF_ASSIGN_OR_RETURN(conv, EnsureIsConvBiasActivation(conv));\n+    config.set_activation_mode(se::dnn::kRelu6);\n+    TF_RETURN_IF_ERROR(conv->set_backend_config(config));\n+    TF_RETURN_IF_ERROR(comp->ReplaceInstruction(instr, gte));\n+    changed = true;\n+  }\n+  return changed;\n+}\n+\n+StatusOr<bool> FuseLeakyRelu(HloComputation* comp, se::CudaComputeCapability cc) {\n+  bool changed = false;\n+  for (HloInstruction* instr : comp->MakeInstructionPostOrder()) {\n+    const DebugOptions& debug_options =\n+    instr->GetModule()->config().debug_options();\n+    if (!debug_options.xla_gpu_use_runtime_fusion() ||\n+        !cc.IsAtLeast(se::CudaComputeCapability::AMPERE)) {\n+      return false;\n+    }\n+    HloInstruction* gte;\n+    HloInstruction* conv;\n+    HloInstruction* alpha;\n+    // We don't want to upgrade depthwise convolutions to ConvBiasActivation,\n+    // because the fused CUDNN functions are slower for some of those.\n+    auto gte_pattern =\n+        m::GetTupleElement(&gte,\n+                           m::Op(&conv)\n+                               .WithPredicate(IsNonDepthwiseConvCustomCall)\n+                               .WithOneUse())\n+            .WithElementType(F16)\n+            .WithPredicate(HasThreeUsers);\n+    if (!Match(instr,\n+               m::Select(m::Compare(gte_pattern,\n+                                    m::Broadcast(m::ConstantEffectiveScalar(0)))\n+                             .WithComparisonDirection(ComparisonDirection::kGt)\n+                             .WithOneUse(),\n+                         gte_pattern,\n+                         m::Multiply(gte_pattern, m::Broadcast(m::ConstantEffectiveScalar(&alpha)))))) {", "source": "StatusOr<bool> FuseLeakyRelu(HloComputation* comp, se::CudaComputeCapability cc) {\n  bool changed = false;\n  for (HloInstruction* instr : comp->MakeInstructionPostOrder()) {\n    const DebugOptions& debug_options =\n    instr->GetModule()->config().debug_options();\n    if (!debug_options.xla_gpu_use_runtime_fusion() ||\n        !cc.IsAtLeast(se::CudaComputeCapability::AMPERE)) {\n      return false;\n    }\n    HloInstruction* gte;\n    HloInstruction* conv;\n    HloInstruction* alpha;\n    // We don't want to upgrade depthwise convolutions to ConvBiasActivation,\n    // because the fused CUDNN functions are slower for some of those.\n    auto gte_pattern =\n        m::GetTupleElement(&gte,\n                           m::Op(&conv)\n                               .WithPredicate(IsNonDepthwiseConvCustomCall)\n                               .WithOneUse())\n            .WithElementType(F16)\n            .WithPredicate(HasThreeUsers);\n    if (!Match(instr,\n               m::Select(m::Compare(gte_pattern,\n                                    m::Broadcast(m::ConstantEffectiveScalar(0)))\n                             .WithComparisonDirection(ComparisonDirection::kGt)\n                             .WithOneUse(),\n                         gte_pattern,\n                         m::Multiply(gte_pattern, m::Broadcast(m::ConstantEffectiveScalar(&alpha)))))) {\n      continue;\n    }\n    TF_ASSIGN_OR_RETURN(CudnnConvBackendConfig config,\n                        conv->backend_config<CudnnConvBackendConfig>());\n    if (config.activation_mode() != se::dnn::kNone) {\n      continue;\n    }\n\n    if (!ConsumeFuel(\"cudnn-fused-convolution-rewriter\", [&] {\n          return absl::StrCat(\"FuseLeakyRelu: \", conv->ToString());\n        })) {\n      continue;\n    }\n    TF_ASSIGN_OR_RETURN(conv, EnsureIsConvBiasActivation(conv));\n    config.set_activation_mode(se::dnn::kLeakyRelu);\n    TF_RETURN_IF_ERROR(conv->set_backend_config(config));\n    TF_RETURN_IF_ERROR(comp->ReplaceInstruction(instr, gte));\n    changed = true;\n  }\n  return changed;\n}", "source_start_line": 680, "tokens": ["StatusOr", "<", "bool", ">", "FuseLeakyRelu", "(", "HloComputation", "*", "comp", ",", "se", "::", "CudaComputeCapability", "cc", ")", "{", "bool", "changed", "=", "false", ";", "for", "(", "HloInstruction", "*", "instr", ":", "comp", "->", "MakeInstructionPostOrder", "(", ")", ")", "{", "const", "DebugOptions", "&", "debug_options", "=", "instr", "->", "GetModule", "(", ")", "->", "config", "(", ")", ".", "debug_options", "(", ")", ";", "if", "(", "!", "debug_options", ".", "xla_gpu_use_runtime_fusion", "(", ")", "||", "!", "cc", ".", "IsAtLeast", "(", "se", "::", "CudaComputeCapability", "::", "AMPERE", ")", ")", "{", "return", "false", ";", "}", "HloInstruction", "*", "gte", ";", "HloInstruction", "*", "conv", ";", "HloInstruction", "*", "alpha", ";", "auto", "gte_pattern", "=", "m", "::", "GetTupleElement", "(", "&", "gte", ",", "m", "::", "Op", "(", "&", "conv", ")", ".", "WithPredicate", "(", "IsNonDepthwiseConvCustomCall", ")", ".", "WithOneUse", "(", ")", ")", ".", "WithElementType", "(", "F16", ")", ".", "WithPredicate", "(", "HasThreeUsers", ")", ";", "if", "(", "!", "Match", "(", "instr", ",", "m", "::", "Select", "(", "m", "::", "Compare", "(", "gte_pattern", ",", "m", "::", "Broadcast", "(", "m", "::", "ConstantEffectiveScalar", "(", "0", ")", ")", ")", ".", "WithComparisonDirection", "(", "ComparisonDirection", "::", "kGt", ")", ".", "WithOneUse", "(", ")", ",", "gte_pattern", ",", "m", "::", "Multiply", "(", "gte_pattern", ",", "m", "::", "Broadcast", "(", "m", "::", "ConstantEffectiveScalar", "(", "&", "alpha", ")", ")", ")", ")", ")", ")", "{", "continue", ";", "}", "TF_ASSIGN_OR_RETURN", "(", "CudnnConvBackendConfig", "config", ",", "conv", "->", "backend_config", "<", "CudnnConvBackendConfig", ">", "(", ")", ")", ";", "if", "(", "config", ".", "activation_mode", "(", ")", "!=", "se", "::", "dnn", "::", "kNone", ")", "{", "continue", ";", "}", "if", "(", "!", "ConsumeFuel", "(", "\"", "\"", ",", "[", "&", "]", "{", "return", "absl", "::", "StrCat", "(", "\"", "\"", ",", "conv", "->", "ToString", "(", ")", ")", ";", "}", ")", ")", "{", "continue", ";", "}", "TF_ASSIGN_OR_RETURN", "(", "conv", ",", "EnsureIsConvBiasActivation", "(", "conv", ")", ")", ";", "config", ".", "set_activation_mode", "(", "se", "::", "dnn", "::", "kLeakyRelu", ")", ";", "TF_RETURN_IF_ERROR", "(", "conv", "->", "set_backend_config", "(", "config", ")", ")", ";", "TF_RETURN_IF_ERROR", "(", "comp", "->", "ReplaceInstruction", "(", "instr", ",", "gte", ")", ")", ";", "changed", "=", "true", ";", "}", "return", "changed", ";", "}"], "to_mask": {"VAR": ["alpha", "cc", "changed", "comp", "conv", "debug_options", "gte", "gte_pattern", "instr"], "METHOD": ["Broadcast", "Compare", "ConstantEffectiveScalar", "ConsumeFuel", "EnsureIsConvBiasActivation", "GetModule", "GetTupleElement", "IsAtLeast", "MakeInstructionPostOrder", "Match", "Multiply", "Op", "ReplaceInstruction", "Select", "StrCat", "TF_ASSIGN_OR_RETURN", "TF_RETURN_IF_ERROR", "ToString", "WithComparisonDirection", "WithElementType", "WithOneUse", "WithPredicate", "activation_mode", "config", "debug_options", "set_activation_mode", "set_backend_config", "xla_gpu_use_runtime_fusion"]}, "attention_idx_tokens": [172, 194], "patch": "@@ -633,6 +633,100 @@\n   return changed;\n }\n \n+StatusOr<bool> FuseRelu6(HloComputation* comp, se::CudaComputeCapability cc) {\n+  bool changed = false;\n+  for (HloInstruction* instr : comp->MakeInstructionPostOrder()) {\n+    const DebugOptions& debug_options =\n+    instr->GetModule()->config().debug_options();\n+    if (!debug_options.xla_gpu_use_runtime_fusion() ||\n+        !cc.IsAtLeast(se::CudaComputeCapability::AMPERE)) {\n+      return false;\n+    }\n+    HloInstruction* gte;\n+    HloInstruction* conv;\n+    // We don't want to upgrade depthwise convolutions to ConvBiasActivation,\n+    // because the fused CUDNN functions are slower for some of those.\n+    if (!Match(instr,\n+               m::Clamp(\n+                   m::Broadcast(m::ConstantEffectiveScalar(0)),\n+                   m::GetTupleElement(\n+                       &gte, m::Op(&conv)\n+                                 .WithPredicate(IsNonDepthwiseConvCustomCall)\n+                                 .WithOneUse())\n+                       .WithOneUse(),\n+                       m::Broadcast(m::ConstantEffectiveScalar(6))))) {\n+      continue;\n+    }\n+    TF_ASSIGN_OR_RETURN(CudnnConvBackendConfig config,\n+                        conv->backend_config<CudnnConvBackendConfig>());\n+    if (config.activation_mode() != se::dnn::kNone) {\n+      continue;\n+    }\n+\n+    if (!ConsumeFuel(\"cudnn-fused-convolution-rewriter\", [&] {\n+          return absl::StrCat(\"FuseRelu6: \", conv->ToString());\n+        })) {\n+      continue;\n+    }\n+    TF_ASSIGN_OR_RETURN(conv, EnsureIsConvBiasActivation(conv));\n+    config.set_activation_mode(se::dnn::kRelu6);\n+    TF_RETURN_IF_ERROR(conv->set_backend_config(config));\n+    TF_RETURN_IF_ERROR(comp->ReplaceInstruction(instr, gte));\n+    changed = true;\n+  }\n+  return changed;\n+}\n+\n+StatusOr<bool> FuseLeakyRelu(HloComputation* comp, se::CudaComputeCapability cc) {\n+  bool changed = false;\n+  for (HloInstruction* instr : comp->MakeInstructionPostOrder()) {\n+    const DebugOptions& debug_options =\n+    instr->GetModule()->config().debug_options();\n+    if (!debug_options.xla_gpu_use_runtime_fusion() ||\n+        !cc.IsAtLeast(se::CudaComputeCapability::AMPERE)) {\n+      return false;\n+    }\n+    HloInstruction* gte;\n+    HloInstruction* conv;\n+    HloInstruction* alpha;\n+    // We don't want to upgrade depthwise convolutions to ConvBiasActivation,\n+    // because the fused CUDNN functions are slower for some of those.\n+    auto gte_pattern =\n+        m::GetTupleElement(&gte,\n+                           m::Op(&conv)\n+                               .WithPredicate(IsNonDepthwiseConvCustomCall)\n+                               .WithOneUse())\n+            .WithElementType(F16)\n+            .WithPredicate(HasThreeUsers);\n+    if (!Match(instr,\n+               m::Select(m::Compare(gte_pattern,\n+                                    m::Broadcast(m::ConstantEffectiveScalar(0)))\n+                             .WithComparisonDirection(ComparisonDirection::kGt)\n+                             .WithOneUse(),\n+                         gte_pattern,\n+                         m::Multiply(gte_pattern, m::Broadcast(m::ConstantEffectiveScalar(&alpha)))))) {", "ext_attention_idx_tokens": [0, 316], "uid": "b0cc9ca3", "question": "How is alpha used?", "code": "StatusOr<bool> FuseLeakyRelu HloComputation* comp se CudaComputeCapability cc { bool changed false; for HloInstruction* instr comp->MakeInstructionPostOrder { const DebugOptions& debug options instr->GetModule ->config debug options ; if !debug options xla gpu use runtime fusion || !cc IsAtLeast se CudaComputeCapability AMPERE { return false; } HloInstruction* gte; HloInstruction* conv; HloInstruction* alpha; We don t want to upgrade depthwise convolutions to ConvBiasActivation because the fused CUDNN functions are slower for some of those auto gte pattern m GetTupleElement &gte m Op &conv WithPredicate IsNonDepthwiseConvCustomCall WithOneUse WithElementType F16 WithPredicate HasThreeUsers ; if !Match instr m Select m Compare gte pattern m Broadcast m ConstantEffectiveScalar 0 WithComparisonDirection ComparisonDirection kGt WithOneUse gte pattern m Multiply gte pattern m Broadcast m ConstantEffectiveScalar &alpha { continue; } TF ASSIGN OR RETURN CudnnConvBackendConfig config conv->backend config<CudnnConvBackendConfig> ; if config activation mode ! se dnn kNone { continue; } if !ConsumeFuel \"cudnn-fused-convolution-rewriter\" [&] { return absl StrCat \"FuseLeakyRelu \" conv->ToString ; } { continue; } TF ASSIGN OR RETURN conv EnsureIsConvBiasActivation conv ; config set activation mode se dnn kLeakyRelu ; TF RETURN IF ERROR conv->set backend config config ; TF RETURN IF ERROR comp->ReplaceInstruction instr gte ; changed true; } return changed; }"}
{"message": "Could this be avoided? E.g., could we detect rather than recover from?", "timestamp": "2023-03-16T14:00:00Z", "file_name": "tensorflow/compiler/mlir/tosa/transforms/legalize_utils.cc", "range": {"start_line": 289, "end_line": 289, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1138718459", "html_url": "https://github.com/tensorflow/tensorflow/pull/60005#discussion_r1138718459", "attention_area": "    std::feclearexcept(FE_ALL_EXCEPT);", "file_path": "files/12/03/00000312.cc", "old_file_path": "files/13/03/00000313.cc", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -285,7 +285,17 @@ Value getTosaConst8bitTable(PatternRewriter& rewriter, Operation* op,\n   for (int32_t i = -128; i < 128; i++) {\n     double dequantized = input_scale * (i - input_zp);\n     double transformed = func(dequantized);\n+\n+    std::feclearexcept(FE_ALL_EXCEPT);", "source": "Value getTosaConst8bitTable(PatternRewriter& rewriter, Operation* op,\n                            double input_scale, int32_t input_zp,\n                            double output_scale, int32_t output_zp,\n                            std::function<double(double)> func) {\n  SmallVector<int8_t, 256> table;\n\n  for (int32_t i = -128; i < 128; i++) {\n    double dequantized = input_scale * (i - input_zp);\n    double transformed = func(dequantized);\n\n    std::feclearexcept(FE_ALL_EXCEPT);\n    int32_t rescaled = std::llround(transformed / output_scale);\n\n    // When transformed/output_scale is generates an exception,\n    // replace it with INT8_MAX\n    if (std::fetestexcept(FE_INVALID)) {\n      table.push_back(INT8_MAX);\n      continue;\n    }\n\n    int32_t quantized = static_cast<int32_t>(rescaled + output_zp);\n    table.push_back(\n        static_cast<int8_t>(std::min(std::max(quantized, -128), 127)));\n  }\n\n  auto element_qtype =\n      UniformQuantizedType::get(true, rewriter.getIntegerType(8),\n                                rewriter.getF32Type(), 1.0f, 0, -128, 127);\n  auto const_type = tensorflow::GetTypeFromTFTensorShape({256}, element_qtype);\n  auto storage_type = tensorflow::GetTypeFromTFTensorShape(\n      {256}, element_qtype.getStorageType());\n  auto const_attr = DenseElementsAttr::get(storage_type, llvm::ArrayRef(table));\n\n  auto const_op =\n      rewriter.create<tosa::ConstOp>(op->getLoc(), const_type, const_attr);\n  return const_op.getResult();\n}", "source_start_line": 279, "tokens": ["Value", "getTosaConst8bitTable", "(", "PatternRewriter", "&", "rewriter", ",", "Operation", "*", "op", ",", "double", "input_scale", ",", "int32_t", "input_zp", ",", "double", "output_scale", ",", "int32_t", "output_zp", ",", "std", "::", "function", "<", "double", "(", "double", ")", ">", "func", ")", "{", "SmallVector", "<", "int8_t", ",", "256", ">", "table", ";", "for", "(", "int32_t", "i", "=", "-128", ";", "i", "<", "128", ";", "i", "++", ")", "{", "double", "dequantized", "=", "input_scale", "*", "(", "i", "-", "input_zp", ")", ";", "double", "transformed", "=", "func", "(", "dequantized", ")", ";", "std", "::", "feclearexcept", "(", "FE_ALL_EXCEPT", ")", ";", "int32_t", "rescaled", "=", "std", "::", "llround", "(", "transformed", "/", "output_scale", ")", ";", "if", "(", "std", "::", "fetestexcept", "(", "FE_INVALID", ")", ")", "{", "table", ".", "push_back", "(", "INT8_MAX", ")", ";", "continue", ";", "}", "int32_t", "quantized", "=", "static_cast", "<", "int32_t", ">", "(", "rescaled", "+", "output_zp", ")", ";", "table", ".", "push_back", "(", "static_cast", "<", "int8_t", ">", "(", "std", "::", "min", "(", "std", "::", "max", "(", "quantized", ",", "-128", ")", ",", "127", ")", ")", ")", ";", "}", "auto", "element_qtype", "=", "UniformQuantizedType", "::", "get", "(", "true", ",", "rewriter", ".", "getIntegerType", "(", "8", ")", ",", "rewriter", ".", "getF32Type", "(", ")", ",", "1.0f", ",", "0", ",", "-128", ",", "127", ")", ";", "auto", "const_type", "=", "tensorflow", "::", "GetTypeFromTFTensorShape", "(", "{", "256", "}", ",", "element_qtype", ")", ";", "auto", "storage_type", "=", "tensorflow", "::", "GetTypeFromTFTensorShape", "(", "{", "256", "}", ",", "element_qtype", ".", "getStorageType", "(", ")", ")", ";", "auto", "const_attr", "=", "DenseElementsAttr", "::", "get", "(", "storage_type", ",", "llvm", "::", "ArrayRef", "(", "table", ")", ")", ";", "auto", "const_op", "=", "rewriter", ".", "create", "<", "tosa", "::", "ConstOp", ">", "(", "op", "->", "getLoc", "(", ")", ",", "const_type", ",", "const_attr", ")", ";", "return", "const_op", ".", "getResult", "(", ")", ";", "}"], "to_mask": {"VAR": ["const_attr", "const_op", "const_type", "dequantized", "element_qtype", "func", "i", "input_scale", "input_zp", "op", "output_scale", "output_zp", "quantized", "rescaled", "rewriter", "storage_type", "table", "transformed"], "METHOD": ["ArrayRef", "GetTypeFromTFTensorShape", "feclearexcept", "fetestexcept", "func", "get", "getF32Type", "getIntegerType", "getLoc", "getResult", "getStorageType", "llround", "max", "min", "push_back", "rewriter", "static_cast"]}, "attention_idx_tokens": [77, 83], "patch": "@@ -285,7 +285,17 @@\n   for (int32_t i = -128; i < 128; i++) {\n     double dequantized = input_scale * (i - input_zp);\n     double transformed = func(dequantized);\n+\n+    std::feclearexcept(FE_ALL_EXCEPT);", "ext_attention_idx_tokens": [77, 128], "uid": "a42ac7ef", "question": "Could this be avoided? E.g., could we detect rather than recover from?", "code": "Value getTosaConst8bitTable PatternRewriter& rewriter Operation* op double input scale int32 t input zp double output scale int32 t output zp std function<double double > func { SmallVector<int8 t 256> table; for int32 t i -128; i < 128; i++ { double dequantized input scale * i - input zp ; double transformed func dequantized ; std feclearexcept FE ALL EXCEPT ; int32 t rescaled std llround transformed output scale ; When transformed output scale is generates an exception replace it with INT8 MAX if std fetestexcept FE INVALID { table push back INT8 MAX ; continue; } int32 t quantized static cast<int32 t> rescaled + output zp ; table push back static cast<int8 t> std min std max quantized -128 127 ; } auto element qtype UniformQuantizedType get true rewriter getIntegerType 8 rewriter getF32Type 1 0f 0 -128 127 ; auto const type tensorflow GetTypeFromTFTensorShape {256} element qtype ; auto storage type tensorflow GetTypeFromTFTensorShape {256} element qtype getStorageType ; auto const attr DenseElementsAttr get storage type llvm ArrayRef table ; auto const op rewriter create<tosa ConstOp> op->getLoc const type const attr ; return const op getResult ; }"}
{"message": "Don't do explicit device placement.  Why doesn't this work on GPU?", "timestamp": "2023-03-21T19:38:19Z", "file_name": "tensorflow/python/kernel_tests/math_ops/reduction_ops_test.py", "range": {"start_line": 575, "end_line": 575, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1143908938", "html_url": "https://github.com/tensorflow/tensorflow/pull/58394#discussion_r1143908938", "attention_area": "    with ops.device(\"/cpu:0\"):", "file_path": "files/39/03/00000339.py", "old_file_path": "files/40/03/00000340.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -525,10 +571,11 @@ def testFloat32(self):\n       self._compareAllAxes(np_arr)\n \n   @test_util.run_deprecated_v1\n-  def testBfloat16(self):\n-    for rank in range(1, _MAX_RANK + 1):\n-      np_arr = self._makeIncremental((2,) * rank, dtypes.bfloat16)\n-      self._compareAllAxes(np_arr, rtol=1e-3, atol=1.)\n+  def testBFloat16(self):\n+    with ops.device(\"/cpu:0\"):", "source": "def testBFloat16(self):\n    with ops.device(\"/cpu:0\"):\n      for rank in range(1, _MAX_RANK + 1):\n        np_arr = self._makeIncremental((2,) * rank, dtypes.bfloat16)\n        self._compareAllAxes(np_arr)", "source_start_line": 574, "tokens": ["def", "testBFloat16", "(", "self", ")", ":", "with", "ops", ".", "device", "(", "\"/cpu:0\"", ")", ":", "for", "rank", "in", "range", "(", "1", ",", "_MAX_RANK", "+", "1", ")", ":", "np_arr", "=", "self", ".", "_makeIncremental", "(", "(", "2", ",", ")", "*", "rank", ",", "dtypes", ".", "bfloat16", ")", "self", ".", "_compareAllAxes", "(", "np_arr", ")"], "to_mask": {"VAR": ["np_arr", "rank", "self"], "METHOD": ["_compareAllAxes", "_makeIncremental", "device", "range"]}, "attention_idx_tokens": [6, 13], "patch": "@@ -525,10 +571,11 @@\n       self._compareAllAxes(np_arr)\n \n   @test_util.run_deprecated_v1\n-  def testBfloat16(self):\n-    for rank in range(1, _MAX_RANK + 1):\n-      np_arr = self._makeIncremental((2,) * rank, dtypes.bfloat16)\n-      self._compareAllAxes(np_arr, rtol=1e-3, atol=1.)\n+  def testBFloat16(self):\n+    with ops.device(\"/cpu:0\"):", "ext_attention_idx_tokens": [0, 48], "uid": "7a0a3626", "question": "Don't do explicit device placement.  Why doesn't this work on GPU?", "code": "def testBFloat16 self with ops device \" cpu 0\" for rank in range 1 MAX RANK + 1 np arr self makeIncremental 2 * rank dtypes bfloat16 self compareAllAxes np arr"}
{"message": "Why do we need the graph?", "timestamp": "2023-03-21T19:40:48Z", "file_name": "tensorflow/python/kernel_tests/math_ops/reduction_ops_test.py", "range": {"start_line": 333, "end_line": 333, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1143911244", "html_url": "https://github.com/tensorflow/tensorflow/pull/58394#discussion_r1143911244", "attention_area": "        with self.session(graph=ops.Graph(), use_gpu=True) as sess:", "file_path": "files/39/03/00000339.py", "old_file_path": "files/40/03/00000340.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -310,6 +310,52 @@ def testFloat32(self):\n             tf_out_sum_xz, tf_out_sum_y = self.evaluate([tf_sum_xz, tf_sum_y])\n           self.assertAllClose(sum_y, tf_out_sum_y)\n           self.assertAllClose(sum_xz, tf_out_sum_xz)\n+  \n+  @test_util.run_deprecated_v1\n+  def testFloat32BFloat16(self):\n+    for dtype in [dtypes.float32, dtypes.bfloat16]:\n+      dtype_np = np.float32 if dtype == dtypes.float32 else dtypes.bfloat16.as_numpy_dtype\n+      for rank in range(1, _MAX_RANK + 1):\n+        np_arr = self._makeIncremental((2,) * rank, dtype)\n+        self._compareAllAxes(np_arr)\n+\n+      for _ in range(10):\n+        size_x = int(2**np.random.uniform(0, 15))\n+        size_y = int(2**np.random.uniform(0, 15))\n+\n+        if size_x * size_y > 1e7:\n+          size_y = int(1e7 / size_x)\n+\n+        arr = np.ones([size_x, size_y], dtype=dtype_np)\n+        col_sum = np.sum(arr, axis=0, dtype=np.float32)\n+        row_sum = np.sum(arr, axis=1, dtype=np.float32)\n+\n+        with self.session(graph=ops.Graph(), use_gpu=True) as sess:", "source": "def testFloat32BFloat16(self):\n    for dtype in [dtypes.float32, dtypes.bfloat16]:\n      dtype_np = np.float32 if dtype == dtypes.float32 else dtypes.bfloat16.as_numpy_dtype\n      for rank in range(1, _MAX_RANK + 1):\n        np_arr = self._makeIncremental((2,) * rank, dtype)\n        self._compareAllAxes(np_arr)\n\n      for _ in range(10):\n        size_x = int(2**np.random.uniform(0, 15))\n        size_y = int(2**np.random.uniform(0, 15))\n\n        if size_x * size_y > 1e7:\n          size_y = int(1e7 / size_x)\n\n        arr = np.ones([size_x, size_y], dtype=dtype_np)\n        col_sum = np.sum(arr, axis=0, dtype=np.float32)\n        row_sum = np.sum(arr, axis=1, dtype=np.float32)\n\n        with self.session(graph=ops.Graph(), use_gpu=True) as sess:\n          tf_row_sum = self._tf_reduce(arr, 1, False)\n          tf_col_sum = self._tf_reduce(arr, 0, False)\n          tf_out_row, tf_out_col = self.evaluate([tf_row_sum, tf_col_sum])\n        if dtype == dtypes.bfloat16:\n          col_sum = dtype_np(col_sum)\n          row_sum = dtype_np(row_sum)\n        self.assertAllCloseAccordingToType(col_sum, tf_out_col)\n        self.assertAllCloseAccordingToType(row_sum, tf_out_row)\n\n      for size_x in [1, 3, 16, 33]:\n        for size_y in [1, 3, 16, 33]:\n          for size_z in [1, 3, 16, 33]:\n            arr = np.ones([size_x, size_y, size_z], dtype=dtype_np)\n            sum_y = np.sum(arr, axis=1, dtype=np.float32)\n            sum_xz = np.sum(arr, axis=(0, 2), dtype=np.float32)\n\n            with self.session(graph=ops.Graph(), use_gpu=True) as sess:\n              tf_sum_xz = self._tf_reduce(arr, [0, 2], False)\n              tf_sum_y = self._tf_reduce(arr, 1, False)\n              tf_out_sum_xz, tf_out_sum_y = self.evaluate([tf_sum_xz, tf_sum_y])\n            if dtype == dtypes.bfloat16:\n              sum_y = dtype_np(sum_y)\n              sum_xz = dtype_np(sum_xz)\n            self.assertAllCloseAccordingToType(sum_y, tf_out_sum_y)\n            self.assertAllCloseAccordingToType(sum_xz, tf_out_sum_xz)", "source_start_line": 315, "tokens": ["def", "testFloat32BFloat16", "(", "self", ")", ":", "for", "dtype", "in", "[", "dtypes", ".", "float32", ",", "dtypes", ".", "bfloat16", "]", ":", "dtype_np", "=", "np", ".", "float32", "if", "dtype", "==", "dtypes", ".", "float32", "else", "dtypes", ".", "bfloat16", ".", "as_numpy_dtype", "for", "rank", "in", "range", "(", "1", ",", "_MAX_RANK", "+", "1", ")", ":", "np_arr", "=", "self", ".", "_makeIncremental", "(", "(", "2", ",", ")", "*", "rank", ",", "dtype", ")", "self", ".", "_compareAllAxes", "(", "np_arr", ")", "for", "_", "in", "range", "(", "10", ")", ":", "size_x", "=", "int", "(", "2", "**", "np", ".", "random", ".", "uniform", "(", "0", ",", "15", ")", ")", "size_y", "=", "int", "(", "2", "**", "np", ".", "random", ".", "uniform", "(", "0", ",", "15", ")", ")", "if", "size_x", "*", "size_y", ">", "1e7", ":", "size_y", "=", "int", "(", "1e7", "/", "size_x", ")", "arr", "=", "np", ".", "ones", "(", "[", "size_x", ",", "size_y", "]", ",", "dtype", "=", "dtype_np", ")", "col_sum", "=", "np", ".", "sum", "(", "arr", ",", "axis", "=", "0", ",", "dtype", "=", "np", ".", "float32", ")", "row_sum", "=", "np", ".", "sum", "(", "arr", ",", "axis", "=", "1", ",", "dtype", "=", "np", ".", "float32", ")", "with", "self", ".", "session", "(", "graph", "=", "ops", ".", "Graph", "(", ")", ",", "use_gpu", "=", "True", ")", "as", "sess", ":", "tf_row_sum", "=", "self", ".", "_tf_reduce", "(", "arr", ",", "1", ",", "False", ")", "tf_col_sum", "=", "self", ".", "_tf_reduce", "(", "arr", ",", "0", ",", "False", ")", "tf_out_row", ",", "tf_out_col", "=", "self", ".", "evaluate", "(", "[", "tf_row_sum", ",", "tf_col_sum", "]", ")", "if", "dtype", "==", "dtypes", ".", "bfloat16", ":", "col_sum", "=", "dtype_np", "(", "col_sum", ")", "row_sum", "=", "dtype_np", "(", "row_sum", ")", "self", ".", "assertAllCloseAccordingToType", "(", "col_sum", ",", "tf_out_col", ")", "self", ".", "assertAllCloseAccordingToType", "(", "row_sum", ",", "tf_out_row", ")", "for", "size_x", "in", "[", "1", ",", "3", ",", "16", ",", "33", "]", ":", "for", "size_y", "in", "[", "1", ",", "3", ",", "16", ",", "33", "]", ":", "for", "size_z", "in", "[", "1", ",", "3", ",", "16", ",", "33", "]", ":", "arr", "=", "np", ".", "ones", "(", "[", "size_x", ",", "size_y", ",", "size_z", "]", ",", "dtype", "=", "dtype_np", ")", "sum_y", "=", "np", ".", "sum", "(", "arr", ",", "axis", "=", "1", ",", "dtype", "=", "np", ".", "float32", ")", "sum_xz", "=", "np", ".", "sum", "(", "arr", ",", "axis", "=", "(", "0", ",", "2", ")", ",", "dtype", "=", "np", ".", "float32", ")", "with", "self", ".", "session", "(", "graph", "=", "ops", ".", "Graph", "(", ")", ",", "use_gpu", "=", "True", ")", "as", "sess", ":", "tf_sum_xz", "=", "self", ".", "_tf_reduce", "(", "arr", ",", "[", "0", ",", "2", "]", ",", "False", ")", "tf_sum_y", "=", "self", ".", "_tf_reduce", "(", "arr", ",", "1", ",", "False", ")", "tf_out_sum_xz", ",", "tf_out_sum_y", "=", "self", ".", "evaluate", "(", "[", "tf_sum_xz", ",", "tf_sum_y", "]", ")", "if", "dtype", "==", "dtypes", ".", "bfloat16", ":", "sum_y", "=", "dtype_np", "(", "sum_y", ")", "sum_xz", "=", "dtype_np", "(", "sum_xz", ")", "self", ".", "assertAllCloseAccordingToType", "(", "sum_y", ",", "tf_out_sum_y", ")", "self", ".", "assertAllCloseAccordingToType", "(", "sum_xz", ",", "tf_out_sum_xz", ")"], "to_mask": {"VAR": ["_", "arr", "col_sum", "dtype", "dtype_np", "np_arr", "rank", "row_sum", "self", "sess", "size_x", "size_y", "size_z", "sum_xz", "sum_y", "tf_col_sum", "tf_out_col", "tf_out_row", "tf_out_sum_xz", "tf_out_sum_y", "tf_row_sum", "tf_sum_xz", "tf_sum_y"], "METHOD": ["Graph", "_compareAllAxes", "_makeIncremental", "_tf_reduce", "assertAllCloseAccordingToType", "dtype_np", "evaluate", "int", "ones", "range", "session", "sum", "uniform"]}, "attention_idx_tokens": [178, 197], "patch": "@@ -310,6 +310,52 @@\n             tf_out_sum_xz, tf_out_sum_y = self.evaluate([tf_sum_xz, tf_sum_y])\n           self.assertAllClose(sum_y, tf_out_sum_y)\n           self.assertAllClose(sum_xz, tf_out_sum_xz)\n+  \n+  @test_util.run_deprecated_v1\n+  def testFloat32BFloat16(self):\n+    for dtype in [dtypes.float32, dtypes.bfloat16]:\n+      dtype_np = np.float32 if dtype == dtypes.float32 else dtypes.bfloat16.as_numpy_dtype\n+      for rank in range(1, _MAX_RANK + 1):\n+        np_arr = self._makeIncremental((2,) * rank, dtype)\n+        self._compareAllAxes(np_arr)\n+\n+      for _ in range(10):\n+        size_x = int(2**np.random.uniform(0, 15))\n+        size_y = int(2**np.random.uniform(0, 15))\n+\n+        if size_x * size_y > 1e7:\n+          size_y = int(1e7 / size_x)\n+\n+        arr = np.ones([size_x, size_y], dtype=dtype_np)\n+        col_sum = np.sum(arr, axis=0, dtype=np.float32)\n+        row_sum = np.sum(arr, axis=1, dtype=np.float32)\n+\n+        with self.session(graph=ops.Graph(), use_gpu=True) as sess:", "ext_attention_idx_tokens": [0, 464], "uid": "1cfa4c0f", "question": "Why do we need the graph?", "code": "def testFloat32BFloat16 self for dtype in [dtypes float32 dtypes bfloat16] dtype np np float32 if dtype dtypes float32 else dtypes bfloat16 as numpy dtype for rank in range 1 MAX RANK + 1 np arr self makeIncremental 2 * rank dtype self compareAllAxes np arr for in range 10 size x int 2**np random uniform 0 15 size y int 2**np random uniform 0 15 if size x * size y > 1e7 size y int 1e7 size x arr np ones [size x size y] dtype dtype np col sum np sum arr axis 0 dtype np float32 row sum np sum arr axis 1 dtype np float32 with self session graph ops Graph use gpu True as sess tf row sum self tf reduce arr 1 False tf col sum self tf reduce arr 0 False tf out row tf out col self evaluate [tf row sum tf col sum] if dtype dtypes bfloat16 col sum dtype np col sum row sum dtype np row sum self assertAllCloseAccordingToType col sum tf out col self assertAllCloseAccordingToType row sum tf out row for size x in [1 3 16 33] for size y in [1 3 16 33] for size z in [1 3 16 33] arr np ones [size x size y size z] dtype dtype np sum y np sum arr axis 1 dtype np float32 sum xz np sum arr axis 0 2 dtype np float32 with self session graph ops Graph use gpu True as sess tf sum xz self tf reduce arr [0 2] False tf sum y self tf reduce arr 1 False tf out sum xz tf out sum y self evaluate [tf sum xz tf sum y] if dtype dtypes bfloat16 sum y dtype np sum y sum xz dtype np sum xz self assertAllCloseAccordingToType sum y tf out sum y self assertAllCloseAccordingToType sum xz tf out sum xz"}
{"message": "I just implemented these changes. Does it look fine now? Also, is there any specific ordering to functions in dtypes.cc or types.h to keep it consistent with other files? For the time being, I placed the code for is_numeric and IsNumericDataType right above the code for is_complex and IsComplexDataType.", "timestamp": "2023-05-09T18:55:43Z", "file_name": "tensorflow/python/ops/math_ops.py", "range": {"start_line": 825, "end_line": 825, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1189018058", "html_url": "https://github.com/tensorflow/tensorflow/pull/60540#discussion_r1189018058", "attention_area": "    elif tf.debugging.is_numeric_tensor(input):", "file_path": "files/92/04/00000492.py", "old_file_path": "files/94/04/00000494.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -822,8 +822,10 @@ def real(input, name=None):\n     if input.dtype.is_complex:\n       real_dtype = input.dtype.real_dtype\n       return gen_math_ops.real(input, Tout=real_dtype, name=name)\n-    else:\n+    elif tf.debugging.is_numeric_tensor(input):", "source": "def real(input, name=None):\n  r\"\"\"Returns the real part of a complex (or real) tensor.\n\n  Given a tensor `input`, this operation returns a tensor of type `float` that\n  is the real part of each element in `input` considered as a complex number.\n\n  For example:\n\n  ```python\n  x = tf.constant([-2.25 + 4.75j, 3.25 + 5.75j])\n  tf.math.real(x)  # [-2.25, 3.25]\n  ```\n\n  If `input` is already real, it is returned unchanged.\n\n  Args:\n    input: A `Tensor`. Must have numeric type.\n    name: A name for the operation (optional).\n\n  Returns:\n    A `Tensor` of type `float32` or `float64`.\n  \"\"\"\n  with ops.name_scope(name, \"Real\", [input]) as name:\n    input = ops.convert_to_tensor(input, name=\"input\")\n    if input.dtype.is_complex:\n      real_dtype = input.dtype.real_dtype\n      return gen_math_ops.real(input, Tout=real_dtype, name=name)\n    elif tf.debugging.is_numeric_tensor(input):\n      return input\n    else:\n      raise TypeError(\"input must be a numeric tensor, but got tensor with dtype {}\".format(input.dtype))", "source_start_line": 798, "tokens": ["def", "real", "(", "input", ",", "name", "=", "None", ")", ":", "r\"\"\"Returns the real part of a complex (or real) tensor.  Given a tensor `input`, this operation returns a tensor of type `float` that  is the real part of each element in `input` considered as a complex number.  For example:  ```python  x = tf.constant([-2.25 + 4.75j, 3.25 + 5.75j])  tf.math.real(x)  # [-2.25, 3.25]  ```  If `input` is already real, it is returned unchanged.  Args:    input: A `Tensor`. Must have numeric type.    name: A name for the operation (optional).  Returns:    A `Tensor` of type `float32` or `float64`.  \"\"\"", "with", "ops", ".", "name_scope", "(", "name", ",", "\"Real\"", ",", "[", "input", "]", ")", "as", "name", ":", "input", "=", "ops", ".", "convert_to_tensor", "(", "input", ",", "name", "=", "\"input\"", ")", "if", "input", ".", "dtype", ".", "is_complex", ":", "real_dtype", "=", "input", ".", "dtype", ".", "real_dtype", "return", "gen_math_ops", ".", "real", "(", "input", ",", "Tout", "=", "real_dtype", ",", "name", "=", "name", ")", "elif", "tf", ".", "debugging", ".", "is_numeric_tensor", "(", "input", ")", ":", "return", "input", "else", ":", "raise", "TypeError", "(", "\"input must be a numeric tensor, but got tensor with dtype {}\"", ".", "format", "(", "input", ".", "dtype", ")", ")"], "to_mask": {"VAR": ["input", "name", "real_dtype"], "METHOD": ["TypeError", "convert_to_tensor", "format", "is_numeric_tensor", "name_scope", "real"]}, "attention_idx_tokens": [68, 77], "patch": "@@ -822,8 +822,10 @@\n     if input.dtype.is_complex:\n       real_dtype = input.dtype.real_dtype\n       return gen_math_ops.real(input, Tout=real_dtype, name=name)\n-    else:\n+    elif tf.debugging.is_numeric_tensor(input):", "ext_attention_idx_tokens": [68, 93], "uid": "0af3cf7b", "question": "I just implemented these changes. Does it look fine now? Also, is there any specific ordering to functions in dtypes.cc or types.h to keep it consistent with other files? For the time being, I placed the code for is_numeric and IsNumericDataType right above the code for is_complex and IsComplexDataType.", "code": "def real input name None r\"\"\"Returns the real part of a complex or real tensor Given a tensor `input` this operation returns a tensor of type `float` that is the real part of each element in `input` considered as a complex number For example ```python x tf constant [-2 25 + 4 75j 3 25 + 5 75j] tf math real x # [-2 25 3 25] ``` If `input` is already real it is returned unchanged Args input A `Tensor` Must have numeric type name A name for the operation optional Returns A `Tensor` of type `float32` or `float64` \"\"\" with ops name scope name \"Real\" [input] as name input ops convert to tensor input name \"input\" if input dtype is complex real dtype input dtype real dtype return gen math ops real input Tout real dtype name name elif tf debugging is numeric tensor input return input else raise TypeError \"input must be a numeric tensor but got tensor with dtype {}\" format input dtype"}
{"message": "Hi. I'm still waiting on Py+CPP Test Suite - Ubuntu CPU, Python 3.9 and Code Check - Changed Files workflows to be run and approved. It seems odd that it's taking this long. Any ideas why?", "timestamp": "2023-05-18T17:42:42Z", "file_name": "tensorflow/python/ops/math_ops.py", "range": {"start_line": 825, "end_line": 825, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1198105604", "html_url": "https://github.com/tensorflow/tensorflow/pull/60540#discussion_r1198105604", "attention_area": "    elif tf.debugging.is_numeric_tensor(input):", "file_path": "files/92/04/00000492.py", "old_file_path": "files/94/04/00000494.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -822,8 +822,10 @@ def real(input, name=None):\n     if input.dtype.is_complex:\n       real_dtype = input.dtype.real_dtype\n       return gen_math_ops.real(input, Tout=real_dtype, name=name)\n-    else:\n+    elif tf.debugging.is_numeric_tensor(input):", "source": "def real(input, name=None):\n  r\"\"\"Returns the real part of a complex (or real) tensor.\n\n  Given a tensor `input`, this operation returns a tensor of type `float` that\n  is the real part of each element in `input` considered as a complex number.\n\n  For example:\n\n  ```python\n  x = tf.constant([-2.25 + 4.75j, 3.25 + 5.75j])\n  tf.math.real(x)  # [-2.25, 3.25]\n  ```\n\n  If `input` is already real, it is returned unchanged.\n\n  Args:\n    input: A `Tensor`. Must have numeric type.\n    name: A name for the operation (optional).\n\n  Returns:\n    A `Tensor` of type `float32` or `float64`.\n  \"\"\"\n  with ops.name_scope(name, \"Real\", [input]) as name:\n    input = ops.convert_to_tensor(input, name=\"input\")\n    if input.dtype.is_complex:\n      real_dtype = input.dtype.real_dtype\n      return gen_math_ops.real(input, Tout=real_dtype, name=name)\n    elif tf.debugging.is_numeric_tensor(input):\n      return input\n    else:\n      raise TypeError(\"input must be a numeric tensor, but got tensor with dtype {}\".format(input.dtype))", "source_start_line": 798, "tokens": ["def", "real", "(", "input", ",", "name", "=", "None", ")", ":", "r\"\"\"Returns the real part of a complex (or real) tensor.  Given a tensor `input`, this operation returns a tensor of type `float` that  is the real part of each element in `input` considered as a complex number.  For example:  ```python  x = tf.constant([-2.25 + 4.75j, 3.25 + 5.75j])  tf.math.real(x)  # [-2.25, 3.25]  ```  If `input` is already real, it is returned unchanged.  Args:    input: A `Tensor`. Must have numeric type.    name: A name for the operation (optional).  Returns:    A `Tensor` of type `float32` or `float64`.  \"\"\"", "with", "ops", ".", "name_scope", "(", "name", ",", "\"Real\"", ",", "[", "input", "]", ")", "as", "name", ":", "input", "=", "ops", ".", "convert_to_tensor", "(", "input", ",", "name", "=", "\"input\"", ")", "if", "input", ".", "dtype", ".", "is_complex", ":", "real_dtype", "=", "input", ".", "dtype", ".", "real_dtype", "return", "gen_math_ops", ".", "real", "(", "input", ",", "Tout", "=", "real_dtype", ",", "name", "=", "name", ")", "elif", "tf", ".", "debugging", ".", "is_numeric_tensor", "(", "input", ")", ":", "return", "input", "else", ":", "raise", "TypeError", "(", "\"input must be a numeric tensor, but got tensor with dtype {}\"", ".", "format", "(", "input", ".", "dtype", ")", ")"], "to_mask": {"VAR": ["input", "name", "real_dtype"], "METHOD": ["TypeError", "convert_to_tensor", "format", "is_numeric_tensor", "name_scope", "real"]}, "attention_idx_tokens": [68, 77], "patch": "@@ -822,8 +822,10 @@\n     if input.dtype.is_complex:\n       real_dtype = input.dtype.real_dtype\n       return gen_math_ops.real(input, Tout=real_dtype, name=name)\n-    else:\n+    elif tf.debugging.is_numeric_tensor(input):", "ext_attention_idx_tokens": [68, 93], "uid": "c6dc3ba0", "question": "Hi. I'm still waiting on Py+CPP Test Suite - Ubuntu CPU, Python 3.9 and Code Check - Changed Files workflows to be run and approved. It seems odd that it's taking this long. Any ideas why?", "code": "def real input name None r\"\"\"Returns the real part of a complex or real tensor Given a tensor `input` this operation returns a tensor of type `float` that is the real part of each element in `input` considered as a complex number For example ```python x tf constant [-2 25 + 4 75j 3 25 + 5 75j] tf math real x # [-2 25 3 25] ``` If `input` is already real it is returned unchanged Args input A `Tensor` Must have numeric type name A name for the operation optional Returns A `Tensor` of type `float32` or `float64` \"\"\" with ops name scope name \"Real\" [input] as name input ops convert to tensor input name \"input\" if input dtype is complex real dtype input dtype real dtype return gen math ops real input Tout real dtype name name elif tf debugging is numeric tensor input return input else raise TypeError \"input must be a numeric tensor but got tensor with dtype {}\" format input dtype"}
{"message": "This is 1 and -1 right, why are both allowed here?", "timestamp": "2023-05-25T17:33:21Z", "file_name": "tensorflow/compiler/mlir/tosa/transforms/legalize_common.cc", "range": {"start_line": 2454, "end_line": 2454, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1205826690", "html_url": "https://github.com/tensorflow/tensorflow/pull/59880#discussion_r1205826690", "attention_area": "      // only add a stride dimension if strides[i] != 1", "file_path": "files/11/05/00000511.cc", "old_file_path": "files/12/05/00000512.cc", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -2448,10 +2446,14 @@ std::optional<Value> convertStridedSliceOp(\n   }\n \n   // Step 2: reshape the sliced array\n-  SmallVector<int64_t> a2_shape(input_rank * 2);\n+  SmallVector<int64_t> a2_shape;\n   for (int i = 0; i < input_rank; ++i) {\n-    a2_shape[i * 2 + 0] = a1_size[i] == -1 ? -1 : a1_size[i] / abs(strides[i]);\n-    a2_shape[i * 2 + 1] = abs(strides[i]);\n+    int64_t abs_stride_i = abs(strides[i]);\n+    a2_shape.push_back(a1_size[i] == -1 ? -1 : a1_size[i] / abs_stride_i);\n+    if (abs_stride_i != 1) {\n+      // only add a stride dimension if strides[i] != 1", "source": "std::optional<Value> convertStridedSliceOp(\n    PatternRewriter& rewriter, Operation* op, Value result_value,\n    Value input_value, Value begin_value, Value end_value, Value strides_value,\n    int32_t begin_mask, int32_t end_mask, int32_t ellipsis_mask,\n    int32_t new_axis_mask, int32_t shrink_axis_mask) {\n  // The mask arguments are bitmasks where bit [i] applies to\n  // dimension [i] of the input tensor.\n  //\n  // The rough algorithm for lowering strided slice is as follows:\n  //\n  // 0. Process begin/end masks, since they are basically syntactic sugar\n  // on top of the begin_value/end_value arrays\n  //\n  // 1. Slice1: Ignoring stride, slice the interesting range from the input\n  // tensor\n  //\n  // 2. Reshape2: Reshape the tensor from (1) such that each dimension with\n  // abs(stride) != 1 is split into two dimensions of size_i/stride_i, stride_i.\n  //\n  // 3. Slice3: Slice the tensor from (2) such that we select index [0] from\n  // each of the stride_i dimensions in (2)\n  //\n  // 4. Reshape4: Reshape the tensor to eliminate the stride_i dimensions, add\n  // any dimensions in new_axis_mask and remove any dimensions in the\n  // shrink_axis_mask\n\n  // Limitations:\n  // * This implementation only supports ellipsis_mask=0 for now\n  auto input_type = input_value.getType().dyn_cast<RankedTensorType>();\n  ShapedType result_type = result_value.getType().cast<ShapedType>();\n\n  if (ellipsis_mask != 0) {\n    (void)rewriter.notifyMatchFailure(op, \"ellipses mask not supported yet\");\n    return std::nullopt;\n  }\n\n  if (!input_type) {\n    (void)rewriter.notifyMatchFailure(op, \"input type has unknown rank\");\n    return std::nullopt;\n  }\n\n  int32_t input_rank = input_type.getRank();\n  Type element_type = input_type.getElementType();\n\n  // Conditionally extract begin/end values if requied.\n  SmallVector<int32_t> begin, end, strides;\n  if (failed(getVectorFromValue32(strides_value, strides))) {\n    (void)rewriter.notifyMatchFailure(op, \"strides isn't a constant\");\n    return std::nullopt;\n  }\n\n  // Current configuration does not support negative strides greater than 1.\n  // Bail out for now (fix if this proves to be legal).\n  for (auto stride : strides)\n    if (stride < -1) return std::nullopt;\n\n  bool all_strides_one = true;\n  int32_t strides_size = strides.size();\n  for (auto stride : strides) all_strides_one &= abs(stride) == 1;\n\n\n  // If all of the masks are set we can just bypass the entire thing.\n  const int32_t all_masks_one = (1 << strides_size) - 1;\n\n  if (failed(getVectorFromValue32(begin_value, begin)) &&\n      begin_mask != all_masks_one) {\n    (void)rewriter.notifyMatchFailure(op, \"begin isn't a constant\");\n    return std::nullopt;\n  }\n\n  if (end_mask != all_masks_one &&\n      failed(getVectorFromValue32(end_value, end))) {\n    (void)rewriter.notifyMatchFailure(op, \"end isn't a constant\");\n    return std::nullopt;\n  }\n\n  if (llvm::any_of(strides, [](auto i) { return i < -1; })) {\n    (void)rewriter.notifyMatchFailure(op, \"stride < -1 unsupported\");\n    return std::nullopt;\n  }\n\n  // Set begin mask values if possible.\n  for (const auto& val : llvm::enumerate(begin))\n    begin_mask |= (val.value() == 0) << val.index();\n\n  // If all begin/end masks are set and striding is one we can just return\n  // the matrix with reversed dims (for negative strides).\n  if (all_strides_one && begin_mask == all_masks_one &&\n      end_mask == all_masks_one) {\n    return reverseNegativeStride(rewriter, op, input_value, strides);\n  }\n\n  // Set the bits true for the remaining dimensions.\n  int32_t new_mask_bits = (1 << input_rank) - all_masks_one - 1;\n  begin_mask |= new_mask_bits;\n  end_mask |= new_mask_bits;\n\n  // Negative values are exclusive from the opposite end while TOSA is\n  // inclusive, we offset to adjust for this.\n  for (auto& b : begin)\n    if (b < 0) b = b - 1;\n  for (auto& e : end)\n    if (e < 0) e = e - 1;\n\n  // Fill the remaining stride and begin/end with default values.\n  strides.resize(input_rank, 1);\n  begin.resize(input_rank, 0);\n  end.resize(input_rank, -1);\n\n  // Set masking-bit overrides.\n  for (int i = 0; i < input_rank; ++i) {\n    if (begin_mask & (1 << i)) begin[i] = 0;\n    if (end_mask & (1 << i)) end[i] = -1;\n  }\n\n  // If we know the static end we can adjust by it.\n  for (int i = 0; i < input_rank; ++i) {\n    if (input_type.isDynamicDim(i)) continue;\n    if (begin[i] < 0) begin[i] += input_type.getDimSize(i) + 1;\n    if (end[i] < 0) end[i] += input_type.getDimSize(i) + 1;\n  }\n\n  // Perform some final validation on the begin/end values.\n  for (int i = 0; i < input_rank; ++i) {\n    if (begin[i] < 0 && input_type.isDynamicDim(i)) {\n      (void)rewriter.notifyMatchFailure(\n          op, \"begin offset is negative on dynamic size\");\n      return std::nullopt;\n    }\n\n    if (end[i] < -1 && input_type.isDynamicDim(i)) {\n      (void)rewriter.notifyMatchFailure(\n          op, \"end is exclusive of final entry on dynamic size\");\n      return std::nullopt;\n    }\n  }\n\n  // Step 0: Process the begin/end masks and build the begin/sizes for the\n  // first slice\n  SmallVector<int64_t> a1_begin(input_rank), a1_size(input_rank);\n  for (int i = 0; i < input_rank; ++i) {\n    // Wrap around index if begin and end is negative\n    a1_begin[i] = begin[i];\n\n    if (end[i] == -1 && input_type.isDynamicDim(i)) {\n      // Slice using -1 as TOSA's sentinal value.\n      a1_size[i] = -1;\n    } else if (end[i] < 0 && input_type.isDynamicDim(i)) {\n      // Other dynamic cases cannot be handled.\n      (void)rewriter.notifyMatchFailure(\n          op, \"input dim is dynamic and slice end depends on the length\");\n      return std::nullopt;\n    } else {\n      a1_size[i] = end[i] - a1_begin[i];\n    }\n\n    // Shrink axis mask means we know the size and stride are 1.\n    if (shrink_axis_mask & (1 << i)) {\n      a1_size[i] = 1;\n      strides[i] = 1;\n    }\n  }\n\n  // Step 1: Slice the input array\n  auto a1_slice_op = CreateOpAndInfer<tosa::SliceOp>(\n      rewriter, op->getLoc(),\n      tensorflow::GetTypeFromTFTensorShape(a1_size, element_type), input_value,\n      rewriter.getDenseI64ArrayAttr(a1_begin),\n      rewriter.getDenseI64ArrayAttr(tensorflow::ConvertMlirShapeToTF(a1_size)));\n\n  // If unary striding is used we can reverse, reshape, and return the result.\n  if (all_strides_one) {\n    auto reversed =\n        reverseNegativeStride(rewriter, op, a1_slice_op.getResult(), strides);\n    auto shape = reversed.getType().cast<RankedTensorType>().getShape();\n\n    SmallVector<int64_t> new_shape;\n    for (int i = 0; i < input_rank; ++i) {\n      if (!(shrink_axis_mask & (1 << i))) {\n        if (new_axis_mask & (1 << i)) new_shape.push_back(1);\n        new_shape.push_back((shape[i]));\n      }\n    }\n\n    return CreateOpAndInfer<tosa::ReshapeOp>(\n               rewriter, op->getLoc(), result_type, reversed,\n               rewriter.getDenseI64ArrayAttr(\n                   tensorflow::ConvertMlirShapeToTF(new_shape)))\n        .getResult();\n  }\n\n  // Step 2: reshape the sliced array\n  SmallVector<int64_t> a2_shape;\n  for (int i = 0; i < input_rank; ++i) {\n    int64_t abs_stride_i = abs(strides[i]);\n    a2_shape.push_back(a1_size[i] == -1 ? -1 : a1_size[i] / abs_stride_i);\n    if (abs_stride_i != 1) {\n      // only add a stride dimension if strides[i] != 1\n      a2_shape.push_back(abs_stride_i);\n    }\n  }\n\n  auto a2_reshape_op = CreateOpAndInfer<tosa::ReshapeOp>(\n      rewriter, op->getLoc(),\n      tensorflow::GetTypeFromTFTensorShape(a2_shape, element_type),\n      a1_slice_op.getResult(),\n      rewriter.getDenseI64ArrayAttr(\n          tensorflow::ConvertMlirShapeToTF(a2_shape)));\n\n  // Step 3: take a slice along the strides\n  SmallVector<int64_t> a3_begin, a3_size;\n  for (int i = 0; i < input_rank; ++i) {\n    int64_t abs_stride_i = abs(strides[i]);\n    a3_begin.push_back(0);\n\n    if (shrink_axis_mask & (1 << i)) {\n      a3_size.push_back(1);\n    } else {\n      a3_size.push_back((a1_size[i] == -1) ? -1 : (a1_size[i] / abs_stride_i));\n    }\n    if (abs_stride_i != 1) {\n      // previous reshape only adds a stride dimension if strides[i] != 1 \n      a3_begin.push_back(0);\n      a3_size.push_back(1);\n    }\n  }\n  assert(a2_shape.size() == a3_begin.size());\n  assert(a2_shape.size() == a3_size.size());\n\n  auto a3_slice_op = CreateOpAndInfer<tosa::SliceOp>(\n      rewriter, op->getLoc(),\n      tensorflow::GetTypeFromTFTensorShape(a3_size, element_type),\n      a2_reshape_op.getResult(), rewriter.getDenseI64ArrayAttr(a3_begin),\n      rewriter.getDenseI64ArrayAttr(tensorflow::ConvertMlirShapeToTF(a3_size)));\n\n  // Step 4: reshape the now-strided tensor\n  SmallVector<int64_t> a4_shape;\n  for (int i = 0; i < input_rank; ++i) {\n    if (!(shrink_axis_mask & (1 << i))) {\n      if (new_axis_mask & (1 << i)) a4_shape.push_back(1);\n      a4_shape.push_back(\n          ((a1_size[i] == -1) ? -1 : (a1_size[i] / abs(strides[i]))));\n    }\n  }\n\n  auto a4_reshape_op =\n      CreateOpAndInfer<tosa::ReshapeOp>(\n          rewriter, op->getLoc(), result_type, a3_slice_op.getResult(),\n          rewriter.getDenseI64ArrayAttr(\n              tensorflow::ConvertMlirShapeToTF(a4_shape)))\n          .getResult();\n\n  return reverseNegativeStride(rewriter, op, a4_reshape_op, strides);\n}", "source_start_line": 2257, "tokens": ["std", "::", "optional", "<", "Value", ">", "convertStridedSliceOp", "(", "PatternRewriter", "&", "rewriter", ",", "Operation", "*", "op", ",", "Value", "result_value", ",", "Value", "input_value", ",", "Value", "begin_value", ",", "Value", "end_value", ",", "Value", "strides_value", ",", "int32_t", "begin_mask", ",", "int32_t", "end_mask", ",", "int32_t", "ellipsis_mask", ",", "int32_t", "new_axis_mask", ",", "int32_t", "shrink_axis_mask", ")", "{", "auto", "input_type", "=", "input_value", ".", "getType", "(", ")", ".", "dyn_cast", "<", "RankedTensorType", ">", "(", ")", ";", "ShapedType", "result_type", "=", "result_value", ".", "getType", "(", ")", ".", "cast", "<", "ShapedType", ">", "(", ")", ";", "if", "(", "ellipsis_mask", "!=", "0", ")", "{", "(", "void", ")", "rewriter", ".", "notifyMatchFailure", "(", "op", ",", "\"", "\"", ")", ";", "return", "std", "::", "nullopt", ";", "}", "if", "(", "!", "input_type", ")", "{", "(", "void", ")", "rewriter", ".", "notifyMatchFailure", "(", "op", ",", "\"", "\"", ")", ";", "return", "std", "::", "nullopt", ";", "}", "int32_t", "input_rank", "=", "input_type", ".", "getRank", "(", ")", ";", "Type", "element_type", "=", "input_type", ".", "getElementType", "(", ")", ";", "SmallVector", "<", "int32_t", ">", "begin", ",", "end", ",", "strides", ";", "if", "(", "failed", "(", "getVectorFromValue32", "(", "strides_value", ",", "strides", ")", ")", ")", "{", "(", "void", ")", "rewriter", ".", "notifyMatchFailure", "(", "op", ",", "\"", "\"", ")", ";", "return", "std", "::", "nullopt", ";", "}", "for", "(", "auto", "stride", ":", "strides", ")", "if", "(", "stride", "<", "-1", ")", "return", "std", "::", "nullopt", ";", "bool", "all_strides_one", "=", "true", ";", "int32_t", "strides_size", "=", "strides", ".", "size", "(", ")", ";", "for", "(", "auto", "stride", ":", "strides", ")", "all_strides_one", "&=", "abs", "(", "stride", ")", "==", "1", ";", "const", "int32_t", "all_masks_one", "=", "(", "1", "<<", "strides_size", ")", "-", "1", ";", "if", "(", "failed", "(", "getVectorFromValue32", "(", "begin_value", ",", "begin", ")", ")", "&&", "begin_mask", "!=", "all_masks_one", ")", "{", "(", "void", ")", "rewriter", ".", "notifyMatchFailure", "(", "op", ",", "\"", "\"", ")", ";", "return", "std", "::", "nullopt", ";", "}", "if", "(", "end_mask", "!=", "all_masks_one", "&&", "failed", "(", "getVectorFromValue32", "(", "end_value", ",", "end", ")", ")", ")", "{", "(", "void", ")", "rewriter", ".", "notifyMatchFailure", "(", "op", ",", "\"", "\"", ")", ";", "return", "std", "::", "nullopt", ";", "}", "if", "(", "llvm", "::", "any_of", "(", "strides", ",", "[", "]", "(", "auto", "i", ")", "{", "return", "i", "<", "-1", ";", "}", ")", ")", "{", "(", "void", ")", "rewriter", ".", "notifyMatchFailure", "(", "op", ",", "\"", "\"", ")", ";", "return", "std", "::", "nullopt", ";", "}", "for", "(", "const", "auto", "&", "val", ":", "llvm", "::", "enumerate", "(", "begin", ")", ")", "begin_mask", "|=", "(", "val", ".", "value", "(", ")", "==", "0", ")", "<<", "val", ".", "index", "(", ")", ";", "if", "(", "all_strides_one", "&&", "begin_mask", "==", "all_masks_one", "&&", "end_mask", "==", "all_masks_one", ")", "{", "return", "reverseNegativeStride", "(", "rewriter", ",", "op", ",", "input_value", ",", "strides", ")", ";", "}", "int32_t", "new_mask_bits", "=", "(", "1", "<<", "input_rank", ")", "-", "all_masks_one", "-", "1", ";", "begin_mask", "|=", "new_mask_bits", ";", "end_mask", "|=", "new_mask_bits", ";", "for", "(", "auto", "&", "b", ":", "begin", ")", "if", "(", "b", "<", "0", ")", "b", "=", "b", "-", "1", ";", "for", "(", "auto", "&", "e", ":", "end", ")", "if", "(", "e", "<", "0", ")", "e", "=", "e", "-", "1", ";", "strides", ".", "resize", "(", "input_rank", ",", "1", ")", ";", "begin", ".", "resize", "(", "input_rank", ",", "0", ")", ";", "end", ".", "resize", "(", "input_rank", ",", "-1", ")", ";", "for", "(", "int", "i", "=", "0", ";", "i", "<", "input_rank", ";", "++", "i", ")", "{", "if", "(", "begin_mask", "&", "(", "1", "<<", "i", ")", ")", "begin", "[", "i", "]", "=", "0", ";", "if", "(", "end_mask", "&", "(", "1", "<<", "i", ")", ")", "end", "[", "i", "]", "=", "-1", ";", "}", "for", "(", "int", "i", "=", "0", ";", "i", "<", "input_rank", ";", "++", "i", ")", "{", "if", "(", "input_type", ".", "isDynamicDim", "(", "i", ")", ")", "continue", ";", "if", "(", "begin", "[", "i", "]", "<", "0", ")", "begin", "[", "i", "]", "+=", "input_type", ".", "getDimSize", "(", "i", ")", "+", "1", ";", "if", "(", "end", "[", "i", "]", "<", "0", ")", "end", "[", "i", "]", "+=", "input_type", ".", "getDimSize", "(", "i", ")", "+", "1", ";", "}", "for", "(", "int", "i", "=", "0", ";", "i", "<", "input_rank", ";", "++", "i", ")", "{", "if", "(", "begin", "[", "i", "]", "<", "0", "&&", "input_type", ".", "isDynamicDim", "(", "i", ")", ")", "{", "(", "void", ")", "rewriter", ".", "notifyMatchFailure", "(", "op", ",", "\"", "\"", ")", ";", "return", "std", "::", "nullopt", ";", "}", "if", "(", "end", "[", "i", "]", "<", "-1", "&&", "input_type", ".", "isDynamicDim", "(", "i", ")", ")", "{", "(", "void", ")", "rewriter", ".", "notifyMatchFailure", "(", "op", ",", "\"", "\"", ")", ";", "return", "std", "::", "nullopt", ";", "}", "}", "SmallVector", "<", "int64_t", ">", "a1_begin", "(", "input_rank", ")", ",", "a1_size", "(", "input_rank", ")", ";", "for", "(", "int", "i", "=", "0", ";", "i", "<", "input_rank", ";", "++", "i", ")", "{", "a1_begin", "[", "i", "]", "=", "begin", "[", "i", "]", ";", "if", "(", "end", "[", "i", "]", "==", "-1", "&&", "input_type", ".", "isDynamicDim", "(", "i", ")", ")", "{", "a1_size", "[", "i", "]", "=", "-1", ";", "}", "else", "if", "(", "end", "[", "i", "]", "<", "0", "&&", "input_type", ".", "isDynamicDim", "(", "i", ")", ")", "{", "(", "void", ")", "rewriter", ".", "notifyMatchFailure", "(", "op", ",", "\"", "\"", ")", ";", "return", "std", "::", "nullopt", ";", "}", "else", "{", "a1_size", "[", "i", "]", "=", "end", "[", "i", "]", "-", "a1_begin", "[", "i", "]", ";", "}", "if", "(", "shrink_axis_mask", "&", "(", "1", "<<", "i", ")", ")", "{", "a1_size", "[", "i", "]", "=", "1", ";", "strides", "[", "i", "]", "=", "1", ";", "}", "}", "auto", "a1_slice_op", "=", "CreateOpAndInfer", "<", "tosa", "::", "SliceOp", ">", "(", "rewriter", ",", "op", "->", "getLoc", "(", ")", ",", "tensorflow", "::", "GetTypeFromTFTensorShape", "(", "a1_size", ",", "element_type", ")", ",", "input_value", ",", "rewriter", ".", "getDenseI64ArrayAttr", "(", "a1_begin", ")", ",", "rewriter", ".", "getDenseI64ArrayAttr", "(", "tensorflow", "::", "ConvertMlirShapeToTF", "(", "a1_size", ")", ")", ")", ";", "if", "(", "all_strides_one", ")", "{", "auto", "reversed", "=", "reverseNegativeStride", "(", "rewriter", ",", "op", ",", "a1_slice_op", ".", "getResult", "(", ")", ",", "strides", ")", ";", "auto", "shape", "=", "reversed", ".", "getType", "(", ")", ".", "cast", "<", "RankedTensorType", ">", "(", ")", ".", "getShape", "(", ")", ";", "SmallVector", "<", "int64_t", ">", "new_shape", ";", "for", "(", "int", "i", "=", "0", ";", "i", "<", "input_rank", ";", "++", "i", ")", "{", "if", "(", "!", "(", "shrink_axis_mask", "&", "(", "1", "<<", "i", ")", ")", ")", "{", "if", "(", "new_axis_mask", "&", "(", "1", "<<", "i", ")", ")", "new_shape", ".", "push_back", "(", "1", ")", ";", "new_shape", ".", "push_back", "(", "(", "shape", "[", "i", "]", ")", ")", ";", "}", "}", "return", "CreateOpAndInfer", "<", "tosa", "::", "ReshapeOp", ">", "(", "rewriter", ",", "op", "->", "getLoc", "(", ")", ",", "result_type", ",", "reversed", ",", "rewriter", ".", "getDenseI64ArrayAttr", "(", "tensorflow", "::", "ConvertMlirShapeToTF", "(", "new_shape", ")", ")", ")", ".", "getResult", "(", ")", ";", "}", "SmallVector", "<", "int64_t", ">", "a2_shape", ";", "for", "(", "int", "i", "=", "0", ";", "i", "<", "input_rank", ";", "++", "i", ")", "{", "int64_t", "abs_stride_i", "=", "abs", "(", "strides", "[", "i", "]", ")", ";", "a2_shape", ".", "push_back", "(", "a1_size", "[", "i", "]", "==", "-1", "?", "-1", ":", "a1_size", "[", "i", "]", "/", "abs_stride_i", ")", ";", "if", "(", "abs_stride_i", "!=", "1", ")", "{", "a2_shape", ".", "push_back", "(", "abs_stride_i", ")", ";", "}", "}", "auto", "a2_reshape_op", "=", "CreateOpAndInfer", "<", "tosa", "::", "ReshapeOp", ">", "(", "rewriter", ",", "op", "->", "getLoc", "(", ")", ",", "tensorflow", "::", "GetTypeFromTFTensorShape", "(", "a2_shape", ",", "element_type", ")", ",", "a1_slice_op", ".", "getResult", "(", ")", ",", "rewriter", ".", "getDenseI64ArrayAttr", "(", "tensorflow", "::", "ConvertMlirShapeToTF", "(", "a2_shape", ")", ")", ")", ";", "SmallVector", "<", "int64_t", ">", "a3_begin", ",", "a3_size", ";", "for", "(", "int", "i", "=", "0", ";", "i", "<", "input_rank", ";", "++", "i", ")", "{", "int64_t", "abs_stride_i", "=", "abs", "(", "strides", "[", "i", "]", ")", ";", "a3_begin", ".", "push_back", "(", "0", ")", ";", "if", "(", "shrink_axis_mask", "&", "(", "1", "<<", "i", ")", ")", "{", "a3_size", ".", "push_back", "(", "1", ")", ";", "}", "else", "{", "a3_size", ".", "push_back", "(", "(", "a1_size", "[", "i", "]", "==", "-1", ")", "?", "-1", ":", "(", "a1_size", "[", "i", "]", "/", "abs_stride_i", ")", ")", ";", "}", "if", "(", "abs_stride_i", "!=", "1", ")", "{", "a3_begin", ".", "push_back", "(", "0", ")", ";", "a3_size", ".", "push_back", "(", "1", ")", ";", "}", "}", "assert", "(", "a2_shape", ".", "size", "(", ")", "==", "a3_begin", ".", "size", "(", ")", ")", ";", "assert", "(", "a2_shape", ".", "size", "(", ")", "==", "a3_size", ".", "size", "(", ")", ")", ";", "auto", "a3_slice_op", "=", "CreateOpAndInfer", "<", "tosa", "::", "SliceOp", ">", "(", "rewriter", ",", "op", "->", "getLoc", "(", ")", ",", "tensorflow", "::", "GetTypeFromTFTensorShape", "(", "a3_size", ",", "element_type", ")", ",", "a2_reshape_op", ".", "getResult", "(", ")", ",", "rewriter", ".", "getDenseI64ArrayAttr", "(", "a3_begin", ")", ",", "rewriter", ".", "getDenseI64ArrayAttr", "(", "tensorflow", "::", "ConvertMlirShapeToTF", "(", "a3_size", ")", ")", ")", ";", "SmallVector", "<", "int64_t", ">", "a4_shape", ";", "for", "(", "int", "i", "=", "0", ";", "i", "<", "input_rank", ";", "++", "i", ")", "{", "if", "(", "!", "(", "shrink_axis_mask", "&", "(", "1", "<<", "i", ")", ")", ")", "{", "if", "(", "new_axis_mask", "&", "(", "1", "<<", "i", ")", ")", "a4_shape", ".", "push_back", "(", "1", ")", ";", "a4_shape", ".", "push_back", "(", "(", "(", "a1_size", "[", "i", "]", "==", "-1", ")", "?", "-1", ":", "(", "a1_size", "[", "i", "]", "/", "abs", "(", "strides", "[", "i", "]", ")", ")", ")", ")", ";", "}", "}", "auto", "a4_reshape_op", "=", "CreateOpAndInfer", "<", "tosa", "::", "ReshapeOp", ">", "(", "rewriter", ",", "op", "->", "getLoc", "(", ")", ",", "result_type", ",", "a3_slice_op", ".", "getResult", "(", ")", ",", "rewriter", ".", "getDenseI64ArrayAttr", "(", "tensorflow", "::", "ConvertMlirShapeToTF", "(", "a4_shape", ")", ")", ")", ".", "getResult", "(", ")", ";", "return", "reverseNegativeStride", "(", "rewriter", ",", "op", ",", "a4_reshape_op", ",", "strides", ")", ";", "}"], "to_mask": {}, "attention_idx_tokens": [null, null], "patch": "@@ -2448,10 +2446,14 @@\n   }\n \n   // Step 2: reshape the sliced array\n-  SmallVector<int64_t> a2_shape(input_rank * 2);\n+  SmallVector<int64_t> a2_shape;\n   for (int i = 0; i < input_rank; ++i) {\n-    a2_shape[i * 2 + 0] = a1_size[i] == -1 ? -1 : a1_size[i] / abs(strides[i]);\n-    a2_shape[i * 2 + 1] = abs(strides[i]);\n+    int64_t abs_stride_i = abs(strides[i]);\n+    a2_shape.push_back(a1_size[i] == -1 ? -1 : a1_size[i] / abs_stride_i);\n+    if (abs_stride_i != 1) {\n+      // only add a stride dimension if strides[i] != 1", "ext_attention_idx_tokens": [1064, 1132], "uid": "4f62759e", "question": "This is 1 and -1 right, why are both allowed here?", "code": "std optional<Value> convertStridedSliceOp PatternRewriter& rewriter Operation* op Value result value Value input value Value begin value Value end value Value strides value int32 t begin mask int32 t end mask int32 t ellipsis mask int32 t new axis mask int32 t shrink axis mask { The mask arguments are bitmasks where bit [i] applies to dimension [i] of the input tensor The rough algorithm for lowering strided slice is as follows 0 Process begin end masks since they are basically syntactic sugar on top of the begin value end value arrays 1 Slice1 Ignoring stride slice the interesting range from the input tensor 2 Reshape2 Reshape the tensor from 1 such that each dimension with abs stride ! 1 is split into two dimensions of size i stride i stride i 3 Slice3 Slice the tensor from 2 such that we select index [0] from each of the stride i dimensions in 2 4 Reshape4 Reshape the tensor to eliminate the stride i dimensions add any dimensions in new axis mask and remove any dimensions in the shrink axis mask Limitations * This implementation only supports ellipsis mask 0 for now auto input type input value getType dyn cast<RankedTensorType> ; ShapedType result type result value getType cast<ShapedType> ; if ellipsis mask ! 0 { void rewriter notifyMatchFailure op \"ellipses mask not supported yet\" ; return std nullopt; } if !input type { void rewriter notifyMatchFailure op \"input type has unknown rank\" ; return std nullopt; } int32 t input rank input type getRank ; Type element type input type getElementType ; Conditionally extract begin end values if requied SmallVector<int32 t> begin end strides; if failed getVectorFromValue32 strides value strides { void rewriter notifyMatchFailure op \"strides isn t a constant\" ; return std nullopt; } Current configuration does not support negative strides greater than 1 Bail out for now fix if this proves to be legal for auto stride strides if stride < -1 return std nullopt; bool all strides one true; int32 t strides size strides size ; for auto stride strides all strides one & abs stride 1; If all of the masks are set we can just bypass the entire thing const int32 t all masks one 1 << strides size - 1; if failed getVectorFromValue32 begin value begin && begin mask ! all masks one { void rewriter notifyMatchFailure op \"begin isn t a constant\" ; return std nullopt; } if end mask ! all masks one && failed getVectorFromValue32 end value end { void rewriter notifyMatchFailure op \"end isn t a constant\" ; return std nullopt; } if llvm any of strides [] auto i { return i < -1; } { void rewriter notifyMatchFailure op \"stride < -1 unsupported\" ; return std nullopt; } Set begin mask values if possible for const auto& val llvm enumerate begin begin mask | val value 0 << val index ; If all begin end masks are set and striding is one we can just return the matrix with reversed dims for negative strides if all strides one && begin mask all masks one && end mask all masks one { return reverseNegativeStride rewriter op input value strides ; } Set the bits true for the remaining dimensions int32 t new mask bits 1 << input rank - all masks one - 1; begin mask | new mask bits; end mask | new mask bits; Negative values are exclusive from the opposite end while TOSA is inclusive we offset to adjust for this for auto& b begin if b < 0 b b - 1; for auto& e end if e < 0 e e - 1; Fill the remaining stride and begin end with default values strides resize input rank 1 ; begin resize input rank 0 ; end resize input rank -1 ; Set masking-bit overrides for int i 0; i < input rank; ++i { if begin mask & 1 << i begin[i] 0; if end mask & 1 << i end[i] -1; } If we know the static end we can adjust by it for int i 0; i < input rank; ++i { if input type isDynamicDim i continue; if begin[i] < 0 begin[i] + input type getDimSize i + 1; if end[i] < 0 end[i] + input type getDimSize i + 1; } Perform some final validation on the begin end values for int i 0; i < input rank; ++i { if begin[i] < 0 && input type isDynamicDim i { void rewriter notifyMatchFailure op \"begin offset is negative on dynamic size\" ; return std nullopt; } if end[i] < -1 && input type isDynamicDim i { void rewriter notifyMatchFailure op \"end is exclusive of final entry on dynamic size\" ; return std nullopt; } } Step 0 Process the begin end masks and build the begin sizes for the first slice SmallVector<int64 t> a1 begin input rank a1 size input rank ; for int i 0; i < input rank; ++i { Wrap around index if begin and end is negative a1 begin[i] begin[i]; if end[i] -1 && input type isDynamicDim i { Slice using -1 as TOSA s sentinal value a1 size[i] -1; } else if end[i] < 0 && input type isDynamicDim i { Other dynamic cases cannot be handled void rewriter notifyMatchFailure op \"input dim is dynamic and slice end depends on the length\" ; return std nullopt; } else { a1 size[i] end[i] - a1 begin[i]; } Shrink axis mask means we know the size and stride are 1 if shrink axis mask & 1 << i { a1 size[i] 1; strides[i] 1; } } Step 1 Slice the input array auto a1 slice op CreateOpAndInfer<tosa SliceOp> rewriter op->getLoc tensorflow GetTypeFromTFTensorShape a1 size element type input value rewriter getDenseI64ArrayAttr a1 begin rewriter getDenseI64ArrayAttr tensorflow ConvertMlirShapeToTF a1 size ; If unary striding is used we can reverse reshape and return the result if all strides one { auto reversed reverseNegativeStride rewriter op a1 slice op getResult strides ; auto shape reversed getType cast<RankedTensorType> getShape ; SmallVector<int64 t> new shape; for int i 0; i < input rank; ++i { if ! shrink axis mask & 1 << i { if new axis mask & 1 << i new shape push back 1 ; new shape push back shape[i] ; } } return CreateOpAndInfer<tosa ReshapeOp> rewriter op->getLoc result type reversed rewriter getDenseI64ArrayAttr tensorflow ConvertMlirShapeToTF new shape getResult ; } Step 2 reshape the sliced array SmallVector<int64 t> a2 shape; for int i 0; i < input rank; ++i { int64 t abs stride i abs strides[i] ; a2 shape push back a1 size[i] -1 ? -1 a1 size[i] abs stride i ; if abs stride i ! 1 { only add a stride dimension if strides[i] ! 1 a2 shape push back abs stride i ; } } auto a2 reshape op CreateOpAndInfer<tosa ReshapeOp> rewriter op->getLoc tensorflow GetTypeFromTFTensorShape a2 shape element type a1 slice op getResult rewriter getDenseI64ArrayAttr tensorflow ConvertMlirShapeToTF a2 shape ; Step 3 take a slice along the strides SmallVector<int64 t> a3 begin a3 size; for int i 0; i < input rank; ++i { int64 t abs stride i abs strides[i] ; a3 begin push back 0 ; if shrink axis mask & 1 << i { a3 size push back 1 ; } else { a3 size push back a1 size[i] -1 ? -1 a1 size[i] abs stride i ; } if abs stride i ! 1 { previous reshape only adds a stride dimension if strides[i] ! 1 a3 begin push back 0 ; a3 size push back 1 ; } } assert a2 shape size a3 begin size ; assert a2 shape size a3 size size ; auto a3 slice op CreateOpAndInfer<tosa SliceOp> rewriter op->getLoc tensorflow GetTypeFromTFTensorShape a3 size element type a2 reshape op getResult rewriter getDenseI64ArrayAttr a3 begin rewriter getDenseI64ArrayAttr tensorflow ConvertMlirShapeToTF a3 size ; Step 4 reshape the now-strided tensor SmallVector<int64 t> a4 shape; for int i 0; i < input rank; ++i { if ! shrink axis mask & 1 << i { if new axis mask & 1 << i a4 shape push back 1 ; a4 shape push back a1 size[i] -1 ? -1 a1 size[i] abs strides[i] ; } } auto a4 reshape op CreateOpAndInfer<tosa ReshapeOp> rewriter op->getLoc result type a3 slice op getResult rewriter getDenseI64ArrayAttr tensorflow ConvertMlirShapeToTF a4 shape getResult ; return reverseNegativeStride rewriter op a4 reshape op strides ; }"}
{"message": "What clang error did we get without the extra pair of parentheses? Could you please post the error message? Thank you!", "timestamp": "2023-07-18T17:23:24Z", "file_name": "tensorflow/core/kernels/mkl/mkl_concat_op.cc", "range": {"start_line": 367, "end_line": 367, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1267095727", "html_url": "https://github.com/tensorflow/tensorflow/pull/60375#discussion_r1267095727", "attention_area": "      dnnl::memory::desc source_md((memory::desc(GET_MEMORY_DESC(srcs_md[i]))));", "file_path": "files/43/06/00000643.cc", "old_file_path": "files/44/06/00000644.cc", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -364,7 +364,7 @@ class MklConcatFwdPrimitive : public MklPrimitive {\n              const std::vector<memory::desc>& srcs_md) {\n     // Create memory descriptors for concat with specified srcs format\n     for (size_t i = 0; i < concat_fwd_dims.num_inputs; i++) {\n-      dnnl::memory::desc source_md(memory::desc(GET_MEMORY_DESC(srcs_md[i])));\n+      dnnl::memory::desc source_md((memory::desc(GET_MEMORY_DESC(srcs_md[i]))));", "source": "void Setup(const MklConcatFwdParams& concat_fwd_dims,\n             const std::vector<memory::desc>& srcs_md) {\n    // Create memory descriptors for concat with specified srcs format\n    for (size_t i = 0; i < concat_fwd_dims.num_inputs; i++) {\n      dnnl::memory::desc source_md((memory::desc(GET_MEMORY_DESC(srcs_md[i]))));\n      context_.src_md.push_back(source_md);\n      std::shared_ptr<dnnl::memory> src_mem(\n          new dnnl::memory(source_md, cpu_engine_, DummyData));\n      context_.data_mem_shdptr.push_back(src_mem);\n      context_.data_mem.push_back(*context_.data_mem_shdptr[i]);\n    }\n    // Store the expected memory format\n    context_.dst_md.reset(new memory::desc({concat_fwd_dims.dst_dims},\n                                           MklDnnType<T>(),\n                                           concat_fwd_dims.mkl_common_format));\n    // Create a concat primitive descriptor\n    context_.fwd_pd.reset(\n        new CONCAT_PRIM_DESC(cpu_engine_, concat_fwd_dims.concat_dims,\n                             context_.src_md, context_.dst_md));\n\n    // Create memory primitive based on dummy data\n    context_.dst_mem.reset(\n        new memory(*context_.dst_md, cpu_engine_, DummyData));\n\n    context_.concat_fwd.reset(new concat(*context_.fwd_pd));\n    std::unordered_map<int, memory> net_args = {\n        {DNNL_ARG_DST, *context_.dst_mem}};\n    for (int i = 0; i < concat_fwd_dims.num_inputs; ++i) {\n      net_args.insert({DNNL_ARG_MULTIPLE_SRC + i, context_.data_mem[i]});\n    }\n\n    context_.fwd_primitives_args.push_back(net_args);\n    context_.fwd_primitives.push_back(*context_.concat_fwd);\n  }", "source_start_line": 363, "tokens": ["void", "Setup", "(", "const", "MklConcatFwdParams", "&", "concat_fwd_dims", ",", "const", "std", "::", "vector", "<", "memory", "::", "desc", ">", "&", "srcs_md", ")", "{", "for", "(", "size_t", "i", "=", "0", ";", "i", "<", "concat_fwd_dims", ".", "num_inputs", ";", "i", "++", ")", "{", "dnnl", "::", "memory", "::", "desc", "source_md", "(", "(", "memory", "::", "desc", "(", "GET_MEMORY_DESC", "(", "srcs_md", "[", "i", "]", ")", ")", ")", ")", ";", "context_", ".", "src_md", ".", "push_back", "(", "source_md", ")", ";", "std", "::", "shared_ptr", "<", "dnnl", "::", "memory", ">", "src_mem", "(", "new", "dnnl", "::", "memory", "(", "source_md", ",", "cpu_engine_", ",", "DummyData", ")", ")", ";", "context_", ".", "data_mem_shdptr", ".", "push_back", "(", "src_mem", ")", ";", "context_", ".", "data_mem", ".", "push_back", "(", "*", "context_", ".", "data_mem_shdptr", "[", "i", "]", ")", ";", "}", "context_", ".", "dst_md", ".", "reset", "(", "new", "memory", "::", "desc", "(", "{", "concat_fwd_dims", ".", "dst_dims", "}", ",", "MklDnnType", "<", "T", ">", "(", ")", ",", "concat_fwd_dims", ".", "mkl_common_format", ")", ")", ";", "context_", ".", "fwd_pd", ".", "reset", "(", "new", "CONCAT_PRIM_DESC", "(", "cpu_engine_", ",", "concat_fwd_dims", ".", "concat_dims", ",", "context_", ".", "src_md", ",", "context_", ".", "dst_md", ")", ")", ";", "context_", ".", "dst_mem", ".", "reset", "(", "new", "memory", "(", "*", "context_", ".", "dst_md", ",", "cpu_engine_", ",", "DummyData", ")", ")", ";", "context_", ".", "concat_fwd", ".", "reset", "(", "new", "concat", "(", "*", "context_", ".", "fwd_pd", ")", ")", ";", "std", "::", "unordered_map", "<", "int", ",", "memory", ">", "net_args", "=", "{", "{", "DNNL_ARG_DST", ",", "*", "context_", ".", "dst_mem", "}", "}", ";", "for", "(", "int", "i", "=", "0", ";", "i", "<", "concat_fwd_dims", ".", "num_inputs", ";", "++", "i", ")", "{", "net_args", ".", "insert", "(", "{", "DNNL_ARG_MULTIPLE_SRC", "+", "i", ",", "context_", ".", "data_mem", "[", "i", "]", "}", ")", ";", "}", "context_", ".", "fwd_primitives_args", ".", "push_back", "(", "net_args", ")", ";", "context_", ".", "fwd_primitives", ".", "push_back", "(", "*", "context_", ".", "concat_fwd", ")", ";", "}"], "to_mask": {"VAR": ["concat_fwd_dims", "i", "net_args", "source_md", "src_mem", "srcs_md"], "METHOD": ["GET_MEMORY_DESC", "MklDnnType", "desc", "insert", "push_back", "reset"]}, "attention_idx_tokens": [38, 60], "patch": "@@ -364,7 +364,7 @@\n              const std::vector<memory::desc>& srcs_md) {\n     // Create memory descriptors for concat with specified srcs format\n     for (size_t i = 0; i < concat_fwd_dims.num_inputs; i++) {\n-      dnnl::memory::desc source_md(memory::desc(GET_MEMORY_DESC(srcs_md[i])));\n+      dnnl::memory::desc source_md((memory::desc(GET_MEMORY_DESC(srcs_md[i]))));", "ext_attention_idx_tokens": [38, 69], "uid": "74ee91ad", "question": "What clang error did we get without the extra pair of parentheses? Could you please post the error message? Thank you!", "code": "void Setup const MklConcatFwdParams& concat fwd dims const std vector<memory desc>& srcs md { Create memory descriptors for concat with specified srcs format for size t i 0; i < concat fwd dims num inputs; i++ { dnnl memory desc source md memory desc GET MEMORY DESC srcs md[i] ; context src md push back source md ; std shared ptr<dnnl memory> src mem new dnnl memory source md cpu engine DummyData ; context data mem shdptr push back src mem ; context data mem push back *context data mem shdptr[i] ; } Store the expected memory format context dst md reset new memory desc {concat fwd dims dst dims} MklDnnType<T> concat fwd dims mkl common format ; Create a concat primitive descriptor context fwd pd reset new CONCAT PRIM DESC cpu engine concat fwd dims concat dims context src md context dst md ; Create memory primitive based on dummy data context dst mem reset new memory *context dst md cpu engine DummyData ; context concat fwd reset new concat *context fwd pd ; std unordered map<int memory> net args { {DNNL ARG DST *context dst mem}}; for int i 0; i < concat fwd dims num inputs; ++i { net args insert {DNNL ARG MULTIPLE SRC + i context data mem[i]} ; } context fwd primitives args push back net args ; context fwd primitives push back *context concat fwd ; }"}
{"message": "Is this always going to work?  This seems like it would be very platform-dependent.", "timestamp": "2023-07-20T17:02:37Z", "file_name": "tensorflow/tsl/platform/cpu_info.cc", "range": {"start_line": 380, "end_line": 380, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1269737470", "html_url": "https://github.com/tensorflow/tensorflow/pull/60026#discussion_r1269737470", "attention_area": "    CPUspresent.open(\"/sys/devices/system/cpu/present\", std::ios::in);", "file_path": "files/73/06/00000673.cc", "old_file_path": "files/74/06/00000674.cc", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -345,6 +352,89 @@ void InitCPUIDInfo() {\n \n #endif  // PLATFORM_IS_X86\n \n+#ifdef PLATFORM_IS_ARM64\n+\n+class CPUIDInfo;\n+void InitCPUIDInfo();\n+\n+CPUIDInfo* cpuid = nullptr;\n+\n+// Structure for basic CPUID info.\n+class CPUIDInfo {\n+ public:\n+  CPUIDInfo() : implementer_(0), variant_(0), cpunum_(0) {}\n+\n+  static void Initialize() {\n+    // Initialize cpuid struct.\n+    if (cpuid != nullptr) {\n+      return;\n+    }\n+\n+    cpuid = new CPUIDInfo;\n+\n+    if (!(getauxval(AT_HWCAP) & HWCAP_CPUID)) {\n+      return;\n+    }\n+\n+    std::ifstream CPUspresent;\n+    CPUspresent.open(\"/sys/devices/system/cpu/present\", std::ios::in);", "source": "static void Initialize() {\n    // Initialize cpuid struct.\n    if (cpuid != nullptr) {\n      return;\n    }\n\n    cpuid = new CPUIDInfo;\n\n    if (!(getauxval(AT_HWCAP) & HWCAP_CPUID)) {\n      return;\n    }\n\n    std::ifstream CPUspresent;\n    CPUspresent.open(\"/sys/devices/system/cpu/present\", std::ios::in);\n    int present_cpu = -1;\n    if (CPUspresent.is_open()) {\n      std::string line;\n      if (bool(getline(CPUspresent, line))) {\n        // We just need to find one CPU that is active\n        // from which we can read MIDR register to find\n        // implement, variant and revision information.\n        auto ending = line.end();\n        for (auto i = line.begin(); i < line.end(); ++i) {\n          if (*i == '-' || *i == ',') {\n            ending = i;\n            break;\n          }\n        }\n        line.erase(ending, line.end());\n        // That should be the fist number.\n        present_cpu = std::stoi(line);\n      }\n    }\n\n    if (present_cpu == -1) {\n      return;\n    }\n\n    std::stringstream str;\n    str << \"/sys/devices/system/cpu/cpu\" << present_cpu\n        << \"/regs/identification/midr_el1\";\n    std::ifstream midr_el1_file(str.str(), std::ios::in);\n    if (midr_el1_file.is_open()) {\n      std::string line;\n      if (bool(getline(midr_el1_file, line))) {\n        uint32 midr_el1 = std::stoul(line, nullptr, 16);\n\n        // Unpack variant and CPU ID.\n        cpuid->implementer_ = (midr_el1 >> 24) & 0xFF;\n        cpuid->variant_ = (midr_el1 >> 20) & 0xF;\n        cpuid->cpunum_ = (midr_el1 >> 4) & 0xFFF;\n      }\n    }\n  }", "source_start_line": 367, "tokens": ["static", "void", "Initialize", "(", ")", "{", "if", "(", "cpuid", "!=", "nullptr", ")", "{", "return", ";", "}", "cpuid", "=", "new", "CPUIDInfo", ";", "if", "(", "!", "(", "getauxval", "(", "AT_HWCAP", ")", "&", "HWCAP_CPUID", ")", ")", "{", "return", ";", "}", "std", "::", "ifstream", "CPUspresent", ";", "CPUspresent", ".", "open", "(", "\"", "\"", ",", "std", "::", "ios", "::", "in", ")", ";", "int", "present_cpu", "=", "-1", ";", "if", "(", "CPUspresent", ".", "is_open", "(", ")", ")", "{", "std", "::", "string", "line", ";", "if", "(", "bool", "(", "getline", "(", "CPUspresent", ",", "line", ")", ")", ")", "{", "auto", "ending", "=", "line", ".", "end", "(", ")", ";", "for", "(", "auto", "i", "=", "line", ".", "begin", "(", ")", ";", "i", "<", "line", ".", "end", "(", ")", ";", "++", "i", ")", "{", "if", "(", "*", "i", "==", "'", "'", "||", "*", "i", "==", "'", "'", ")", "{", "ending", "=", "i", ";", "break", ";", "}", "}", "line", ".", "erase", "(", "ending", ",", "line", ".", "end", "(", ")", ")", ";", "present_cpu", "=", "std", "::", "stoi", "(", "line", ")", ";", "}", "}", "if", "(", "present_cpu", "==", "-1", ")", "{", "return", ";", "}", "std", "::", "stringstream", "str", ";", "str", "<<", "\"", "\"", "<<", "present_cpu", "<<", "\"", "\"", ";", "std", "::", "ifstream", "midr_el1_file", "(", "str", ".", "str", "(", ")", ",", "std", "::", "ios", "::", "in", ")", ";", "if", "(", "midr_el1_file", ".", "is_open", "(", ")", ")", "{", "std", "::", "string", "line", ";", "if", "(", "bool", "(", "getline", "(", "midr_el1_file", ",", "line", ")", ")", ")", "{", "uint32", "midr_el1", "=", "std", "::", "stoul", "(", "line", ",", "nullptr", ",", "16", ")", ";", "cpuid", "->", "implementer_", "=", "(", "midr_el1", ">>", "24", ")", "&", "0xFF", ";", "cpuid", "->", "variant_", "=", "(", "midr_el1", ">>", "20", ")", "&", "0xF", ";", "cpuid", "->", "cpunum_", "=", "(", "midr_el1", ">>", "4", ")", "&", "0xFFF", ";", "}", "}", "}"], "to_mask": {"VAR": ["CPUspresent", "ending", "i", "line", "midr_el1", "midr_el1_file", "present_cpu", "str"], "METHOD": ["begin", "bool", "end", "erase", "getauxval", "getline", "is_open", "open", "stoi", "stoul", "str"]}, "attention_idx_tokens": [42, 55], "patch": "@@ -345,6 +352,89 @@\n \n #endif  // PLATFORM_IS_X86\n \n+#ifdef PLATFORM_IS_ARM64\n+\n+class CPUIDInfo;\n+void InitCPUIDInfo();\n+\n+CPUIDInfo* cpuid = nullptr;\n+\n+// Structure for basic CPUID info.\n+class CPUIDInfo {\n+ public:\n+  CPUIDInfo() : implementer_(0), variant_(0), cpunum_(0) {}\n+\n+  static void Initialize() {\n+    // Initialize cpuid struct.\n+    if (cpuid != nullptr) {\n+      return;\n+    }\n+\n+    cpuid = new CPUIDInfo;\n+\n+    if (!(getauxval(AT_HWCAP) & HWCAP_CPUID)) {\n+      return;\n+    }\n+\n+    std::ifstream CPUspresent;\n+    CPUspresent.open(\"/sys/devices/system/cpu/present\", std::ios::in);", "ext_attention_idx_tokens": [0, 289], "uid": "9d665ba1", "question": "Is this always going to work?  This seems like it would be very platform-dependent.", "code": "static void Initialize { Initialize cpuid struct if cpuid ! nullptr { return; } cpuid new CPUIDInfo; if ! getauxval AT HWCAP & HWCAP CPUID { return; } std ifstream CPUspresent; CPUspresent open \" sys devices system cpu present\" std ios in ; int present cpu -1; if CPUspresent is open { std string line; if bool getline CPUspresent line { We just need to find one CPU that is active from which we can read MIDR register to find implement variant and revision information auto ending line end ; for auto i line begin ; i < line end ; ++i { if *i - || *i { ending i; break; } } line erase ending line end ; That should be the fist number present cpu std stoi line ; } } if present cpu -1 { return; } std stringstream str; str << \" sys devices system cpu cpu\" << present cpu << \" regs identification midr el1\"; std ifstream midr el1 file str str std ios in ; if midr el1 file is open { std string line; if bool getline midr el1 file line { uint32 midr el1 std stoul line nullptr 16 ; Unpack variant and CPU ID cpuid->implementer midr el1 >> 24 & 0xFF; cpuid->variant midr el1 >> 20 & 0xF; cpuid->cpunum midr el1 >> 4 & 0xFFF; } } }"}
{"message": "Could you explain why this change is needed?", "timestamp": "2023-07-21T17:33:51Z", "file_name": "tensorflow/lite/delegates/gpu/common/testing/interpreter_utils.cc", "range": {"start_line": 53, "end_line": 53, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1270922313", "html_url": "https://github.com/tensorflow/tensorflow/pull/60749#discussion_r1270922313", "attention_area": "    if(interpreter->tensor(interpreter->inputs()[i])->type !=  kTfLiteFloat32){", "file_path": "files/88/06/00000688.cc", "old_file_path": "files/89/06/00000689.cc", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -50,12 +50,17 @@ absl::Status InterpreterInvokeWithOpResolver(\n     return absl::InternalError(\"Unable to allocate TfLite tensors\");\n   }\n   for (int i = 0; i < inputs.size(); ++i) {\n-    DCHECK_EQ(interpreter->tensor(interpreter->inputs()[i])->type,\n-              kTfLiteFloat32);\n+    if(interpreter->tensor(interpreter->inputs()[i])->type !=  kTfLiteFloat32){", "source": "absl::Status InterpreterInvokeWithOpResolver(\n    const ::tflite::Model* model, TfLiteDelegate* delegate,\n    const OpResolver& op_resolver, const std::vector<TensorFloat32>& inputs,\n    std::vector<TensorFloat32>* outputs) {\n  auto interpreter = std::make_unique<Interpreter>();\n  if (InterpreterBuilder(model, op_resolver)(&interpreter) != kTfLiteOk) {\n    return absl::InternalError(\"Unable to create TfLite InterpreterBuilder\");\n  }\n  if (delegate && interpreter->ModifyGraphWithDelegate(delegate) != kTfLiteOk) {\n    return absl::InternalError(\n        \"Unable to modify TfLite graph with the delegate\");\n  }\n  interpreter->SetNumThreads(1);\n  if (interpreter->AllocateTensors() != kTfLiteOk) {\n    return absl::InternalError(\"Unable to allocate TfLite tensors\");\n  }\n  for (int i = 0; i < inputs.size(); ++i) {\n    if(interpreter->tensor(interpreter->inputs()[i])->type !=  kTfLiteFloat32){\n      return absl::InternalError(\n        \"input data_type is not float32\");\n    }\n    float* tflite_data =\n        interpreter->typed_tensor<float>(interpreter->inputs()[i]);\n    if(inputs[i].data.size() * sizeof(float) == \n        interpreter->tensor(interpreter->inputs()[i])->bytes){\n      return absl::InternalError(\n        \"input data size doesn't match for this input\");\n    }\n    std::memcpy(tflite_data, inputs[i].data.data(),\n                inputs[i].data.size() * sizeof(float));\n  }\n  if (interpreter->Invoke() != kTfLiteOk) {\n    return absl::InternalError(\"Unable to invoke TfLite interpreter\");\n  }\n  if (!outputs || !outputs->empty()) {\n    return absl::InternalError(\"Invalid outputs pointer\");\n  }\n  outputs->reserve(interpreter->outputs().size());\n  for (auto t : interpreter->outputs()) {\n    const TfLiteTensor* out_tensor = interpreter->tensor(t);\n    TensorFloat32 bhwc;\n    bhwc.id = t;\n    // TODO(impjdi) Relax this condition to arbitrary batch size.\n    if (out_tensor->dims->data[0] != 1) {\n      return absl::InternalError(\"Batch dimension is expected to be 1\");\n    }\n    bhwc.shape.b = out_tensor->dims->data[0];\n    switch (out_tensor->dims->size) {\n      case 2:\n        bhwc.shape.h = 1;\n        bhwc.shape.w = 1;\n        bhwc.shape.c = out_tensor->dims->data[1];\n        break;\n      case 3:\n        bhwc.shape.h = 1;\n        bhwc.shape.w = out_tensor->dims->data[1];\n        bhwc.shape.c = out_tensor->dims->data[2];\n        break;\n      case 4:\n        bhwc.shape.h = out_tensor->dims->data[1];\n        bhwc.shape.w = out_tensor->dims->data[2];\n        bhwc.shape.c = out_tensor->dims->data[3];\n        break;\n      default:\n        return absl::InternalError(\"Unsupported dimensions size \" +\n                                   std::to_string(out_tensor->dims->size));\n    }\n    bhwc.data = std::vector<float>(\n        out_tensor->data.f,\n        out_tensor->data.f + out_tensor->bytes / sizeof(float));\n    outputs->push_back(bhwc);\n  }\n  return absl::OkStatus();\n}", "source_start_line": 36, "tokens": ["absl", "::", "Status", "InterpreterInvokeWithOpResolver", "(", "const", "::", "tflite", "::", "Model", "*", "model", ",", "TfLiteDelegate", "*", "delegate", ",", "const", "OpResolver", "&", "op_resolver", ",", "const", "std", "::", "vector", "<", "TensorFloat32", ">", "&", "inputs", ",", "std", "::", "vector", "<", "TensorFloat32", ">", "*", "outputs", ")", "{", "auto", "interpreter", "=", "std", "::", "make_unique", "<", "Interpreter", ">", "(", ")", ";", "if", "(", "InterpreterBuilder", "(", "model", ",", "op_resolver", ")", "(", "&", "interpreter", ")", "!=", "kTfLiteOk", ")", "{", "return", "absl", "::", "InternalError", "(", "\"", "\"", ")", ";", "}", "if", "(", "delegate", "&&", "interpreter", "->", "ModifyGraphWithDelegate", "(", "delegate", ")", "!=", "kTfLiteOk", ")", "{", "return", "absl", "::", "InternalError", "(", "\"", "\"", ")", ";", "}", "interpreter", "->", "SetNumThreads", "(", "1", ")", ";", "if", "(", "interpreter", "->", "AllocateTensors", "(", ")", "!=", "kTfLiteOk", ")", "{", "return", "absl", "::", "InternalError", "(", "\"", "\"", ")", ";", "}", "for", "(", "int", "i", "=", "0", ";", "i", "<", "inputs", ".", "size", "(", ")", ";", "++", "i", ")", "{", "if", "(", "interpreter", "->", "tensor", "(", "interpreter", "->", "inputs", "(", ")", "[", "i", "]", ")", "->", "type", "!=", "kTfLiteFloat32", ")", "{", "return", "absl", "::", "InternalError", "(", "\"", "\"", ")", ";", "}", "float", "*", "tflite_data", "=", "interpreter", "->", "typed_tensor", "<", "float", ">", "(", "interpreter", "->", "inputs", "(", ")", "[", "i", "]", ")", ";", "if", "(", "inputs", "[", "i", "]", ".", "data", ".", "size", "(", ")", "*", "sizeof", "(", "float", ")", "==", "interpreter", "->", "tensor", "(", "interpreter", "->", "inputs", "(", ")", "[", "i", "]", ")", "->", "bytes", ")", "{", "return", "absl", "::", "InternalError", "(", "\"", "\"", ")", ";", "}", "std", "::", "memcpy", "(", "tflite_data", ",", "inputs", "[", "i", "]", ".", "data", ".", "data", "(", ")", ",", "inputs", "[", "i", "]", ".", "data", ".", "size", "(", ")", "*", "sizeof", "(", "float", ")", ")", ";", "}", "if", "(", "interpreter", "->", "Invoke", "(", ")", "!=", "kTfLiteOk", ")", "{", "return", "absl", "::", "InternalError", "(", "\"", "\"", ")", ";", "}", "if", "(", "!", "outputs", "||", "!", "outputs", "->", "empty", "(", ")", ")", "{", "return", "absl", "::", "InternalError", "(", "\"", "\"", ")", ";", "}", "outputs", "->", "reserve", "(", "interpreter", "->", "outputs", "(", ")", ".", "size", "(", ")", ")", ";", "for", "(", "auto", "t", ":", "interpreter", "->", "outputs", "(", ")", ")", "{", "const", "TfLiteTensor", "*", "out_tensor", "=", "interpreter", "->", "tensor", "(", "t", ")", ";", "TensorFloat32", "bhwc", ";", "bhwc", ".", "id", "=", "t", ";", "if", "(", "out_tensor", "->", "dims", "->", "data", "[", "0", "]", "!=", "1", ")", "{", "return", "absl", "::", "InternalError", "(", "\"", "\"", ")", ";", "}", "bhwc", ".", "shape", ".", "b", "=", "out_tensor", "->", "dims", "->", "data", "[", "0", "]", ";", "switch", "(", "out_tensor", "->", "dims", "->", "size", ")", "{", "case", "2", ":", "bhwc", ".", "shape", ".", "h", "=", "1", ";", "bhwc", ".", "shape", ".", "w", "=", "1", ";", "bhwc", ".", "shape", ".", "c", "=", "out_tensor", "->", "dims", "->", "data", "[", "1", "]", ";", "break", ";", "case", "3", ":", "bhwc", ".", "shape", ".", "h", "=", "1", ";", "bhwc", ".", "shape", ".", "w", "=", "out_tensor", "->", "dims", "->", "data", "[", "1", "]", ";", "bhwc", ".", "shape", ".", "c", "=", "out_tensor", "->", "dims", "->", "data", "[", "2", "]", ";", "break", ";", "case", "4", ":", "bhwc", ".", "shape", ".", "h", "=", "out_tensor", "->", "dims", "->", "data", "[", "1", "]", ";", "bhwc", ".", "shape", ".", "w", "=", "out_tensor", "->", "dims", "->", "data", "[", "2", "]", ";", "bhwc", ".", "shape", ".", "c", "=", "out_tensor", "->", "dims", "->", "data", "[", "3", "]", ";", "break", ";", "default", ":", "return", "absl", "::", "InternalError", "(", "\"", "\"", "+", "std", "::", "to_string", "(", "out_tensor", "->", "dims", "->", "size", ")", ")", ";", "}", "bhwc", ".", "data", "=", "std", "::", "vector", "<", "float", ">", "(", "out_tensor", "->", "data", ".", "f", ",", "out_tensor", "->", "data", ".", "f", "+", "out_tensor", "->", "bytes", "/", "sizeof", "(", "float", ")", ")", ";", "outputs", "->", "push_back", "(", "bhwc", ")", ";", "}", "return", "absl", "::", "OkStatus", "(", ")", ";", "}"], "to_mask": {"VAR": ["bhwc", "delegate", "i", "inputs", "interpreter", "model", "op_resolver", "out_tensor", "outputs", "tflite_data"], "METHOD": ["AllocateTensors", "InternalError", "InterpreterBuilder", "Invoke", "ModifyGraphWithDelegate", "OkStatus", "SetNumThreads", "data", "empty", "inputs", "interpreter", "make_unique", "memcpy", "outputs", "push_back", "reserve", "size", "tensor", "to_string", "vector"]}, "attention_idx_tokens": [151, 171], "patch": "@@ -50,12 +50,17 @@\n     return absl::InternalError(\"Unable to allocate TfLite tensors\");\n   }\n   for (int i = 0; i < inputs.size(); ++i) {\n-    DCHECK_EQ(interpreter->tensor(interpreter->inputs()[i])->type,\n-              kTfLiteFloat32);\n+    if(interpreter->tensor(interpreter->inputs()[i])->type !=  kTfLiteFloat32){", "ext_attention_idx_tokens": [151, 264], "uid": "b7399862", "question": "Could you explain why this change is needed?", "code": "absl Status InterpreterInvokeWithOpResolver const tflite Model* model TfLiteDelegate* delegate const OpResolver& op resolver const std vector<TensorFloat32>& inputs std vector<TensorFloat32>* outputs { auto interpreter std make unique<Interpreter> ; if InterpreterBuilder model op resolver &interpreter ! kTfLiteOk { return absl InternalError \"Unable to create TfLite InterpreterBuilder\" ; } if delegate && interpreter->ModifyGraphWithDelegate delegate ! kTfLiteOk { return absl InternalError \"Unable to modify TfLite graph with the delegate\" ; } interpreter->SetNumThreads 1 ; if interpreter->AllocateTensors ! kTfLiteOk { return absl InternalError \"Unable to allocate TfLite tensors\" ; } for int i 0; i < inputs size ; ++i { if interpreter->tensor interpreter->inputs [i] ->type ! kTfLiteFloat32 { return absl InternalError \"input data type is not float32\" ; } float* tflite data interpreter->typed tensor<float> interpreter->inputs [i] ; if inputs[i] data size * sizeof float interpreter->tensor interpreter->inputs [i] ->bytes { return absl InternalError \"input data size doesn t match for this input\" ; } std memcpy tflite data inputs[i] data data inputs[i] data size * sizeof float ; } if interpreter->Invoke ! kTfLiteOk { return absl InternalError \"Unable to invoke TfLite interpreter\" ; } if !outputs || !outputs->empty { return absl InternalError \"Invalid outputs pointer\" ; } outputs->reserve interpreter->outputs size ; for auto t interpreter->outputs { const TfLiteTensor* out tensor interpreter->tensor t ; TensorFloat32 bhwc; bhwc id t; TODO impjdi Relax this condition to arbitrary batch size if out tensor->dims->data[0] ! 1 { return absl InternalError \"Batch dimension is expected to be 1\" ; } bhwc shape b out tensor->dims->data[0]; switch out tensor->dims->size { case 2 bhwc shape h 1; bhwc shape w 1; bhwc shape c out tensor->dims->data[1]; break; case 3 bhwc shape h 1; bhwc shape w out tensor->dims->data[1]; bhwc shape c out tensor->dims->data[2]; break; case 4 bhwc shape h out tensor->dims->data[1]; bhwc shape w out tensor->dims->data[2]; bhwc shape c out tensor->dims->data[3]; break; default return absl InternalError \"Unsupported dimensions size \" + std to string out tensor->dims->size ; } bhwc data std vector<float> out tensor->data f out tensor->data f + out tensor->bytes sizeof float ; outputs->push back bhwc ; } return absl OkStatus ; }"}
{"message": "This looks like a bug fix that can land in a separate PR, together with a regression test?", "timestamp": "2023-09-27T08:20:39Z", "file_name": "tensorflow/core/util/autotune_maps/conv_parameters.cc", "range": {"start_line": 97, "end_line": 97, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1338235829", "html_url": "https://github.com/tensorflow/tensorflow/pull/61941#discussion_r1338235829", "attention_area": "  proto_.set_trans_b(trans_b);", "file_path": "files/11/08/00000811.cc", "old_file_path": "files/12/08/00000812.cc", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -94,7 +94,7 @@ MatmulParameters::MatmulParameters(\n   proto_.set_c_dtype(c_dtype);\n \n   proto_.set_trans_a(trans_a);\n-  proto_.set_trans_b(trans_a);\n+  proto_.set_trans_b(trans_b);", "source": "MatmulParameters::MatmulParameters(\n    se::StreamExecutor* stream_exec, DataType ab_dtype, DataType c_dtype,\n    bool trans_a, bool trans_b, uint64_t m, uint64_t n, uint64_t k, int64_t lda,\n    int64_t ldb, int64_t ldc,\n    stream_executor::dnn::ActivationMode activation_mode, int version)\n    : device_id_(stream_exec->device_ordinal()) {\n  proto_.set_ab_dtype(ab_dtype);\n  proto_.set_c_dtype(c_dtype);\n\n  proto_.set_trans_a(trans_a);\n  proto_.set_trans_b(trans_b);\n  proto_.set_m(m);\n  proto_.set_n(n);\n  proto_.set_k(k);\n  proto_.set_lda(lda);\n  proto_.set_ldb(ldb);\n  proto_.set_ldc(ldc);\n  proto_.set_activation_mode(activation_mode);\n\n  // Have to convert to std::string because apparently our open-source protobuf\n  // does not speak absl::string_view.\n  proto_.set_device_identifier(\n      std::string(stream_exec->GetDeviceDescription().model_str()));\n  proto_.set_version(version);\n  hash_code_ = ComputeHash(device_id_, proto_);\n}", "source_start_line": 87, "tokens": ["MatmulParameters", "::", "MatmulParameters", "(", "se", "::", "StreamExecutor", "*", "stream_exec", ",", "DataType", "ab_dtype", ",", "DataType", "c_dtype", ",", "bool", "trans_a", ",", "bool", "trans_b", ",", "uint64_t", "m", ",", "uint64_t", "n", ",", "uint64_t", "k", ",", "int64_t", "lda", ",", "int64_t", "ldb", ",", "int64_t", "ldc", ",", "stream_executor", "::", "dnn", "::", "ActivationMode", "activation_mode", ",", "int", "version", ")", ":", "device_id_", "(", "stream_exec", "->", "device_ordinal", "(", ")", ")", "{", "proto_", ".", "set_ab_dtype", "(", "ab_dtype", ")", ";", "proto_", ".", "set_c_dtype", "(", "c_dtype", ")", ";", "proto_", ".", "set_trans_a", "(", "trans_a", ")", ";", "proto_", ".", "set_trans_b", "(", "trans_b", ")", ";", "proto_", ".", "set_m", "(", "m", ")", ";", "proto_", ".", "set_n", "(", "n", ")", ";", "proto_", ".", "set_k", "(", "k", ")", ";", "proto_", ".", "set_lda", "(", "lda", ")", ";", "proto_", ".", "set_ldb", "(", "ldb", ")", ";", "proto_", ".", "set_ldc", "(", "ldc", ")", ";", "proto_", ".", "set_activation_mode", "(", "activation_mode", ")", ";", "proto_", ".", "set_device_identifier", "(", "std", "::", "string", "(", "stream_exec", "->", "GetDeviceDescription", "(", ")", ".", "model_str", "(", ")", ")", ")", ";", "proto_", ".", "set_version", "(", "version", ")", ";", "hash_code_", "=", "ComputeHash", "(", "device_id_", ",", "proto_", ")", ";", "}"], "to_mask": {"VAR": ["ab_dtype", "activation_mode", "c_dtype", "k", "lda", "ldb", "ldc", "m", "n", "stream_exec", "trans_a", "trans_b", "version"], "METHOD": ["ComputeHash", "GetDeviceDescription", "device_ordinal", "model_str", "set_ab_dtype", "set_activation_mode", "set_c_dtype", "set_device_identifier", "set_k", "set_lda", "set_ldb", "set_ldc", "set_m", "set_n", "set_trans_a", "set_trans_b", "set_version", "string"]}, "attention_idx_tokens": [81, 87], "patch": "@@ -94,7 +94,7 @@\n   proto_.set_c_dtype(c_dtype);\n \n   proto_.set_trans_a(trans_a);\n-  proto_.set_trans_b(trans_a);\n+  proto_.set_trans_b(trans_b);", "ext_attention_idx_tokens": [81, 94], "uid": "029f1a18", "question": "This looks like a bug fix that can land in a separate PR, together with a regression test?", "code": "MatmulParameters MatmulParameters se StreamExecutor* stream exec DataType ab dtype DataType c dtype bool trans a bool trans b uint64 t m uint64 t n uint64 t k int64 t lda int64 t ldb int64 t ldc stream executor dnn ActivationMode activation mode int version device id stream exec->device ordinal { proto set ab dtype ab dtype ; proto set c dtype c dtype ; proto set trans a trans a ; proto set trans b trans b ; proto set m m ; proto set n n ; proto set k k ; proto set lda lda ; proto set ldb ldb ; proto set ldc ldc ; proto set activation mode activation mode ; Have to convert to std string because apparently our open-source protobuf does not speak absl string view proto set device identifier std string stream exec->GetDeviceDescription model str ; proto set version version ; hash code ComputeHash device id proto ; }"}
{"message": "What changed in this block?", "timestamp": "2023-11-03T16:54:36Z", "file_name": "tensorflow/core/kernels/xent_op.cc", "range": {"start_line": 98, "end_line": 98, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1381978692", "html_url": "https://github.com/tensorflow/tensorflow/pull/60585#discussion_r1381978692", "attention_area": "", "file_path": "files/29/08/00000829.cc", "old_file_path": "files/30/08/00000830.cc", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -87,15 +95,16 @@ class SoftmaxXentWithLogitsOp : public OpKernel {\n     // Try to reuse the logits_in buffer for the backprop output.\n     OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                 {0}, 1, shape_in, &back_out));\n-    if (shape_in.dim_size(0) > 0) {\n-      functor::XentFunctor<Device, T> functor;\n-      functor(context->eigen_device<Device>(), shape_in.AsEigenDSizes<2>(),\n-              BCast::ToIndexArray<2>(bcast.x_bcast()),\n-              BCast::ToIndexArray<2>(bcast.y_bcast()),\n-              logits_in.template shaped<T, 2>(bcast.x_reshape()),\n-              labels_in.template shaped<T, 2>(bcast.y_reshape()),\n-              scratch.matrix<T>(), loss_out->vec<T>(), back_out->matrix<T>());\n-    }\n+", "source": "void Compute(OpKernelContext* context) override {\n    const Tensor& logits_in = context->input(0);\n    const Tensor& labels_in = context->input(1);\n\n    TensorShape shape_in = logits_in.shape();\n\n    BCast bcast(BCast::FromShape(logits_in.shape()),\n                BCast::FromShape(labels_in.shape()),\n                /*fewer_dims_optimization=*/false);\n    if (!logits_in.IsSameSize(labels_in)) {\n      OP_REQUIRES(context, bcast.IsValid(),\n                  errors::InvalidArgument(\n                      \"logits and labels must be broadcastable: logits_size=\",\n                      logits_in.shape().DebugString(),\n                      \" labels_size=\", labels_in.shape().DebugString()));\n      shape_in = BCast::ToShape(bcast.output_shape());\n    }\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(shape_in),\n                errors::InvalidArgument(\"logits and labels must be either \"\n                                        \"2-dimensional, or broadcasted to be \"\n                                        \"2-dimensional\"));\n\n    if (std::is_same<Device, GPUDevice>::value) {\n      OP_REQUIRES(context, !OpDeterminismRequired(),\n                  errors::Unimplemented(\n                      \"The GPU implementation of SoftmaxCrossEntropyWithLogits\"\n                      \" that would have been executed is not deterministic.\"\n                      \" Note that the Python API uses an alternative,\"\n                      \" deterministic, GPU-accelerated path when determinism is\"\n                      \" enabled.\"));\n    }\n\n    // loss is 1-D (one per example), and size is batch_size.\n\n    Tensor scratch;\n    if (std::is_same<Device, CPUDevice>::value) {\n       OP_REQUIRES_OK(\n        context, context->allocate_temp(DataTypeToEnum<T>::value,\n                                        TensorShape({shape_in.dim_size(0), shape_in.dim_size(1)}),\n                                        &scratch));\n    } else {\n       OP_REQUIRES_OK(\n        context, context->allocate_temp(DataTypeToEnum<T>::value,\n                                        TensorShape({shape_in.dim_size(0), 1}),\n                                        &scratch));\n    }\n   \n\n    Tensor* loss_out = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(\n                       0, TensorShape({shape_in.dim_size(0)}), &loss_out));\n    Tensor* back_out = nullptr;\n    // Try to reuse the logits_in buffer for the backprop output.\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 1, shape_in, &back_out));\n\n    if (shape_in.dim_size(0) <= 0) return;\n\n    functor::XentFunctor<Device, T> functor;\n    functor(context->eigen_device<Device>(), shape_in.AsEigenDSizes<2>(),\n        BCast::ToIndexArray<2>(bcast.x_bcast()),\n        BCast::ToIndexArray<2>(bcast.y_bcast()),\n        logits_in.template shaped<T, 2>(bcast.x_reshape()),\n        labels_in.template shaped<T, 2>(bcast.y_reshape()),\n        scratch.matrix<T>(), loss_out->vec<T>(), back_out->matrix<T>());\n  }", "source_start_line": 42, "tokens": ["void", "Compute", "(", "OpKernelContext", "*", "context", ")", "override", "{", "const", "Tensor", "&", "logits_in", "=", "context", "->", "input", "(", "0", ")", ";", "const", "Tensor", "&", "labels_in", "=", "context", "->", "input", "(", "1", ")", ";", "TensorShape", "shape_in", "=", "logits_in", ".", "shape", "(", ")", ";", "BCast", "bcast", "(", "BCast", "::", "FromShape", "(", "logits_in", ".", "shape", "(", ")", ")", ",", "BCast", "::", "FromShape", "(", "labels_in", ".", "shape", "(", ")", ")", ",", "false", ")", ";", "if", "(", "!", "logits_in", ".", "IsSameSize", "(", "labels_in", ")", ")", "{", "OP_REQUIRES", "(", "context", ",", "bcast", ".", "IsValid", "(", ")", ",", "errors", "::", "InvalidArgument", "(", "\"", "\"", ",", "logits_in", ".", "shape", "(", ")", ".", "DebugString", "(", ")", ",", "\"", "\"", ",", "labels_in", ".", "shape", "(", ")", ".", "DebugString", "(", ")", ")", ")", ";", "shape_in", "=", "BCast", "::", "ToShape", "(", "bcast", ".", "output_shape", "(", ")", ")", ";", "}", "OP_REQUIRES", "(", "context", ",", "TensorShapeUtils", "::", "IsMatrix", "(", "shape_in", ")", ",", "errors", "::", "InvalidArgument", "(", "\"", "\"", "\"", "\"", "\"", "\"", ")", ")", ";", "if", "(", "std", "::", "is_same", "<", "Device", ",", "GPUDevice", ">", "::", "value", ")", "{", "OP_REQUIRES", "(", "context", ",", "!", "OpDeterminismRequired", "(", ")", ",", "errors", "::", "Unimplemented", "(", "\"", "\"", "\"", "\"", "\"", "\"", "\"", "\"", "\"", "\"", ")", ")", ";", "}", "Tensor", "scratch", ";", "if", "(", "std", "::", "is_same", "<", "Device", ",", "CPUDevice", ">", "::", "value", ")", "{", "OP_REQUIRES_OK", "(", "context", ",", "context", "->", "allocate_temp", "(", "DataTypeToEnum", "<", "T", ">", "::", "value", ",", "TensorShape", "(", "{", "shape_in", ".", "dim_size", "(", "0", ")", ",", "shape_in", ".", "dim_size", "(", "1", ")", "}", ")", ",", "&", "scratch", ")", ")", ";", "}", "else", "{", "OP_REQUIRES_OK", "(", "context", ",", "context", "->", "allocate_temp", "(", "DataTypeToEnum", "<", "T", ">", "::", "value", ",", "TensorShape", "(", "{", "shape_in", ".", "dim_size", "(", "0", ")", ",", "1", "}", ")", ",", "&", "scratch", ")", ")", ";", "}", "Tensor", "*", "loss_out", "=", "nullptr", ";", "OP_REQUIRES_OK", "(", "context", ",", "context", "->", "allocate_output", "(", "0", ",", "TensorShape", "(", "{", "shape_in", ".", "dim_size", "(", "0", ")", "}", ")", ",", "&", "loss_out", ")", ")", ";", "Tensor", "*", "back_out", "=", "nullptr", ";", "OP_REQUIRES_OK", "(", "context", ",", "context", "->", "forward_input_or_allocate_output", "(", "{", "0", "}", ",", "1", ",", "shape_in", ",", "&", "back_out", ")", ")", ";", "if", "(", "shape_in", ".", "dim_size", "(", "0", ")", "<=", "0", ")", "return", ";", "functor", "::", "XentFunctor", "<", "Device", ",", "T", ">", "functor", ";", "functor", "(", "context", "->", "eigen_device", "<", "Device", ">", "(", ")", ",", "shape_in", ".", "AsEigenDSizes", "<", "2", ">", "(", ")", ",", "BCast", "::", "ToIndexArray", "<", "2", ">", "(", "bcast", ".", "x_bcast", "(", ")", ")", ",", "BCast", "::", "ToIndexArray", "<", "2", ">", "(", "bcast", ".", "y_bcast", "(", ")", ")", ",", "logits_in", ".", "template", "shaped", "<", "T", ",", "2", ">", "(", "bcast", ".", "x_reshape", "(", ")", ")", ",", "labels_in", ".", "template", "shaped", "<", "T", ",", "2", ">", "(", "bcast", ".", "y_reshape", "(", ")", ")", ",", "scratch", ".", "matrix", "<", "T", ">", "(", ")", ",", "loss_out", "->", "vec", "<", "T", ">", "(", ")", ",", "back_out", "->", "matrix", "<", "T", ">", "(", ")", ")", ";", "}"], "to_mask": {"VAR": ["back_out", "bcast", "context", "functor", "labels_in", "logits_in", "loss_out", "scratch", "shape_in"], "METHOD": ["DebugString", "FromShape", "InvalidArgument", "IsMatrix", "IsSameSize", "IsValid", "OP_REQUIRES", "OP_REQUIRES_OK", "OpDeterminismRequired", "TensorShape", "ToIndexArray", "ToShape", "Unimplemented", "allocate_output", "allocate_temp", "back_out", "context", "dim_size", "forward_input_or_allocate_output", "functor", "input", "labels_in", "logits_in", "loss_out", "output_shape", "scratch", "shape", "shape_in", "x_bcast", "x_reshape", "y_bcast", "y_reshape"]}, "attention_idx_tokens": [null, null], "patch": "@@ -87,15 +95,16 @@\n     // Try to reuse the logits_in buffer for the backprop output.\n     OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                 {0}, 1, shape_in, &back_out));\n-    if (shape_in.dim_size(0) > 0) {\n-      functor::XentFunctor<Device, T> functor;\n-      functor(context->eigen_device<Device>(), shape_in.AsEigenDSizes<2>(),\n-              BCast::ToIndexArray<2>(bcast.x_bcast()),\n-              BCast::ToIndexArray<2>(bcast.y_bcast()),\n-              logits_in.template shaped<T, 2>(bcast.x_reshape()),\n-              labels_in.template shaped<T, 2>(bcast.y_reshape()),\n-              scratch.matrix<T>(), loss_out->vec<T>(), back_out->matrix<T>());\n-    }\n+", "ext_attention_idx_tokens": [356, 489], "uid": "593d60eb", "question": "What changed in this block?", "code": "void Compute OpKernelContext* context override { const Tensor& logits in context->input 0 ; const Tensor& labels in context->input 1 ; TensorShape shape in logits in shape ; BCast bcast BCast FromShape logits in shape BCast FromShape labels in shape *fewer dims optimization * false ; if !logits in IsSameSize labels in { OP REQUIRES context bcast IsValid errors InvalidArgument \"logits and labels must be broadcastable logits size \" logits in shape DebugString \" labels size \" labels in shape DebugString ; shape in BCast ToShape bcast output shape ; } OP REQUIRES context TensorShapeUtils IsMatrix shape in errors InvalidArgument \"logits and labels must be either \" \"2-dimensional or broadcasted to be \" \"2-dimensional\" ; if std is same<Device GPUDevice> value { OP REQUIRES context !OpDeterminismRequired errors Unimplemented \"The GPU implementation of SoftmaxCrossEntropyWithLogits\" \" that would have been executed is not deterministic \" \" Note that the Python API uses an alternative \" \" deterministic GPU-accelerated path when determinism is\" \" enabled \" ; } loss is 1-D one per example and size is batch size Tensor scratch; if std is same<Device CPUDevice> value { OP REQUIRES OK context context->allocate temp DataTypeToEnum<T> value TensorShape {shape in dim size 0 shape in dim size 1 } &scratch ; } else { OP REQUIRES OK context context->allocate temp DataTypeToEnum<T> value TensorShape {shape in dim size 0 1} &scratch ; } Tensor* loss out nullptr; OP REQUIRES OK context context->allocate output 0 TensorShape {shape in dim size 0 } &loss out ; Tensor* back out nullptr; Try to reuse the logits in buffer for the backprop output OP REQUIRES OK context context->forward input or allocate output {0} 1 shape in &back out ; if shape in dim size 0 < 0 return; functor XentFunctor<Device T> functor; functor context->eigen device<Device> shape in AsEigenDSizes<2> BCast ToIndexArray<2> bcast x bcast BCast ToIndexArray<2> bcast y bcast logits in template shaped<T 2> bcast x reshape labels in template shaped<T 2> bcast y reshape scratch matrix<T> loss out->vec<T> back out->matrix<T> ; }"}
{"message": "Why is the max error larger when you have more information for computing it?  What if use_gpu is `False` - then I'd expect the error to not change.  And have you tested with rocm to know there is a difference?  ", "timestamp": "2023-11-09T16:22:19Z", "file_name": "tensorflow/python/kernel_tests/nn_ops/conv_ops_test.py", "range": {"start_line": 2715, "end_line": 2715, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1388247313", "html_url": "https://github.com/tensorflow/tensorflow/pull/62362#discussion_r1388247313", "attention_area": "          max_err=0.005 if test.is_built_with_rocm() else 0.003)", "file_path": "files/43/08/00000843.py", "old_file_path": "files/44/08/00000844.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -2711,7 +2711,8 @@ def testInputGradientKernelSizeMatchesInputSize(self):\n           padding=\"VALID\",\n           test_input=True,\n           data_format=data_format,\n-          use_gpu=use_gpu)\n+          use_gpu=use_gpu,\n+          max_err=0.005 if test.is_built_with_rocm() else 0.003)", "source": "def testInputGradientKernelSizeMatchesInputSize(self):\n    for (data_format, use_gpu) in GetTestConfigs():\n      self.ConstructAndTestGradient(\n          batch=2,\n          input_rows=4,\n          input_cols=3,\n          filter_rows=4,\n          filter_cols=3,\n          in_depth=2,\n          out_depth=3,\n          stride_rows=1,\n          stride_cols=1,\n          padding=\"VALID\",\n          test_input=True,\n          data_format=data_format,\n          use_gpu=use_gpu,\n          max_err=0.005 if test.is_built_with_rocm() else 0.003)", "source_start_line": 2699, "tokens": ["def", "testInputGradientKernelSizeMatchesInputSize", "(", "self", ")", ":", "for", "(", "data_format", ",", "use_gpu", ")", "in", "GetTestConfigs", "(", ")", ":", "self", ".", "ConstructAndTestGradient", "(", "batch", "=", "2", ",", "input_rows", "=", "4", ",", "input_cols", "=", "3", ",", "filter_rows", "=", "4", ",", "filter_cols", "=", "3", ",", "in_depth", "=", "2", ",", "out_depth", "=", "3", ",", "stride_rows", "=", "1", ",", "stride_cols", "=", "1", ",", "padding", "=", "\"VALID\"", ",", "test_input", "=", "True", ",", "data_format", "=", "data_format", ",", "use_gpu", "=", "use_gpu", ",", "max_err", "=", "0.005", "if", "test", ".", "is_built_with_rocm", "(", ")", "else", "0.003", ")"], "to_mask": {"VAR": ["self"], "METHOD": ["ConstructAndTestGradient", "GetTestConfigs", "is_built_with_rocm"]}, "attention_idx_tokens": [73, 84], "patch": "@@ -2711,7 +2711,8 @@\n           padding=\"VALID\",\n           test_input=True,\n           data_format=data_format,\n-          use_gpu=use_gpu)\n+          use_gpu=use_gpu,\n+          max_err=0.005 if test.is_built_with_rocm() else 0.003)", "ext_attention_idx_tokens": [69, 84], "uid": "6d810e27", "question": "Why is the max error larger when you have more information for computing it?  What if use_gpu is `False` - then I'd expect the error to not change.  And have you tested with rocm to know there is a difference?  ", "code": "def testInputGradientKernelSizeMatchesInputSize self for data format use gpu in GetTestConfigs self ConstructAndTestGradient batch 2 input rows 4 input cols 3 filter rows 4 filter cols 3 in depth 2 out depth 3 stride rows 1 stride cols 1 padding \"VALID\" test input True data format data format use gpu use gpu max err 0 005 if test is built with rocm else 0 003"}
{"message": "Can you use something in [`tsl/platform/cpu_info.h`](https://github.com/google/tsl/blob/0edca33c9c206492b77caf2a253072c307649624/tsl/platform/cpu_info.h#L61)?  Internally we don't actually use `std::thread` or `hardware_concurrency`.\r\n\r\nDo you know what the cause is, and why it mainly affects large core counts?  I would expect it to have less of an impact in those cases.\r\n", "timestamp": "2023-12-04T18:04:20Z", "file_name": "third_party/xla/third_party/tsl/tsl/platform/threadpool.cc", "range": {"start_line": 111, "end_line": 111, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1414297083", "html_url": "https://github.com/tensorflow/tensorflow/pull/62152#discussion_r1414297083", "attention_area": "  if(num_threads == std::thread::hardware_concurrency() && num_threads >= 16){", "file_path": "files/68/08/00000868.cc", "old_file_path": "files/69/08/00000869.cc", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -107,6 +107,12 @@ ThreadPool::ThreadPool(Env* env, const ThreadOptions& thread_options,\n                        bool low_latency_hint, Eigen::Allocator* allocator) {\n   CHECK_GE(num_threads, 1);\n \n+#ifdef DNNL_AARCH64_USE_ACL\n+  if(num_threads == std::thread::hardware_concurrency() && num_threads >= 16){", "source": "ThreadPool::ThreadPool(Env* env, const ThreadOptions& thread_options,\n                       const string& name, int num_threads,\n                       bool low_latency_hint, Eigen::Allocator* allocator) {\n  CHECK_GE(num_threads, 1);\n\n#ifdef DNNL_AARCH64_USE_ACL\n  if(num_threads == std::thread::hardware_concurrency() && num_threads >= 16){\n    num_threads = num_threads - 1;\n  }\n#endif  // DNNL_AARCH64_USE_ACL\n\n#ifdef TENSORFLOW_THREADSCALING_EXPERIMENTAL\n  CHECK_GT(absl::GetFlag(FLAGS_tensorflow_num_threads_scale_factor), 0);\n  num_threads *= absl::GetFlag(FLAGS_tensorflow_num_threads_scale_factor);\n  if (num_threads < 1) num_threads = 1;\n#endif  // TENSORFLOW_THREADSCALING_EXPERIMENTAL\n\n  eigen_threadpool_.reset(new Eigen::ThreadPoolTempl<EigenEnvironment>(\n      num_threads, low_latency_hint,\n      EigenEnvironment(env, thread_options, \"tf_\" + name)));\n  underlying_threadpool_ = eigen_threadpool_.get();\n  threadpool_device_.reset(new Eigen::ThreadPoolDevice(underlying_threadpool_,\n                                                       num_threads, allocator));\n}", "source_start_line": 105, "tokens": ["ThreadPool", "::", "ThreadPool", "(", "Env", "*", "env", ",", "const", "ThreadOptions", "&", "thread_options", ",", "const", "string", "&", "name", ",", "int", "num_threads", ",", "bool", "low_latency_hint", ",", "Eigen", "::", "Allocator", "*", "allocator", ")", "{", "CHECK_GE", "(", "num_threads", ",", "1", ")", ";", "#ifdef", "DNNL_AARCH64_USE_ACL", "if", "(", "num_threads", "==", "std", "::", "thread", "::", "hardware_concurrency", "(", ")", "&&", "num_threads", ">=", "16", ")", "{", "num_threads", "=", "num_threads", "-", "1", ";", "}", "#endif", "#ifdef", "TENSORFLOW_THREADSCALING_EXPERIMENTAL", "CHECK_GT", "(", "absl", "::", "GetFlag", "(", "FLAGS_tensorflow_num_threads_scale_factor", ")", ",", "0", ")", ";", "num_threads", "*=", "absl", "::", "GetFlag", "(", "FLAGS_tensorflow_num_threads_scale_factor", ")", ";", "if", "(", "num_threads", "<", "1", ")", "num_threads", "=", "1", ";", "#endif", "eigen_threadpool_", ".", "reset", "(", "new", "Eigen", "::", "ThreadPoolTempl", "<", "EigenEnvironment", ">", "(", "num_threads", ",", "low_latency_hint", ",", "EigenEnvironment", "(", "env", ",", "thread_options", ",", "\"", "\"", "+", "name", ")", ")", ")", ";", "underlying_threadpool_", "=", "eigen_threadpool_", ".", "get", "(", ")", ";", "threadpool_device_", ".", "reset", "(", "new", "Eigen", "::", "ThreadPoolDevice", "(", "underlying_threadpool_", ",", "num_threads", ",", "allocator", ")", ")", ";", "}"], "to_mask": {"VAR": ["allocator", "env", "low_latency_hint", "name", "num_threads", "thread_options"], "METHOD": ["CHECK_GE", "CHECK_GT", "EigenEnvironment", "GetFlag", "get", "hardware_concurrency", "reset"]}, "attention_idx_tokens": [40, 56], "patch": "@@ -107,6 +107,12 @@\n                        bool low_latency_hint, Eigen::Allocator* allocator) {\n   CHECK_GE(num_threads, 1);\n \n+#ifdef DNNL_AARCH64_USE_ACL\n+  if(num_threads == std::thread::hardware_concurrency() && num_threads >= 16){", "ext_attention_idx_tokens": [38, 66], "uid": "97e08e72", "question": "Can you use something in [`tsl/platform/cpu_info.h`](https://github.com/google/tsl/blob/0edca33c9c206492b77caf2a253072c307649624/tsl/platform/cpu_info.h#L61)?  Internally we don't actually use `std::thread` or `hardware_concurrency`.    Do you know what the cause is, and why it mainly affects large core counts?  I would expect it to have less of an impact in those cases.  ", "code": "ThreadPool ThreadPool Env* env const ThreadOptions& thread options const string& name int num threads bool low latency hint Eigen Allocator* allocator { CHECK GE num threads 1 ; #ifdef DNNL AARCH64 USE ACL if num threads std thread hardware concurrency && num threads > 16 { num threads num threads - 1; } #endif DNNL AARCH64 USE ACL #ifdef TENSORFLOW THREADSCALING EXPERIMENTAL CHECK GT absl GetFlag FLAGS tensorflow num threads scale factor 0 ; num threads * absl GetFlag FLAGS tensorflow num threads scale factor ; if num threads < 1 num threads 1; #endif TENSORFLOW THREADSCALING EXPERIMENTAL eigen threadpool reset new Eigen ThreadPoolTempl<EigenEnvironment> num threads low latency hint EigenEnvironment env thread options \"tf \" + name ; underlying threadpool eigen threadpool get ; threadpool device reset new Eigen ThreadPoolDevice underlying threadpool num threads allocator ; }"}
{"message": "If you're mainly talking about overall core counts, then it would affect systems with num_threads < 16 as well.  So where does the large number of cores come into play?", "timestamp": "2023-12-12T16:18:26Z", "file_name": "third_party/xla/third_party/tsl/tsl/platform/threadpool.cc", "range": {"start_line": 111, "end_line": 111, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1424249790", "html_url": "https://github.com/tensorflow/tensorflow/pull/62152#discussion_r1424249790", "attention_area": "  if(num_threads == std::thread::hardware_concurrency() && num_threads >= 16){", "file_path": "files/68/08/00000868.cc", "old_file_path": "files/69/08/00000869.cc", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -107,6 +107,12 @@ ThreadPool::ThreadPool(Env* env, const ThreadOptions& thread_options,\n                        bool low_latency_hint, Eigen::Allocator* allocator) {\n   CHECK_GE(num_threads, 1);\n \n+#ifdef DNNL_AARCH64_USE_ACL\n+  if(num_threads == std::thread::hardware_concurrency() && num_threads >= 16){", "source": "ThreadPool::ThreadPool(Env* env, const ThreadOptions& thread_options,\n                       const string& name, int num_threads,\n                       bool low_latency_hint, Eigen::Allocator* allocator) {\n  CHECK_GE(num_threads, 1);\n\n#ifdef DNNL_AARCH64_USE_ACL\n  if(num_threads == std::thread::hardware_concurrency() && num_threads >= 16){\n    num_threads = num_threads - 1;\n  }\n#endif  // DNNL_AARCH64_USE_ACL\n\n#ifdef TENSORFLOW_THREADSCALING_EXPERIMENTAL\n  CHECK_GT(absl::GetFlag(FLAGS_tensorflow_num_threads_scale_factor), 0);\n  num_threads *= absl::GetFlag(FLAGS_tensorflow_num_threads_scale_factor);\n  if (num_threads < 1) num_threads = 1;\n#endif  // TENSORFLOW_THREADSCALING_EXPERIMENTAL\n\n  eigen_threadpool_.reset(new Eigen::ThreadPoolTempl<EigenEnvironment>(\n      num_threads, low_latency_hint,\n      EigenEnvironment(env, thread_options, \"tf_\" + name)));\n  underlying_threadpool_ = eigen_threadpool_.get();\n  threadpool_device_.reset(new Eigen::ThreadPoolDevice(underlying_threadpool_,\n                                                       num_threads, allocator));\n}", "source_start_line": 105, "tokens": ["ThreadPool", "::", "ThreadPool", "(", "Env", "*", "env", ",", "const", "ThreadOptions", "&", "thread_options", ",", "const", "string", "&", "name", ",", "int", "num_threads", ",", "bool", "low_latency_hint", ",", "Eigen", "::", "Allocator", "*", "allocator", ")", "{", "CHECK_GE", "(", "num_threads", ",", "1", ")", ";", "#ifdef", "DNNL_AARCH64_USE_ACL", "if", "(", "num_threads", "==", "std", "::", "thread", "::", "hardware_concurrency", "(", ")", "&&", "num_threads", ">=", "16", ")", "{", "num_threads", "=", "num_threads", "-", "1", ";", "}", "#endif", "#ifdef", "TENSORFLOW_THREADSCALING_EXPERIMENTAL", "CHECK_GT", "(", "absl", "::", "GetFlag", "(", "FLAGS_tensorflow_num_threads_scale_factor", ")", ",", "0", ")", ";", "num_threads", "*=", "absl", "::", "GetFlag", "(", "FLAGS_tensorflow_num_threads_scale_factor", ")", ";", "if", "(", "num_threads", "<", "1", ")", "num_threads", "=", "1", ";", "#endif", "eigen_threadpool_", ".", "reset", "(", "new", "Eigen", "::", "ThreadPoolTempl", "<", "EigenEnvironment", ">", "(", "num_threads", ",", "low_latency_hint", ",", "EigenEnvironment", "(", "env", ",", "thread_options", ",", "\"", "\"", "+", "name", ")", ")", ")", ";", "underlying_threadpool_", "=", "eigen_threadpool_", ".", "get", "(", ")", ";", "threadpool_device_", ".", "reset", "(", "new", "Eigen", "::", "ThreadPoolDevice", "(", "underlying_threadpool_", ",", "num_threads", ",", "allocator", ")", ")", ";", "}"], "to_mask": {"VAR": ["allocator", "env", "low_latency_hint", "name", "num_threads", "thread_options"], "METHOD": ["CHECK_GE", "CHECK_GT", "EigenEnvironment", "GetFlag", "get", "hardware_concurrency", "reset"]}, "attention_idx_tokens": [40, 56], "patch": "@@ -107,6 +107,12 @@\n                        bool low_latency_hint, Eigen::Allocator* allocator) {\n   CHECK_GE(num_threads, 1);\n \n+#ifdef DNNL_AARCH64_USE_ACL\n+  if(num_threads == std::thread::hardware_concurrency() && num_threads >= 16){", "ext_attention_idx_tokens": [38, 66], "uid": "dfee944f", "question": "If you're mainly talking about overall core counts, then it would affect systems with num_threads < 16 as well.  So where does the large number of cores come into play?", "code": "ThreadPool ThreadPool Env* env const ThreadOptions& thread options const string& name int num threads bool low latency hint Eigen Allocator* allocator { CHECK GE num threads 1 ; #ifdef DNNL AARCH64 USE ACL if num threads std thread hardware concurrency && num threads > 16 { num threads num threads - 1; } #endif DNNL AARCH64 USE ACL #ifdef TENSORFLOW THREADSCALING EXPERIMENTAL CHECK GT absl GetFlag FLAGS tensorflow num threads scale factor 0 ; num threads * absl GetFlag FLAGS tensorflow num threads scale factor ; if num threads < 1 num threads 1; #endif TENSORFLOW THREADSCALING EXPERIMENTAL eigen threadpool reset new Eigen ThreadPoolTempl<EigenEnvironment> num threads low latency hint EigenEnvironment env thread options \"tf \" + name ; underlying threadpool eigen threadpool get ; threadpool device reset new Eigen ThreadPoolDevice underlying threadpool num threads allocator ; }"}
{"message": "Are you sure it's only enabled with MKL?  I believe I added this for CPU in commit 8cb3e0a4901bb7d5f62acc033220408ade3dc4e8.", "timestamp": "2023-12-20T15:09:17Z", "file_name": "tensorflow/core/grappler/optimizers/remapper_test.cc", "range": {"start_line": 1952, "end_line": 1952, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1432837085", "html_url": "https://github.com/tensorflow/tensorflow/pull/62648#discussion_r1432837085", "attention_area": "    if (IsMKLEnabled()) activations.push_back(\"Tanh\");", "file_path": "files/74/08/00000874.cc", "old_file_path": "files/75/08/00000875.cc", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -1946,13 +1948,8 @@ class RemapperFuseMatMulWithBiasAndActivationTest : public RemapperTest {\n   template <DataType DTYPE>\n   void RunTest() {\n     using ::tensorflow::ops::Placeholder;\n-\n-#if defined(INTEL_MKL) && defined(ENABLE_MKL)\n-    std::vector<string> activations = {\"Relu\", \"Relu6\", \"Elu\", \"Tanh\",\n-                                       \"LeakyRelu\"};\n-#else\n     std::vector<string> activations = {\"Relu\", \"Relu6\", \"Elu\", \"LeakyRelu\"};\n-#endif\n+    if (IsMKLEnabled()) activations.push_back(\"Tanh\");", "source": "void RunTest() {\n    using ::tensorflow::ops::Placeholder;\n    std::vector<string> activations = {\"Relu\", \"Relu6\", \"Elu\", \"LeakyRelu\"};\n    if (IsMKLEnabled()) activations.push_back(\"Tanh\");\n\n    for (const string& activation : activations) {\n      if (DTYPE == DT_HALF && activation != \"Relu\") continue;\n      tensorflow::Scope s = tensorflow::Scope::NewRootScope();\n\n      auto lhs_shape = ops::Placeholder::Shape({8, 32});\n      auto rhs_shape = ops::Placeholder::Shape({32, 64});\n      auto bias_shape = ops::Placeholder::Shape({64});\n\n      auto lhs = Placeholder(s.WithOpName(\"lhs\"), DTYPE, lhs_shape);\n      auto rhs = Placeholder(s.WithOpName(\"rhs\"), DTYPE, rhs_shape);\n      auto bias = Placeholder(s.WithOpName(\"bias\"), DTYPE, bias_shape);\n\n      auto matmul = ops::MatMul(s.WithOpName(\"matmul\"), lhs, rhs);\n      auto bias_add = ops::BiasAdd(s.WithOpName(\"bias_add\"), matmul, bias);\n\n      float leakyrelu_alpha = 0.5;\n\n      ops::Identity fetch = [&]() -> ops::Identity {\n        auto activate = s.WithOpName(\"activation\");\n        auto fetch = s.WithOpName(\"fetch\");\n\n        if (activation == \"Relu\") {\n          return ops::Identity(fetch, ops::Relu(activate, bias_add));\n        } else if (activation == \"Relu6\") {\n          return ops::Identity(fetch, ops::Relu6(activate, bias_add));\n        } else if (activation == \"Elu\") {\n          return ops::Identity(fetch, ops::Elu(activate, bias_add));\n        } else if (IsMKLEnabled() && activation == \"Tanh\") {\n          return ops::Identity(fetch, ops::Tanh(activate, bias_add));\n        } else if (activation == \"LeakyRelu\") {\n          auto attr = ops::internal::LeakyRelu::Alpha(leakyrelu_alpha);\n          return ops::Identity(\n              fetch, ops::internal::LeakyRelu(activate, bias_add, attr));\n        }\n\n        return ops::Identity(fetch, bias);\n      }();\n\n      auto lhs_t = GenerateTensorWithSetRandom<DTYPE>({8, 32});\n      auto rhs_t = GenerateTensorWithSetRandom<DTYPE>({32, 64});\n      auto bias_t = GenerateTensorWithSetRandom<DTYPE>({64});\n\n      GrapplerItem item;\n      item.fetch = {\"fetch\"};\n      item.feed = {{\"lhs\", lhs_t}, {\"rhs\", rhs_t}, {\"bias\", bias_t}}", "source_start_line": 1949, "tokens": ["void", "RunTest", "(", ")", "{", "using", "::", "tensorflow", "::", "ops", "::", "Placeholder", ";", "std", "::", "vector", "<", "string", ">", "activations", "=", "{", "\"", "\"", ",", "\"", "\"", ",", "\"", "\"", ",", "\"", "\"", "}", ";", "if", "(", "IsMKLEnabled", "(", ")", ")", "activations", ".", "push_back", "(", "\"", "\"", ")", ";", "for", "(", "const", "string", "&", "activation", ":", "activations", ")", "{", "if", "(", "DTYPE", "==", "DT_HALF", "&&", "activation", "!=", "\"", "\"", ")", "continue", ";", "tensorflow", "::", "Scope", "s", "=", "tensorflow", "::", "Scope", "::", "NewRootScope", "(", ")", ";", "auto", "lhs_shape", "=", "ops", "::", "Placeholder", "::", "Shape", "(", "{", "8", ",", "32", "}", ")", ";", "auto", "rhs_shape", "=", "ops", "::", "Placeholder", "::", "Shape", "(", "{", "32", ",", "64", "}", ")", ";", "auto", "bias_shape", "=", "ops", "::", "Placeholder", "::", "Shape", "(", "{", "64", "}", ")", ";", "auto", "lhs", "=", "Placeholder", "(", "s", ".", "WithOpName", "(", "\"", "\"", ")", ",", "DTYPE", ",", "lhs_shape", ")", ";", "auto", "rhs", "=", "Placeholder", "(", "s", ".", "WithOpName", "(", "\"", "\"", ")", ",", "DTYPE", ",", "rhs_shape", ")", ";", "auto", "bias", "=", "Placeholder", "(", "s", ".", "WithOpName", "(", "\"", "\"", ")", ",", "DTYPE", ",", "bias_shape", ")", ";", "auto", "matmul", "=", "ops", "::", "MatMul", "(", "s", ".", "WithOpName", "(", "\"", "\"", ")", ",", "lhs", ",", "rhs", ")", ";", "auto", "bias_add", "=", "ops", "::", "BiasAdd", "(", "s", ".", "WithOpName", "(", "\"", "\"", ")", ",", "matmul", ",", "bias", ")", ";", "float", "leakyrelu_alpha", "=", "0.5", ";", "ops", "::", "Identity", "fetch", "=", "[", "&", "]", "(", ")", "->", "ops", "::", "Identity", "{", "auto", "activate", "=", "s", ".", "WithOpName", "(", "\"", "\"", ")", ";", "auto", "fetch", "=", "s", ".", "WithOpName", "(", "\"", "\"", ")", ";", "if", "(", "activation", "==", "\"", "\"", ")", "{", "return", "ops", "::", "Identity", "(", "fetch", ",", "ops", "::", "Relu", "(", "activate", ",", "bias_add", ")", ")", ";", "}", "else", "if", "(", "activation", "==", "\"", "\"", ")", "{", "return", "ops", "::", "Identity", "(", "fetch", ",", "ops", "::", "Relu6", "(", "activate", ",", "bias_add", ")", ")", ";", "}", "else", "if", "(", "activation", "==", "\"", "\"", ")", "{", "return", "ops", "::", "Identity", "(", "fetch", ",", "ops", "::", "Elu", "(", "activate", ",", "bias_add", ")", ")", ";", "}", "else", "if", "(", "IsMKLEnabled", "(", ")", "&&", "activation", "==", "\"", "\"", ")", "{", "return", "ops", "::", "Identity", "(", "fetch", ",", "ops", "::", "Tanh", "(", "activate", ",", "bias_add", ")", ")", ";", "}", "else", "if", "(", "activation", "==", "\"", "\"", ")", "{", "auto", "attr", "=", "ops", "::", "internal", "::", "LeakyRelu", "::", "Alpha", "(", "leakyrelu_alpha", ")", ";", "return", "ops", "::", "Identity", "(", "fetch", ",", "ops", "::", "internal", "::", "LeakyRelu", "(", "activate", ",", "bias_add", ",", "attr", ")", ")", ";", "}", "return", "ops", "::", "Identity", "(", "fetch", ",", "bias", ")", ";", "}", "(", ")", ";", "auto", "lhs_t", "=", "GenerateTensorWithSetRandom", "<", "DTYPE", ">", "(", "{", "8", ",", "32", "}", ")", ";", "auto", "rhs_t", "=", "GenerateTensorWithSetRandom", "<", "DTYPE", ">", "(", "{", "32", ",", "64", "}", ")", ";", "auto", "bias_t", "=", "GenerateTensorWithSetRandom", "<", "DTYPE", ">", "(", "{", "64", "}", ")", ";", "GrapplerItem", "item", ";", "item", ".", "fetch", "=", "{", "\"", "\"", "}", ";", "item", ".", "feed", "=", "{", "{", "\"", "\"", ",", "lhs_t", "}", ",", "{", "\"", "\"", ",", "rhs_t", "}", ",", "{", "\"", "\"", ",", "bias_t", "", "}", "}"], "to_mask": {}, "attention_idx_tokens": [35, 48], "patch": "@@ -1946,13 +1948,8 @@\n   template <DataType DTYPE>\n   void RunTest() {\n     using ::tensorflow::ops::Placeholder;\n-\n-#if defined(INTEL_MKL) && defined(ENABLE_MKL)\n-    std::vector<string> activations = {\"Relu\", \"Relu6\", \"Elu\", \"Tanh\",\n-                                       \"LeakyRelu\"};\n-#else\n     std::vector<string> activations = {\"Relu\", \"Relu6\", \"Elu\", \"LeakyRelu\"};\n-#endif\n+    if (IsMKLEnabled()) activations.push_back(\"Tanh\");", "ext_attention_idx_tokens": [13, 48], "uid": "3806a765", "question": "Are you sure it's only enabled with MKL?  I believe I added this for CPU in commit 8cb3e0a4901bb7d5f62acc033220408ade3dc4e8.", "code": "void RunTest { using tensorflow ops Placeholder; std vector<string> activations {\"Relu\" \"Relu6\" \"Elu\" \"LeakyRelu\"}; if IsMKLEnabled activations push back \"Tanh\" ; for const string& activation activations { if DTYPE DT HALF && activation ! \"Relu\" continue; tensorflow Scope s tensorflow Scope NewRootScope ; auto lhs shape ops Placeholder Shape {8 32} ; auto rhs shape ops Placeholder Shape {32 64} ; auto bias shape ops Placeholder Shape {64} ; auto lhs Placeholder s WithOpName \"lhs\" DTYPE lhs shape ; auto rhs Placeholder s WithOpName \"rhs\" DTYPE rhs shape ; auto bias Placeholder s WithOpName \"bias\" DTYPE bias shape ; auto matmul ops MatMul s WithOpName \"matmul\" lhs rhs ; auto bias add ops BiasAdd s WithOpName \"bias add\" matmul bias ; float leakyrelu alpha 0 5; ops Identity fetch [&] -> ops Identity { auto activate s WithOpName \"activation\" ; auto fetch s WithOpName \"fetch\" ; if activation \"Relu\" { return ops Identity fetch ops Relu activate bias add ; } else if activation \"Relu6\" { return ops Identity fetch ops Relu6 activate bias add ; } else if activation \"Elu\" { return ops Identity fetch ops Elu activate bias add ; } else if IsMKLEnabled && activation \"Tanh\" { return ops Identity fetch ops Tanh activate bias add ; } else if activation \"LeakyRelu\" { auto attr ops internal LeakyRelu Alpha leakyrelu alpha ; return ops Identity fetch ops internal LeakyRelu activate bias add attr ; } return ops Identity fetch bias ; } ; auto lhs t GenerateTensorWithSetRandom<DTYPE> {8 32} ; auto rhs t GenerateTensorWithSetRandom<DTYPE> {32 64} ; auto bias t GenerateTensorWithSetRandom<DTYPE> {64} ; GrapplerItem item; item fetch {\"fetch\"}; item feed {{\"lhs\" lhs t} {\"rhs\" rhs t} {\"bias\" bias t}}"}
{"message": "@charettes Do you have suggestions on how to detect whether a full subquery is necessary? I imagine we'll need to look through the expressions in the `WhereNode` and see if there are any that are not a field on the model, but I'm not sure how to do that.", "timestamp": "2024-02-19T17:44:50Z", "file_name": "django/contrib/admin/filters.py", "range": {"start_line": 143, "end_line": 143, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1494884722", "html_url": "https://github.com/django/django/pull/17880#discussion_r1494884722", "attention_area": "                    filter=models.Q(pk__in=lookup_qs),", "file_path": "files/37/01/00000137.py", "old_file_path": "files/36/01/00000136.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -140,7 +140,7 @@ def get_facet_counts(self, pk_attname, filtered_qs):\n             if lookup_qs is not None:\n                 counts[f\"{i}__c\"] = models.Count(\n                     pk_attname,\n-                    filter=lookup_qs.query.where,\n+                    filter=models.Q(pk__in=lookup_qs),", "source": "def get_facet_counts(self, pk_attname, filtered_qs):\n        original_value = self.used_parameters.get(self.parameter_name)\n        counts = {}\n        for i, choice in enumerate(self.lookup_choices):\n            self.used_parameters[self.parameter_name] = choice[0]\n            lookup_qs = self.queryset(self.request, filtered_qs)\n            if lookup_qs is not None:\n                counts[f\"{i}__c\"] = models.Count(\n                    pk_attname,\n                    filter=models.Q(pk__in=lookup_qs),\n                )\n        self.used_parameters[self.parameter_name] = original_value\n        return counts", "source_start_line": 134, "tokens": ["def", "get_facet_counts", "(", "self", ",", "pk_attname", ",", "filtered_qs", ")", ":", "original_value", "=", "self", ".", "used_parameters", ".", "get", "(", "self", ".", "parameter_name", ")", "counts", "=", "{", "}", "for", "i", ",", "choice", "in", "enumerate", "(", "self", ".", "lookup_choices", ")", ":", "self", ".", "used_parameters", "[", "self", ".", "parameter_name", "]", "=", "choice", "[", "0", "]", "lookup_qs", "=", "self", ".", "queryset", "(", "self", ".", "request", ",", "filtered_qs", ")", "if", "lookup_qs", "is", "not", "None", ":", "counts", "[", "f\"", "{", "i", "}", "\"", "]", "=", "models", ".", "Count", "(", "pk_attname", ",", "filter", "=", "models", ".", "Q", "(", "pk__in", "=", "lookup_qs", ")", ",", ")", "self", ".", "used_parameters", "[", "self", ".", "parameter_name", "]", "=", "original_value", "return", "counts"], "to_mask": {"VAR": ["choice", "counts", "filtered_qs", "i", "lookup_qs", "original_value", "pk_attname", "self"], "METHOD": ["Count", "Q", "enumerate", "get", "queryset"]}, "attention_idx_tokens": [84, 94], "patch": "@@ -140,7 +140,7 @@\n             if lookup_qs is not None:\n                 counts[f\"{i}__c\"] = models.Count(\n                     pk_attname,\n-                    filter=lookup_qs.query.where,\n+                    filter=models.Q(pk__in=lookup_qs),", "ext_attention_idx_tokens": [84, 95], "uid": "e8cbb4bf", "question": "@charettes Do you have suggestions on how to detect whether a full subquery is necessary? I imagine we'll need to look through the expressions in the `WhereNode` and see if there are any that are not a field on the model, but I'm not sure how to do that.", "code": "def get facet counts self pk attname filtered qs original value self used parameters get self parameter name counts {} for i choice in enumerate self lookup choices self used parameters[self parameter name] choice[0] lookup qs self queryset self request filtered qs if lookup qs is not None counts[f\"{i} c\"] models Count pk attname filter models Q pk in lookup qs self used parameters[self parameter name] original value return counts"}
{"message": "How did you access the asv profile btw? Is that from running it locally?", "timestamp": "2024-02-24T23:09:32Z", "file_name": "django/urls/resolvers.py", "range": {"start_line": 171, "end_line": 171, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1501711798", "html_url": "https://github.com/django/django/pull/17904#discussion_r1501711798", "attention_area": "        \"\"\"", "file_path": "files/67/01/00000167.py", "old_file_path": "files/66/01/00000166.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -164,12 +169,11 @@ def _check_pattern_startswith_slash(self):\n         \"\"\"\n         Check that the pattern does not begin with a forward slash.\n         \"\"\"", "source": "def _check_pattern_startswith_slash(self):\n        \"\"\"\n        Check that the pattern does not begin with a forward slash.\n        \"\"\"\n        if not settings.APPEND_SLASH:\n            # Skip check as it can be useful to start a URL pattern with a slash\n            # when APPEND_SLASH=False.\n            return []\n        if self._regex.startswith((\"/\", \"^/\", \"^\\\\/\")) and not self._regex.endswith(\n            \"/\"\n        ):\n            warning = Warning(\n                \"Your URL pattern {} has a route beginning with a '/'. Remove this \"\n                \"slash as it is unnecessary. If this pattern is targeted in an \"\n                \"include(), ensure the include() pattern has a trailing '/'.\".format(\n                    self.describe()\n                ),\n                id=\"urls.W002\",\n            )\n            return [warning]\n        else:\n            return []", "source_start_line": 168, "tokens": ["def", "_check_pattern_startswith_slash", "(", "self", ")", ":", "\"\"\"        Check that the pattern does not begin with a forward slash.        \"\"\"", "if", "not", "settings", ".", "APPEND_SLASH", ":", "return", "[", "]", "if", "self", ".", "_regex", ".", "startswith", "(", "(", "\"/\"", ",", "\"^/\"", ",", "\"^\\\\/\"", ")", ")", "and", "not", "self", ".", "_regex", ".", "endswith", "(", "\"/\"", ")", ":", "warning", "=", "Warning", "(", "\"Your URL pattern {} has a route beginning with a '/'. Remove this \"", "\"slash as it is unnecessary. If this pattern is targeted in an \"", "\"include(), ensure the include() pattern has a trailing '/'.\"", ".", "format", "(", "self", ".", "describe", "(", ")", ")", ",", "id", "=", "\"urls.W002\"", ",", ")", "return", "[", "warning", "]", "else", ":", "return", "[", "]"], "to_mask": {"VAR": ["self", "warning"], "METHOD": ["Warning", "describe", "endswith", "format", "startswith"]}, "attention_idx_tokens": [null, null], "patch": "@@ -164,12 +169,11 @@\n         \"\"\"\n         Check that the pattern does not begin with a forward slash.\n         \"\"\"\n-        regex_pattern = self.regex.pattern", "ext_attention_idx_tokens": [7, 39], "uid": "90b9847a", "question": "How did you access the asv profile btw? Is that from running it locally?", "code": "def check pattern startswith slash self \"\"\" Check that the pattern does not begin with a forward slash \"\"\" if not settings APPEND SLASH # Skip check as it can be useful to start a URL pattern with a slash # when APPEND SLASH False return [] if self regex startswith \" \" \"^ \" \"^\\\\ \" and not self regex endswith \" \" warning Warning \"Your URL pattern {} has a route beginning with a Remove this \" \"slash as it is unnecessary If this pattern is targeted in an \" \"include ensure the include pattern has a trailing \" format self describe id \"urls W002\" return [warning] else return []"}
{"message": "> Are we OK with renaming them in a patch release, though?\r\n\r\nI think we need guidance from a fellow (cc @felixxm @nessita) \ud83d\ude4f ", "timestamp": "2024-02-26T07:36:42Z", "file_name": "django/contrib/admin/filters.py", "range": {"start_line": 143, "end_line": 143, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1502147542", "html_url": "https://github.com/django/django/pull/17880#discussion_r1502147542", "attention_area": "                    filter=models.Q(pk__in=lookup_qs),", "file_path": "files/37/01/00000137.py", "old_file_path": "files/36/01/00000136.py", "filters": {"comment_message": false, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -140,7 +140,7 @@ def get_facet_counts(self, pk_attname, filtered_qs):\n             if lookup_qs is not None:\n                 counts[f\"{i}__c\"] = models.Count(\n                     pk_attname,\n-                    filter=lookup_qs.query.where,\n+                    filter=models.Q(pk__in=lookup_qs),", "source": "def get_facet_counts(self, pk_attname, filtered_qs):\n        original_value = self.used_parameters.get(self.parameter_name)\n        counts = {}\n        for i, choice in enumerate(self.lookup_choices):\n            self.used_parameters[self.parameter_name] = choice[0]\n            lookup_qs = self.queryset(self.request, filtered_qs)\n            if lookup_qs is not None:\n                counts[f\"{i}__c\"] = models.Count(\n                    pk_attname,\n                    filter=models.Q(pk__in=lookup_qs),\n                )\n        self.used_parameters[self.parameter_name] = original_value\n        return counts", "source_start_line": 134, "tokens": ["def", "get_facet_counts", "(", "self", ",", "pk_attname", ",", "filtered_qs", ")", ":", "original_value", "=", "self", ".", "used_parameters", ".", "get", "(", "self", ".", "parameter_name", ")", "counts", "=", "{", "}", "for", "i", ",", "choice", "in", "enumerate", "(", "self", ".", "lookup_choices", ")", ":", "self", ".", "used_parameters", "[", "self", ".", "parameter_name", "]", "=", "choice", "[", "0", "]", "lookup_qs", "=", "self", ".", "queryset", "(", "self", ".", "request", ",", "filtered_qs", ")", "if", "lookup_qs", "is", "not", "None", ":", "counts", "[", "f\"", "{", "i", "}", "\"", "]", "=", "models", ".", "Count", "(", "pk_attname", ",", "filter", "=", "models", ".", "Q", "(", "pk__in", "=", "lookup_qs", ")", ",", ")", "self", ".", "used_parameters", "[", "self", ".", "parameter_name", "]", "=", "original_value", "return", "counts"], "to_mask": {"VAR": ["choice", "counts", "filtered_qs", "i", "lookup_qs", "original_value", "pk_attname", "self"], "METHOD": ["Count", "Q", "enumerate", "get", "queryset"]}, "attention_idx_tokens": [84, 94], "patch": "@@ -140,7 +140,7 @@\n             if lookup_qs is not None:\n                 counts[f\"{i}__c\"] = models.Count(\n                     pk_attname,\n-                    filter=lookup_qs.query.where,\n+                    filter=models.Q(pk__in=lookup_qs),", "ext_attention_idx_tokens": [84, 95], "uid": "bbcf582e", "question": "> Are we OK with renaming them in a patch release, though?    I think we need guidance from a fellow (cc @felixxm @nessita) \ud83d\ude4f ", "code": "def get facet counts self pk attname filtered qs original value self used parameters get self parameter name counts {} for i choice in enumerate self lookup choices self used parameters[self parameter name] choice[0] lookup qs self queryset self request filtered qs if lookup qs is not None counts[f\"{i} c\"] models Count pk attname filter models Q pk in lookup qs self used parameters[self parameter name] original value return counts"}
{"message": "What's the goal of creating these instances in `setUpTestData` if there is a single test? Do you expect more tests to be added?", "timestamp": "2024-03-06T12:01:34Z", "file_name": "tests/auth_tests/test_decorators.py", "range": {"start_line": 163, "end_line": 163, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1514348206", "html_url": "https://github.com/django/django/pull/17943#discussion_r1514348206", "attention_area": "        cls.user_pass.user_permissions.add(*perms)", "file_path": "files/91/01/00000191.py", "old_file_path": "files/92/01/00000192.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -142,3 +146,37 @@ def a_view(request):\n         request.user = self.user\n         with self.assertRaises(PermissionDenied):\n             a_view(request)\n+\n+\n+class UserPassesTestDecoratorTest(TestCase):\n+    factory = RequestFactory()\n+\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.user_pass = models.User.objects.create(username=\"joe\", password=\"qwerty\")\n+        cls.user_deny = models.User.objects.create(username=\"jim\", password=\"qwerty\")\n+        models.Group.objects.create(name=\"Joe group\")\n+        # Add permissions auth.add_customuser and auth.change_customuser\n+        perms = models.Permission.objects.filter(\n+            codename__in=(\"add_customuser\", \"change_customuser\")\n+        )\n+        cls.user_pass.user_permissions.add(*perms)", "source": "def setUpTestData(cls):\n        cls.user_pass = models.User.objects.create(username=\"joe\", password=\"qwerty\")\n        cls.user_deny = models.User.objects.create(username=\"jim\", password=\"qwerty\")\n        models.Group.objects.create(name=\"Joe group\")\n        # Add permissions auth.add_customuser and auth.change_customuser\n        perms = models.Permission.objects.filter(\n            codename__in=(\"add_customuser\", \"change_customuser\")\n        )\n        cls.user_pass.user_permissions.add(*perms)", "source_start_line": 155, "tokens": ["def", "setUpTestData", "(", "cls", ")", ":", "cls", ".", "user_pass", "=", "models", ".", "User", ".", "objects", ".", "create", "(", "username", "=", "\"joe\"", ",", "password", "=", "\"qwerty\"", ")", "cls", ".", "user_deny", "=", "models", ".", "User", ".", "objects", ".", "create", "(", "username", "=", "\"jim\"", ",", "password", "=", "\"qwerty\"", ")", "models", ".", "Group", ".", "objects", ".", "create", "(", "name", "=", "\"Joe group\"", ")", "perms", "=", "models", ".", "Permission", ".", "objects", ".", "filter", "(", "codename__in", "=", "(", "\"add_customuser\"", ",", "\"change_customuser\"", ")", ")", "cls", ".", "user_pass", ".", "user_permissions", ".", "add", "(", "*", "perms", ")"], "to_mask": {"VAR": ["cls", "perms", "user_deny", "user_pass"], "METHOD": ["add", "create", "filter"]}, "attention_idx_tokens": [76, 86], "patch": "@@ -142,3 +146,37 @@\n         request.user = self.user\n         with self.assertRaises(PermissionDenied):\n             a_view(request)\n+\n+\n+class UserPassesTestDecoratorTest(TestCase):\n+    factory = RequestFactory()\n+\n+    @classmethod\n+    def setUpTestData(cls):\n+        cls.user_pass = models.User.objects.create(username=\"joe\", password=\"qwerty\")\n+        cls.user_deny = models.User.objects.create(username=\"jim\", password=\"qwerty\")\n+        models.Group.objects.create(name=\"Joe group\")\n+        # Add permissions auth.add_customuser and auth.change_customuser\n+        perms = models.Permission.objects.filter(\n+            codename__in=(\"add_customuser\", \"change_customuser\")\n+        )\n+        cls.user_pass.user_permissions.add(*perms)", "ext_attention_idx_tokens": [0, 86], "uid": "b87465ae", "question": "What's the goal of creating these instances in `setUpTestData` if there is a single test? Do you expect more tests to be added?", "code": "def setUpTestData cls cls user pass models User objects create username \"joe\" password \"qwerty\" cls user deny models User objects create username \"jim\" password \"qwerty\" models Group objects create name \"Joe group\" # Add permissions auth add customuser and auth change customuser perms models Permission objects filter codename in \"add customuser\" \"change customuser\" cls user pass user permissions add *perms"}
{"message": "@bigfootjon What do you think? :point_up: ", "timestamp": "2024-03-13T05:03:59Z", "file_name": "django/contrib/sessions/backends/signed_cookies.py", "range": {"start_line": 103, "end_line": 103, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1522522472", "html_url": "https://github.com/django/django/pull/17372#discussion_r1522522472", "attention_area": "        pass", "file_path": "files/04/02/00000204.py", "old_file_path": "files/03/02/00000203.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -79,3 +97,7 @@ def _get_session_key(self):\n     @classmethod\n     def clear_expired(cls):\n         pass\n+\n+    @classmethod\n+    async def aclear_expired(cls):\n+        pass", "source": "async def aclear_expired(cls):\n        pass", "source_start_line": 102, "tokens": ["async", "def", "aclear_expired", "(", "cls", ")", ":", "pass"], "to_mask": {"VAR": ["cls"], "METHOD": []}, "attention_idx_tokens": [7, 7], "patch": "@@ -79,3 +97,7 @@\n     @classmethod\n     def clear_expired(cls):\n         pass\n+\n+    @classmethod\n+    async def aclear_expired(cls):\n+        pass", "ext_attention_idx_tokens": [null, null], "uid": "76fa7067", "question": "@bigfootjon What do you think? :point_up: ", "code": "async def aclear expired cls pass"}
{"message": "Is there an async API for files? My understanding is that Python does not expose an async file io model. IIRC somewhere in Django (ASGI support for static files?) that has a context switch due to this same limitation.", "timestamp": "2024-03-13T13:28:07Z", "file_name": "django/contrib/sessions/backends/signed_cookies.py", "range": {"start_line": 103, "end_line": 103, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1523261853", "html_url": "https://github.com/django/django/pull/17372#discussion_r1523261853", "attention_area": "        pass", "file_path": "files/04/02/00000204.py", "old_file_path": "files/03/02/00000203.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -79,3 +97,7 @@ def _get_session_key(self):\n     @classmethod\n     def clear_expired(cls):\n         pass\n+\n+    @classmethod\n+    async def aclear_expired(cls):\n+        pass", "source": "async def aclear_expired(cls):\n        pass", "source_start_line": 102, "tokens": ["async", "def", "aclear_expired", "(", "cls", ")", ":", "pass"], "to_mask": {"VAR": ["cls"], "METHOD": []}, "attention_idx_tokens": [7, 7], "patch": "@@ -79,3 +97,7 @@\n     @classmethod\n     def clear_expired(cls):\n         pass\n+\n+    @classmethod\n+    async def aclear_expired(cls):\n+        pass", "ext_attention_idx_tokens": [null, null], "uid": "89355530", "question": "Is there an async API for files? My understanding is that Python does not expose an async file io model. IIRC somewhere in Django (ASGI support for static files?) that has a context switch due to this same limitation.", "code": "async def aclear expired cls pass"}
{"message": "As this case is covered by the default Django settings (i.e. `ADMINS` is an empty list and `AdminEmailHandler` is in the default logging), I think it might be worth adding a release note.\r\nI can be persuaded out of it (I see @felixxm approved earlier - maybe you have thoughts?).", "timestamp": "2024-04-12T07:28:06Z", "file_name": "tests/view_tests/tests/test_defaults.py", "range": {"start_line": 126, "end_line": 126, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1562143552", "html_url": "https://github.com/django/django/pull/18059#discussion_r1562143552", "attention_area": "        self.assertIs(response.wsgi_request, response.context.request)", "file_path": "files/72/02/00000272.py", "old_file_path": "files/71/02/00000271.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -123,7 +123,7 @@ def test_bad_request(self):\n     )\n     def test_custom_bad_request_template(self):\n         response = self.client.get(\"/raises400/\")\n-        self.assertIs(response.wsgi_request, response.context[-1].request)\n+        self.assertIs(response.wsgi_request, response.context.request)", "source": "def test_custom_bad_request_template(self):\n        response = self.client.get(\"/raises400/\")\n        self.assertIs(response.wsgi_request, response.context.request)", "source_start_line": 124, "tokens": ["def", "test_custom_bad_request_template", "(", "self", ")", ":", "response", "=", "self", ".", "client", ".", "get", "(", "\"/raises400/\"", ")", "self", ".", "assertIs", "(", "response", ".", "wsgi_request", ",", "response", ".", "context", ".", "request", ")"], "to_mask": {"VAR": ["response", "self"], "METHOD": ["assertIs", "get"]}, "attention_idx_tokens": [16, 29], "patch": "@@ -123,7 +123,7 @@\n     )\n     def test_custom_bad_request_template(self):\n         response = self.client.get(\"/raises400/\")\n-        self.assertIs(response.wsgi_request, response.context[-1].request)\n+        self.assertIs(response.wsgi_request, response.context.request)", "ext_attention_idx_tokens": [16, 29], "uid": "b14679a1", "question": "As this case is covered by the default Django settings (i.e. `ADMINS` is an empty list and `AdminEmailHandler` is in the default logging), I think it might be worth adding a release note.  I can be persuaded out of it (I see @felixxm approved earlier - maybe you have thoughts?).", "code": "def test custom bad request template self response self client get \" raises400 \" self assertIs response wsgi request response context request"}
{"message": "Is this and the changes to `django/contrib/admin/templates/admin/edit_inline/tabular.html` and `django/contrib/admin/templates/admin/edit_inline/stacked.html` required?\r\nThe way I read the existing feature it looks like it is applied only for fieldsets rather than formsets.", "timestamp": "2024-04-16T11:52:48Z", "file_name": "django/contrib/admin/helpers.py", "range": {"start_line": 451, "end_line": 451, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1567225988", "html_url": "https://github.com/django/django/pull/17910#discussion_r1567225988", "attention_area": "", "file_path": "files/83/02/00000283.py", "old_file_path": "files/82/02/00000282.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -438,6 +443,12 @@ def inline_formset_data(self):\n     def forms(self):\n         return self.formset.forms\n \n+    @cached_property\n+    def is_collapsible(self):\n+        if any(self.formset.errors):\n+            return False\n+        return \"collapse\" in self.classes\n+", "source": "def is_collapsible(self):\n        if any(self.formset.errors):\n            return False\n        return \"collapse\" in self.classes", "source_start_line": 447, "tokens": ["def", "is_collapsible", "(", "self", ")", ":", "if", "any", "(", "self", ".", "formset", ".", "errors", ")", ":", "return", "False", "return", "\"collapse\"", "in", "self", ".", "classes"], "to_mask": {"VAR": ["self"], "METHOD": ["any"]}, "attention_idx_tokens": [null, null], "patch": "@@ -438,6 +443,12 @@\n     def forms(self):\n         return self.formset.forms\n \n+    @cached_property\n+    def is_collapsible(self):\n+        if any(self.formset.errors):\n+            return False\n+        return \"collapse\" in self.classes\n+", "ext_attention_idx_tokens": [0, 23], "uid": "ccc2a888", "question": "Is this and the changes to `django/contrib/admin/templates/admin/edit_inline/tabular.html` and `django/contrib/admin/templates/admin/edit_inline/stacked.html` required?  The way I read the existing feature it looks like it is applied only for fieldsets rather than formsets.", "code": "def is collapsible self if any self formset errors return False return \"collapse\" in self classes"}
{"message": "We also have in the docs:\r\n> Some browsers (e.g. Chrome or Firefox) support headless testing\r\n\r\nShould we add edge in here?", "timestamp": "2024-05-10T10:43:57Z", "file_name": "django/test/selenium.py", "range": {"start_line": 86, "end_line": 86, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1596596510", "html_url": "https://github.com/django/django/pull/18149#discussion_r1596596510", "attention_area": "                case \"chrome\" | \"edge\":", "file_path": "files/12/03/00000312.py", "old_file_path": "files/10/03/00000310.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -83,7 +83,7 @@ def create_options(self):\n         options = self.import_options(self.browser)()\n         if self.headless:\n             match self.browser:\n-                case \"chrome\":\n+                case \"chrome\" | \"edge\":", "source": "def create_options(self):\n        options = self.import_options(self.browser)()\n        if self.headless:\n            match self.browser:\n                case \"chrome\" | \"edge\":\n                    options.add_argument(\"--headless=new\")\n                case \"firefox\":\n                    options.add_argument(\"-headless\")", "source_start_line": 82, "tokens": ["def", "create_options", "(", "self", ")", ":", "options", "=", "self", ".", "import_options", "(", "self", ".", "browser", ")", "(", ")", "if", "self", ".", "headless", ":", "match", "self", ".", "browser", ":", "case", "\"chrome\"", "|", "\"edge\"", ":", "options", ".", "add_argument", "(", "\"--headless=new\"", ")", "case", "\"firefox\"", ":", "options", ".", "add_argument", "(", "\"-headless\"", ")"], "to_mask": {"VAR": ["options", "self"], "METHOD": ["add_argument", "import_options"]}, "attention_idx_tokens": [28, 32], "patch": "@@ -83,7 +83,7 @@\n         options = self.import_options(self.browser)()\n         if self.headless:\n             match self.browser:\n-                case \"chrome\":\n+                case \"chrome\" | \"edge\":", "ext_attention_idx_tokens": [28, 38], "uid": "d89b2dc0", "question": "We also have in the docs:  > Some browsers (e.g. Chrome or Firefox) support headless testing    Should we add edge in here?", "code": "def create options self options self import options self browser if self headless match self browser case \"chrome\" | \"edge\" options add argument \"--headless new\" case \"firefox\" options add argument \"-headless\""}
{"message": "Also would adding supporting for \"chromium\" be almost the same as these changes?", "timestamp": "2024-05-10T10:45:56Z", "file_name": "django/test/selenium.py", "range": {"start_line": 86, "end_line": 86, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1596600265", "html_url": "https://github.com/django/django/pull/18149#discussion_r1596600265", "attention_area": "                case \"chrome\" | \"edge\":", "file_path": "files/12/03/00000312.py", "old_file_path": "files/10/03/00000310.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -83,7 +83,7 @@ def create_options(self):\n         options = self.import_options(self.browser)()\n         if self.headless:\n             match self.browser:\n-                case \"chrome\":\n+                case \"chrome\" | \"edge\":", "source": "def create_options(self):\n        options = self.import_options(self.browser)()\n        if self.headless:\n            match self.browser:\n                case \"chrome\" | \"edge\":\n                    options.add_argument(\"--headless=new\")\n                case \"firefox\":\n                    options.add_argument(\"-headless\")", "source_start_line": 82, "tokens": ["def", "create_options", "(", "self", ")", ":", "options", "=", "self", ".", "import_options", "(", "self", ".", "browser", ")", "(", ")", "if", "self", ".", "headless", ":", "match", "self", ".", "browser", ":", "case", "\"chrome\"", "|", "\"edge\"", ":", "options", ".", "add_argument", "(", "\"--headless=new\"", ")", "case", "\"firefox\"", ":", "options", ".", "add_argument", "(", "\"-headless\"", ")"], "to_mask": {"VAR": ["options", "self"], "METHOD": ["add_argument", "import_options"]}, "attention_idx_tokens": [28, 32], "patch": "@@ -83,7 +83,7 @@\n         options = self.import_options(self.browser)()\n         if self.headless:\n             match self.browser:\n-                case \"chrome\":\n+                case \"chrome\" | \"edge\":", "ext_attention_idx_tokens": [28, 38], "uid": "0ae03209", "question": "Also would adding supporting for \"chromium\" be almost the same as these changes?", "code": "def create options self options self import options self browser if self headless match self browser case \"chrome\" | \"edge\" options add argument \"--headless new\" case \"firefox\" options add argument \"-headless\""}
{"message": "so what is the consensus?\r\n\r\n* test y/n?\r\n* identity check y/n?", "timestamp": "2024-07-09T16:50:02Z", "file_name": "django/db/models/sql/query.py", "range": {"start_line": 653, "end_line": 653, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1670876803", "html_url": "https://github.com/django/django/pull/18353#discussion_r1670876803", "attention_area": "        if limit is True:", "file_path": "files/97/03/00000397.py", "old_file_path": "files/96/03/00000396.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -650,13 +650,13 @@ def exists(self, limit=True):\n                 for combined_query in q.combined_queries\n             )\n         q.clear_ordering(force=True)\n-        if limit:\n+        if limit is True:", "source": "def exists(self, limit=True):\n        q = self.clone()\n        if not (q.distinct and q.is_sliced):\n            if q.group_by is True:\n                q.add_fields(\n                    (f.attname for f in self.model._meta.concrete_fields), False\n                )\n                # Disable GROUP BY aliases to avoid orphaning references to the\n                # SELECT clause which is about to be cleared.\n                q.set_group_by(allow_aliases=False)\n            q.clear_select_clause()\n        if q.combined_queries and q.combinator == \"union\":\n            q.combined_queries = tuple(\n                combined_query.exists(limit=False)\n                for combined_query in q.combined_queries\n            )\n        q.clear_ordering(force=True)\n        if limit is True:\n            q.set_limits(high=1)\n        q.add_annotation(Value(1), \"a\")\n        return q", "source_start_line": 636, "tokens": ["def", "exists", "(", "self", ",", "limit", "=", "True", ")", ":", "q", "=", "self", ".", "clone", "(", ")", "if", "not", "(", "q", ".", "distinct", "and", "q", ".", "is_sliced", ")", ":", "if", "q", ".", "group_by", "is", "True", ":", "q", ".", "add_fields", "(", "(", "f", ".", "attname", "for", "f", "in", "self", ".", "model", ".", "_meta", ".", "concrete_fields", ")", ",", "False", ")", "q", ".", "set_group_by", "(", "allow_aliases", "=", "False", ")", "q", ".", "clear_select_clause", "(", ")", "if", "q", ".", "combined_queries", "and", "q", ".", "combinator", "==", "\"union\"", ":", "q", ".", "combined_queries", "=", "tuple", "(", "combined_query", ".", "exists", "(", "limit", "=", "False", ")", "for", "combined_query", "in", "q", ".", "combined_queries", ")", "q", ".", "clear_ordering", "(", "force", "=", "True", ")", "if", "limit", "is", "True", ":", "q", ".", "set_limits", "(", "high", "=", "1", ")", "q", ".", "add_annotation", "(", "Value", "(", "1", ")", ",", "\"a\"", ")", "return", "q"], "to_mask": {"VAR": ["combined_queries", "limit", "q", "self"], "METHOD": ["Value", "add_annotation", "add_fields", "clear_ordering", "clear_select_clause", "clone", "exists", "set_group_by", "set_limits", "tuple"]}, "attention_idx_tokens": [111, 115], "patch": "@@ -650,13 +650,13 @@\n                 for combined_query in q.combined_queries\n             )\n         q.clear_ordering(force=True)\n-        if limit:\n+        if limit is True:", "ext_attention_idx_tokens": [111, 136], "uid": "307ad988", "question": "so what is the consensus?    * test y/n?  * identity check y/n?", "code": "def exists self limit True q self clone if not q distinct and q is sliced if q group by is True q add fields f attname for f in self model meta concrete fields False # Disable GROUP BY aliases to avoid orphaning references to the # SELECT clause which is about to be cleared q set group by allow aliases False q clear select clause if q combined queries and q combinator \"union\" q combined queries tuple combined query exists limit False for combined query in q combined queries q clear ordering force True if limit is True q set limits high 1 q add annotation Value 1 \"a\" return q"}
{"message": "@felixxm Do you remember the \"why\" here? It seems that Snowflake also needs this behavior, otherwise other backends tests fail with \"Connection is closed\" when running tests in parallel. I'm wondering what a name for a feature flag could be.", "timestamp": "2024-12-24T00:21:27Z", "file_name": "tests/backends/base/test_creation.py", "range": {"start_line": 66, "end_line": 66, "start_character": 0, "end_character": 0}, "project": "django/django", "api_url": "https://api.github.com/repos/django/django/pulls/comments/1896226725", "html_url": "https://github.com/django/django/pull/13448#discussion_r1896226725", "attention_area": "        if connection.vendor == 'oracle':", "file_path": "files/35/08/00000835.py", "old_file_path": "files/36/08/00000836.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -49,31 +50,57 @@ def test_custom_test_name_with_test_prefix(self):\n         self.assertEqual(signature[3], test_name)\n \n \n+@override_settings(INSTALLED_APPS=['backends.base.app_unmigrated'])\n @mock.patch.object(connection, 'ensure_connection')\n-@mock.patch('django.core.management.commands.migrate.Command.handle', return_value=None)\n+@mock.patch.object(connection, 'prepare_database')\n+@mock.patch('django.db.migrations.recorder.MigrationRecorder.has_table', return_value=False)\n+@mock.patch('django.db.migrations.executor.MigrationExecutor.migrate')\n+@mock.patch('django.core.management.commands.migrate.Command.sync_apps')\n class TestDbCreationTests(SimpleTestCase):\n-    def test_migrate_test_setting_false(self, mocked_migrate, mocked_ensure_connection):\n+    available_apps = ['backends.base.app_unmigrated']\n+\n+    def test_migrate_test_setting_false(self, mocked_sync_apps, mocked_migrate, *mocked_objects):\n         test_connection = get_connection_copy()\n         test_connection.settings_dict['TEST']['MIGRATE'] = False\n         creation = test_connection.creation_class(test_connection)\n+        if connection.vendor == 'oracle':", "source": "def test_migrate_test_setting_false(self, mocked_sync_apps, mocked_migrate, *mocked_objects):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = False\n        creation = test_connection.creation_class(test_connection)\n        if connection.vendor == 'oracle':\n            # Don't close connection on Oracle.\n            creation.connection.close = mock.Mock()\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_create_test_db'):\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n            # Migrations don't run.\n            mocked_migrate.assert_called()\n            args, kwargs = mocked_migrate.call_args\n            self.assertEqual(args, ([],))\n            self.assertEqual(kwargs['plan'], [])\n            # App is synced.\n            mocked_sync_apps.assert_called()\n            mocked_args, _ = mocked_sync_apps.call_args\n            self.assertEqual(mocked_args[1], {'app_unmigrated'})\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)", "source_start_line": 62, "tokens": ["def", "test_migrate_test_setting_false", "(", "self", ",", "mocked_sync_apps", ",", "mocked_migrate", ",", "*", "mocked_objects", ")", ":", "test_connection", "=", "get_connection_copy", "(", ")", "test_connection", ".", "settings_dict", "[", "'TEST'", "]", "[", "'MIGRATE'", "]", "=", "False", "creation", "=", "test_connection", ".", "creation_class", "(", "test_connection", ")", "if", "connection", ".", "vendor", "==", "'oracle'", ":", "creation", ".", "connection", ".", "close", "=", "mock", ".", "Mock", "(", ")", "old_database_name", "=", "test_connection", ".", "settings_dict", "[", "'NAME'", "]", "try", ":", "with", "mock", ".", "patch", ".", "object", "(", "creation", ",", "'_create_test_db'", ")", ":", "creation", ".", "create_test_db", "(", "verbosity", "=", "0", ",", "autoclobber", "=", "True", ",", "serialize", "=", "False", ")", "mocked_migrate", ".", "assert_called", "(", ")", "args", ",", "kwargs", "=", "mocked_migrate", ".", "call_args", "self", ".", "assertEqual", "(", "args", ",", "(", "[", "]", ",", ")", ")", "self", ".", "assertEqual", "(", "kwargs", "[", "'plan'", "]", ",", "[", "]", ")", "mocked_sync_apps", ".", "assert_called", "(", ")", "mocked_args", ",", "_", "=", "mocked_sync_apps", ".", "call_args", "self", ".", "assertEqual", "(", "mocked_args", "[", "1", "]", ",", "{", "'app_unmigrated'", "}", ")", "finally", ":", "with", "mock", ".", "patch", ".", "object", "(", "creation", ",", "'_destroy_test_db'", ")", ":", "creation", ".", "destroy_test_db", "(", "old_database_name", ",", "verbosity", "=", "0", ")"], "to_mask": {"VAR": ["_", "args", "close", "creation", "kwargs", "mocked_args", "mocked_migrate", "mocked_objects", "mocked_sync_apps", "old_database_name", "self", "test_connection"], "METHOD": ["Mock", "assertEqual", "assert_called", "create_test_db", "creation_class", "destroy_test_db", "get_connection_copy", "object"]}, "attention_idx_tokens": [37, 43], "patch": "@@ -49,31 +50,57 @@\n         self.assertEqual(signature[3], test_name)\n \n \n+@override_settings(INSTALLED_APPS=['backends.base.app_unmigrated'])\n @mock.patch.object(connection, 'ensure_connection')\n-@mock.patch('django.core.management.commands.migrate.Command.handle', return_value=None)\n+@mock.patch.object(connection, 'prepare_database')\n+@mock.patch('django.db.migrations.recorder.MigrationRecorder.has_table', return_value=False)\n+@mock.patch('django.db.migrations.executor.MigrationExecutor.migrate')\n+@mock.patch('django.core.management.commands.migrate.Command.sync_apps')\n class TestDbCreationTests(SimpleTestCase):\n-    def test_migrate_test_setting_false(self, mocked_migrate, mocked_ensure_connection):\n+    available_apps = ['backends.base.app_unmigrated']\n+\n+    def test_migrate_test_setting_false(self, mocked_sync_apps, mocked_migrate, *mocked_objects):\n         test_connection = get_connection_copy()\n         test_connection.settings_dict['TEST']['MIGRATE'] = False\n         creation = test_connection.creation_class(test_connection)\n+        if connection.vendor == 'oracle':", "ext_attention_idx_tokens": [0, 177], "uid": "87d03c64", "question": "@felixxm Do you remember the \"why\" here? It seems that Snowflake also needs this behavior, otherwise other backends tests fail with \"Connection is closed\" when running tests in parallel. I'm wondering what a name for a feature flag could be.", "code": "def test migrate test setting false self mocked sync apps mocked migrate *mocked objects test connection get connection copy test connection settings dict[ TEST ][ MIGRATE ] False creation test connection creation class test connection if connection vendor oracle # Don t close connection on Oracle creation connection close mock Mock old database name test connection settings dict[ NAME ] try with mock patch object creation create test db creation create test db verbosity 0 autoclobber True serialize False # Migrations don t run mocked migrate assert called args kwargs mocked migrate call args self assertEqual args [] self assertEqual kwargs[ plan ] [] # App is synced mocked sync apps assert called mocked args mocked sync apps call args self assertEqual mocked args[1] { app unmigrated } finally with mock patch object creation destroy test db creation destroy test db old database name verbosity 0"}
{"message": "@fchollet Is it test_spare_output ? I am getting confused.\r\nSince we can convert a SparseTensor into a DenseTensor using tf.sparse.to_dense", "timestamp": "2024-01-08T06:29:10Z", "file_name": "keras/layers/preprocessing/discretization_test.py", "range": {"start_line": 137, "end_line": 137, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1444206342", "html_url": "https://github.com/keras-team/keras/pull/19029#discussion_r1444206342", "attention_area": "        layer = layers.Discretization(bin_boundaries=[0.0, 0.5, 1.0])", "file_path": "files/05/00/00000005.py", "old_file_path": "files/06/00/00000006.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -125,6 +126,15 @@ def test_saving(self):\n         model = saving_api.load_model(fpath)\n         self.assertAllClose(layer(ref_input), ref_output)\n \n+    @pytest.mark.skipif(\n+        backend.backend() != \"tensorflow\",\n+        reason=\"Sparse tensor only works in TensorFlow\",\n+    )\n     def test_sparse_inputs(self):\n-        # TODO\n-        pass\n+        from keras.utils.module_utils import tensorflow as tf\n+\n+        x = tf.sparse.from_dense(np.array([[-1.0, 0.2, 0.7, 1.2]]))\n+        layer = layers.Discretization(bin_boundaries=[0.0, 0.5, 1.0])", "source": "def test_sparse_inputs(self):\n        from keras.utils.module_utils import tensorflow as tf\n\n        x = tf.sparse.from_dense(np.array([[-1.0, 0.2, 0.7, 1.2]]))\n        layer = layers.Discretization(bin_boundaries=[0.0, 0.5, 1.0])\n        output = layer(x)\n        self.assertTrue(backend.is_tensor(output))\n        self.assertAllClose(output, np.array([[0, 1, 2, 3]]))", "source_start_line": 133, "tokens": ["def", "test_sparse_inputs", "(", "self", ")", ":", "from", "keras", ".", "utils", ".", "module_utils", "import", "tensorflow", "as", "tf", "x", "=", "tf", ".", "sparse", ".", "from_dense", "(", "np", ".", "array", "(", "[", "[", "-", "1.0", ",", "0.2", ",", "0.7", ",", "1.2", "]", "]", ")", ")", "layer", "=", "layers", ".", "Discretization", "(", "bin_boundaries", "=", "[", "0.0", ",", "0.5", ",", "1.0", "]", ")", "output", "=", "layer", "(", "x", ")", "self", ".", "assertTrue", "(", "backend", ".", "is_tensor", "(", "output", ")", ")", "self", ".", "assertAllClose", "(", "output", ",", "np", ".", "array", "(", "[", "[", "0", ",", "1", ",", "2", ",", "3", "]", "]", ")", ")"], "to_mask": {"VAR": ["layer", "output", "self", "x"], "METHOD": ["Discretization", "array", "assertAllClose", "assertTrue", "from_dense", "is_tensor", "layer"]}, "attention_idx_tokens": [42, 57], "patch": "@@ -125,6 +126,15 @@\n         model = saving_api.load_model(fpath)\n         self.assertAllClose(layer(ref_input), ref_output)\n \n+    @pytest.mark.skipif(\n+        backend.backend() != \"tensorflow\",\n+        reason=\"Sparse tensor only works in TensorFlow\",\n+    )\n     def test_sparse_inputs(self):\n-        # TODO\n-        pass\n+        from keras.utils.module_utils import tensorflow as tf\n+\n+        x = tf.sparse.from_dense(np.array([[-1.0, 0.2, 0.7, 1.2]]))\n+        layer = layers.Discretization(bin_boundaries=[0.0, 0.5, 1.0])", "ext_attention_idx_tokens": [0, 63], "uid": "65a0536f", "question": "@fchollet Is it test_spare_output ? I am getting confused.  Since we can convert a SparseTensor into a DenseTensor using tf.sparse.to_dense", "code": "def test sparse inputs self from keras utils module utils import tensorflow as tf x tf sparse from dense np array [[-1 0 0 2 0 7 1 2]] layer layers Discretization bin boundaries [0 0 0 5 1 0] output layer x self assertTrue backend is tensor output self assertAllClose output np array [[0 1 2 3]]"}
{"message": "What I don't get is this: why is `standardize_dtype` being called on a shape element? Also, shouldn't the dtype of a shape element be int?", "timestamp": "2024-02-22T22:31:30Z", "file_name": "keras/backend/common/variables.py", "range": {"start_line": 427, "end_line": 427, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1500019606", "html_url": "https://github.com/keras-team/keras/pull/19212#discussion_r1500019606", "attention_area": "    elif hasattr(dtype, \"__str__\") and \"_DimExpr\" in str(dtype):", "file_path": "files/56/00/00000056.py", "old_file_path": "files/57/00/00000057.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -424,6 +424,8 @@ def standardize_dtype(dtype):\n         \"torch\" in str(dtype) or \"jax.numpy\" in str(dtype)\n     ):\n         dtype = str(dtype).split(\".\")[-1]\n+    elif hasattr(dtype, \"__str__\") and \"_DimExpr\" in str(dtype):", "source": "def standardize_dtype(dtype):\n    if dtype is None:\n        return config.floatx()\n    dtype = PYTHON_DTYPES_MAP.get(dtype, dtype)\n    if hasattr(dtype, \"name\"):\n        dtype = dtype.name\n    elif hasattr(dtype, \"__str__\") and (\n        \"torch\" in str(dtype) or \"jax.numpy\" in str(dtype)\n    ):\n        dtype = str(dtype).split(\".\")[-1]\n    elif hasattr(dtype, \"__str__\") and \"_DimExpr\" in str(dtype):\n        return config.floatx()\n    elif hasattr(dtype, \"__name__\"):\n        dtype = dtype.__name__\n\n    if dtype not in ALLOWED_DTYPES:\n        raise ValueError(f\"Invalid dtype: {dtype}\")\n    return dtype", "source_start_line": 417, "tokens": ["def", "standardize_dtype", "(", "dtype", ")", ":", "if", "dtype", "is", "None", ":", "return", "config", ".", "floatx", "(", ")", "dtype", "=", "PYTHON_DTYPES_MAP", ".", "get", "(", "dtype", ",", "dtype", ")", "if", "hasattr", "(", "dtype", ",", "\"name\"", ")", ":", "dtype", "=", "dtype", ".", "name", "elif", "hasattr", "(", "dtype", ",", "\"__str__\"", ")", "and", "(", "\"torch\"", "in", "str", "(", "dtype", ")", "or", "\"jax.numpy\"", "in", "str", "(", "dtype", ")", ")", ":", "dtype", "=", "str", "(", "dtype", ")", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "elif", "hasattr", "(", "dtype", ",", "\"__str__\"", ")", "and", "\"_DimExpr\"", "in", "str", "(", "dtype", ")", ":", "return", "config", ".", "floatx", "(", ")", "elif", "hasattr", "(", "dtype", ",", "\"__name__\"", ")", ":", "dtype", "=", "dtype", ".", "__name__", "if", "dtype", "not", "in", "ALLOWED_DTYPES", ":", "raise", "ValueError", "(", "f\"", "{", "dtype", "}", "\"", ")", "return", "dtype"], "to_mask": {"VAR": ["dtype"], "METHOD": ["ValueError", "floatx", "get", "hasattr", "split", "str"]}, "attention_idx_tokens": [79, 93], "patch": "@@ -424,6 +424,8 @@\n         \"torch\" in str(dtype) or \"jax.numpy\" in str(dtype)\n     ):\n         dtype = str(dtype).split(\".\")[-1]\n+    elif hasattr(dtype, \"__str__\") and \"_DimExpr\" in str(dtype):", "ext_attention_idx_tokens": [79, 107], "uid": "002ce2fe", "question": "What I don't get is this: why is `standardize_dtype` being called on a shape element? Also, shouldn't the dtype of a shape element be int?", "code": "def standardize dtype dtype if dtype is None return config floatx dtype PYTHON DTYPES MAP get dtype dtype if hasattr dtype \"name\" dtype dtype name elif hasattr dtype \" str \" and \"torch\" in str dtype or \"jax numpy\" in str dtype dtype str dtype split \" \" [-1] elif hasattr dtype \" str \" and \" DimExpr\" in str dtype return config floatx elif hasattr dtype \" name \" dtype dtype name if dtype not in ALLOWED DTYPES raise ValueError f\"Invalid dtype {dtype}\" return dtype"}
{"message": "What is the issue? Numerical difference across backends?", "timestamp": "2024-03-08T08:29:28Z", "file_name": "integration_tests/numerical_test.py", "range": {"start_line": 47, "end_line": 47, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1517391791", "html_url": "https://github.com/keras-team/keras/pull/19260#discussion_r1517391791", "attention_area": "            # TODO: Renable the following line.", "file_path": "files/74/00/00000074.py", "old_file_path": "files/75/00/00000075.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -41,7 +44,8 @@ def build_keras_model(keras_module, num_classes):\n             keras_module.layers.Conv2D(\n                 64, kernel_size=(3, 3), activation=\"relu\"\n             ),\n-            keras_module.layers.BatchNormalization(scale=False, center=True),\n+            # TODO: Renable the following line.", "source": "def build_keras_model(keras_module, num_classes):\n    input_shape = (28, 28, 1)\n\n    model = keras_module.Sequential(\n        [\n            keras_module.Input(shape=input_shape),\n            keras_module.layers.Conv2D(\n                32, kernel_size=(3, 3), activation=\"relu\"\n            ),\n            keras_module.layers.BatchNormalization(),\n            keras_module.layers.MaxPooling2D(pool_size=(2, 2)),\n            keras_module.layers.Conv2D(\n                64, kernel_size=(3, 3), activation=\"relu\"\n            ),\n            # TODO: Renable the following line.\n            # keras_module.layers.BatchNormalization(scale=False, center=True),\n            keras_module.layers.MaxPooling2D(pool_size=(2, 2)),\n            keras_module.layers.Flatten(),\n            keras_module.layers.Dense(num_classes, activation=\"softmax\"),\n        ]\n    )\n\n    model.summary()\n    return model", "source_start_line": 33, "tokens": ["def", "build_keras_model", "(", "keras_module", ",", "num_classes", ")", ":", "input_shape", "=", "(", "28", ",", "28", ",", "1", ")", "model", "=", "keras_module", ".", "Sequential", "(", "[", "keras_module", ".", "Input", "(", "shape", "=", "input_shape", ")", ",", "keras_module", ".", "layers", ".", "Conv2D", "(", "32", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "activation", "=", "\"relu\"", ")", ",", "keras_module", ".", "layers", ".", "BatchNormalization", "(", ")", ",", "keras_module", ".", "layers", ".", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ")", ",", "keras_module", ".", "layers", ".", "Conv2D", "(", "64", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "activation", "=", "\"relu\"", ")", ",", "keras_module", ".", "layers", ".", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ")", ",", "keras_module", ".", "layers", ".", "Flatten", "(", ")", ",", "keras_module", ".", "layers", ".", "Dense", "(", "num_classes", ",", "activation", "=", "\"softmax\"", ")", ",", "]", ")", "model", ".", "summary", "(", ")", "return", "model"], "to_mask": {"VAR": ["input_shape", "keras_module", "model", "num_classes"], "METHOD": ["BatchNormalization", "Conv2D", "Dense", "Flatten", "Input", "MaxPooling2D", "Sequential", "summary"]}, "attention_idx_tokens": [null, null], "patch": "@@ -41,7 +44,8 @@\n             keras_module.layers.Conv2D(\n                 64, kernel_size=(3, 3), activation=\"relu\"\n             ),\n-            keras_module.layers.BatchNormalization(scale=False, center=True),\n+            # TODO: Renable the following line.", "ext_attention_idx_tokens": [98, 112], "uid": "ccacf180", "question": "What is the issue? Numerical difference across backends?", "code": "def build keras model keras module num classes input shape 28 28 1 model keras module Sequential [ keras module Input shape input shape keras module layers Conv2D 32 kernel size 3 3 activation \"relu\" keras module layers BatchNormalization keras module layers MaxPooling2D pool size 2 2 keras module layers Conv2D 64 kernel size 3 3 activation \"relu\" # TODO Renable the following line # keras module layers BatchNormalization scale False center True keras module layers MaxPooling2D pool size 2 2 keras module layers Flatten keras module layers Dense num classes activation \"softmax\" ] model summary return model"}
{"message": "But isn't the issue with JAX specifically? I'm confused.", "timestamp": "2024-03-11T23:19:18Z", "file_name": "keras/layers/layer.py", "range": {"start_line": 951, "end_line": 951, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1520534855", "html_url": "https://github.com/keras-team/keras/pull/19287#discussion_r1520534855", "attention_area": "            lambda v: v.value if isinstance(v, KerasVariable) else v,", "file_path": "files/80/00/00000080.py", "old_file_path": "files/81/00/00000081.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -945,11 +947,14 @@ def stateless_call(\n             )\n \n         # Gather variable mapping\n-        trainable_mapping = zip(self.trainable_variables, trainable_variables)\n-        non_trainable_mapping = zip(\n-            self.non_trainable_variables, non_trainable_variables\n+        all_variables = map(\n+            lambda v: v.value if isinstance(v, KerasVariable) else v,", "source": "def stateless_call(\n        self,\n        trainable_variables,\n        non_trainable_variables,\n        *args,\n        return_losses=False,\n        **kwargs,\n    ):\n        \"\"\"Call the layer without any side effects.\n\n        Args:\n            trainable_variables: List of trainable variables of the model.\n            non_trainable_variables: List of non-trainable variables of the\n                model.\n            *args: Positional arguments to be passed to `call()`.\n            return_losses: If `True`, `stateless_call()` will return the list of\n                losses created during `call()` as part of its return values.\n            **kwargs: Keyword arguments to be passed to `call()`.\n\n        Returns:\n            A tuple. By default, returns `(outputs, non_trainable_variables)`.\n                If `return_losses = True`, then returns\n                `(outputs, non_trainable_variables, losses)`.\n\n        Note: `non_trainable_variables` include not only non-trainable weights\n        such as `BatchNormalization` statistics, but also RNG seed state\n        (if there are any random operations part of the layer, such as dropout),\n        and `Metric` state (if there are any metrics attached to the layer).\n        These are all elements of state of the layer.\n\n        Example:\n\n        ```python\n        model = ...\n        data = ...\n        trainable_variables = model.trainable_variables\n        non_trainable_variables = model.non_trainable_variables\n        # Call the model with zero side effects\n        outputs, non_trainable_variables = model.stateless_call(\n            trainable_variables,\n            non_trainable_variables,\n            data,\n        )\n        # Attach the updated state to the model\n        # (until you do this, the model is still in its pre-call state).\n        for ref_var, value in zip(\n            model.non_trainable_variables, non_trainable_variables\n        ):\n            ref_var.assign(value)\n        ```\n        \"\"\"\n        self._check_super_called()\n\n        if not self.built:\n            raise ValueError(\n                f\"To call stateless_call, {self.__class__.__name__} must be \"\n                \"built (i.e. its variables must have been already created). \"\n                \"You can build it by calling it on some data.\"\n            )\n        if len(trainable_variables) != len(self.trainable_variables):\n            raise ValueError(\n                \"Argument `trainable_variables` must be a list of tensors \"\n                \"corresponding 1:1 to \"\n                f\"{self.__class__.__name__}().trainable_variables. \"\n                f\"Received list with length {len(trainable_variables)}, \"\n                f\"but expected {len(self.trainable_variables)} variables.\"\n            )\n        if len(non_trainable_variables) != len(self.non_trainable_variables):\n            raise ValueError(\n                \"Argument `non_trainable_variables` must be a list of tensors \"\n                \"corresponding 1:1 to \"\n                f\"{self.__class__.__name__}().non_trainable_variables. \"\n                f\"Received list with length {len(non_trainable_variables)}, \"\n                f\"but expected {len(self.non_trainable_variables)} variables.\"\n            )\n\n        # Gather variable mapping\n        all_variables = map(\n            lambda v: v.value if isinstance(v, KerasVariable) else v,\n            itertools.chain(trainable_variables, non_trainable_variables),\n        )\n        mapping = zip(\n            self.trainable_variables + self.non_trainable_variables,\n            all_variables,\n        )\n\n        # Call in stateless scope\n        losses = None\n        with backend.StatelessScope(\n            state_mapping=mapping, collect_losses=return_losses\n        ) as scope:\n            if isinstance(\n                self.dtype_policy, dtype_policies.QuantizedDTypePolicy\n            ):\n                outputs = self.quantized_call(*args, **kwargs)\n            else:\n                outputs = self.call(*args, **kwargs)\n            if return_losses:\n                losses = self.losses\n\n        # Gather updated non-trainable variables\n        non_trainable_variables = []\n        for v in self.non_trainable_variables:\n            new_v = scope.get_current_value(v)\n            if new_v is not None:\n                non_trainable_variables.append(new_v)\n            else:\n                non_trainable_variables.append(v)\n\n        if return_losses:\n            return outputs, non_trainable_variables, losses\n        return outputs, non_trainable_variables", "source_start_line": 873, "tokens": ["def", "stateless_call", "(", "self", ",", "trainable_variables", ",", "non_trainable_variables", ",", "*", "args", ",", "return_losses", "=", "False", ",", "**", "kwargs", ",", ")", ":", "\"\"\"Call the layer without any side effects.        Args:            trainable_variables: List of trainable variables of the model.            non_trainable_variables: List of non-trainable variables of the                model.            *args: Positional arguments to be passed to `call()`.            return_losses: If `True`, `stateless_call()` will return the list of                losses created during `call()` as part of its return values.            **kwargs: Keyword arguments to be passed to `call()`.        Returns:            A tuple. By default, returns `(outputs, non_trainable_variables)`.                If `return_losses = True`, then returns                `(outputs, non_trainable_variables, losses)`.        Note: `non_trainable_variables` include not only non-trainable weights        such as `BatchNormalization` statistics, but also RNG seed state        (if there are any random operations part of the layer, such as dropout),        and `Metric` state (if there are any metrics attached to the layer).        These are all elements of state of the layer.        Example:        ```python        model = ...        data = ...        trainable_variables = model.trainable_variables        non_trainable_variables = model.non_trainable_variables        # Call the model with zero side effects        outputs, non_trainable_variables = model.stateless_call(            trainable_variables,            non_trainable_variables,            data,        )        # Attach the updated state to the model        # (until you do this, the model is still in its pre-call state).        for ref_var, value in zip(            model.non_trainable_variables, non_trainable_variables        ):            ref_var.assign(value)        ```        \"\"\"", "self", ".", "_check_super_called", "(", ")", "if", "not", "self", ".", "built", ":", "raise", "ValueError", "(", "f\"", "{", "self", ".", "__class__", ".", "__name__", "}", "\"", "\"built (i.e. its variables must have been already created). \"", "\"You can build it by calling it on some data.\"", ")", "if", "len", "(", "trainable_variables", ")", "!=", "len", "(", "self", ".", "trainable_variables", ")", ":", "raise", "ValueError", "(", "\"Argument `trainable_variables` must be a list of tensors \"", "\"corresponding 1:1 to \"", "f\"", "{", "self", ".", "__class__", ".", "__name__", "}", "\"", "f\"", "{", "len", "(", "trainable_variables", ")", "}", "\"", "f\"", "{", "len", "(", "self", ".", "trainable_variables", ")", "}", "\"", ")", "if", "len", "(", "non_trainable_variables", ")", "!=", "len", "(", "self", ".", "non_trainable_variables", ")", ":", "raise", "ValueError", "(", "\"Argument `non_trainable_variables` must be a list of tensors \"", "\"corresponding 1:1 to \"", "f\"", "{", "self", ".", "__class__", ".", "__name__", "}", "\"", "f\"", "{", "len", "(", "non_trainable_variables", ")", "}", "\"", "f\"", "{", "len", "(", "self", ".", "non_trainable_variables", ")", "}", "\"", ")", "all_variables", "=", "map", "(", "lambda", "v", ":", "v", ".", "value", "if", "isinstance", "(", "v", ",", "KerasVariable", ")", "else", "v", ",", "itertools", ".", "chain", "(", "trainable_variables", ",", "non_trainable_variables", ")", ",", ")", "mapping", "=", "zip", "(", "self", ".", "trainable_variables", "+", "self", ".", "non_trainable_variables", ",", "all_variables", ",", ")", "losses", "=", "None", "with", "backend", ".", "StatelessScope", "(", "state_mapping", "=", "mapping", ",", "collect_losses", "=", "return_losses", ")", "as", "scope", ":", "if", "isinstance", "(", "self", ".", "dtype_policy", ",", "dtype_policies", ".", "QuantizedDTypePolicy", ")", ":", "outputs", "=", "self", ".", "quantized_call", "(", "*", "args", ",", "**", "kwargs", ")", "else", ":", "outputs", "=", "self", ".", "call", "(", "*", "args", ",", "**", "kwargs", ")", "if", "return_losses", ":", "losses", "=", "self", ".", "losses", "non_trainable_variables", "=", "[", "]", "for", "v", "in", "self", ".", "non_trainable_variables", ":", "new_v", "=", "scope", ".", "get_current_value", "(", "v", ")", "if", "new_v", "is", "not", "None", ":", "non_trainable_variables", ".", "append", "(", "new_v", ")", "else", ":", "non_trainable_variables", ".", "append", "(", "v", ")", "if", "return_losses", ":", "return", "outputs", ",", "non_trainable_variables", ",", "losses", "return", "outputs", ",", "non_trainable_variables"], "to_mask": {"VAR": ["all_variables", "args", "losses", "mapping", "new_v", "non_trainable_variables", "outputs", "return_losses", "scope", "self", "trainable_variables", "v"], "METHOD": ["StatelessScope", "ValueError", "_check_super_called", "append", "call", "chain", "get_current_value", "isinstance", "len", "map", "quantized_call", "zip"]}, "attention_idx_tokens": [144, 159], "patch": "@@ -945,11 +947,14 @@\n             )\n \n         # Gather variable mapping\n-        trainable_mapping = zip(self.trainable_variables, trainable_variables)\n-        non_trainable_mapping = zip(\n-            self.non_trainable_variables, non_trainable_variables\n+        all_variables = map(\n+            lambda v: v.value if isinstance(v, KerasVariable) else v,", "ext_attention_idx_tokens": [140, 184], "uid": "de39fd5f", "question": "But isn't the issue with JAX specifically? I'm confused.", "code": "def stateless call self trainable variables non trainable variables *args return losses False **kwargs \"\"\"Call the layer without any side effects Args trainable variables List of trainable variables of the model non trainable variables List of non-trainable variables of the model *args Positional arguments to be passed to `call ` return losses If `True` `stateless call ` will return the list of losses created during `call ` as part of its return values **kwargs Keyword arguments to be passed to `call ` Returns A tuple By default returns ` outputs non trainable variables ` If `return losses True` then returns ` outputs non trainable variables losses ` Note `non trainable variables` include not only non-trainable weights such as `BatchNormalization` statistics but also RNG seed state if there are any random operations part of the layer such as dropout and `Metric` state if there are any metrics attached to the layer These are all elements of state of the layer Example ```python model data trainable variables model trainable variables non trainable variables model non trainable variables # Call the model with zero side effects outputs non trainable variables model stateless call trainable variables non trainable variables data # Attach the updated state to the model # until you do this the model is still in its pre-call state for ref var value in zip model non trainable variables non trainable variables ref var assign value ``` \"\"\" self check super called if not self built raise ValueError f\"To call stateless call {self class name } must be \" \"built i e its variables must have been already created \" \"You can build it by calling it on some data \" if len trainable variables ! len self trainable variables raise ValueError \"Argument `trainable variables` must be a list of tensors \" \"corresponding 1 1 to \" f\"{self class name } trainable variables \" f\"Received list with length {len trainable variables } \" f\"but expected {len self trainable variables } variables \" if len non trainable variables ! len self non trainable variables raise ValueError \"Argument `non trainable variables` must be a list of tensors \" \"corresponding 1 1 to \" f\"{self class name } non trainable variables \" f\"Received list with length {len non trainable variables } \" f\"but expected {len self non trainable variables } variables \" # Gather variable mapping all variables map lambda v v value if isinstance v KerasVariable else v itertools chain trainable variables non trainable variables mapping zip self trainable variables + self non trainable variables all variables # Call in stateless scope losses None with backend StatelessScope state mapping mapping collect losses return losses as scope if isinstance self dtype policy dtype policies QuantizedDTypePolicy outputs self quantized call *args **kwargs else outputs self call *args **kwargs if return losses losses self losses # Gather updated non-trainable variables non trainable variables [] for v in self non trainable variables new v scope get current value v if new v is not None non trainable variables append new v else non trainable variables append v if return losses return outputs non trainable variables losses return outputs non trainable variables"}
{"message": "Was that for a circular dependency?", "timestamp": "2024-03-20T18:15:07Z", "file_name": "keras/backend/jax/distribution_lib.py", "range": {"start_line": 85, "end_line": 85, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1532579652", "html_url": "https://github.com/keras-team/keras/pull/19342#discussion_r1532579652", "attention_area": "    from keras.utils import jax_utils", "file_path": "files/00/01/00000100.py", "old_file_path": "files/01/01/00000101.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -84,6 +82,8 @@ def distribute_tensor(tensor, layout):\n     Returns:\n         Distributed value.\n     \"\"\"\n+    from keras.utils import jax_utils", "source": "def distribute_tensor(tensor, layout):\n    \"\"\"Distribute the tensor based on the layout.\n\n    Note that this function can be used both in eager context, or within a\n    jitted function.\n\n    Args:\n        tensor: `jax.Array` that need to be distributed.\n        layout: `TensorLayout` for the distribution information, or a\n            `jax.sharding.Sharding` instance.\n\n    Returns:\n        Distributed value.\n    \"\"\"\n    from keras.utils import jax_utils\n\n    if not isinstance(layout, jax.sharding.Sharding):\n        layout = _to_jax_layout(layout)\n    # TODO(scottzhu): This might not be a cheap check, we should consider\n    # have some proper JAX API for doing this check.\n    if jax_utils.is_in_jax_tracing_scope():\n        return jax.lax.with_sharding_constraint(tensor, layout)\n\n    if layout.is_fully_addressable:\n        return jax.device_put(tensor, layout)\n    else:\n        # Need to only distribute the value to local addressible devices, and\n        # repack them back into global format.\n        mapping = layout.addressable_devices_indices_map(tensor.shape)\n        local_values = jax.device_put(\n            [tensor[i] for i in mapping.values()], list(mapping.keys())\n        )\n        global_value = jax.make_array_from_single_device_arrays(\n            tensor.shape, layout, local_values\n        )\n        return global_value", "source_start_line": 71, "tokens": ["def", "distribute_tensor", "(", "tensor", ",", "layout", ")", ":", "\"\"\"Distribute the tensor based on the layout.    Note that this function can be used both in eager context, or within a    jitted function.    Args:        tensor: `jax.Array` that need to be distributed.        layout: `TensorLayout` for the distribution information, or a            `jax.sharding.Sharding` instance.    Returns:        Distributed value.    \"\"\"", "from", "keras", ".", "utils", "import", "jax_utils", "if", "not", "isinstance", "(", "layout", ",", "jax", ".", "sharding", ".", "Sharding", ")", ":", "layout", "=", "_to_jax_layout", "(", "layout", ")", "if", "jax_utils", ".", "is_in_jax_tracing_scope", "(", ")", ":", "return", "jax", ".", "lax", ".", "with_sharding_constraint", "(", "tensor", ",", "layout", ")", "if", "layout", ".", "is_fully_addressable", ":", "return", "jax", ".", "device_put", "(", "tensor", ",", "layout", ")", "else", ":", "mapping", "=", "layout", ".", "addressable_devices_indices_map", "(", "tensor", ".", "shape", ")", "local_values", "=", "jax", ".", "device_put", "(", "[", "tensor", "[", "i", "]", "for", "i", "in", "mapping", ".", "values", "(", ")", "]", ",", "list", "(", "mapping", ".", "keys", "(", ")", ")", ")", "global_value", "=", "jax", ".", "make_array_from_single_device_arrays", "(", "tensor", ".", "shape", ",", "layout", ",", "local_values", ")", "return", "global_value"], "to_mask": {"VAR": ["global_value", "layout", "local_values", "mapping", "tensor"], "METHOD": ["_to_jax_layout", "addressable_devices_indices_map", "device_put", "is_in_jax_tracing_scope", "isinstance", "keys", "list", "make_array_from_single_device_arrays", "values", "with_sharding_constraint"]}, "attention_idx_tokens": [9, 14], "patch": "@@ -84,6 +82,8 @@\n     Returns:\n         Distributed value.\n     \"\"\"\n+    from keras.utils import jax_utils", "ext_attention_idx_tokens": [9, 27], "uid": "49623ad9", "question": "Was that for a circular dependency?", "code": "def distribute tensor tensor layout \"\"\"Distribute the tensor based on the layout Note that this function can be used both in eager context or within a jitted function Args tensor `jax Array` that need to be distributed layout `TensorLayout` for the distribution information or a `jax sharding Sharding` instance Returns Distributed value \"\"\" from keras utils import jax utils if not isinstance layout jax sharding Sharding layout to jax layout layout # TODO scottzhu This might not be a cheap check we should consider # have some proper JAX API for doing this check if jax utils is in jax tracing scope return jax lax with sharding constraint tensor layout if layout is fully addressable return jax device put tensor layout else # Need to only distribute the value to local addressible devices and # repack them back into global format mapping layout addressable devices indices map tensor shape local values jax device put [tensor[i] for i in mapping values ] list mapping keys global value jax make array from single device arrays tensor shape layout local values return global value"}
{"message": "Ok, will do. Still in the `keras/utils` folder though?", "timestamp": "2024-03-20T20:12:58Z", "file_name": "keras/random/seed_generator.py", "range": {"start_line": 100, "end_line": 100, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1532790566", "html_url": "https://github.com/keras-team/keras/pull/19342#discussion_r1532790566", "attention_area": "    from keras.utils import jax_utils", "file_path": "files/02/01/00000102.py", "old_file_path": "files/03/01/00000103.py", "filters": {"comment_message": false, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -98,6 +97,8 @@ def from_config(cls, config):\n \n \n def global_seed_generator():\n+    from keras.utils import jax_utils", "source": "def global_seed_generator():\n    from keras.utils import jax_utils\n\n    if jax_utils.is_in_jax_tracing_scope():\n        raise ValueError(\n            \"[JAX RNG] When tracing a JAX function, \"\n            \"you should only use seeded random ops, e.g. \"\n            \"you should create a `SeedGenerator` instance, attach it \"\n            \"to your layer/model, and pass the instance as the `seed` \"\n            \"argument when calling random ops. Unseeded random ops \"\n            \"would get incorrectly traced by JAX and would become constant \"\n            \"after tracing. Example:\\n\\n\"\n            \"```\\n\"\n            \"# Make sure to set the seed generator as a layer attribute\\n\"\n            \"self.seed_generator = keras.random.SeedGenerator(seed=1337)\\n\"\n            \"...\\n\"\n            \"out = keras.random.normal(shape=(1,), seed=self.seed_generator)\\n\"\n            \"```\"\n        )\n    gen = global_state.get_global_attribute(\"global_seed_generator\")\n    if gen is None:\n        gen = SeedGenerator()\n        global_state.set_global_attribute(\"global_seed_generator\", gen)\n    return gen", "source_start_line": 99, "tokens": ["def", "global_seed_generator", "(", ")", ":", "from", "keras", ".", "utils", "import", "jax_utils", "if", "jax_utils", ".", "is_in_jax_tracing_scope", "(", ")", ":", "raise", "ValueError", "(", "\"[JAX RNG] When tracing a JAX function, \"", "\"you should only use seeded random ops, e.g. \"", "\"you should create a `SeedGenerator` instance, attach it \"", "\"to your layer/model, and pass the instance as the `seed` \"", "\"argument when calling random ops. Unseeded random ops \"", "\"would get incorrectly traced by JAX and would become constant \"", "\"after tracing. Example:\\n\\n\"", "\"```\\n\"", "\"# Make sure to set the seed generator as a layer attribute\\n\"", "\"self.seed_generator = keras.random.SeedGenerator(seed=1337)\\n\"", "\"...\\n\"", "\"out = keras.random.normal(shape=(1,), seed=self.seed_generator)\\n\"", "\"```\"", ")", "gen", "=", "global_state", ".", "get_global_attribute", "(", "\"global_seed_generator\"", ")", "if", "gen", "is", "None", ":", "gen", "=", "SeedGenerator", "(", ")", "global_state", ".", "set_global_attribute", "(", "\"global_seed_generator\"", ",", "gen", ")", "return", "gen"], "to_mask": {"VAR": ["gen"], "METHOD": ["SeedGenerator", "ValueError", "get_global_attribute", "is_in_jax_tracing_scope", "set_global_attribute"]}, "attention_idx_tokens": [5, 10], "patch": "@@ -98,6 +97,8 @@\n \n \n def global_seed_generator():\n+    from keras.utils import jax_utils", "ext_attention_idx_tokens": [5, 17], "uid": "d1125518", "question": "Ok, will do. Still in the `keras/utils` folder though?", "code": "def global seed generator from keras utils import jax utils if jax utils is in jax tracing scope raise ValueError \"[JAX RNG] When tracing a JAX function \" \"you should only use seeded random ops e g \" \"you should create a `SeedGenerator` instance attach it \" \"to your layer model and pass the instance as the `seed` \" \"argument when calling random ops Unseeded random ops \" \"would get incorrectly traced by JAX and would become constant \" \"after tracing Example \\n\\n\" \"```\\n\" \"# Make sure to set the seed generator as a layer attribute\\n\" \"self seed generator keras random SeedGenerator seed 1337 \\n\" \" \\n\" \"out keras random normal shape 1 seed self seed generator \\n\" \"```\" gen global state get global attribute \"global seed generator\" if gen is None gen SeedGenerator global state set global attribute \"global seed generator\" gen return gen"}
{"message": "Why was this necessary?", "timestamp": "2024-03-25T17:18:38Z", "file_name": "keras/layers/core/dense.py", "range": {"start_line": 336, "end_line": 336, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1537947788", "html_url": "https://github.com/keras-team/keras/pull/19377#discussion_r1537947788", "attention_area": "            raise NotImplementedError(", "file_path": "files/28/01/00000128.py", "old_file_path": "files/29/01/00000129.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -331,6 +331,12 @@ def grad_fn(*args, upstream=None):\n     def quantize(self, mode):\n         import gc\n \n+        # Prevent quantization of the subclasses\n+        if type(self) is not Dense:\n+            raise NotImplementedError(", "source": "def quantize(self, mode):\n        import gc\n\n        # Prevent quantization of the subclasses\n        if type(self) is not Dense:\n            raise NotImplementedError(\n                f\"Layer {self.__class__.__name__} does not have a `quantize()` \"\n                \"method implemented.\"\n            )\n        self._check_quantize_args(mode, self.compute_dtype)\n        if mode == \"int8\":\n            if backend.standardize_dtype(self._kernel.dtype) == \"int8\":\n                raise ValueError(\"`quantize` can only be done once per layer.\")\n            # Configure `self.inputs_quantizer`\n            self.inputs_quantizer = quantizers.AbsMaxQuantizer(axis=-1)\n            # Quantize `self._kernel` to int8 and compute corresponding scale\n            kernel_value, kernel_scale = quantizers.abs_max_quantize(\n                self._kernel, axis=0\n            )\n            kernel_scale = ops.squeeze(kernel_scale, axis=0)\n            self._tracker.unlock()\n            self._untrack_variable(self._kernel)\n            kernel_shape = self._kernel.shape\n            del self._kernel\n            self._kernel = self.add_weight(\n                name=\"kernel\",\n                shape=kernel_shape,\n                # Prevent adding a large constant to the computation graph\n                initializer=lambda shape, dtype: kernel_value,\n                dtype=\"int8\",\n                trainable=False,\n            )\n            self.kernel_scale = self.add_weight(\n                name=\"kernel_scale\",\n                shape=(self.units,),\n                # Prevent adding a large constant to the computation graph\n                initializer=lambda shape, dtype: kernel_scale,\n                trainable=False,\n            )\n            self._tracker.lock()\n        else:\n            NotImplementedError(\n                \"Invalid quantization mode. Expected 'int8'. \"\n                f\"Received: mode={mode}\"\n            )\n\n        # Set new dtype policy\n        if not isinstance(\n            self.dtype_policy, dtype_policies.QuantizedDTypePolicy\n        ):\n            quantized_dtype = f\"{mode}_from_{self.dtype_policy.name}\"\n            self.dtype_policy = dtype_policies.get(quantized_dtype)\n\n        # Release memory manually because sometimes the backend doesn't\n        gc.collect()", "source_start_line": 331, "tokens": ["def", "quantize", "(", "self", ",", "mode", ")", ":", "import", "gc", "if", "type", "(", "self", ")", "is", "not", "Dense", ":", "raise", "NotImplementedError", "(", "f\"", "{", "self", ".", "__class__", ".", "__name__", "}", "\"", "\"method implemented.\"", ")", "self", ".", "_check_quantize_args", "(", "mode", ",", "self", ".", "compute_dtype", ")", "if", "mode", "==", "\"int8\"", ":", "if", "backend", ".", "standardize_dtype", "(", "self", ".", "_kernel", ".", "dtype", ")", "==", "\"int8\"", ":", "raise", "ValueError", "(", "\"`quantize` can only be done once per layer.\"", ")", "self", ".", "inputs_quantizer", "=", "quantizers", ".", "AbsMaxQuantizer", "(", "axis", "=", "-", "1", ")", "kernel_value", ",", "kernel_scale", "=", "quantizers", ".", "abs_max_quantize", "(", "self", ".", "_kernel", ",", "axis", "=", "0", ")", "kernel_scale", "=", "ops", ".", "squeeze", "(", "kernel_scale", ",", "axis", "=", "0", ")", "self", ".", "_tracker", ".", "unlock", "(", ")", "self", ".", "_untrack_variable", "(", "self", ".", "_kernel", ")", "kernel_shape", "=", "self", ".", "_kernel", ".", "shape", "del", "self", ".", "_kernel", "self", ".", "_kernel", "=", "self", ".", "add_weight", "(", "name", "=", "\"kernel\"", ",", "shape", "=", "kernel_shape", ",", "initializer", "=", "lambda", "shape", ",", "dtype", ":", "kernel_value", ",", "dtype", "=", "\"int8\"", ",", "trainable", "=", "False", ",", ")", "self", ".", "kernel_scale", "=", "self", ".", "add_weight", "(", "name", "=", "\"kernel_scale\"", ",", "shape", "=", "(", "self", ".", "units", ",", ")", ",", "initializer", "=", "lambda", "shape", ",", "dtype", ":", "kernel_scale", ",", "trainable", "=", "False", ",", ")", "self", ".", "_tracker", ".", "lock", "(", ")", "else", ":", "NotImplementedError", "(", "\"Invalid quantization mode. Expected 'int8'. \"", "f\"", "{", "mode", "}", "\"", ")", "if", "not", "isinstance", "(", "self", ".", "dtype_policy", ",", "dtype_policies", ".", "QuantizedDTypePolicy", ")", ":", "quantized_dtype", "=", "f\"", "{", "mode", "}", "{", "self", ".", "dtype_policy", ".", "name", "}", "\"", "self", ".", "dtype_policy", "=", "dtype_policies", ".", "get", "(", "quantized_dtype", ")", "gc", ".", "collect", "(", ")"], "to_mask": {"VAR": ["_kernel", "dtype_policy", "inputs_quantizer", "kernel_scale", "kernel_shape", "kernel_value", "mode", "quantized_dtype", "self"], "METHOD": ["AbsMaxQuantizer", "NotImplementedError", "ValueError", "_check_quantize_args", "_untrack_variable", "abs_max_quantize", "add_weight", "collect", "get", "isinstance", "lock", "squeeze", "standardize_dtype", "type", "unlock"]}, "attention_idx_tokens": [19, 21], "patch": "@@ -331,6 +331,12 @@\n     def quantize(self, mode):\n         import gc\n \n+        # Prevent quantization of the subclasses\n+        if type(self) is not Dense:\n+            raise NotImplementedError(", "ext_attention_idx_tokens": [10, 42], "uid": "b68b8bb0", "question": "Why was this necessary?", "code": "def quantize self mode import gc # Prevent quantization of the subclasses if type self is not Dense raise NotImplementedError f\"Layer {self class name } does not have a `quantize ` \" \"method implemented \" self check quantize args mode self compute dtype if mode \"int8\" if backend standardize dtype self kernel dtype \"int8\" raise ValueError \"`quantize` can only be done once per layer \" # Configure `self inputs quantizer` self inputs quantizer quantizers AbsMaxQuantizer axis -1 # Quantize `self kernel` to int8 and compute corresponding scale kernel value kernel scale quantizers abs max quantize self kernel axis 0 kernel scale ops squeeze kernel scale axis 0 self tracker unlock self untrack variable self kernel kernel shape self kernel shape del self kernel self kernel self add weight name \"kernel\" shape kernel shape # Prevent adding a large constant to the computation graph initializer lambda shape dtype kernel value dtype \"int8\" trainable False self kernel scale self add weight name \"kernel scale\" shape self units # Prevent adding a large constant to the computation graph initializer lambda shape dtype kernel scale trainable False self tracker lock else NotImplementedError \"Invalid quantization mode Expected int8 \" f\"Received mode {mode}\" # Set new dtype policy if not isinstance self dtype policy dtype policies QuantizedDTypePolicy quantized dtype f\"{mode} from {self dtype policy name}\" self dtype policy dtype policies get quantized dtype # Release memory manually because sometimes the backend doesn t gc collect"}
{"message": "Sorry, I misunderstood the review.\r\nWhat's the difference in the two approaches?", "timestamp": "2024-04-01T06:14:02Z", "file_name": "keras/losses/losses.py", "range": {"start_line": 1991, "end_line": 1991, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1546001123", "html_url": "https://github.com/keras-team/keras/pull/19409#discussion_r1546001123", "attention_area": "    y_pred = ops.convert_to_tensor(y_pred)", "file_path": "files/50/01/00000150.py", "old_file_path": "files/49/01/00000149.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1934,3 +1934,69 @@ def ctc(y_true, y_pred):\n     return ops.ctc_loss(\n         y_true, y_pred, label_length, input_length, mask_index=0\n     )\n+\n+\n+@keras_export(\"keras.losses.Dice\")\n+class Dice(LossFunctionWrapper):\n+    \"\"\"Computes the Dice loss value between `y_true` and `y_pred`.\n+\n+    Formula:\n+    ```python\n+    loss = 1 - (2 * sum(y_true * y_pred)) / (sum(y_true) + sum(y_pred))\n+    ```\n+\n+    Args:\n+        y_true: tensor of true targets.\n+        y_pred: tensor of predicted targets.\n+\n+    Returns:\n+        Dice loss value.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        reduction=\"sum_over_batch_size\",\n+        name=\"dice\",\n+    ):\n+        super().__init__(\n+            dice,\n+            name=name,\n+            reduction=reduction,\n+        )\n+\n+    def get_config(self):\n+        return {\n+            \"name\": self.name,\n+            \"reduction\": self.reduction,\n+        }\n+\n+\n+@keras_export(\"keras.losses.dice\")\n+def dice(y_true, y_pred):\n+    \"\"\"Computes the Dice loss value between `y_true` and `y_pred`.\n+\n+    Formula:\n+    ```python\n+    loss = 1 - (2 * sum(y_true * y_pred)) / (sum(y_true) + sum(y_pred))\n+    ```\n+\n+    Args:\n+        y_true: tensor of true targets.\n+        y_pred: tensor of predicted targets.\n+\n+    Returns:\n+        Dice loss value.\n+    \"\"\"\n+    y_true = ops.convert_to_tensor(y_true)\n+    y_pred = ops.convert_to_tensor(y_pred)", "source": "def dice(y_true, y_pred):\n    \"\"\"Computes the Dice loss value between `y_true` and `y_pred`.\n\n    Formula:\n    ```python\n    loss = 1 - (2 * sum(y_true * y_pred)) / (sum(y_true) + sum(y_pred))\n    ```\n\n    Args:\n        y_true: tensor of true targets.\n        y_pred: tensor of predicted targets.\n\n    Returns:\n        Dice loss value.\n    \"\"\"\n    y_true = ops.convert_to_tensor(y_true)\n    y_pred = ops.convert_to_tensor(y_pred)\n\n    inputs = ops.reshape(y_true, [-1])\n    targets = ops.reshape(y_pred, [-1])\n\n    intersection = ops.sum(ops.dot(inputs, targets))\n    dice = ops.divide(\n        2.0 * intersection,\n        ops.sum(y_true) + ops.sum(y_pred) + backend.epsilon(),\n    )\n\n    return 1 - dice", "source_start_line": 1975, "tokens": ["def", "dice", "(", "y_true", ",", "y_pred", ")", ":", "\"\"\"Computes the Dice loss value between `y_true` and `y_pred`.    Formula:    ```python    loss = 1 - (2 * sum(y_true * y_pred)) / (sum(y_true) + sum(y_pred))    ```    Args:        y_true: tensor of true targets.        y_pred: tensor of predicted targets.    Returns:        Dice loss value.    \"\"\"", "y_true", "=", "ops", ".", "convert_to_tensor", "(", "y_true", ")", "y_pred", "=", "ops", ".", "convert_to_tensor", "(", "y_pred", ")", "inputs", "=", "ops", ".", "reshape", "(", "y_true", ",", "[", "-", "1", "]", ")", "targets", "=", "ops", ".", "reshape", "(", "y_pred", ",", "[", "-", "1", "]", ")", "intersection", "=", "ops", ".", "sum", "(", "ops", ".", "dot", "(", "inputs", ",", "targets", ")", ")", "dice", "=", "ops", ".", "divide", "(", "2.0", "*", "intersection", ",", "ops", ".", "sum", "(", "y_true", ")", "+", "ops", ".", "sum", "(", "y_pred", ")", "+", "backend", ".", "epsilon", "(", ")", ",", ")", "return", "1", "-", "dice"], "to_mask": {"VAR": ["dice", "inputs", "intersection", "targets", "y_pred", "y_true"], "METHOD": ["convert_to_tensor", "divide", "dot", "epsilon", "reshape", "sum"]}, "attention_idx_tokens": [17, 24], "patch": "@@ -1934,3 +1934,69 @@\n     return ops.ctc_loss(\n         y_true, y_pred, label_length, input_length, mask_index=0\n     )\n+\n+\n+@keras_export(\"keras.losses.Dice\")\n+class Dice(LossFunctionWrapper):\n+    \"\"\"Computes the Dice loss value between `y_true` and `y_pred`.\n+\n+    Formula:\n+    ```python\n+    loss = 1 - (2 * sum(y_true * y_pred)) / (sum(y_true) + sum(y_pred))\n+    ```\n+\n+    Args:\n+        y_true: tensor of true targets.\n+        y_pred: tensor of predicted targets.\n+\n+    Returns:\n+        Dice loss value.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        reduction=\"sum_over_batch_size\",\n+        name=\"dice\",\n+    ):\n+        super().__init__(\n+            dice,\n+            name=name,\n+            reduction=reduction,\n+        )\n+\n+    def get_config(self):\n+        return {\n+            \"name\": self.name,\n+            \"reduction\": self.reduction,\n+        }\n+\n+\n+@keras_export(\"keras.losses.dice\")\n+def dice(y_true, y_pred):\n+    \"\"\"Computes the Dice loss value between `y_true` and `y_pred`.\n+\n+    Formula:\n+    ```python\n+    loss = 1 - (2 * sum(y_true * y_pred)) / (sum(y_true) + sum(y_pred))\n+    ```\n+\n+    Args:\n+        y_true: tensor of true targets.\n+        y_pred: tensor of predicted targets.\n+\n+    Returns:\n+        Dice loss value.\n+    \"\"\"\n+    y_true = ops.convert_to_tensor(y_true)\n+    y_pred = ops.convert_to_tensor(y_pred)", "ext_attention_idx_tokens": [0, 96], "uid": "d5b00b60", "question": "Sorry, I misunderstood the review.  What's the difference in the two approaches?", "code": "def dice y true y pred \"\"\"Computes the Dice loss value between `y true` and `y pred` Formula ```python loss 1 - 2 * sum y true * y pred sum y true + sum y pred ``` Args y true tensor of true targets y pred tensor of predicted targets Returns Dice loss value \"\"\" y true ops convert to tensor y true y pred ops convert to tensor y pred inputs ops reshape y true [-1] targets ops reshape y pred [-1] intersection ops sum ops dot inputs targets dice ops divide 2 0 * intersection ops sum y true + ops sum y pred + backend epsilon return 1 - dice"}
{"message": "Any issue with `call`?", "timestamp": "2024-04-04T16:39:30Z", "file_name": "keras/export/export_lib_test.py", "range": {"start_line": 634, "end_line": 634, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1552055868", "html_url": "https://github.com/keras-team/keras/pull/19434#discussion_r1552055868", "attention_area": "                model.__call__,", "file_path": "files/55/01/00000155.py", "old_file_path": "files/56/01/00000156.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -611,7 +631,7 @@ def test_export_archive_errors(self):\n         ):\n             export_archive.add_endpoint(\n                 \"call\",\n-                model.call,\n+                model.__call__,", "source": "def test_export_archive_errors(self):\n        temp_filepath = os.path.join(self.get_temp_dir(), \"exported_model\")\n        model = models.Sequential([layers.Dense(2)])\n        model(tf.random.normal((2, 3)))\n\n        # Endpoint name reuse\n        export_archive = export_lib.ExportArchive()\n        export_archive.track(model)\n        export_archive.add_endpoint(\n            \"call\",\n            model.__call__,\n            input_signature=[tf.TensorSpec(shape=(None, 3), dtype=tf.float32)],\n        )\n        with self.assertRaisesRegex(ValueError, \"already taken\"):\n            export_archive.add_endpoint(\n                \"call\",\n                model.__call__,\n                input_signature=[\n                    tf.TensorSpec(shape=(None, 3), dtype=tf.float32)\n                ],\n            )\n\n        # Write out with no endpoints\n        export_archive = export_lib.ExportArchive()\n        export_archive.track(model)\n        with self.assertRaisesRegex(ValueError, \"No endpoints have been set\"):\n            export_archive.write_out(temp_filepath)\n\n        # Invalid object type\n        with self.assertRaisesRegex(ValueError, \"Invalid resource type\"):\n            export_archive = export_lib.ExportArchive()\n            export_archive.track(\"model\")\n\n        # Set endpoint with no input signature\n        export_archive = export_lib.ExportArchive()\n        export_archive.track(model)\n        with self.assertRaisesRegex(\n            ValueError, \"you must provide an `input_signature`\"\n        ):\n            export_archive.add_endpoint(\n                \"call\",\n                model.__call__,\n            )\n\n        # Set endpoint that has never been called\n        export_archive = export_lib.ExportArchive()\n        export_archive.track(model)\n\n        @tf.function()\n        def my_endpoint(x):\n            return model(x)\n\n        export_archive = export_lib.ExportArchive()\n        export_archive.track(model)\n        with self.assertRaisesRegex(\n            ValueError, \"you must either provide a function\"\n        ):\n            export_archive.add_endpoint(\n                \"call\",\n                my_endpoint,\n            )", "source_start_line": 593, "tokens": ["def", "test_export_archive_errors", "(", "self", ")", ":", "temp_filepath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "get_temp_dir", "(", ")", ",", "\"exported_model\"", ")", "model", "=", "models", ".", "Sequential", "(", "[", "layers", ".", "Dense", "(", "2", ")", "]", ")", "model", "(", "tf", ".", "random", ".", "normal", "(", "(", "2", ",", "3", ")", ")", ")", "export_archive", "=", "export_lib", ".", "ExportArchive", "(", ")", "export_archive", ".", "track", "(", "model", ")", "export_archive", ".", "add_endpoint", "(", "\"call\"", ",", "model", ".", "__call__", ",", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "shape", "=", "(", "None", ",", "3", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "]", ",", ")", "with", "self", ".", "assertRaisesRegex", "(", "ValueError", ",", "\"already taken\"", ")", ":", "export_archive", ".", "add_endpoint", "(", "\"call\"", ",", "model", ".", "__call__", ",", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "shape", "=", "(", "None", ",", "3", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "]", ",", ")", "export_archive", "=", "export_lib", ".", "ExportArchive", "(", ")", "export_archive", ".", "track", "(", "model", ")", "with", "self", ".", "assertRaisesRegex", "(", "ValueError", ",", "\"No endpoints have been set\"", ")", ":", "export_archive", ".", "write_out", "(", "temp_filepath", ")", "with", "self", ".", "assertRaisesRegex", "(", "ValueError", ",", "\"Invalid resource type\"", ")", ":", "export_archive", "=", "export_lib", ".", "ExportArchive", "(", ")", "export_archive", ".", "track", "(", "\"model\"", ")", "export_archive", "=", "export_lib", ".", "ExportArchive", "(", ")", "export_archive", ".", "track", "(", "model", ")", "with", "self", ".", "assertRaisesRegex", "(", "ValueError", ",", "\"you must provide an `input_signature`\"", ")", ":", "export_archive", ".", "add_endpoint", "(", "\"call\"", ",", "model", ".", "__call__", ",", ")", "export_archive", "=", "export_lib", ".", "ExportArchive", "(", ")", "export_archive", ".", "track", "(", "model", ")", "@", "tf", ".", "function", "(", ")", "def", "my_endpoint", "(", "x", ")", ":", "return", "model", "(", "x", ")", "export_archive", "=", "export_lib", ".", "ExportArchive", "(", ")", "export_archive", ".", "track", "(", "model", ")", "with", "self", ".", "assertRaisesRegex", "(", "ValueError", ",", "\"you must either provide a function\"", ")", ":", "export_archive", ".", "add_endpoint", "(", "\"call\"", ",", "my_endpoint", ",", ")"], "to_mask": {"VAR": ["export_archive", "model", "self", "temp_filepath", "x"], "METHOD": ["Dense", "ExportArchive", "Sequential", "TensorSpec", "add_endpoint", "assertRaisesRegex", "function", "get_temp_dir", "join", "model", "normal", "track", "write_out"]}, "attention_idx_tokens": [224, 227], "patch": "@@ -611,7 +631,7 @@\n         ):\n             export_archive.add_endpoint(\n                 \"call\",\n-                model.call,\n+                model.__call__,", "ext_attention_idx_tokens": [224, 228], "uid": "c8dcd665", "question": "Any issue with `call`?", "code": "def test export archive errors self temp filepath os path join self get temp dir \"exported model\" model models Sequential [layers Dense 2 ] model tf random normal 2 3 # Endpoint name reuse export archive export lib ExportArchive export archive track model export archive add endpoint \"call\" model call input signature [tf TensorSpec shape None 3 dtype tf float32 ] with self assertRaisesRegex ValueError \"already taken\" export archive add endpoint \"call\" model call input signature [ tf TensorSpec shape None 3 dtype tf float32 ] # Write out with no endpoints export archive export lib ExportArchive export archive track model with self assertRaisesRegex ValueError \"No endpoints have been set\" export archive write out temp filepath # Invalid object type with self assertRaisesRegex ValueError \"Invalid resource type\" export archive export lib ExportArchive export archive track \"model\" # Set endpoint with no input signature export archive export lib ExportArchive export archive track model with self assertRaisesRegex ValueError \"you must provide an `input signature`\" export archive add endpoint \"call\" model call # Set endpoint that has never been called export archive export lib ExportArchive export archive track model @tf function def my endpoint x return model x export archive export lib ExportArchive export archive track model with self assertRaisesRegex ValueError \"you must either provide a function\" export archive add endpoint \"call\" my endpoint"}
{"message": "What's the original issue with using a list though?", "timestamp": "2024-04-12T05:14:32Z", "file_name": "keras/backend/torch/layer.py", "range": {"start_line": 16, "end_line": 16, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1562022500", "html_url": "https://github.com/keras-team/keras/pull/19495#discussion_r1562022500", "attention_area": "        self.torch_params = torch.nn.ParameterDict(", "file_path": "files/68/01/00000168.py", "old_file_path": "files/69/01/00000169.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -13,8 +13,8 @@ def _post_build(self):\n         self._track_variables()\n \n     def _track_variables(self):\n-        self.torch_params = torch.nn.ParameterList(\n-            [variable.value for variable in self.variables]\n+        self.torch_params = torch.nn.ParameterDict(", "source": "def _track_variables(self):\n        self.torch_params = torch.nn.ParameterDict(\n            {variable.path: variable.value for variable in self.variables}\n        )", "source_start_line": 15, "tokens": ["def", "_track_variables", "(", "self", ")", ":", "self", ".", "torch_params", "=", "torch", ".", "nn", ".", "ParameterDict", "(", "{", "variable", ".", "path", ":", "variable", ".", "value", "for", "variable", "in", "self", ".", "variables", "}", ")"], "to_mask": {"VAR": ["self", "torch_params"], "METHOD": ["ParameterDict"]}, "attention_idx_tokens": [6, 15], "patch": "@@ -13,8 +13,8 @@\n         self._track_variables()\n \n     def _track_variables(self):\n-        self.torch_params = torch.nn.ParameterList(\n-            [variable.value for variable in self.variables]\n+        self.torch_params = torch.nn.ParameterDict(", "ext_attention_idx_tokens": [6, 31], "uid": "02c5841c", "question": "What's the original issue with using a list though?", "code": "def track variables self self torch params torch nn ParameterDict {variable path variable value for variable in self variables}"}
{"message": "Isn't this because MLX doesn't support int64?", "timestamp": "2024-04-23T17:04:15Z", "file_name": "keras/src/backend/mlx/core.py", "range": {"start_line": 74, "end_line": 74, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1576597280", "html_url": "https://github.com/keras-team/keras/pull/19599#discussion_r1576597280", "attention_area": "        x = x.astype(standardize_dtype(x.dtype))", "file_path": "files/24/02/00000224.py", "old_file_path": "files/25/02/00000225.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -71,8 +71,6 @@ def convert_to_tensor(x, dtype=None, sparse=None):\n         return x.value\n \n     if isinstance(x, np.ndarray):\n-        if x.dtype == np.int64:\n-            x = x.astype(np.int32)\n         x = x.astype(standardize_dtype(x.dtype))", "source": "def convert_to_tensor(x, dtype=None, sparse=None):\n    if sparse:\n        raise ValueError(\"`sparse=True` is not supported with mlx backend\")\n    mlx_dtype = to_mlx_dtype(dtype) if dtype is not None else None\n\n    if is_tensor(x):\n        if dtype is None:\n            return x\n        return x.astype(mlx_dtype)\n\n    if isinstance(x, Variable):\n        if dtype and standardize_dtype(dtype) != x.dtype:\n            return x.value.astype(mlx_dtype)\n        return x.value\n\n    if isinstance(x, np.ndarray):\n        x = x.astype(standardize_dtype(x.dtype))\n        return mx.array(x, dtype=mlx_dtype)\n\n    if isinstance(x, list):\n\n        def to_scalar_list(x):\n            if isinstance(x, list):\n                return [to_scalar_list(xi) for xi in x]\n            elif isinstance(x, mx.array):\n                if x.ndim == 0:\n                    return x.item()\n                else:\n                    return x.tolist()\n            else:\n                return x\n\n        return mx.array(to_scalar_list(x), dtype=mlx_dtype)\n\n    return mx.array(x, dtype=mlx_dtype)", "source_start_line": 58, "tokens": ["def", "convert_to_tensor", "(", "x", ",", "dtype", "=", "None", ",", "sparse", "=", "None", ")", ":", "if", "sparse", ":", "raise", "ValueError", "(", "\"`sparse=True` is not supported with mlx backend\"", ")", "mlx_dtype", "=", "to_mlx_dtype", "(", "dtype", ")", "if", "dtype", "is", "not", "None", "else", "None", "if", "is_tensor", "(", "x", ")", ":", "if", "dtype", "is", "None", ":", "return", "x", "return", "x", ".", "astype", "(", "mlx_dtype", ")", "if", "isinstance", "(", "x", ",", "Variable", ")", ":", "if", "dtype", "and", "standardize_dtype", "(", "dtype", ")", "!=", "x", ".", "dtype", ":", "return", "x", ".", "value", ".", "astype", "(", "mlx_dtype", ")", "return", "x", ".", "value", "if", "isinstance", "(", "x", ",", "np", ".", "ndarray", ")", ":", "x", "=", "x", ".", "astype", "(", "standardize_dtype", "(", "x", ".", "dtype", ")", ")", "return", "mx", ".", "array", "(", "x", ",", "dtype", "=", "mlx_dtype", ")", "if", "isinstance", "(", "x", ",", "list", ")", ":", "def", "to_scalar_list", "(", "x", ")", ":", "if", "isinstance", "(", "x", ",", "list", ")", ":", "return", "[", "to_scalar_list", "(", "xi", ")", "for", "xi", "in", "x", "]", "elif", "isinstance", "(", "x", ",", "mx", ".", "array", ")", ":", "if", "x", ".", "ndim", "==", "0", ":", "return", "x", ".", "item", "(", ")", "else", ":", "return", "x", ".", "tolist", "(", ")", "else", ":", "return", "x", "return", "mx", ".", "array", "(", "to_scalar_list", "(", "x", ")", ",", "dtype", "=", "mlx_dtype", ")", "return", "mx", ".", "array", "(", "x", ",", "dtype", "=", "mlx_dtype", ")"], "to_mask": {"VAR": ["dtype", "mlx_dtype", "sparse", "x"], "METHOD": ["ValueError", "array", "astype", "is_tensor", "isinstance", "item", "standardize_dtype", "to_mlx_dtype", "to_scalar_list", "tolist"]}, "attention_idx_tokens": [98, 110], "patch": "@@ -71,8 +71,6 @@\n         return x.value\n \n     if isinstance(x, np.ndarray):\n-        if x.dtype == np.int64:\n-            x = x.astype(np.int32)\n         x = x.astype(standardize_dtype(x.dtype))", "ext_attention_idx_tokens": [98, 110], "uid": "61b2e9ec", "question": "Isn't this because MLX doesn't support int64?", "code": "def convert to tensor x dtype None sparse None if sparse raise ValueError \"`sparse True` is not supported with mlx backend\" mlx dtype to mlx dtype dtype if dtype is not None else None if is tensor x if dtype is None return x return x astype mlx dtype if isinstance x Variable if dtype and standardize dtype dtype ! x dtype return x value astype mlx dtype return x value if isinstance x np ndarray x x astype standardize dtype x dtype return mx array x dtype mlx dtype if isinstance x list def to scalar list x if isinstance x list return [to scalar list xi for xi in x] elif isinstance x mx array if x ndim 0 return x item else return x tolist else return x return mx array to scalar list x dtype mlx dtype return mx array x dtype mlx dtype"}
{"message": "How do you create a compiled graph in OpenVINO?", "timestamp": "2024-05-19T22:40:40Z", "file_name": "keras/src/ops/function.py", "range": {"start_line": 84, "end_line": 84, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1606115086", "html_url": "https://github.com/keras-team/keras/pull/19727#discussion_r1606115086", "attention_area": "        if backend() == \"openvino\":", "file_path": "files/48/02/00000248.py", "old_file_path": "files/49/02/00000249.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -81,6 +81,32 @@ def __init__(self, inputs, outputs, name=None):\n         self._nodes_by_depth = nodes_by_depth\n         self._operations = operations\n         self._operations_by_depth = operations_by_depth\n+        if backend() == \"openvino\":", "source": "def __init__(self, inputs, outputs, name=None):\n        super().__init__(name=name)\n\n        if backend() == \"tensorflow\":\n            # Temporary work around for\n            # https://github.com/keras-team/keras/issues/931\n            # This stop tensorflow from wrapping tf.function output in a\n            # _DictWrapper object.\n            _self_setattr_tracking = getattr(\n                self, \"_self_setattr_tracking\", True\n            )\n            self._self_setattr_tracking = False\n        self._inputs_struct = tree.map_structure(lambda x: x, inputs)\n        self._outputs_struct = tree.map_structure(lambda x: x, outputs)\n        self._inputs = tree.flatten(inputs)\n        self._outputs = tree.flatten(outputs)\n        if not self._inputs:\n            raise ValueError(\n                \"`inputs` argument cannot be empty. Received:\\n\"\n                f\"inputs={inputs}\\n\"\n                f\"outputs={outputs}\"\n            )\n        if not self._outputs:\n            raise ValueError(\n                \"`outputs` argument cannot be empty. Received:\\n\"\n                f\"inputs={inputs}\\n\"\n                f\"outputs={outputs}\"\n            )\n\n        if backend() == \"tensorflow\":\n            self._self_setattr_tracking = _self_setattr_tracking\n\n        (nodes, nodes_by_depth, operations, operations_by_depth) = map_graph(\n            self._inputs, self._outputs\n        )\n        self._nodes = nodes\n        self._nodes_by_depth = nodes_by_depth\n        self._operations = operations\n        self._operations_by_depth = operations_by_depth\n        if backend() == \"openvino\":\n            from keras.src.backend.openvino.core import OPENVINO_DTYPES\n            from keras.src.backend.openvino.core import get_device\n            import openvino as ov\n            import openvino.runtime.opset14 as ov_opset\n            from openvino import Core\n            # prepare OpenVINO parameters\n            ov_inputs = []\n            for _input in self._inputs:\n                ov_type = OPENVINO_DTYPES[_input.dtype]\n                ov_shape = _input.shape\n                ov_shape = list(ov_shape)\n                for i in range(len(ov_shape)):\n                    if ov_shape[i] is None:\n                        ov_shape[i] = -1\n                param = ov_opset.parameter(shape=ov_shape, dtype=ov_type)\n                ov_inputs.append(param)\n                pass\n            # build OpenVINO graph - ov.Model\n            ov_outputs = self._run_through_graph(ov_inputs, operation_fn=lambda op: op)\n            ov_outputs = tree.flatten(ov_outputs)\n            self._ov_model = ov.Model(results=ov_outputs, parameters=ov_inputs)\n            self._ov_core = Core()\n            self._ov_device = get_device()\n            self._ov_compiled_model = self._ov_core.compile_model(self._ov_model, self._ov_device)\n            pass", "source_start_line": 45, "tokens": ["def", "__init__", "(", "self", ",", "inputs", ",", "outputs", ",", "name", "=", "None", ")", ":", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "if", "backend", "(", ")", "==", "\"tensorflow\"", ":", "_self_setattr_tracking", "=", "getattr", "(", "self", ",", "\"_self_setattr_tracking\"", ",", "True", ")", "self", ".", "_self_setattr_tracking", "=", "False", "self", ".", "_inputs_struct", "=", "tree", ".", "map_structure", "(", "lambda", "x", ":", "x", ",", "inputs", ")", "self", ".", "_outputs_struct", "=", "tree", ".", "map_structure", "(", "lambda", "x", ":", "x", ",", "outputs", ")", "self", ".", "_inputs", "=", "tree", ".", "flatten", "(", "inputs", ")", "self", ".", "_outputs", "=", "tree", ".", "flatten", "(", "outputs", ")", "if", "not", "self", ".", "_inputs", ":", "raise", "ValueError", "(", "\"`inputs` argument cannot be empty. Received:\\n\"", "f\"", "{", "inputs", "}", "\\n", "\"", "f\"", "{", "outputs", "}", "\"", ")", "if", "not", "self", ".", "_outputs", ":", "raise", "ValueError", "(", "\"`outputs` argument cannot be empty. Received:\\n\"", "f\"", "{", "inputs", "}", "\\n", "\"", "f\"", "{", "outputs", "}", "\"", ")", "if", "backend", "(", ")", "==", "\"tensorflow\"", ":", "self", ".", "_self_setattr_tracking", "=", "_self_setattr_tracking", "(", "nodes", ",", "nodes_by_depth", ",", "operations", ",", "operations_by_depth", ")", "=", "map_graph", "(", "self", ".", "_inputs", ",", "self", ".", "_outputs", ")", "self", ".", "_nodes", "=", "nodes", "self", ".", "_nodes_by_depth", "=", "nodes_by_depth", "self", ".", "_operations", "=", "operations", "self", ".", "_operations_by_depth", "=", "operations_by_depth", "if", "backend", "(", ")", "==", "\"openvino\"", ":", "from", "keras", ".", "src", ".", "backend", ".", "openvino", ".", "core", "import", "OPENVINO_DTYPES", "from", "keras", ".", "src", ".", "backend", ".", "openvino", ".", "core", "import", "get_device", "import", "openvino", "as", "ov", "import", "openvino", ".", "runtime", ".", "opset14", "as", "ov_opset", "from", "openvino", "import", "Core", "ov_inputs", "=", "[", "]", "for", "_input", "in", "self", ".", "_inputs", ":", "ov_type", "=", "OPENVINO_DTYPES", "[", "_input", ".", "dtype", "]", "ov_shape", "=", "_input", ".", "shape", "ov_shape", "=", "list", "(", "ov_shape", ")", "for", "i", "in", "range", "(", "len", "(", "ov_shape", ")", ")", ":", "if", "ov_shape", "[", "i", "]", "is", "None", ":", "ov_shape", "[", "i", "]", "=", "-", "1", "param", "=", "ov_opset", ".", "parameter", "(", "shape", "=", "ov_shape", ",", "dtype", "=", "ov_type", ")", "ov_inputs", ".", "append", "(", "param", ")", "pass", "ov_outputs", "=", "self", ".", "_run_through_graph", "(", "ov_inputs", ",", "operation_fn", "=", "lambda", "op", ":", "op", ")", "ov_outputs", "=", "tree", ".", "flatten", "(", "ov_outputs", ")", "self", ".", "_ov_model", "=", "ov", ".", "Model", "(", "results", "=", "ov_outputs", ",", "parameters", "=", "ov_inputs", ")", "self", ".", "_ov_core", "=", "Core", "(", ")", "self", ".", "_ov_device", "=", "get_device", "(", ")", "self", ".", "_ov_compiled_model", "=", "self", ".", "_ov_core", ".", "compile_model", "(", "self", ".", "_ov_model", ",", "self", ".", "_ov_device", ")", "pass"], "to_mask": {"VAR": ["_input", "_inputs", "_inputs_struct", "_nodes", "_nodes_by_depth", "_operations", "_operations_by_depth", "_outputs", "_outputs_struct", "_ov_compiled_model", "_ov_core", "_ov_device", "_ov_model", "_self_setattr_tracking", "i", "inputs", "name", "outputs", "ov_inputs", "ov_outputs", "ov_shape", "ov_type", "param", "self"], "METHOD": ["Core", "Model", "ValueError", "__init__", "_run_through_graph", "append", "backend", "compile_model", "flatten", "get_device", "getattr", "len", "list", "map_graph", "map_structure", "parameter", "range", "super"]}, "attention_idx_tokens": [192, 198], "patch": "@@ -81,6 +81,32 @@\n         self._nodes_by_depth = nodes_by_depth\n         self._operations = operations\n         self._operations_by_depth = operations_by_depth\n+        if backend() == \"openvino\":", "ext_attention_idx_tokens": [192, 387], "uid": "8d065bb5", "question": "How do you create a compiled graph in OpenVINO?", "code": "def init self inputs outputs name None super init name name if backend \"tensorflow\" # Temporary work around for # https github com keras-team keras issues 931 # This stop tensorflow from wrapping tf function output in a # DictWrapper object self setattr tracking getattr self \" self setattr tracking\" True self self setattr tracking False self inputs struct tree map structure lambda x x inputs self outputs struct tree map structure lambda x x outputs self inputs tree flatten inputs self outputs tree flatten outputs if not self inputs raise ValueError \"`inputs` argument cannot be empty Received \\n\" f\"inputs {inputs}\\n\" f\"outputs {outputs}\" if not self outputs raise ValueError \"`outputs` argument cannot be empty Received \\n\" f\"inputs {inputs}\\n\" f\"outputs {outputs}\" if backend \"tensorflow\" self self setattr tracking self setattr tracking nodes nodes by depth operations operations by depth map graph self inputs self outputs self nodes nodes self nodes by depth nodes by depth self operations operations self operations by depth operations by depth if backend \"openvino\" from keras src backend openvino core import OPENVINO DTYPES from keras src backend openvino core import get device import openvino as ov import openvino runtime opset14 as ov opset from openvino import Core # prepare OpenVINO parameters ov inputs [] for input in self inputs ov type OPENVINO DTYPES[ input dtype] ov shape input shape ov shape list ov shape for i in range len ov shape if ov shape[i] is None ov shape[i] -1 param ov opset parameter shape ov shape dtype ov type ov inputs append param pass # build OpenVINO graph - ov Model ov outputs self run through graph ov inputs operation fn lambda op op ov outputs tree flatten ov outputs self ov model ov Model results ov outputs parameters ov inputs self ov core Core self ov device get device self ov compiled model self ov core compile model self ov model self ov device pass"}
{"message": "Ok, but do you think I can change it to `True` to be consistent with `compute_loss`? Or should I keep `False` for backwards compatibility?", "timestamp": "2024-06-11T23:39:09Z", "file_name": "keras/src/backend/jax/trainer.py", "range": {"start_line": 37, "end_line": 37, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1635594311", "html_url": "https://github.com/keras-team/keras/pull/19840#discussion_r1635594311", "attention_area": "        training,", "file_path": "files/70/02/00000270.py", "old_file_path": "files/71/02/00000271.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -34,7 +34,7 @@ def compute_loss_and_updates(\n         x,\n         y,\n         sample_weight,\n-        training=False,\n+        training,", "source": "def compute_loss_and_updates(\n        self,\n        trainable_variables,\n        non_trainable_variables,\n        metrics_variables,\n        x,\n        y,\n        sample_weight,\n        training,\n        optimizer_variables=None,\n    ):\n        \"\"\"This method is stateless and is intended for use with jax.grad.\"\"\"\n        kwargs = {}\n        if self._call_has_training_arg:\n            kwargs[\"training\"] = training\n\n        # Run stateless forward pass\n        y_pred, non_trainable_variables, losses = self.stateless_call(\n            trainable_variables,\n            non_trainable_variables,\n            x,\n            return_losses=True,\n            **kwargs,\n        )\n        if losses:\n            # Make forward pass losses available to compute_loss.\n            self._losses_override.clear()\n            self._losses_override = losses\n\n        loss, variables = self.stateless_compute_loss(\n            trainable_variables,\n            non_trainable_variables,\n            metrics_variables,\n            x=x,\n            y=y,\n            y_pred=y_pred,\n            sample_weight=sample_weight,\n            training=training,\n        )\n        if losses:\n            self._losses_override.clear()\n        (trainable_variables, non_trainable_variables, metrics_variables) = (\n            variables\n        )\n\n        # Handle loss scaling\n        unscaled_loss = loss\n        if training and self.optimizer is not None:\n            # Scale loss with a StatelessScope, to use an update scale variable.\n            mapping = list(zip(self.optimizer.variables, optimizer_variables))\n            with backend.StatelessScope(state_mapping=mapping):\n                loss = self.optimizer.scale_loss(loss)\n        return loss, (\n            unscaled_loss,\n            y_pred,\n            non_trainable_variables,\n            metrics_variables,\n        )", "source_start_line": 29, "tokens": ["def", "compute_loss_and_updates", "(", "self", ",", "trainable_variables", ",", "non_trainable_variables", ",", "metrics_variables", ",", "x", ",", "y", ",", "sample_weight", ",", "training", ",", "optimizer_variables", "=", "None", ",", ")", ":", "\"\"\"This method is stateless and is intended for use with jax.grad.\"\"\"", "kwargs", "=", "{", "}", "if", "self", ".", "_call_has_training_arg", ":", "kwargs", "[", "\"training\"", "]", "=", "training", "y_pred", ",", "non_trainable_variables", ",", "losses", "=", "self", ".", "stateless_call", "(", "trainable_variables", ",", "non_trainable_variables", ",", "x", ",", "return_losses", "=", "True", ",", "**", "kwargs", ",", ")", "if", "losses", ":", "self", ".", "_losses_override", ".", "clear", "(", ")", "self", ".", "_losses_override", "=", "losses", "loss", ",", "variables", "=", "self", ".", "stateless_compute_loss", "(", "trainable_variables", ",", "non_trainable_variables", ",", "metrics_variables", ",", "x", "=", "x", ",", "y", "=", "y", ",", "y_pred", "=", "y_pred", ",", "sample_weight", "=", "sample_weight", ",", "training", "=", "training", ",", ")", "if", "losses", ":", "self", ".", "_losses_override", ".", "clear", "(", ")", "(", "trainable_variables", ",", "non_trainable_variables", ",", "metrics_variables", ")", "=", "(", "variables", ")", "unscaled_loss", "=", "loss", "if", "training", "and", "self", ".", "optimizer", "is", "not", "None", ":", "mapping", "=", "list", "(", "zip", "(", "self", ".", "optimizer", ".", "variables", ",", "optimizer_variables", ")", ")", "with", "backend", ".", "StatelessScope", "(", "state_mapping", "=", "mapping", ")", ":", "loss", "=", "self", ".", "optimizer", ".", "scale_loss", "(", "loss", ")", "return", "loss", ",", "(", "unscaled_loss", ",", "y_pred", ",", "non_trainable_variables", ",", "metrics_variables", ",", ")"], "to_mask": {"VAR": ["_losses_override", "kwargs", "loss", "losses", "mapping", "metrics_variables", "non_trainable_variables", "optimizer_variables", "sample_weight", "self", "trainable_variables", "training", "unscaled_loss", "variables", "x", "y", "y_pred"], "METHOD": ["StatelessScope", "clear", "list", "scale_loss", "stateless_call", "stateless_compute_loss", "zip"]}, "attention_idx_tokens": [17, 18], "patch": "@@ -34,7 +34,7 @@\n         x,\n         y,\n         sample_weight,\n-        training=False,\n+        training,", "ext_attention_idx_tokens": [17, 22], "uid": "78984048", "question": "Ok, but do you think I can change it to `True` to be consistent with `compute_loss`? Or should I keep `False` for backwards compatibility?", "code": "def compute loss and updates self trainable variables non trainable variables metrics variables x y sample weight training optimizer variables None \"\"\"This method is stateless and is intended for use with jax grad \"\"\" kwargs {} if self call has training arg kwargs[\"training\"] training # Run stateless forward pass y pred non trainable variables losses self stateless call trainable variables non trainable variables x return losses True **kwargs if losses # Make forward pass losses available to compute loss self losses override clear self losses override losses loss variables self stateless compute loss trainable variables non trainable variables metrics variables x x y y y pred y pred sample weight sample weight training training if losses self losses override clear trainable variables non trainable variables metrics variables variables # Handle loss scaling unscaled loss loss if training and self optimizer is not None # Scale loss with a StatelessScope to use an update scale variable mapping list zip self optimizer variables optimizer variables with backend StatelessScope state mapping mapping loss self optimizer scale loss loss return loss unscaled loss y pred non trainable variables metrics variables"}
{"message": "It's not supported how? Could we support it? The code is written in backend-agnostic ops.", "timestamp": "2024-07-21T04:31:12Z", "file_name": "keras/src/ops/nn_test.py", "range": {"start_line": 1255, "end_line": 1255, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1685636544", "html_url": "https://github.com/keras-team/keras/pull/20022#discussion_r1685636544", "attention_area": "            pytest.skip(\"unsupported tuple dim by torch\")", "file_path": "files/32/03/00000332.py", "old_file_path": "files/33/03/00000333.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1248,6 +1250,17 @@ def test_softmax(self):\n             ],\n         )\n \n+    def test_softmax_correctness_with_axis_tuple(self):\n+        if backend.backend() == \"torch\":\n+            pytest.skip(\"unsupported tuple dim by torch\")", "source": "def test_softmax_correctness_with_axis_tuple(self):\n        if backend.backend() == \"torch\":\n            pytest.skip(\"unsupported tuple dim by torch\")\n\n        input = np.array([[[1.0, 2.0], [3.0, 4.0]], [[5.0, 6.0], [7.0, 8.0]]])\n        combination = combinations(range(3), 2)\n        for axis in list(combination):\n            result = knn.softmax(input, axis=axis)\n            normalized_sum_by_axis = np.sum(result, axis=axis)\n            self.assertAllClose(normalized_sum_by_axis, 1.0)", "source_start_line": 1253, "tokens": ["def", "test_softmax_correctness_with_axis_tuple", "(", "self", ")", ":", "if", "backend", ".", "backend", "(", ")", "==", "\"torch\"", ":", "pytest", ".", "skip", "(", "\"unsupported tuple dim by torch\"", ")", "input", "=", "np", ".", "array", "(", "[", "[", "[", "1.0", ",", "2.0", "]", ",", "[", "3.0", ",", "4.0", "]", "]", ",", "[", "[", "5.0", ",", "6.0", "]", ",", "[", "7.0", ",", "8.0", "]", "]", "]", ")", "combination", "=", "combinations", "(", "range", "(", "3", ")", ",", "2", ")", "for", "axis", "in", "list", "(", "combination", ")", ":", "result", "=", "knn", ".", "softmax", "(", "input", ",", "axis", "=", "axis", ")", "normalized_sum_by_axis", "=", "np", ".", "sum", "(", "result", ",", "axis", "=", "axis", ")", "self", ".", "assertAllClose", "(", "normalized_sum_by_axis", ",", "1.0", ")"], "to_mask": {"VAR": ["axis", "combination", "input", "normalized_sum_by_axis", "result", "self"], "METHOD": ["array", "assertAllClose", "backend", "combinations", "list", "range", "skip", "softmax", "sum"]}, "attention_idx_tokens": [15, 20], "patch": "@@ -1248,6 +1250,17 @@\n             ],\n         )\n \n+    def test_softmax_correctness_with_axis_tuple(self):\n+        if backend.backend() == \"torch\":\n+            pytest.skip(\"unsupported tuple dim by torch\")", "ext_attention_idx_tokens": [0, 107], "uid": "a4e20250", "question": "It's not supported how? Could we support it? The code is written in backend-agnostic ops.", "code": "def test softmax correctness with axis tuple self if backend backend \"torch\" pytest skip \"unsupported tuple dim by torch\" input np array [[[1 0 2 0] [3 0 4 0]] [[5 0 6 0] [7 0 8 0]]] combination combinations range 3 2 for axis in list combination result knn softmax input axis axis normalized sum by axis np sum result axis axis self assertAllClose normalized sum by axis 1 0"}
{"message": "Wouldn't an epsilon value of 1e-12 generally lead to overflow in float32, float16?", "timestamp": "2024-09-02T16:37:09Z", "file_name": "keras/src/backend/tensorflow/nn.py", "range": {"start_line": 901, "end_line": 901, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1741120759", "html_url": "https://github.com/keras-team/keras/pull/20196#discussion_r1741120759", "attention_area": "def l2_normalize(x, axis=None, epsilon=1e-12):", "file_path": "files/69/03/00000369.py", "old_file_path": "files/70/03/00000370.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -898,6 +898,11 @@ def ctc_decode(\n     return decoded_dense, scores\n \n \n+def l2_normalize(x, axis=None, epsilon=1e-12):", "source": "def l2_normalize(x, axis=None, epsilon=1e-12):\n    x = convert_to_tensor(x)\n    return tf.nn.l2_normalize(x, axis=axis, epsilon=epsilon)", "source_start_line": 901, "tokens": ["def", "l2_normalize", "(", "x", ",", "axis", "=", "None", ",", "epsilon", "=", "1e-12", ")", ":", "x", "=", "convert_to_tensor", "(", "x", ")", "return", "tf", ".", "nn", ".", "l2_normalize", "(", "x", ",", "axis", "=", "axis", ",", "epsilon", "=", "epsilon", ")"], "to_mask": {"VAR": ["axis", "epsilon", "x"], "METHOD": ["convert_to_tensor", "l2_normalize"]}, "attention_idx_tokens": [0, 13], "patch": "@@ -898,6 +898,11 @@\n     return decoded_dense, scores\n \n \n+def l2_normalize(x, axis=None, epsilon=1e-12):", "ext_attention_idx_tokens": [0, 36], "uid": "34323af3", "question": "Wouldn't an epsilon value of 1e-12 generally lead to overflow in float32, float16?", "code": "def l2 normalize x axis None epsilon 1e-12 x convert to tensor x return tf nn l2 normalize x axis axis epsilon epsilon"}
{"message": "Is this a TODO?", "timestamp": "2024-09-09T17:54:58Z", "file_name": "keras/src/utils/saved_model_utils.py", "range": {"start_line": 25, "end_line": 25, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1750685252", "html_url": "https://github.com/keras-team/keras/pull/20239#discussion_r1750685252", "attention_area": "            pass", "file_path": "files/86/03/00000386.py", "old_file_path": null, "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": true}, "language": "python", "replies": {}, "diff_hunk": "@@ -0,0 +1,70 @@\n+import json\n+import zipfile\n+\n+import h5py\n+\n+from keras.saving import deserialize_keras_object\n+from keras.src.saving.saving_lib import H5IOStore\n+\n+_CONFIG_FILENAME = \"config.json\"\n+_METADATA_FILENAME = \"metadata.json\"\n+_VARS_FNAME = \"model.weights\"\n+\n+\n+class KerasFileEditor:\n+    def __init__(self, filepath, reference_model=None, custom_objects=None):\n+        self.filepath = filepath\n+        self.custom_objects = custom_objects\n+        self.metadata = None\n+        self.reference_model = None\n+        self.config = None\n+\n+        if filepath.endswith(\".keras\"):\n+            self.init_for_keras(custom_objects, filepath, reference_model)\n+        elif filepath.endswith(\".weights.h5\"):\n+            pass", "source": "def __init__(self, filepath, reference_model=None, custom_objects=None):\n        self.filepath = filepath\n        self.custom_objects = custom_objects\n        self.metadata = None\n        self.reference_model = None\n        self.config = None\n\n        if filepath.endswith(\".keras\"):\n            self.init_for_keras(custom_objects, filepath, reference_model)\n        elif filepath.endswith(\".weights.h5\"):\n            pass\n        else:\n            raise ValueError(\n                \"Invalid filename: \"\n                \"expected a `.keras` `.weights.h5` extension. \"\n                f\"Received: filepath={filepath}\"\n            )\n\n        def recursive_search(data):\n            result = {}\n            for key in data.keys():\n                value = data[key]\n                if isinstance(value, h5py.Group) and len(value) == 0:\n                    continue\n                if hasattr(value, \"keys\"):\n                    result[key] = recursive_search(value)\n                else:\n                    result[key] = value\n            return result\n\n        archive = zipfile.ZipFile(filepath, \"r\")\n        weights_store = H5IOStore(\n            _VARS_FNAME + \".h5\", archive=archive, mode=\"r\"\n        )\n        self.nested_dict = recursive_search(weights_store.h5_file)", "source_start_line": 15, "tokens": ["def", "__init__", "(", "self", ",", "filepath", ",", "reference_model", "=", "None", ",", "custom_objects", "=", "None", ")", ":", "self", ".", "filepath", "=", "filepath", "self", ".", "custom_objects", "=", "custom_objects", "self", ".", "metadata", "=", "None", "self", ".", "reference_model", "=", "None", "self", ".", "config", "=", "None", "if", "filepath", ".", "endswith", "(", "\".keras\"", ")", ":", "self", ".", "init_for_keras", "(", "custom_objects", ",", "filepath", ",", "reference_model", ")", "elif", "filepath", ".", "endswith", "(", "\".weights.h5\"", ")", ":", "pass", "else", ":", "raise", "ValueError", "(", "\"Invalid filename: \"", "\"expected a `.keras` `.weights.h5` extension. \"", "f\"", "{", "filepath", "}", "\"", ")", "def", "recursive_search", "(", "data", ")", ":", "result", "=", "{", "}", "for", "key", "in", "data", ".", "keys", "(", ")", ":", "value", "=", "data", "[", "key", "]", "if", "isinstance", "(", "value", ",", "h5py", ".", "Group", ")", "and", "len", "(", "value", ")", "==", "0", ":", "continue", "if", "hasattr", "(", "value", ",", "\"keys\"", ")", ":", "result", "[", "key", "]", "=", "recursive_search", "(", "value", ")", "else", ":", "result", "[", "key", "]", "=", "value", "return", "result", "archive", "=", "zipfile", ".", "ZipFile", "(", "filepath", ",", "\"r\"", ")", "weights_store", "=", "H5IOStore", "(", "_VARS_FNAME", "+", "\".h5\"", ",", "archive", "=", "archive", ",", "mode", "=", "\"r\"", ")", "self", ".", "nested_dict", "=", "recursive_search", "(", "weights_store", ".", "h5_file", ")"], "to_mask": {"VAR": ["archive", "config", "custom_objects", "data", "filepath", "key", "metadata", "nested_dict", "reference_model", "result", "self", "value", "weights_store"], "METHOD": ["H5IOStore", "ValueError", "ZipFile", "endswith", "hasattr", "init_for_keras", "isinstance", "keys", "len", "recursive_search"]}, "attention_idx_tokens": [67, 67], "patch": "@@ -0,0 +1,70 @@\n+import json\n+import zipfile\n+\n+import h5py\n+\n+from keras.saving import deserialize_keras_object\n+from keras.src.saving.saving_lib import H5IOStore\n+\n+_CONFIG_FILENAME = \"config.json\"\n+_METADATA_FILENAME = \"metadata.json\"\n+_VARS_FNAME = \"model.weights\"\n+\n+\n+class KerasFileEditor:\n+    def __init__(self, filepath, reference_model=None, custom_objects=None):\n+        self.filepath = filepath\n+        self.custom_objects = custom_objects\n+        self.metadata = None\n+        self.reference_model = None\n+        self.config = None\n+\n+        if filepath.endswith(\".keras\"):\n+            self.init_for_keras(custom_objects, filepath, reference_model)\n+        elif filepath.endswith(\".weights.h5\"):\n+            pass", "ext_attention_idx_tokens": [0, 186], "uid": "1ac49aa7", "question": "Is this a TODO?", "code": "def init self filepath reference model None custom objects None self filepath filepath self custom objects custom objects self metadata None self reference model None self config None if filepath endswith \" keras\" self init for keras custom objects filepath reference model elif filepath endswith \" weights h5\" pass else raise ValueError \"Invalid filename \" \"expected a ` keras` ` weights h5` extension \" f\"Received filepath {filepath}\" def recursive search data result {} for key in data keys value data[key] if isinstance value h5py Group and len value 0 continue if hasattr value \"keys\" result[key] recursive search value else result[key] value return result archive zipfile ZipFile filepath \"r\" weights store H5IOStore VARS FNAME + \" h5\" archive archive mode \"r\" self nested dict recursive search weights store h5 file"}
{"message": "I was trying to match [`_get_jax_state` signature](https://github.com/keras-team/keras/blob/master/keras/src/backend/jax/trainer.py#L943-L948).\r\nSo you're saying there isn't any use case that users want to get some of the variables only?", "timestamp": "2024-09-11T17:34:24Z", "file_name": "keras/src/models/model.py", "range": {"start_line": 561, "end_line": 561, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1755220216", "html_url": "https://github.com/keras-team/keras/pull/20247#discussion_r1755220216", "attention_area": "        trainable_variables=False,", "file_path": "files/88/03/00000388.py", "old_file_path": "files/89/03/00000389.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -556,6 +556,125 @@ def _get_variable_map(self):\n         map_saveable_variables(self, store=store, visited_saveables=set())\n         return store\n \n+    def get_nested_variables(\n+        self,\n+        trainable_variables=False,", "source": "def get_nested_variables(\n        self,\n        trainable_variables=False,\n        non_trainable_variables=False,\n        optimizer_variables=False,\n        metrics_variables=False,\n    ):\n        \"\"\"Retrieves tree-like structure of specified variables of the model.\n\n        This method allows selective retrieval of different variables\n        (trainable, non-trainable, optimizer, and metrics) associated with the\n        model. The variables are returned in a nested dictionary format,\n        where the keys correspond to the variable names and the values are the\n        nested representations of the variables.\n\n        Args:\n            trainable_variables: Whether to include trainable variables.\n            non_trainable_variables: Whether to include non-trainable variables.\n            optimizer_variables: Whether to include optimizer variables.\n            metrics_variables: Whether to include metrics variables.\n\n        Returns:\n            dict: A dictionary containing the nested representations of the\n                requested variables. The keys are the variable names, and the\n                values are the corresponding nested dictionaries. If no variable\n                types are requested, an empty dictionary is returned.\n        \"\"\"\n        variables = {}\n        if trainable_variables:\n            variables[\"trainable_variables\"] = self._create_nested_dict(\n                self.trainable_variables\n            )\n        if non_trainable_variables:\n            variables[\"non_trainable_variables\"] = self._create_nested_dict(\n                self.non_trainable_variables\n            )\n        if optimizer_variables:\n            variables[\"optimizer_variables\"] = self._create_nested_dict(\n                self.optimizer.variables\n            )\n        if metrics_variables:\n            variables[\"metrics_variables\"] = self._create_nested_dict(\n                self.metrics_variables\n            )\n\n        return variables", "source_start_line": 559, "tokens": ["def", "get_nested_variables", "(", "self", ",", "trainable_variables", "=", "False", ",", "non_trainable_variables", "=", "False", ",", "optimizer_variables", "=", "False", ",", "metrics_variables", "=", "False", ",", ")", ":", "\"\"\"Retrieves tree-like structure of specified variables of the model.        This method allows selective retrieval of different variables        (trainable, non-trainable, optimizer, and metrics) associated with the        model. The variables are returned in a nested dictionary format,        where the keys correspond to the variable names and the values are the        nested representations of the variables.        Args:            trainable_variables: Whether to include trainable variables.            non_trainable_variables: Whether to include non-trainable variables.            optimizer_variables: Whether to include optimizer variables.            metrics_variables: Whether to include metrics variables.        Returns:            dict: A dictionary containing the nested representations of the                requested variables. The keys are the variable names, and the                values are the corresponding nested dictionaries. If no variable                types are requested, an empty dictionary is returned.        \"\"\"", "variables", "=", "{", "}", "if", "trainable_variables", ":", "variables", "[", "\"trainable_variables\"", "]", "=", "self", ".", "_create_nested_dict", "(", "self", ".", "trainable_variables", ")", "if", "non_trainable_variables", ":", "variables", "[", "\"non_trainable_variables\"", "]", "=", "self", ".", "_create_nested_dict", "(", "self", ".", "non_trainable_variables", ")", "if", "optimizer_variables", ":", "variables", "[", "\"optimizer_variables\"", "]", "=", "self", ".", "_create_nested_dict", "(", "self", ".", "optimizer", ".", "variables", ")", "if", "metrics_variables", ":", "variables", "[", "\"metrics_variables\"", "]", "=", "self", ".", "_create_nested_dict", "(", "self", ".", "metrics_variables", ")", "return", "variables"], "to_mask": {"VAR": ["metrics_variables", "non_trainable_variables", "optimizer_variables", "self", "trainable_variables", "variables"], "METHOD": ["_create_nested_dict"]}, "attention_idx_tokens": [5, 8], "patch": "@@ -556,6 +556,125 @@\n         map_saveable_variables(self, store=store, visited_saveables=set())\n         return store\n \n+    def get_nested_variables(\n+        self,\n+        trainable_variables=False,", "ext_attention_idx_tokens": [0, 95], "uid": "b4373e88", "question": "I was trying to match [`_get_jax_state` signature](https://github.com/keras-team/keras/blob/master/keras/src/backend/jax/trainer.py#L943-L948).  So you're saying there isn't any use case that users want to get some of the variables only?", "code": "def get nested variables self trainable variables False non trainable variables False optimizer variables False metrics variables False \"\"\"Retrieves tree-like structure of specified variables of the model This method allows selective retrieval of different variables trainable non-trainable optimizer and metrics associated with the model The variables are returned in a nested dictionary format where the keys correspond to the variable names and the values are the nested representations of the variables Args trainable variables Whether to include trainable variables non trainable variables Whether to include non-trainable variables optimizer variables Whether to include optimizer variables metrics variables Whether to include metrics variables Returns dict A dictionary containing the nested representations of the requested variables The keys are the variable names and the values are the corresponding nested dictionaries If no variable types are requested an empty dictionary is returned \"\"\" variables {} if trainable variables variables[\"trainable variables\"] self create nested dict self trainable variables if non trainable variables variables[\"non trainable variables\"] self create nested dict self non trainable variables if optimizer variables variables[\"optimizer variables\"] self create nested dict self optimizer variables if metrics variables variables[\"metrics variables\"] self create nested dict self metrics variables return variables"}
{"message": "@mattdangerw do you see an issue with always including metrics and optimizer variables?", "timestamp": "2024-09-12T19:39:48Z", "file_name": "keras/src/models/model.py", "range": {"start_line": 561, "end_line": 561, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1757484050", "html_url": "https://github.com/keras-team/keras/pull/20247#discussion_r1757484050", "attention_area": "        trainable_variables=False,", "file_path": "files/88/03/00000388.py", "old_file_path": "files/89/03/00000389.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -556,6 +556,125 @@ def _get_variable_map(self):\n         map_saveable_variables(self, store=store, visited_saveables=set())\n         return store\n \n+    def get_nested_variables(\n+        self,\n+        trainable_variables=False,", "source": "def get_nested_variables(\n        self,\n        trainable_variables=False,\n        non_trainable_variables=False,\n        optimizer_variables=False,\n        metrics_variables=False,\n    ):\n        \"\"\"Retrieves tree-like structure of specified variables of the model.\n\n        This method allows selective retrieval of different variables\n        (trainable, non-trainable, optimizer, and metrics) associated with the\n        model. The variables are returned in a nested dictionary format,\n        where the keys correspond to the variable names and the values are the\n        nested representations of the variables.\n\n        Args:\n            trainable_variables: Whether to include trainable variables.\n            non_trainable_variables: Whether to include non-trainable variables.\n            optimizer_variables: Whether to include optimizer variables.\n            metrics_variables: Whether to include metrics variables.\n\n        Returns:\n            dict: A dictionary containing the nested representations of the\n                requested variables. The keys are the variable names, and the\n                values are the corresponding nested dictionaries. If no variable\n                types are requested, an empty dictionary is returned.\n        \"\"\"\n        variables = {}\n        if trainable_variables:\n            variables[\"trainable_variables\"] = self._create_nested_dict(\n                self.trainable_variables\n            )\n        if non_trainable_variables:\n            variables[\"non_trainable_variables\"] = self._create_nested_dict(\n                self.non_trainable_variables\n            )\n        if optimizer_variables:\n            variables[\"optimizer_variables\"] = self._create_nested_dict(\n                self.optimizer.variables\n            )\n        if metrics_variables:\n            variables[\"metrics_variables\"] = self._create_nested_dict(\n                self.metrics_variables\n            )\n\n        return variables", "source_start_line": 559, "tokens": ["def", "get_nested_variables", "(", "self", ",", "trainable_variables", "=", "False", ",", "non_trainable_variables", "=", "False", ",", "optimizer_variables", "=", "False", ",", "metrics_variables", "=", "False", ",", ")", ":", "\"\"\"Retrieves tree-like structure of specified variables of the model.        This method allows selective retrieval of different variables        (trainable, non-trainable, optimizer, and metrics) associated with the        model. The variables are returned in a nested dictionary format,        where the keys correspond to the variable names and the values are the        nested representations of the variables.        Args:            trainable_variables: Whether to include trainable variables.            non_trainable_variables: Whether to include non-trainable variables.            optimizer_variables: Whether to include optimizer variables.            metrics_variables: Whether to include metrics variables.        Returns:            dict: A dictionary containing the nested representations of the                requested variables. The keys are the variable names, and the                values are the corresponding nested dictionaries. If no variable                types are requested, an empty dictionary is returned.        \"\"\"", "variables", "=", "{", "}", "if", "trainable_variables", ":", "variables", "[", "\"trainable_variables\"", "]", "=", "self", ".", "_create_nested_dict", "(", "self", ".", "trainable_variables", ")", "if", "non_trainable_variables", ":", "variables", "[", "\"non_trainable_variables\"", "]", "=", "self", ".", "_create_nested_dict", "(", "self", ".", "non_trainable_variables", ")", "if", "optimizer_variables", ":", "variables", "[", "\"optimizer_variables\"", "]", "=", "self", ".", "_create_nested_dict", "(", "self", ".", "optimizer", ".", "variables", ")", "if", "metrics_variables", ":", "variables", "[", "\"metrics_variables\"", "]", "=", "self", ".", "_create_nested_dict", "(", "self", ".", "metrics_variables", ")", "return", "variables"], "to_mask": {"VAR": ["metrics_variables", "non_trainable_variables", "optimizer_variables", "self", "trainable_variables", "variables"], "METHOD": ["_create_nested_dict"]}, "attention_idx_tokens": [5, 8], "patch": "@@ -556,6 +556,125 @@\n         map_saveable_variables(self, store=store, visited_saveables=set())\n         return store\n \n+    def get_nested_variables(\n+        self,\n+        trainable_variables=False,", "ext_attention_idx_tokens": [0, 95], "uid": "60ce2227", "question": "@mattdangerw do you see an issue with always including metrics and optimizer variables?", "code": "def get nested variables self trainable variables False non trainable variables False optimizer variables False metrics variables False \"\"\"Retrieves tree-like structure of specified variables of the model This method allows selective retrieval of different variables trainable non-trainable optimizer and metrics associated with the model The variables are returned in a nested dictionary format where the keys correspond to the variable names and the values are the nested representations of the variables Args trainable variables Whether to include trainable variables non trainable variables Whether to include non-trainable variables optimizer variables Whether to include optimizer variables metrics variables Whether to include metrics variables Returns dict A dictionary containing the nested representations of the requested variables The keys are the variable names and the values are the corresponding nested dictionaries If no variable types are requested an empty dictionary is returned \"\"\" variables {} if trainable variables variables[\"trainable variables\"] self create nested dict self trainable variables if non trainable variables variables[\"non trainable variables\"] self create nested dict self non trainable variables if optimizer variables variables[\"optimizer variables\"] self create nested dict self optimizer variables if metrics variables variables[\"metrics variables\"] self create nested dict self metrics variables return variables"}
{"message": "Can you explain why this is necessary?", "timestamp": "2024-10-08T00:06:38Z", "file_name": "keras/src/random/seed_generator.py", "range": {"start_line": 75, "end_line": 75, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1791020637", "html_url": "https://github.com/keras-team/keras/pull/20330#discussion_r1791020637", "attention_area": "            self.state = self.backend.BackendVariable(", "file_path": "files/11/04/00000411.py", "old_file_path": "files/12/04/00000412.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -72,7 +72,7 @@ def seed_initializer(*args, **kwargs):\n             return self.backend.convert_to_tensor([seed, 0], dtype=dtype)\n \n         with backend.name_scope(self.name, caller=self):\n-            self.state = self.backend.Variable(\n+            self.state = self.backend.BackendVariable(", "source": "def __init__(self, seed=None, name=None, **kwargs):\n        if name is None:\n            name = auto_name(self.__class__.__name__)\n        self.name = name\n\n        custom_backend = kwargs.pop(\"backend\", None)\n        if kwargs:\n            raise ValueError(f\"Unrecognized keyword arguments: {kwargs}\")\n        if custom_backend is not None:\n            self.backend = custom_backend\n        else:\n            self.backend = backend\n\n        self._initial_seed = seed\n        if seed is None:\n            seed = make_default_seed()\n\n        if not isinstance(seed, int):\n            raise ValueError(\n                \"Argument `seed` must be an integer. \" f\"Received: seed={seed}\"\n            )\n\n        def seed_initializer(*args, **kwargs):\n            dtype = kwargs.get(\"dtype\", None)\n            return self.backend.convert_to_tensor([seed, 0], dtype=dtype)\n\n        with backend.name_scope(self.name, caller=self):\n            self.state = self.backend.BackendVariable(\n                seed_initializer,\n                shape=(2,),\n                dtype=self.backend.random_seed_dtype(),\n                trainable=False,\n                name=\"seed_generator_state\",\n            )", "source_start_line": 48, "tokens": ["def", "__init__", "(", "self", ",", "seed", "=", "None", ",", "name", "=", "None", ",", "**", "kwargs", ")", ":", "if", "name", "is", "None", ":", "name", "=", "auto_name", "(", "self", ".", "__class__", ".", "__name__", ")", "self", ".", "name", "=", "name", "custom_backend", "=", "kwargs", ".", "pop", "(", "\"backend\"", ",", "None", ")", "if", "kwargs", ":", "raise", "ValueError", "(", "f\"", "{", "kwargs", "}", "\"", ")", "if", "custom_backend", "is", "not", "None", ":", "self", ".", "backend", "=", "custom_backend", "else", ":", "self", ".", "backend", "=", "backend", "self", ".", "_initial_seed", "=", "seed", "if", "seed", "is", "None", ":", "seed", "=", "make_default_seed", "(", ")", "if", "not", "isinstance", "(", "seed", ",", "int", ")", ":", "raise", "ValueError", "(", "\"Argument `seed` must be an integer. \"", "f\"", "{", "seed", "}", "\"", ")", "def", "seed_initializer", "(", "*", "args", ",", "**", "kwargs", ")", ":", "dtype", "=", "kwargs", ".", "get", "(", "\"dtype\"", ",", "None", ")", "return", "self", ".", "backend", ".", "convert_to_tensor", "(", "[", "seed", ",", "0", "]", ",", "dtype", "=", "dtype", ")", "with", "backend", ".", "name_scope", "(", "self", ".", "name", ",", "caller", "=", "self", ")", ":", "self", ".", "state", "=", "self", ".", "backend", ".", "BackendVariable", "(", "seed_initializer", ",", "shape", "=", "(", "2", ",", ")", ",", "dtype", "=", "self", ".", "backend", ".", "random_seed_dtype", "(", ")", ",", "trainable", "=", "False", ",", "name", "=", "\"seed_generator_state\"", ",", ")"], "to_mask": {"VAR": ["_initial_seed", "args", "backend", "custom_backend", "dtype", "name", "seed", "self", "state"], "METHOD": ["BackendVariable", "ValueError", "auto_name", "convert_to_tensor", "get", "isinstance", "make_default_seed", "name_scope", "pop", "random_seed_dtype"]}, "attention_idx_tokens": [162, 171], "patch": "@@ -72,7 +72,7 @@\n             return self.backend.convert_to_tensor([seed, 0], dtype=dtype)\n \n         with backend.name_scope(self.name, caller=self):\n-            self.state = self.backend.Variable(\n+            self.state = self.backend.BackendVariable(", "ext_attention_idx_tokens": [162, 173], "uid": "89203821", "question": "Can you explain why this is necessary?", "code": "def init self seed None name None **kwargs if name is None name auto name self class name self name name custom backend kwargs pop \"backend\" None if kwargs raise ValueError f\"Unrecognized keyword arguments {kwargs}\" if custom backend is not None self backend custom backend else self backend backend self initial seed seed if seed is None seed make default seed if not isinstance seed int raise ValueError \"Argument `seed` must be an integer \" f\"Received seed {seed}\" def seed initializer *args **kwargs dtype kwargs get \"dtype\" None return self backend convert to tensor [seed 0] dtype dtype with backend name scope self name caller self self state self backend BackendVariable seed initializer shape 2 dtype self backend random seed dtype trainable False name \"seed generator state\""}
{"message": "Why is this necessary?", "timestamp": "2024-10-15T18:34:36Z", "file_name": "keras/src/losses/losses.py", "range": {"start_line": 27, "end_line": 27, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1801721822", "html_url": "https://github.com/keras-team/keras/pull/20358#discussion_r1801721822", "attention_area": "        y_true, y_pred = optree.tree_transpose_map(", "file_path": "files/18/04/00000418.py", "old_file_path": "files/19/04/00000419.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -23,7 +24,9 @@ def __init__(\n         self._fn_kwargs = kwargs\n \n     def call(self, y_true, y_pred):\n-        y_true, y_pred = squeeze_or_expand_to_same_rank(y_true, y_pred)\n+        y_true, y_pred = optree.tree_transpose_map(", "source": "def call(self, y_true, y_pred):\n        y_true, y_pred = optree.tree_transpose_map(\n            squeeze_or_expand_to_same_rank, y_true, y_pred\n        )\n        return self.fn(y_true, y_pred, **self._fn_kwargs)", "source_start_line": 26, "tokens": ["def", "call", "(", "self", ",", "y_true", ",", "y_pred", ")", ":", "y_true", ",", "y_pred", "=", "optree", ".", "tree_transpose_map", "(", "squeeze_or_expand_to_same_rank", ",", "y_true", ",", "y_pred", ")", "return", "self", ".", "fn", "(", "y_true", ",", "y_pred", ",", "**", "self", ".", "_fn_kwargs", ")"], "to_mask": {"VAR": ["self", "y_pred", "y_true"], "METHOD": ["fn", "tree_transpose_map"]}, "attention_idx_tokens": [10, 17], "patch": "@@ -23,7 +24,9 @@\n         self._fn_kwargs = kwargs\n \n     def call(self, y_true, y_pred):\n-        y_true, y_pred = squeeze_or_expand_to_same_rank(y_true, y_pred)\n+        y_true, y_pred = optree.tree_transpose_map(", "ext_attention_idx_tokens": [10, 37], "uid": "22d1a0d2", "question": "Why is this necessary?", "code": "def call self y true y pred y true y pred optree tree transpose map squeeze or expand to same rank y true y pred return self fn y true y pred **self fn kwargs"}
{"message": "Why is this change necessary?", "timestamp": "2024-10-16T18:14:34Z", "file_name": "keras/src/callbacks/tensorboard_test.py", "range": {"start_line": 424, "end_line": 424, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1803589503", "html_url": "https://github.com/keras-team/keras/pull/20358#discussion_r1803589503", "attention_area": "        x, y = np.ones((10, 10)), np.ones((10, 10, 1))", "file_path": "files/23/04/00000423.py", "old_file_path": "files/24/04/00000424.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -421,7 +421,7 @@ def test_TensorBoard_projector_callback(self):\n         model.compile(\n             optimizer=\"adam\", loss=losses.BinaryCrossentropy(from_logits=True)\n         )\n-        x, y = np.ones((10, 10)), np.ones((10, 10))\n+        x, y = np.ones((10, 10)), np.ones((10, 10, 1))", "source": "def test_TensorBoard_projector_callback(self):\n        model = models.Sequential(\n            [\n                layers.Input((10,)),\n                layers.Embedding(10, 10, name=\"test_embedding\"),\n                layers.Dense(1, activation=\"sigmoid\"),\n            ]\n        )\n        model.compile(\n            optimizer=\"adam\", loss=losses.BinaryCrossentropy(from_logits=True)\n        )\n        x, y = np.ones((10, 10)), np.ones((10, 10, 1))\n        logdir, _, _ = self._get_log_dirs()\n        tb_cbk = callbacks.TensorBoard(\n            logdir,\n            embeddings_freq=1,\n            embeddings_metadata={\"test_embedding\": \"metadata.tsv\"},\n        )\n\n        model.fit(\n            x,\n            y,\n            batch_size=2,\n            epochs=2,\n            validation_data=(x, y),\n            callbacks=[tb_cbk],\n        )\n\n        with open(os.path.join(logdir, \"projector_config.pbtxt\")) as f:\n            self.assertEqual(\n                f.readlines(),\n                [\n                    \"embeddings {\\n\",\n                    \"  tensor_name: \"\n                    '\"layer_with_weights-0/embeddings/.ATTRIBUTES/'\n                    'VARIABLE_VALUE\"\\n',\n                    '  metadata_path: \"metadata.tsv\"\\n',\n                    \"}\\n\",\n                ],\n            )", "source_start_line": 413, "tokens": ["def", "test_TensorBoard_projector_callback", "(", "self", ")", ":", "model", "=", "models", ".", "Sequential", "(", "[", "layers", ".", "Input", "(", "(", "10", ",", ")", ")", ",", "layers", ".", "Embedding", "(", "10", ",", "10", ",", "name", "=", "\"test_embedding\"", ")", ",", "layers", ".", "Dense", "(", "1", ",", "activation", "=", "\"sigmoid\"", ")", ",", "]", ")", "model", ".", "compile", "(", "optimizer", "=", "\"adam\"", ",", "loss", "=", "losses", ".", "BinaryCrossentropy", "(", "from_logits", "=", "True", ")", ")", "x", ",", "y", "=", "np", ".", "ones", "(", "(", "10", ",", "10", ")", ")", ",", "np", ".", "ones", "(", "(", "10", ",", "10", ",", "1", ")", ")", "logdir", ",", "_", ",", "_", "=", "self", ".", "_get_log_dirs", "(", ")", "tb_cbk", "=", "callbacks", ".", "TensorBoard", "(", "logdir", ",", "embeddings_freq", "=", "1", ",", "embeddings_metadata", "=", "{", "\"test_embedding\"", ":", "\"metadata.tsv\"", "}", ",", ")", "model", ".", "fit", "(", "x", ",", "y", ",", "batch_size", "=", "2", ",", "epochs", "=", "2", ",", "validation_data", "=", "(", "x", ",", "y", ")", ",", "callbacks", "=", "[", "tb_cbk", "]", ",", ")", "with", "open", "(", "os", ".", "path", ".", "join", "(", "logdir", ",", "\"projector_config.pbtxt\"", ")", ")", "as", "f", ":", "self", ".", "assertEqual", "(", "f", ".", "readlines", "(", ")", ",", "[", "\"embeddings {\\n\"", ",", "\"  tensor_name: \"", "'\"layer_with_weights-0/embeddings/.ATTRIBUTES/'", "'VARIABLE_VALUE\"\\n'", ",", "'  metadata_path: \"metadata.tsv\"\\n'", ",", "\"}\\n\"", ",", "]", ",", ")"], "to_mask": {"VAR": ["_", "f", "logdir", "model", "self", "tb_cbk", "x", "y"], "METHOD": ["BinaryCrossentropy", "Dense", "Embedding", "Input", "Sequential", "TensorBoard", "_get_log_dirs", "assertEqual", "compile", "fit", "join", "ones", "open", "readlines"]}, "attention_idx_tokens": [68, 94], "patch": "@@ -421,7 +421,7 @@\n         model.compile(\n             optimizer=\"adam\", loss=losses.BinaryCrossentropy(from_logits=True)\n         )\n-        x, y = np.ones((10, 10)), np.ones((10, 10))\n+        x, y = np.ones((10, 10)), np.ones((10, 10, 1))", "ext_attention_idx_tokens": [68, 105], "uid": "3c363a25", "question": "Why is this change necessary?", "code": "def test TensorBoard projector callback self model models Sequential [ layers Input 10 layers Embedding 10 10 name \"test embedding\" layers Dense 1 activation \"sigmoid\" ] model compile optimizer \"adam\" loss losses BinaryCrossentropy from logits True x y np ones 10 10 np ones 10 10 1 logdir self get log dirs tb cbk callbacks TensorBoard logdir embeddings freq 1 embeddings metadata {\"test embedding\" \"metadata tsv\"} model fit x y batch size 2 epochs 2 validation data x y callbacks [tb cbk] with open os path join logdir \"projector config pbtxt\" as f self assertEqual f readlines [ \"embeddings {\\n\" \" tensor name \" \"layer with weights-0 embeddings ATTRIBUTES VARIABLE VALUE\"\\n metadata path \"metadata tsv\"\\n \"}\\n\" ]"}
{"message": "What is the implication here -- do users have to specify this key in the data?", "timestamp": "2024-10-18T21:26:30Z", "file_name": "keras/src/layers/preprocessing/image_preprocessing/base_image_preprocessing_layer.py", "range": {"start_line": 165, "end_line": 165, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1807029816", "html_url": "https://github.com/keras-team/keras/pull/20368#discussion_r1807029816", "attention_area": "                if \"orig_width\" not in data:", "file_path": "files/28/04/00000428.py", "old_file_path": "files/29/04/00000429.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -144,17 +158,47 @@ def call(self, data, training=True):\n                         \"`bounding_box_format='xyxy'`.\"\n                     )\n                 bounding_boxes = densify_bounding_boxes(\n-                    data[\"bounding_boxes\"], backend=self.backend\n+                    data[\"bounding_boxes\"],\n+                    is_batched=is_batched,\n+                    backend=self.backend,\n                 )\n+                if \"orig_width\" not in data:", "source": "def call(self, data, training=True):\n        transformation = self.get_random_transformation(data, training=training)\n        if isinstance(data, dict):\n            is_batched = self._is_batched(data[\"images\"])\n            if is_batched:\n                data[\"images\"] = self.transform_images(\n                    self.backend.convert_to_tensor(data[\"images\"]),\n                    transformation=transformation,\n                    training=training,\n                )\n            else:\n                data[\"images\"] = self.transform_single_image(\n                    self.backend.convert_to_tensor(data[\"images\"]),\n                    transformation=transformation,\n                    training=training,\n                )\n            if \"bounding_boxes\" in data:\n                if not self.bounding_box_format:\n                    raise ValueError(\n                        \"You passed an input with a 'bounding_boxes' key, \"\n                        \"but you didn't specify a bounding box format. \"\n                        \"Pass a `bounding_box_format` argument to your \"\n                        f\"{self.__class__.__name__} layer, e.g. \"\n                        \"`bounding_box_format='xyxy'`.\"\n                    )\n                bounding_boxes = densify_bounding_boxes(\n                    data[\"bounding_boxes\"],\n                    is_batched=is_batched,\n                    backend=self.backend,\n                )\n                if \"orig_width\" not in data:\n                    raise ValueError(\n                        \"'orig_width' key is missing from the input data. \"\n                        \"Please provide the original image width.\"\n                    )\n\n                if \"orig_height\" not in data:\n                    raise ValueError(\n                        \"'orig_height' key is missing from the input data. \"\n                        \"Please provide the original image width.\"\n                    )\n\n                if is_batched:\n                    orig_width = self.backend.numpy.expand_dims(\n                        data[\"orig_width\"], axis=-1\n                    )\n                    orig_height = self.backend.numpy.expand_dims(\n                        data[\"orig_height\"], axis=-1\n                    )\n                    data[\"bounding_boxes\"] = self.transform_bounding_boxes(\n                        bounding_boxes,\n                        orig_height,\n                        orig_width,\n                        transformation=transformation,\n                        training=training,\n                    )\n                else:\n                    orig_width = self.backend.numpy.expand_dims(\n                        [data[\"orig_width\"]], axis=-1\n                    )\n                    orig_height = self.backend.numpy.expand_dims(\n                        [data[\"orig_height\"]], axis=-1\n                    )\n                    data[\"bounding_boxes\"] = self.transform_single_bounding_box(\n                        bounding_boxes,\n                        orig_height,\n                        orig_width,\n                        transformation=transformation,\n                        training=training,\n                    )\n            if \"labels\" in data:\n                if is_batched:\n                    data[\"labels\"] = self.transform_labels(\n                        self.backend.convert_to_tensor(data[\"labels\"]),\n                        transformation=transformation,\n                        training=training,\n                    )\n                else:\n                    data[\"labels\"] = self.transform_single_label(\n                        self.backend.convert_to_tensor(data[\"labels\"]),\n                        transformation=transformation,\n                        training=training,\n                    )\n            if \"segmentation_masks\" in data:\n                if is_batched:\n                    data[\"segmentation_masks\"] = (\n                        self.transform_segmentation_masks(\n                            data[\"segmentation_masks\"],\n                            transformation=transformation,\n                            training=training,\n                        )\n                    )\n                else:\n                    data[\"segmentation_masks\"] = (\n                        self.transform_single_segmentation_mask(\n                            data[\"segmentation_masks\"],\n                            transformation=transformation,\n                            training=training,\n                        )\n                    )\n            return data\n\n        # `data` is just images.\n        if self._is_batched(data):\n            return self.transform_images(\n                self.backend.convert_to_tensor(data),\n                transformation=transformation,\n                training=training,\n            )\n        return self.transform_single_image(\n            self.backend.convert_to_tensor(data),\n            transformation=transformation,\n            training=training,\n        )", "source_start_line": 135, "tokens": ["def", "call", "(", "self", ",", "data", ",", "training", "=", "True", ")", ":", "transformation", "=", "self", ".", "get_random_transformation", "(", "data", ",", "training", "=", "training", ")", "if", "isinstance", "(", "data", ",", "dict", ")", ":", "is_batched", "=", "self", ".", "_is_batched", "(", "data", "[", "\"images\"", "]", ")", "if", "is_batched", ":", "data", "[", "\"images\"", "]", "=", "self", ".", "transform_images", "(", "self", ".", "backend", ".", "convert_to_tensor", "(", "data", "[", "\"images\"", "]", ")", ",", "transformation", "=", "transformation", ",", "training", "=", "training", ",", ")", "else", ":", "data", "[", "\"images\"", "]", "=", "self", ".", "transform_single_image", "(", "self", ".", "backend", ".", "convert_to_tensor", "(", "data", "[", "\"images\"", "]", ")", ",", "transformation", "=", "transformation", ",", "training", "=", "training", ",", ")", "if", "\"bounding_boxes\"", "in", "data", ":", "if", "not", "self", ".", "bounding_box_format", ":", "raise", "ValueError", "(", "\"You passed an input with a 'bounding_boxes' key, \"", "\"but you didn't specify a bounding box format. \"", "\"Pass a `bounding_box_format` argument to your \"", "f\"", "{", "self", ".", "__class__", ".", "__name__", "}", "\"", "\"`bounding_box_format='xyxy'`.\"", ")", "bounding_boxes", "=", "densify_bounding_boxes", "(", "data", "[", "\"bounding_boxes\"", "]", ",", "is_batched", "=", "is_batched", ",", "backend", "=", "self", ".", "backend", ",", ")", "if", "\"orig_width\"", "not", "in", "data", ":", "raise", "ValueError", "(", "\"'orig_width' key is missing from the input data. \"", "\"Please provide the original image width.\"", ")", "if", "\"orig_height\"", "not", "in", "data", ":", "raise", "ValueError", "(", "\"'orig_height' key is missing from the input data. \"", "\"Please provide the original image width.\"", ")", "if", "is_batched", ":", "orig_width", "=", "self", ".", "backend", ".", "numpy", ".", "expand_dims", "(", "data", "[", "\"orig_width\"", "]", ",", "axis", "=", "-", "1", ")", "orig_height", "=", "self", ".", "backend", ".", "numpy", ".", "expand_dims", "(", "data", "[", "\"orig_height\"", "]", ",", "axis", "=", "-", "1", ")", "data", "[", "\"bounding_boxes\"", "]", "=", "self", ".", "transform_bounding_boxes", "(", "bounding_boxes", ",", "orig_height", ",", "orig_width", ",", "transformation", "=", "transformation", ",", "training", "=", "training", ",", ")", "else", ":", "orig_width", "=", "self", ".", "backend", ".", "numpy", ".", "expand_dims", "(", "[", "data", "[", "\"orig_width\"", "]", "]", ",", "axis", "=", "-", "1", ")", "orig_height", "=", "self", ".", "backend", ".", "numpy", ".", "expand_dims", "(", "[", "data", "[", "\"orig_height\"", "]", "]", ",", "axis", "=", "-", "1", ")", "data", "[", "\"bounding_boxes\"", "]", "=", "self", ".", "transform_single_bounding_box", "(", "bounding_boxes", ",", "orig_height", ",", "orig_width", ",", "transformation", "=", "transformation", ",", "training", "=", "training", ",", ")", "if", "\"labels\"", "in", "data", ":", "if", "is_batched", ":", "data", "[", "\"labels\"", "]", "=", "self", ".", "transform_labels", "(", "self", ".", "backend", ".", "convert_to_tensor", "(", "data", "[", "\"labels\"", "]", ")", ",", "transformation", "=", "transformation", ",", "training", "=", "training", ",", ")", "else", ":", "data", "[", "\"labels\"", "]", "=", "self", ".", "transform_single_label", "(", "self", ".", "backend", ".", "convert_to_tensor", "(", "data", "[", "\"labels\"", "]", ")", ",", "transformation", "=", "transformation", ",", "training", "=", "training", ",", ")", "if", "\"segmentation_masks\"", "in", "data", ":", "if", "is_batched", ":", "data", "[", "\"segmentation_masks\"", "]", "=", "(", "self", ".", "transform_segmentation_masks", "(", "data", "[", "\"segmentation_masks\"", "]", ",", "transformation", "=", "transformation", ",", "training", "=", "training", ",", ")", ")", "else", ":", "data", "[", "\"segmentation_masks\"", "]", "=", "(", "self", ".", "transform_single_segmentation_mask", "(", "data", "[", "\"segmentation_masks\"", "]", ",", "transformation", "=", "transformation", ",", "training", "=", "training", ",", ")", ")", "return", "data", "if", "self", ".", "_is_batched", "(", "data", ")", ":", "return", "self", ".", "transform_images", "(", "self", ".", "backend", ".", "convert_to_tensor", "(", "data", ")", ",", "transformation", "=", "transformation", ",", "training", "=", "training", ",", ")", "return", "self", ".", "transform_single_image", "(", "self", ".", "backend", ".", "convert_to_tensor", "(", "data", ")", ",", "transformation", "=", "transformation", ",", "training", "=", "training", ",", ")"], "to_mask": {"VAR": ["bounding_boxes", "data", "is_batched", "orig_height", "orig_width", "self", "training", "transformation"], "METHOD": ["ValueError", "_is_batched", "convert_to_tensor", "densify_bounding_boxes", "expand_dims", "get_random_transformation", "isinstance", "transform_bounding_boxes", "transform_images", "transform_labels", "transform_segmentation_masks", "transform_single_bounding_box", "transform_single_image", "transform_single_label", "transform_single_segmentation_mask"]}, "attention_idx_tokens": [156, 161], "patch": "@@ -144,17 +158,47 @@\n                         \"`bounding_box_format='xyxy'`.\"\n                     )\n                 bounding_boxes = densify_bounding_boxes(\n-                    data[\"bounding_boxes\"], backend=self.backend\n+                    data[\"bounding_boxes\"],\n+                    is_batched=is_batched,\n+                    backend=self.backend,\n                 )\n+                if \"orig_width\" not in data:", "ext_attention_idx_tokens": [140, 311], "uid": "f9497be2", "question": "What is the implication here -- do users have to specify this key in the data?", "code": "def call self data training True transformation self get random transformation data training training if isinstance data dict is batched self is batched data[\"images\"] if is batched data[\"images\"] self transform images self backend convert to tensor data[\"images\"] transformation transformation training training else data[\"images\"] self transform single image self backend convert to tensor data[\"images\"] transformation transformation training training if \"bounding boxes\" in data if not self bounding box format raise ValueError \"You passed an input with a bounding boxes key \" \"but you didn t specify a bounding box format \" \"Pass a `bounding box format` argument to your \" f\"{self class name } layer e g \" \"`bounding box format xyxy ` \" bounding boxes densify bounding boxes data[\"bounding boxes\"] is batched is batched backend self backend if \"orig width\" not in data raise ValueError \" orig width key is missing from the input data \" \"Please provide the original image width \" if \"orig height\" not in data raise ValueError \" orig height key is missing from the input data \" \"Please provide the original image width \" if is batched orig width self backend numpy expand dims data[\"orig width\"] axis -1 orig height self backend numpy expand dims data[\"orig height\"] axis -1 data[\"bounding boxes\"] self transform bounding boxes bounding boxes orig height orig width transformation transformation training training else orig width self backend numpy expand dims [data[\"orig width\"]] axis -1 orig height self backend numpy expand dims [data[\"orig height\"]] axis -1 data[\"bounding boxes\"] self transform single bounding box bounding boxes orig height orig width transformation transformation training training if \"labels\" in data if is batched data[\"labels\"] self transform labels self backend convert to tensor data[\"labels\"] transformation transformation training training else data[\"labels\"] self transform single label self backend convert to tensor data[\"labels\"] transformation transformation training training if \"segmentation masks\" in data if is batched data[\"segmentation masks\"] self transform segmentation masks data[\"segmentation masks\"] transformation transformation training training else data[\"segmentation masks\"] self transform single segmentation mask data[\"segmentation masks\"] transformation transformation training training return data # `data` is just images if self is batched data return self transform images self backend convert to tensor data transformation transformation training training return self transform single image self backend convert to tensor data transformation transformation training training"}
{"message": "Any chance that this could succeed yet yield an incorrect result?", "timestamp": "2024-10-30T17:20:25Z", "file_name": "keras/src/trainers/compile_utils.py", "range": {"start_line": 674, "end_line": 674, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1823083386", "html_url": "https://github.com/keras-team/keras/pull/20426#discussion_r1823083386", "attention_area": "                y_true = tree.pack_sequence_as(y_pred, flat_y_true)", "file_path": "files/56/04/00000456.py", "old_file_path": "files/57/04/00000457.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -664,20 +665,20 @@ def call(self, y_true, y_pred, sample_weight=None):\n         try:\n             tree.assert_same_structure(y_pred, y_true, check_types=False)\n         except ValueError:\n-            # y_true is either flat or leaf\n-            if (\n-                not tree.is_nested(y_true)\n-                and hasattr(y_pred, \"__len__\")\n-                and len(y_pred) == 1\n-            ):\n-                y_true = [y_true]\n+            # y_true is either:\n+            #   - flat or leaf\n+            #   - has the same structure but uses different (but reconcilable)\n+            #     container types, e.g `list` vs `tuple`\n+            flat_y_true = tree.flatten(y_true)\n             try:\n-                y_true = tree.pack_sequence_as(y_pred, y_true)\n+                y_true = tree.pack_sequence_as(y_pred, flat_y_true)", "source": "def call(self, y_true, y_pred, sample_weight=None):\n        try:\n            tree.assert_same_structure(y_pred, y_true, check_types=False)\n        except ValueError:\n            # y_true is either:\n            #   - flat or leaf\n            #   - has the same structure but uses different (but reconcilable)\n            #     container types, e.g `list` vs `tuple`\n            flat_y_true = tree.flatten(y_true)\n            try:\n                y_true = tree.pack_sequence_as(y_pred, flat_y_true)\n            except:\n                y_true_struct = tree.map_structure(lambda _: \"*\", y_true)\n                y_pred_struct = tree.map_structure(lambda _: \"*\", y_pred)\n                raise ValueError(\n                    \"y_true and y_pred have different structures.\\n\"\n                    f\"y_true: {y_true_struct}\\n\"\n                    f\"y_pred: {y_pred_struct}\\n\"\n                )\n\n        if not self.built:\n            self.build(y_true, y_pred)\n\n        try:\n            tree.assert_same_structure(\n                self._y_pred_build_structure, y_pred, check_types=False\n            )\n        except ValueError:\n            y_pred = tree.pack_sequence_as(\n                self._y_pred_build_structure, tree.flatten(y_pred)\n            )\n            y_true = tree.pack_sequence_as(\n                self._y_pred_build_structure, tree.flatten(y_true)\n            )\n\n        # We need to add a dummy `None` if the model has only a single output.\n        metrics = [None] if len(self.metrics) == 0 else self.metrics\n\n        # Iterate all losses in flat form.\n        loss_values = []\n\n        def resolve_path(path, object):\n            for _path in path:\n                object = object[_path]\n            return object\n\n        for (path, loss_fn, loss_weight, name), metric in zip(\n            self._flat_losses, metrics\n        ):\n            y_t, y_p = resolve_path(path, y_true), resolve_path(path, y_pred)\n            if sample_weight is not None and tree.is_nested(sample_weight):\n                _sample_weight = resolve_path(path, sample_weight)\n            else:\n                _sample_weight = sample_weight\n            value = ops.cast(\n                loss_fn(y_t, y_p, _sample_weight), dtype=self.dtype\n            )\n            if loss_weight is not None:\n                value = ops.multiply(value, loss_weight)\n            loss_values.append(value)\n            # Record individual losses.\n            if metric:\n                metric.update_state(\n                    value, sample_weight=tree.flatten(y_p)[0].shape[0]\n                )\n\n        if loss_values:\n            total_loss = sum(loss_values)\n            return total_loss\n        return None", "source_start_line": 664, "tokens": ["def", "call", "(", "self", ",", "y_true", ",", "y_pred", ",", "sample_weight", "=", "None", ")", ":", "try", ":", "tree", ".", "assert_same_structure", "(", "y_pred", ",", "y_true", ",", "check_types", "=", "False", ")", "except", "ValueError", ":", "flat_y_true", "=", "tree", ".", "flatten", "(", "y_true", ")", "try", ":", "y_true", "=", "tree", ".", "pack_sequence_as", "(", "y_pred", ",", "flat_y_true", ")", "except", ":", "y_true_struct", "=", "tree", ".", "map_structure", "(", "lambda", "_", ":", "\"*\"", ",", "y_true", ")", "y_pred_struct", "=", "tree", ".", "map_structure", "(", "lambda", "_", ":", "\"*\"", ",", "y_pred", ")", "raise", "ValueError", "(", "\"y_true and y_pred have different structures.\\n\"", "f\"", "{", "y_true_struct", "}", "\\n", "\"", "f\"", "{", "y_pred_struct", "}", "\\n", "\"", ")", "if", "not", "self", ".", "built", ":", "self", ".", "build", "(", "y_true", ",", "y_pred", ")", "try", ":", "tree", ".", "assert_same_structure", "(", "self", ".", "_y_pred_build_structure", ",", "y_pred", ",", "check_types", "=", "False", ")", "except", "ValueError", ":", "y_pred", "=", "tree", ".", "pack_sequence_as", "(", "self", ".", "_y_pred_build_structure", ",", "tree", ".", "flatten", "(", "y_pred", ")", ")", "y_true", "=", "tree", ".", "pack_sequence_as", "(", "self", ".", "_y_pred_build_structure", ",", "tree", ".", "flatten", "(", "y_true", ")", ")", "metrics", "=", "[", "None", "]", "if", "len", "(", "self", ".", "metrics", ")", "==", "0", "else", "self", ".", "metrics", "loss_values", "=", "[", "]", "def", "resolve_path", "(", "path", ",", "object", ")", ":", "for", "_path", "in", "path", ":", "object", "=", "object", "[", "_path", "]", "return", "object", "for", "(", "path", ",", "loss_fn", ",", "loss_weight", ",", "name", ")", ",", "metric", "in", "zip", "(", "self", ".", "_flat_losses", ",", "metrics", ")", ":", "y_t", ",", "y_p", "=", "resolve_path", "(", "path", ",", "y_true", ")", ",", "resolve_path", "(", "path", ",", "y_pred", ")", "if", "sample_weight", "is", "not", "None", "and", "tree", ".", "is_nested", "(", "sample_weight", ")", ":", "_sample_weight", "=", "resolve_path", "(", "path", ",", "sample_weight", ")", "else", ":", "_sample_weight", "=", "sample_weight", "value", "=", "ops", ".", "cast", "(", "loss_fn", "(", "y_t", ",", "y_p", ",", "_sample_weight", ")", ",", "dtype", "=", "self", ".", "dtype", ")", "if", "loss_weight", "is", "not", "None", ":", "value", "=", "ops", ".", "multiply", "(", "value", ",", "loss_weight", ")", "loss_values", ".", "append", "(", "value", ")", "if", "metric", ":", "metric", ".", "update_state", "(", "value", ",", "sample_weight", "=", "tree", ".", "flatten", "(", "y_p", ")", "[", "0", "]", ".", "shape", "[", "0", "]", ")", "if", "loss_values", ":", "total_loss", "=", "sum", "(", "loss_values", ")", "return", "total_loss", "return", "None"], "to_mask": {"VAR": ["_path", "_sample_weight", "flat_y_true", "loss_values", "metric", "metrics", "object", "path", "sample_weight", "self", "total_loss", "value", "y_p", "y_pred", "y_pred_struct", "y_t", "y_true", "y_true_struct"], "METHOD": ["ValueError", "append", "assert_same_structure", "build", "cast", "flatten", "is_nested", "len", "loss_fn", "map_structure", "multiply", "pack_sequence_as", "resolve_path", "sum", "update_state", "zip"]}, "attention_idx_tokens": [41, 50], "patch": "@@ -664,20 +665,20 @@\n         try:\n             tree.assert_same_structure(y_pred, y_true, check_types=False)\n         except ValueError:\n-            # y_true is either flat or leaf\n-            if (\n-                not tree.is_nested(y_true)\n-                and hasattr(y_pred, \"__len__\")\n-                and len(y_pred) == 1\n-            ):\n-                y_true = [y_true]\n+            # y_true is either:\n+            #   - flat or leaf\n+            #   - has the same structure but uses different (but reconcilable)\n+            #     container types, e.g `list` vs `tuple`\n+            flat_y_true = tree.flatten(y_true)\n             try:\n-                y_true = tree.pack_sequence_as(y_pred, y_true)\n+                y_true = tree.pack_sequence_as(y_pred, flat_y_true)", "ext_attention_idx_tokens": [31, 95], "uid": "7f85ad1b", "question": "Any chance that this could succeed yet yield an incorrect result?", "code": "def call self y true y pred sample weight None try tree assert same structure y pred y true check types False except ValueError # y true is either # - flat or leaf # - has the same structure but uses different but reconcilable # container types e g `list` vs `tuple` flat y true tree flatten y true try y true tree pack sequence as y pred flat y true except y true struct tree map structure lambda \"*\" y true y pred struct tree map structure lambda \"*\" y pred raise ValueError \"y true and y pred have different structures \\n\" f\"y true {y true struct}\\n\" f\"y pred {y pred struct}\\n\" if not self built self build y true y pred try tree assert same structure self y pred build structure y pred check types False except ValueError y pred tree pack sequence as self y pred build structure tree flatten y pred y true tree pack sequence as self y pred build structure tree flatten y true # We need to add a dummy `None` if the model has only a single output metrics [None] if len self metrics 0 else self metrics # Iterate all losses in flat form loss values [] def resolve path path object for path in path object object[ path] return object for path loss fn loss weight name metric in zip self flat losses metrics y t y p resolve path path y true resolve path path y pred if sample weight is not None and tree is nested sample weight sample weight resolve path path sample weight else sample weight sample weight value ops cast loss fn y t y p sample weight dtype self dtype if loss weight is not None value ops multiply value loss weight loss values append value # Record individual losses if metric metric update state value sample weight tree flatten y p [0] shape[0] if loss values total loss sum loss values return total loss return None"}
{"message": "@nglehuy\r\ncould you provide a reproducible script for the issue?", "timestamp": "2024-11-24T13:58:01Z", "file_name": "keras/src/utils/summary_utils.py", "range": {"start_line": 99, "end_line": 99, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1855457216", "html_url": "https://github.com/keras-team/keras/pull/20002#discussion_r1855457216", "attention_area": "            if hasattr(layer, \"output_shape\"):", "file_path": "files/03/05/00000503.py", "old_file_path": "files/04/05/00000504.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -96,12 +96,15 @@ def format_shape(shape):\n             )\n     else:\n         try:\n-            outputs = layer.compute_output_shape(**layer._build_shapes_dict)\n+            if hasattr(layer, \"output_shape\"):", "source": "def format_layer_shape(layer):\n    if not layer._inbound_nodes and not layer._build_shapes_dict:\n        return \"?\"\n\n    def format_shape(shape):\n        highlighted = [highlight_number(x) for x in shape]\n        return \"(\" + \", \".join(highlighted) + \")\"\n\n    # There are 2 approaches to get output shapes:\n    # 1. Using `layer._inbound_nodes`, which is possible if the model is a\n    # Sequential or Functional.\n    # 2. Using `layer._build_shapes_dict`, which is possible if users manually\n    # build the layer.\n    if len(layer._inbound_nodes) > 0:\n        for i in range(len(layer._inbound_nodes)):\n            outputs = layer._inbound_nodes[i].output_tensors\n            output_shapes = tree.map_structure(\n                lambda x: format_shape(x.shape), outputs\n            )\n    else:\n        try:\n            if hasattr(layer, \"output_shape\"):\n                output_shapes = layer.output_shape\n            else:\n                outputs = layer.compute_output_shape(**layer._build_shapes_dict)\n                output_shapes = tree.map_shape_structure(\n                    lambda x: format_shape(x), outputs\n                )\n        except NotImplementedError:\n            return \"?\"\n    if len(output_shapes) == 1:\n        return output_shapes[0]\n    out = str(output_shapes)\n    out = out.replace(\"'\", \"\")\n    return out", "source_start_line": 78, "tokens": ["def", "format_layer_shape", "(", "layer", ")", ":", "if", "not", "layer", ".", "_inbound_nodes", "and", "not", "layer", ".", "_build_shapes_dict", ":", "return", "\"?\"", "def", "format_shape", "(", "shape", ")", ":", "highlighted", "=", "[", "highlight_number", "(", "x", ")", "for", "x", "in", "shape", "]", "return", "\"(\"", "+", "\", \"", ".", "join", "(", "highlighted", ")", "+", "\")\"", "if", "len", "(", "layer", ".", "_inbound_nodes", ")", ">", "0", ":", "for", "i", "in", "range", "(", "len", "(", "layer", ".", "_inbound_nodes", ")", ")", ":", "outputs", "=", "layer", ".", "_inbound_nodes", "[", "i", "]", ".", "output_tensors", "output_shapes", "=", "tree", ".", "map_structure", "(", "lambda", "x", ":", "format_shape", "(", "x", ".", "shape", ")", ",", "outputs", ")", "else", ":", "try", ":", "if", "hasattr", "(", "layer", ",", "\"output_shape\"", ")", ":", "output_shapes", "=", "layer", ".", "output_shape", "else", ":", "outputs", "=", "layer", ".", "compute_output_shape", "(", "**", "layer", ".", "_build_shapes_dict", ")", "output_shapes", "=", "tree", ".", "map_shape_structure", "(", "lambda", "x", ":", "format_shape", "(", "x", ")", ",", "outputs", ")", "except", "NotImplementedError", ":", "return", "\"?\"", "if", "len", "(", "output_shapes", ")", "==", "1", ":", "return", "output_shapes", "[", "0", "]", "out", "=", "str", "(", "output_shapes", ")", "out", "=", "out", ".", "replace", "(", "\"'\"", ",", "\"\"", ")", "return", "out"], "to_mask": {"VAR": ["highlighted", "i", "layer", "out", "output_shapes", "outputs", "shape"], "METHOD": ["compute_output_shape", "format_shape", "hasattr", "highlight_number", "join", "len", "map_shape_structure", "map_structure", "range", "replace", "str"]}, "attention_idx_tokens": [103, 110], "patch": "@@ -96,12 +96,15 @@\n             )\n     else:\n         try:\n-            outputs = layer.compute_output_shape(**layer._build_shapes_dict)\n+            if hasattr(layer, \"output_shape\"):", "ext_attention_idx_tokens": [103, 157], "uid": "8f3b7245", "question": "@nglehuy  could you provide a reproducible script for the issue?", "code": "def format layer shape layer if not layer inbound nodes and not layer build shapes dict return \"?\" def format shape shape highlighted [highlight number x for x in shape] return \" \" + \" \" join highlighted + \" \" # There are 2 approaches to get output shapes # 1 Using `layer inbound nodes` which is possible if the model is a # Sequential or Functional # 2 Using `layer build shapes dict` which is possible if users manually # build the layer if len layer inbound nodes > 0 for i in range len layer inbound nodes outputs layer inbound nodes[i] output tensors output shapes tree map structure lambda x format shape x shape outputs else try if hasattr layer \"output shape\" output shapes layer output shape else outputs layer compute output shape **layer build shapes dict output shapes tree map shape structure lambda x format shape x outputs except NotImplementedError return \"?\" if len output shapes 1 return output shapes[0] out str output shapes out out replace \" \" \"\" return out"}
{"message": "Can you provide more details? Having an op that isn't jittable seems like a bug in the top. Also, this should be `self.backend.backend()` rather than `backend.backend()`", "timestamp": "2024-12-01T08:45:15Z", "file_name": "keras/src/layers/preprocessing/image_preprocessing/equalization.py", "range": {"start_line": 92, "end_line": 92, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1864785551", "html_url": "https://github.com/keras-team/keras/pull/20570#discussion_r1864785551", "attention_area": "            # for JAX bincount is never jittable because of output shape", "file_path": "files/29/05/00000529.py", "old_file_path": null, "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": true}, "language": "python", "replies": {}, "diff_hunk": "@@ -0,0 +1,193 @@\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing_layer import (  # noqa: E501\n+    BaseImagePreprocessingLayer,\n+)\n+\n+\n+@keras_export(\"keras.layers.Equalization\")\n+class Equalization(BaseImagePreprocessingLayer):\n+    \"\"\"Preprocessing layer for histogram equalization on image channels.\n+\n+    Histogram equalization is a technique to adjust image intensities to\n+    enhance contrast by effectively spreading out the most frequent\n+    intensity values. This layer applies equalization on a channel-wise\n+    basis, which can improve the visibility of details in images.\n+\n+    This layer works with both grayscale and color images, performing\n+    equalization independently on each color channel. At inference time,\n+    the equalization is consistently applied.\n+\n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n+    Args:\n+        value_range: Optional list/tuple of 2 floats specifying the lower\n+            and upper limits of the input data values. Defaults to `[0, 255]`.\n+            If the input image has been scaled, use the appropriate range\n+            (e.g., `[0.0, 1.0]`). The equalization will be scaled to this\n+            range, and output values will be clipped accordingly.\n+        bins: Integer specifying the number of histogram bins to use for\n+            equalization. Defaults to 256, which is suitable for 8-bit images.\n+            Larger values can provide more granular intensity redistribution.\n+\n+    Inputs: 3D (HWC) or 4D (NHWC) tensor, with float or int dtype. Input pixel\n+        values can be of any range (e.g. `[0., 1.)` or `[0, 255]`)\n+\n+    Output: 3D (HWC) or 4D (NHWC) tensor with intensities redistributed to\n+        enhance contrast. The output will be of the same shape and dtype as\n+        the input, with values scaled and clipped to the specified\n+        `value_range`.\n+\n+    Example:\n+\n+    ```python\n+    # Create an equalization layer for standard 8-bit images\n+    equalizer = keras.layers.Equalization()\n+\n+    # An image with uneven intensity distribution\n+    image = [...] # your input image\n+\n+    # Apply histogram equalization\n+    equalized_image = equalizer(image)\n+\n+    # For images with custom value range\n+    custom_equalizer = keras.layers.Equalization(\n+        value_range=[0.0, 1.0],  # for normalized images\n+        bins=128  # fewer bins for more subtle equalization\n+    )\n+    custom_equalized = custom_equalizer(normalized_image)\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, value_range=(0, 255), bins=256, **kwargs):\n+        super().__init__(**kwargs)\n+        self.bins = bins\n+        self._set_value_range(value_range)\n+\n+    def _set_value_range(self, value_range):\n+        if not isinstance(value_range, (tuple, list)):\n+            raise ValueError(\n+                self._VALUE_RANGE_VALIDATION_ERROR\n+                + f\"Received: value_range={value_range}\"\n+            )\n+        if len(value_range) != 2:\n+            raise ValueError(\n+                self._VALUE_RANGE_VALIDATION_ERROR\n+                + f\"Received: value_range={value_range}\"\n+            )\n+        self.value_range = sorted(value_range)\n+\n+    def _custom_histogram_fixed_width(self, values, value_range, nbins):\n+        values = self.backend.cast(values, \"float32\")\n+        value_min, value_max = value_range\n+        value_min = self.backend.cast(value_min, \"float32\")\n+        value_max = self.backend.cast(value_max, \"float32\")\n+\n+        scaled = (values - value_min) * (nbins - 1) / (value_max - value_min)\n+        indices = self.backend.cast(scaled, \"int32\")\n+        indices = self.backend.numpy.clip(indices, 0, nbins - 1)\n+\n+        if backend.backend() == \"jax\":\n+            # for JAX bincount is never jittable because of output shape", "source": "def _custom_histogram_fixed_width(self, values, value_range, nbins):\n        values = self.backend.cast(values, \"float32\")\n        value_min, value_max = value_range\n        value_min = self.backend.cast(value_min, \"float32\")\n        value_max = self.backend.cast(value_max, \"float32\")\n\n        scaled = (values - value_min) * (nbins - 1) / (value_max - value_min)\n        indices = self.backend.cast(scaled, \"int32\")\n        indices = self.backend.numpy.clip(indices, 0, nbins - 1)\n\n        if backend.backend() == \"jax\":\n            # for JAX bincount is never jittable because of output shape\n            flat_indices = self.backend.numpy.reshape(indices, [-1])\n            one_hot = self.backend.numpy.eye(nbins)[flat_indices]\n            histogram = self.backend.numpy.sum(one_hot, axis=0)\n        else:\n            # TensorFlow/PyTorch/NumPy implementation using bincount\n            flat_indices = self.backend.numpy.reshape(indices, [-1])\n            histogram = self.backend.numpy.bincount(\n                flat_indices,\n                minlength=nbins,\n            )\n\n        return histogram", "source_start_line": 81, "tokens": ["def", "_custom_histogram_fixed_width", "(", "self", ",", "values", ",", "value_range", ",", "nbins", ")", ":", "values", "=", "self", ".", "backend", ".", "cast", "(", "values", ",", "\"float32\"", ")", "value_min", ",", "value_max", "=", "value_range", "value_min", "=", "self", ".", "backend", ".", "cast", "(", "value_min", ",", "\"float32\"", ")", "value_max", "=", "self", ".", "backend", ".", "cast", "(", "value_max", ",", "\"float32\"", ")", "scaled", "=", "(", "values", "-", "value_min", ")", "*", "(", "nbins", "-", "1", ")", "/", "(", "value_max", "-", "value_min", ")", "indices", "=", "self", ".", "backend", ".", "cast", "(", "scaled", ",", "\"int32\"", ")", "indices", "=", "self", ".", "backend", ".", "numpy", ".", "clip", "(", "indices", ",", "0", ",", "nbins", "-", "1", ")", "if", "backend", ".", "backend", "(", ")", "==", "\"jax\"", ":", "flat_indices", "=", "self", ".", "backend", ".", "numpy", ".", "reshape", "(", "indices", ",", "[", "-", "1", "]", ")", "one_hot", "=", "self", ".", "backend", ".", "numpy", ".", "eye", "(", "nbins", ")", "[", "flat_indices", "]", "histogram", "=", "self", ".", "backend", ".", "numpy", ".", "sum", "(", "one_hot", ",", "axis", "=", "0", ")", "else", ":", "flat_indices", "=", "self", ".", "backend", ".", "numpy", ".", "reshape", "(", "indices", ",", "[", "-", "1", "]", ")", "histogram", "=", "self", ".", "backend", ".", "numpy", ".", "bincount", "(", "flat_indices", ",", "minlength", "=", "nbins", ",", ")", "return", "histogram"], "to_mask": {"VAR": ["flat_indices", "histogram", "indices", "nbins", "one_hot", "scaled", "self", "value_max", "value_min", "value_range", "values"], "METHOD": ["backend", "bincount", "cast", "clip", "eye", "reshape", "sum"]}, "attention_idx_tokens": [null, null], "patch": "@@ -0,0 +1,193 @@\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing_layer import (  # noqa: E501\n+    BaseImagePreprocessingLayer,\n+)\n+\n+\n+@keras_export(\"keras.layers.Equalization\")\n+class Equalization(BaseImagePreprocessingLayer):\n+    \"\"\"Preprocessing layer for histogram equalization on image channels.\n+\n+    Histogram equalization is a technique to adjust image intensities to\n+    enhance contrast by effectively spreading out the most frequent\n+    intensity values. This layer applies equalization on a channel-wise\n+    basis, which can improve the visibility of details in images.\n+\n+    This layer works with both grayscale and color images, performing\n+    equalization independently on each color channel. At inference time,\n+    the equalization is consistently applied.\n+\n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n+    Args:\n+        value_range: Optional list/tuple of 2 floats specifying the lower\n+            and upper limits of the input data values. Defaults to `[0, 255]`.\n+            If the input image has been scaled, use the appropriate range\n+            (e.g., `[0.0, 1.0]`). The equalization will be scaled to this\n+            range, and output values will be clipped accordingly.\n+        bins: Integer specifying the number of histogram bins to use for\n+            equalization. Defaults to 256, which is suitable for 8-bit images.\n+            Larger values can provide more granular intensity redistribution.\n+\n+    Inputs: 3D (HWC) or 4D (NHWC) tensor, with float or int dtype. Input pixel\n+        values can be of any range (e.g. `[0., 1.)` or `[0, 255]`)\n+\n+    Output: 3D (HWC) or 4D (NHWC) tensor with intensities redistributed to\n+        enhance contrast. The output will be of the same shape and dtype as\n+        the input, with values scaled and clipped to the specified\n+        `value_range`.\n+\n+    Example:\n+\n+    ```python\n+    # Create an equalization layer for standard 8-bit images\n+    equalizer = keras.layers.Equalization()\n+\n+    # An image with uneven intensity distribution\n+    image = [...] # your input image\n+\n+    # Apply histogram equalization\n+    equalized_image = equalizer(image)\n+\n+    # For images with custom value range\n+    custom_equalizer = keras.layers.Equalization(\n+        value_range=[0.0, 1.0],  # for normalized images\n+        bins=128  # fewer bins for more subtle equalization\n+    )\n+    custom_equalized = custom_equalizer(normalized_image)\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, value_range=(0, 255), bins=256, **kwargs):\n+        super().__init__(**kwargs)\n+        self.bins = bins\n+        self._set_value_range(value_range)\n+\n+    def _set_value_range(self, value_range):\n+        if not isinstance(value_range, (tuple, list)):\n+            raise ValueError(\n+                self._VALUE_RANGE_VALIDATION_ERROR\n+                + f\"Received: value_range={value_range}\"\n+            )\n+        if len(value_range) != 2:\n+            raise ValueError(\n+                self._VALUE_RANGE_VALIDATION_ERROR\n+                + f\"Received: value_range={value_range}\"\n+            )\n+        self.value_range = sorted(value_range)\n+\n+    def _custom_histogram_fixed_width(self, values, value_range, nbins):\n+        values = self.backend.cast(values, \"float32\")\n+        value_min, value_max = value_range\n+        value_min = self.backend.cast(value_min, \"float32\")\n+        value_max = self.backend.cast(value_max, \"float32\")\n+\n+        scaled = (values - value_min) * (nbins - 1) / (value_max - value_min)\n+        indices = self.backend.cast(scaled, \"int32\")\n+        indices = self.backend.numpy.clip(indices, 0, nbins - 1)\n+\n+        if backend.backend() == \"jax\":\n+            # for JAX bincount is never jittable because of output shape", "ext_attention_idx_tokens": [0, 196], "uid": "aac9f832", "question": "Can you provide more details? Having an op that isn't jittable seems like a bug in the top. Also, this should be `self.backend.backend()` rather than `backend.backend()`", "code": "def custom histogram fixed width self values value range nbins values self backend cast values \"float32\" value min value max value range value min self backend cast value min \"float32\" value max self backend cast value max \"float32\" scaled values - value min * nbins - 1 value max - value min indices self backend cast scaled \"int32\" indices self backend numpy clip indices 0 nbins - 1 if backend backend \"jax\" # for JAX bincount is never jittable because of output shape flat indices self backend numpy reshape indices [-1] one hot self backend numpy eye nbins [flat indices] histogram self backend numpy sum one hot axis 0 else # TensorFlow PyTorch NumPy implementation using bincount flat indices self backend numpy reshape indices [-1] histogram self backend numpy bincount flat indices minlength nbins return histogram"}
{"message": "Why lambda?", "timestamp": "2024-12-04T20:35:39Z", "file_name": "keras/src/layers/preprocessing/image_preprocessing/mix_up.py", "range": {"start_line": 76, "end_line": 76, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1870246920", "html_url": "https://github.com/keras-team/keras/pull/20590#discussion_r1870246920", "attention_area": "        lambda_sample = self._sample_from_beta(", "file_path": "files/32/05/00000532.py", "old_file_path": null, "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": true}, "language": "python", "replies": {}, "diff_hunk": "@@ -0,0 +1,163 @@\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing_layer import (  # noqa: E501\n+    BaseImagePreprocessingLayer,\n+)\n+from keras.src.random import SeedGenerator\n+\n+\n+@keras_export(\"keras.layers.MixUp\")\n+class MixUp(BaseImagePreprocessingLayer):\n+    \"\"\"MixUp implements the MixUp data augmentation technique.\n+\n+    Args:\n+        alpha: Float between 0 and 1. Inverse scale parameter for the gamma\n+            distribution. This controls the shape of the distribution from which\n+            the smoothing values are sampled. Defaults to 0.2, which is a\n+            recommended value when training an imagenet1k classification model.\n+        seed: Integer. Used to create a random seed.\n+\n+    References:\n+        - [MixUp paper](https://arxiv.org/abs/1710.09412).\n+        - [MixUp for Object Detection paper](https://arxiv.org/pdf/1902.04103).\n+\n+    Example:\n+    ```python\n+    (images, labels), _ = keras.datasets.cifar10.load_data()\n+    images, labels = images[:10], labels[:10]\n+    # Labels must be floating-point and one-hot encoded\n+    labels = tf.cast(tf.one_hot(labels, 10), tf.float32)\n+    mixup = keras.layers.preprocessing.MixUp(10)\n+    augmented_images, updated_labels = mixup(\n+        {'images': images, 'labels': labels}\n+    )\n+    # output == {'images': updated_images, 'labels': updated_labels}\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, alpha=0.2, seed=None, **kwargs):\n+        super().__init__(**kwargs)\n+        self.alpha = alpha\n+        self.seed = seed\n+        self.generator = SeedGenerator(seed)\n+\n+    def _sample_from_beta(self, alpha, beta, shape, seed):\n+        sample_alpha = self.backend.random.gamma(\n+            shape,\n+            alpha=alpha,\n+            seed=seed,\n+        )\n+        sample_beta = self.backend.random.gamma(\n+            shape,\n+            alpha=beta,\n+            seed=seed,\n+        )\n+        return sample_alpha / (sample_alpha + sample_beta)\n+\n+    def get_random_transformation(self, data, training=True, seed=None):\n+        if isinstance(data, dict):\n+            images = data[\"images\"]\n+        else:\n+            images = data\n+\n+        images_shape = self.backend.shape(images)\n+\n+        if len(images_shape) == 3:\n+            batch_size = 1\n+        else:\n+            batch_size = self.backend.shape(images)[0]\n+\n+        if seed is None:\n+            seed = self._get_seed_generator(self.backend._backend)\n+\n+        permutation_order = self.backend.random.shuffle(\n+            self.backend.numpy.arange(0, batch_size), seed=seed\n+        )\n+\n+        lambda_sample = self._sample_from_beta(", "source": "def get_random_transformation(self, data, training=True, seed=None):\n        if isinstance(data, dict):\n            images = data[\"images\"]\n        else:\n            images = data\n\n        images_shape = self.backend.shape(images)\n\n        if len(images_shape) == 3:\n            batch_size = 1\n        else:\n            batch_size = self.backend.shape(images)[0]\n\n        if seed is None:\n            seed = self._get_seed_generator(self.backend._backend)\n\n        permutation_order = self.backend.random.shuffle(\n            self.backend.numpy.arange(0, batch_size), seed=seed\n        )\n\n        lambda_sample = self._sample_from_beta(\n            self.alpha, self.alpha, (batch_size,), seed=seed\n        )\n\n        return {\n            \"lambda_sample\": lambda_sample,\n            \"permutation_order\": permutation_order,\n        }", "source_start_line": 56, "tokens": ["def", "get_random_transformation", "(", "self", ",", "data", ",", "training", "=", "True", ",", "seed", "=", "None", ")", ":", "if", "isinstance", "(", "data", ",", "dict", ")", ":", "images", "=", "data", "[", "\"images\"", "]", "else", ":", "images", "=", "data", "images_shape", "=", "self", ".", "backend", ".", "shape", "(", "images", ")", "if", "len", "(", "images_shape", ")", "==", "3", ":", "batch_size", "=", "1", "else", ":", "batch_size", "=", "self", ".", "backend", ".", "shape", "(", "images", ")", "[", "0", "]", "if", "seed", "is", "None", ":", "seed", "=", "self", ".", "_get_seed_generator", "(", "self", ".", "backend", ".", "_backend", ")", "permutation_order", "=", "self", ".", "backend", ".", "random", ".", "shuffle", "(", "self", ".", "backend", ".", "numpy", ".", "arange", "(", "0", ",", "batch_size", ")", ",", "seed", "=", "seed", ")", "lambda_sample", "=", "self", ".", "_sample_from_beta", "(", "self", ".", "alpha", ",", "self", ".", "alpha", ",", "(", "batch_size", ",", ")", ",", "seed", "=", "seed", ")", "return", "{", "\"lambda_sample\"", ":", "lambda_sample", ",", "\"permutation_order\"", ":", "permutation_order", ",", "}"], "to_mask": {"VAR": ["batch_size", "data", "images", "images_shape", "lambda_sample", "permutation_order", "seed", "self", "training"], "METHOD": ["_get_seed_generator", "_sample_from_beta", "arange", "isinstance", "len", "shape", "shuffle"]}, "attention_idx_tokens": [115, 120], "patch": "@@ -0,0 +1,163 @@\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing_layer import (  # noqa: E501\n+    BaseImagePreprocessingLayer,\n+)\n+from keras.src.random import SeedGenerator\n+\n+\n+@keras_export(\"keras.layers.MixUp\")\n+class MixUp(BaseImagePreprocessingLayer):\n+    \"\"\"MixUp implements the MixUp data augmentation technique.\n+\n+    Args:\n+        alpha: Float between 0 and 1. Inverse scale parameter for the gamma\n+            distribution. This controls the shape of the distribution from which\n+            the smoothing values are sampled. Defaults to 0.2, which is a\n+            recommended value when training an imagenet1k classification model.\n+        seed: Integer. Used to create a random seed.\n+\n+    References:\n+        - [MixUp paper](https://arxiv.org/abs/1710.09412).\n+        - [MixUp for Object Detection paper](https://arxiv.org/pdf/1902.04103).\n+\n+    Example:\n+    ```python\n+    (images, labels), _ = keras.datasets.cifar10.load_data()\n+    images, labels = images[:10], labels[:10]\n+    # Labels must be floating-point and one-hot encoded\n+    labels = tf.cast(tf.one_hot(labels, 10), tf.float32)\n+    mixup = keras.layers.preprocessing.MixUp(10)\n+    augmented_images, updated_labels = mixup(\n+        {'images': images, 'labels': labels}\n+    )\n+    # output == {'images': updated_images, 'labels': updated_labels}\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, alpha=0.2, seed=None, **kwargs):\n+        super().__init__(**kwargs)\n+        self.alpha = alpha\n+        self.seed = seed\n+        self.generator = SeedGenerator(seed)\n+\n+    def _sample_from_beta(self, alpha, beta, shape, seed):\n+        sample_alpha = self.backend.random.gamma(\n+            shape,\n+            alpha=alpha,\n+            seed=seed,\n+        )\n+        sample_beta = self.backend.random.gamma(\n+            shape,\n+            alpha=beta,\n+            seed=seed,\n+        )\n+        return sample_alpha / (sample_alpha + sample_beta)\n+\n+    def get_random_transformation(self, data, training=True, seed=None):\n+        if isinstance(data, dict):\n+            images = data[\"images\"]\n+        else:\n+            images = data\n+\n+        images_shape = self.backend.shape(images)\n+\n+        if len(images_shape) == 3:\n+            batch_size = 1\n+        else:\n+            batch_size = self.backend.shape(images)[0]\n+\n+        if seed is None:\n+            seed = self._get_seed_generator(self.backend._backend)\n+\n+        permutation_order = self.backend.random.shuffle(\n+            self.backend.numpy.arange(0, batch_size), seed=seed\n+        )\n+\n+        lambda_sample = self._sample_from_beta(", "ext_attention_idx_tokens": [0, 148], "uid": "7bc52160", "question": "Why lambda?", "code": "def get random transformation self data training True seed None if isinstance data dict images data[\"images\"] else images data images shape self backend shape images if len images shape 3 batch size 1 else batch size self backend shape images [0] if seed is None seed self get seed generator self backend backend permutation order self backend random shuffle self backend numpy arange 0 batch size seed seed lambda sample self sample from beta self alpha self alpha batch size seed seed return { \"lambda sample\" lambda sample \"permutation order\" permutation order }"}
{"message": "Do you mean at the start of this function or even before? ", "timestamp": "2024-12-14T17:48:28Z", "file_name": "keras/src/trainers/data_adapters/data_adapter_utils.py", "range": {"start_line": 125, "end_line": 125, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1885152788", "html_url": "https://github.com/keras-team/keras/pull/20638#discussion_r1885152788", "attention_area": "    if hasattr(y, \"astype\"):", "file_path": "files/60/05/00000560.py", "old_file_path": "files/61/05/00000561.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -121,7 +121,15 @@ def class_weight_to_sample_weights(y, class_weight):\n             y = np.argmax(y, axis=-1)\n         else:\n             y = np.squeeze(y, axis=-1)\n-    y = np.round(y).astype(\"int32\")\n+    y = np.round(y)\n+    if hasattr(y, \"astype\"):", "source": "def class_weight_to_sample_weights(y, class_weight):\n    sample_weight = np.ones(shape=(y.shape[0],), dtype=backend.floatx())\n    if len(y.shape) > 1:\n        if y.shape[-1] != 1:\n            y = np.argmax(y, axis=-1)\n        else:\n            y = np.squeeze(y, axis=-1)\n    y = np.round(y)\n    if hasattr(y, \"astype\"):\n        y = y.astype(\"int32\")\n    else:\n        # must be a torch tensor object\n        import torch\n\n        y = y.to(torch.int32)\n\n    for i in range(y.shape[0]):\n        sample_weight[i] = class_weight.get(int(y[i]), 1.0)\n    return sample_weight", "source_start_line": 117, "tokens": ["def", "class_weight_to_sample_weights", "(", "y", ",", "class_weight", ")", ":", "sample_weight", "=", "np", ".", "ones", "(", "shape", "=", "(", "y", ".", "shape", "[", "0", "]", ",", ")", ",", "dtype", "=", "backend", ".", "floatx", "(", ")", ")", "if", "len", "(", "y", ".", "shape", ")", ">", "1", ":", "if", "y", ".", "shape", "[", "-", "1", "]", "!=", "1", ":", "y", "=", "np", ".", "argmax", "(", "y", ",", "axis", "=", "-", "1", ")", "else", ":", "y", "=", "np", ".", "squeeze", "(", "y", ",", "axis", "=", "-", "1", ")", "y", "=", "np", ".", "round", "(", "y", ")", "if", "hasattr", "(", "y", ",", "\"astype\"", ")", ":", "y", "=", "y", ".", "astype", "(", "\"int32\"", ")", "else", ":", "import", "torch", "y", "=", "y", ".", "to", "(", "torch", ".", "int32", ")", "for", "i", "in", "range", "(", "y", ".", "shape", "[", "0", "]", ")", ":", "sample_weight", "[", "i", "]", "=", "class_weight", ".", "get", "(", "int", "(", "y", "[", "i", "]", ")", ",", "1.0", ")", "return", "sample_weight"], "to_mask": {"VAR": ["class_weight", "i", "sample_weight", "y"], "METHOD": ["argmax", "astype", "floatx", "get", "hasattr", "int", "len", "ones", "range", "round", "squeeze", "to"]}, "attention_idx_tokens": [91, 98], "patch": "@@ -121,7 +121,15 @@\n             y = np.argmax(y, axis=-1)\n         else:\n             y = np.squeeze(y, axis=-1)\n-    y = np.round(y).astype(\"int32\")\n+    y = np.round(y)\n+    if hasattr(y, \"astype\"):", "ext_attention_idx_tokens": [83, 133], "uid": "e87521f3", "question": "Do you mean at the start of this function or even before? ", "code": "def class weight to sample weights y class weight sample weight np ones shape y shape[0] dtype backend floatx if len y shape > 1 if y shape[-1] ! 1 y np argmax y axis -1 else y np squeeze y axis -1 y np round y if hasattr y \"astype\" y y astype \"int32\" else # must be a torch tensor object import torch y y to torch int32 for i in range y shape[0] sample weight[i] class weight get int y[i] 1 0 return sample weight"}
{"message": "This seems like an important thing to support, can you attach a TODO with an issue number to this line?", "timestamp": "2024-12-14T19:29:28Z", "file_name": "keras/src/backend/openvino/trainer.py", "range": {"start_line": 169, "end_line": 169, "start_character": 0, "end_character": 0}, "project": "keras-team/keras", "api_url": "https://api.github.com/repos/keras-team/keras/pulls/comments/1885364987", "html_url": "https://github.com/keras-team/keras/pull/19727#discussion_r1885364987", "attention_area": "            \"`fit` is not supported with openvino backend\"", "file_path": "files/64/05/00000564.py", "old_file_path": null, "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": true}, "language": "python", "replies": {}, "diff_hunk": "@@ -0,0 +1,272 @@\n+import numpy as np\n+import openvino as ov\n+import openvino.runtime.opset14 as ov_opset\n+\n+from keras.src import backend\n+from keras.src import callbacks as callbacks_module\n+from keras.src import tree\n+from keras.src.backend.openvino.core import OPENVINO_DTYPES\n+from keras.src.backend.openvino.core import OpenVINOKerasTensor\n+from keras.src.backend.openvino.core import get_device\n+from keras.src.trainers import trainer as base_trainer\n+from keras.src.trainers.data_adapters import data_adapter_utils\n+from keras.src.trainers.epoch_iterator import EpochIterator\n+from keras.src.utils import traceback_utils\n+\n+\n+class OpenVINOTrainer(base_trainer.Trainer):\n+    def __init__(self):\n+        super().__init__()\n+        self.test_function = None\n+        self.predict_function = None\n+        self.ov_compiled_model = None\n+        self.ov_device = None\n+        self.struct_params = None\n+        self.struct_outputs = None\n+\n+    def _unpack_singleton(self, x):\n+        if isinstance(x, (list, tuple)) and len(x) == 1:\n+            return x[0]\n+        return x\n+\n+    def test_step(self, data):\n+        raise NotImplementedError(\n+            \"`test_step` is not supported with openvino backend\"\n+        )\n+\n+    def predict_step(self, data):\n+        x, _, _ = data_adapter_utils.unpack_x_y_sample_weight(data)\n+        ov_compiled_model = self._get_compiled_model(x)\n+        flatten_x = tree.flatten(x)\n+        y_pred = ov_compiled_model(flatten_x)\n+        # recover structure of the model output\n+        y_pred = self._unpack_singleton(\n+            tree.pack_sequence_as(self.struct_outputs, y_pred.to_tuple())\n+        )\n+        return y_pred\n+\n+    def make_test_function(self, force=False):\n+        if self.test_function is not None and not force:\n+            return self.test_function\n+\n+        def one_test_step(data):\n+            data = data[0]\n+            return self.test_step(data)\n+\n+        def multi_test_steps(data):\n+            for single_step_data in data:\n+                logs = one_test_step([single_step_data])\n+            return logs\n+\n+        if self.steps_per_execution > 1:\n+            test_step = multi_test_steps\n+        else:\n+            test_step = one_test_step\n+\n+        self.test_function = test_step\n+\n+    def _parameterize_data(self, data):\n+        if isinstance(data, (list, tuple)):\n+            parametrize_data = []\n+            for elem in data:\n+                param_elem = self._parameterize_data(elem)\n+                parametrize_data.append(param_elem)\n+        elif isinstance(data, dict):\n+            parametrize_data = dict()\n+            for elem_name, elem in data.items():\n+                param_elem = self._parameterize_data(elem)\n+                parametrize_data[elem_name] = param_elem\n+        elif isinstance(data, np.ndarray) or np.isscalar(data):\n+            ov_type = OPENVINO_DTYPES[str(data.dtype)]\n+            ov_shape = list(data.shape)\n+            param = ov_opset.parameter(shape=ov_shape, dtype=ov_type)\n+            parametrize_data = OpenVINOKerasTensor(param.output(0))\n+        elif isinstance(data, int):\n+            param = ov_opset.parameter(shape=[], dtype=ov.Type.i32)\n+            parametrize_data = OpenVINOKerasTensor(param.output(0))\n+        elif isinstance(data, float):\n+            param = ov_opset.parameter(shape=[], dtype=ov.Type.f32)\n+            parametrize_data = OpenVINOKerasTensor(param.output(0))\n+        else:\n+            raise \"Unknown type of input data {}\".format(type(data))\n+        return parametrize_data\n+\n+    def _get_compiled_model(self, data):\n+        if (\n+            self.ov_compiled_model is not None\n+            and get_device() == self.ov_device\n+        ):\n+            return self.ov_compiled_model\n+\n+        # remove the previous cached compiled model if exists\n+        del self.ov_compiled_model\n+\n+        # prepare parameterized input\n+        self.struct_params = self._parameterize_data(data)\n+        # construct OpenVINO graph during calling Keras Model\n+        self.struct_outputs = self(self.struct_params)\n+\n+        parameters = []\n+        for p in tree.flatten(self.struct_params):\n+            parameters.append(p.output.get_node())\n+        results = []\n+        for r in tree.flatten(self.struct_outputs):\n+            results.append(ov_opset.result(r.output))\n+\n+        # prepare compiled model from scratch\n+        ov_model = ov.Model(results=results, parameters=parameters)\n+        self.ov_compiled_model = ov.compile_model(ov_model, get_device())\n+        self.ov_device = get_device()\n+        return self.ov_compiled_model\n+\n+    def make_predict_function(self, force=False):\n+        if self.predict_function is not None and not force:\n+            return self.predict_function\n+\n+        def one_predict_step(data):\n+            data = data[0]\n+            return self.predict_step(data)\n+\n+        def multi_predict_steps(data):\n+            outputs = one_predict_step(data[:1])\n+\n+            for single_step_data in data[1:]:\n+                step_outputs = one_predict_step([single_step_data])\n+                outputs = tree.map_structure(\n+                    lambda t1, t2: np.concatenate([t1, t2]),\n+                    outputs,\n+                    step_outputs,\n+                )\n+            return outputs\n+\n+        if self.steps_per_execution > 1:\n+            predict_step = multi_predict_steps\n+        else:\n+            predict_step = one_predict_step\n+\n+        self.predict_function = predict_step\n+\n+    def fit(\n+        self,\n+        x=None,\n+        y=None,\n+        batch_size=None,\n+        epochs=1,\n+        verbose=\"auto\",\n+        callbacks=None,\n+        validation_split=0.0,\n+        validation_data=None,\n+        shuffle=True,\n+        class_weight=None,\n+        sample_weight=None,\n+        initial_epoch=0,\n+        steps_per_epoch=None,\n+        validation_steps=None,\n+        validation_batch_size=None,\n+        validation_freq=1,\n+    ):\n+        raise NotImplementedError(\n+            \"`fit` is not supported with openvino backend\"", "source": "def fit(\n        self,\n        x=None,\n        y=None,\n        batch_size=None,\n        epochs=1,\n        verbose=\"auto\",\n        callbacks=None,\n        validation_split=0.0,\n        validation_data=None,\n        shuffle=True,\n        class_weight=None,\n        sample_weight=None,\n        initial_epoch=0,\n        steps_per_epoch=None,\n        validation_steps=None,\n        validation_batch_size=None,\n        validation_freq=1,\n    ):\n        raise NotImplementedError(\n            \"`fit` is not supported with openvino backend\"\n        )", "source_start_line": 149, "tokens": ["def", "fit", "(", "self", ",", "x", "=", "None", ",", "y", "=", "None", ",", "batch_size", "=", "None", ",", "epochs", "=", "1", ",", "verbose", "=", "\"auto\"", ",", "callbacks", "=", "None", ",", "validation_split", "=", "0.0", ",", "validation_data", "=", "None", ",", "shuffle", "=", "True", ",", "class_weight", "=", "None", ",", "sample_weight", "=", "None", ",", "initial_epoch", "=", "0", ",", "steps_per_epoch", "=", "None", ",", "validation_steps", "=", "None", ",", "validation_batch_size", "=", "None", ",", "validation_freq", "=", "1", ",", ")", ":", "raise", "NotImplementedError", "(", "\"`fit` is not supported with openvino backend\"", ")"], "to_mask": {"VAR": ["batch_size", "callbacks", "class_weight", "epochs", "initial_epoch", "sample_weight", "self", "shuffle", "steps_per_epoch", "validation_batch_size", "validation_data", "validation_freq", "validation_split", "validation_steps", "verbose", "x", "y"], "METHOD": ["NotImplementedError"]}, "attention_idx_tokens": [74, 74], "patch": "@@ -0,0 +1,272 @@\n+import numpy as np\n+import openvino as ov\n+import openvino.runtime.opset14 as ov_opset\n+\n+from keras.src import backend\n+from keras.src import callbacks as callbacks_module\n+from keras.src import tree\n+from keras.src.backend.openvino.core import OPENVINO_DTYPES\n+from keras.src.backend.openvino.core import OpenVINOKerasTensor\n+from keras.src.backend.openvino.core import get_device\n+from keras.src.trainers import trainer as base_trainer\n+from keras.src.trainers.data_adapters import data_adapter_utils\n+from keras.src.trainers.epoch_iterator import EpochIterator\n+from keras.src.utils import traceback_utils\n+\n+\n+class OpenVINOTrainer(base_trainer.Trainer):\n+    def __init__(self):\n+        super().__init__()\n+        self.test_function = None\n+        self.predict_function = None\n+        self.ov_compiled_model = None\n+        self.ov_device = None\n+        self.struct_params = None\n+        self.struct_outputs = None\n+\n+    def _unpack_singleton(self, x):\n+        if isinstance(x, (list, tuple)) and len(x) == 1:\n+            return x[0]\n+        return x\n+\n+    def test_step(self, data):\n+        raise NotImplementedError(\n+            \"`test_step` is not supported with openvino backend\"\n+        )\n+\n+    def predict_step(self, data):\n+        x, _, _ = data_adapter_utils.unpack_x_y_sample_weight(data)\n+        ov_compiled_model = self._get_compiled_model(x)\n+        flatten_x = tree.flatten(x)\n+        y_pred = ov_compiled_model(flatten_x)\n+        # recover structure of the model output\n+        y_pred = self._unpack_singleton(\n+            tree.pack_sequence_as(self.struct_outputs, y_pred.to_tuple())\n+        )\n+        return y_pred\n+\n+    def make_test_function(self, force=False):\n+        if self.test_function is not None and not force:\n+            return self.test_function\n+\n+        def one_test_step(data):\n+            data = data[0]\n+            return self.test_step(data)\n+\n+        def multi_test_steps(data):\n+            for single_step_data in data:\n+                logs = one_test_step([single_step_data])\n+            return logs\n+\n+        if self.steps_per_execution > 1:\n+            test_step = multi_test_steps\n+        else:\n+            test_step = one_test_step\n+\n+        self.test_function = test_step\n+\n+    def _parameterize_data(self, data):\n+        if isinstance(data, (list, tuple)):\n+            parametrize_data = []\n+            for elem in data:\n+                param_elem = self._parameterize_data(elem)\n+                parametrize_data.append(param_elem)\n+        elif isinstance(data, dict):\n+            parametrize_data = dict()\n+            for elem_name, elem in data.items():\n+                param_elem = self._parameterize_data(elem)\n+                parametrize_data[elem_name] = param_elem\n+        elif isinstance(data, np.ndarray) or np.isscalar(data):\n+            ov_type = OPENVINO_DTYPES[str(data.dtype)]\n+            ov_shape = list(data.shape)\n+            param = ov_opset.parameter(shape=ov_shape, dtype=ov_type)\n+            parametrize_data = OpenVINOKerasTensor(param.output(0))\n+        elif isinstance(data, int):\n+            param = ov_opset.parameter(shape=[], dtype=ov.Type.i32)\n+            parametrize_data = OpenVINOKerasTensor(param.output(0))\n+        elif isinstance(data, float):\n+            param = ov_opset.parameter(shape=[], dtype=ov.Type.f32)\n+            parametrize_data = OpenVINOKerasTensor(param.output(0))\n+        else:\n+            raise \"Unknown type of input data {}\".format(type(data))\n+        return parametrize_data\n+\n+    def _get_compiled_model(self, data):\n+        if (\n+            self.ov_compiled_model is not None\n+            and get_device() == self.ov_device\n+        ):\n+            return self.ov_compiled_model\n+\n+        # remove the previous cached compiled model if exists\n+        del self.ov_compiled_model\n+\n+        # prepare parameterized input\n+        self.struct_params = self._parameterize_data(data)\n+        # construct OpenVINO graph during calling Keras Model\n+        self.struct_outputs = self(self.struct_params)\n+\n+        parameters = []\n+        for p in tree.flatten(self.struct_params):\n+            parameters.append(p.output.get_node())\n+        results = []\n+        for r in tree.flatten(self.struct_outputs):\n+            results.append(ov_opset.result(r.output))\n+\n+        # prepare compiled model from scratch\n+        ov_model = ov.Model(results=results, parameters=parameters)\n+        self.ov_compiled_model = ov.compile_model(ov_model, get_device())\n+        self.ov_device = get_device()\n+        return self.ov_compiled_model\n+\n+    def make_predict_function(self, force=False):\n+        if self.predict_function is not None and not force:\n+            return self.predict_function\n+\n+        def one_predict_step(data):\n+            data = data[0]\n+            return self.predict_step(data)\n+\n+        def multi_predict_steps(data):\n+            outputs = one_predict_step(data[:1])\n+\n+            for single_step_data in data[1:]:\n+                step_outputs = one_predict_step([single_step_data])\n+                outputs = tree.map_structure(\n+                    lambda t1, t2: np.concatenate([t1, t2]),\n+                    outputs,\n+                    step_outputs,\n+                )\n+            return outputs\n+\n+        if self.steps_per_execution > 1:\n+            predict_step = multi_predict_steps\n+        else:\n+            predict_step = one_predict_step\n+\n+        self.predict_function = predict_step\n+\n+    def fit(\n+        self,\n+        x=None,\n+        y=None,\n+        batch_size=None,\n+        epochs=1,\n+        verbose=\"auto\",\n+        callbacks=None,\n+        validation_split=0.0,\n+        validation_data=None,\n+        shuffle=True,\n+        class_weight=None,\n+        sample_weight=None,\n+        initial_epoch=0,\n+        steps_per_epoch=None,\n+        validation_steps=None,\n+        validation_batch_size=None,\n+        validation_freq=1,\n+    ):\n+        raise NotImplementedError(\n+            \"`fit` is not supported with openvino backend\"", "ext_attention_idx_tokens": [0, 75], "uid": "2f9e409e", "question": "This seems like an important thing to support, can you attach a TODO with an issue number to this line?", "code": "def fit self x None y None batch size None epochs 1 verbose \"auto\" callbacks None validation split 0 0 validation data None shuffle True class weight None sample weight None initial epoch 0 steps per epoch None validation steps None validation batch size None validation freq 1 raise NotImplementedError \"`fit` is not supported with openvino backend\""}
{"message": "What happens to the inverse? On line 563, I see that it is tested, but excludes the value below `vmin`. But that was when it became 0 for everything, which could never be inverted uniquely; is it uniquely invertible now?", "timestamp": "2024-01-04T07:28:38Z", "file_name": "lib/matplotlib/tests/test_colors.py", "range": {"start_line": 558, "end_line": 558, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1441419921", "html_url": "https://github.com/matplotlib/matplotlib/pull/27589#discussion_r1441419921", "attention_area": "    expected = [-1/16, 0, 1/16, 1/4, 1]", "file_path": "files/09/00/00000009.py", "old_file_path": "files/10/00/00000010.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -555,7 +555,7 @@ def test_PowerNorm():\n     assert_array_almost_equal(norm(a), pnorm(a))\n \n     a = np.array([-0.5, 0, 2, 4, 8], dtype=float)\n-    expected = [0, 0, 1/16, 1/4, 1]\n+    expected = [-1/16, 0, 1/16, 1/4, 1]", "source": "def test_PowerNorm():\n    # Check an exponent of 1 gives same results as a normal linear\n    # normalization. Also implicitly checks that vmin/vmax are\n    # automatically initialized from first array input.\n    a = np.array([0, 0.5, 1, 1.5], dtype=float)\n    pnorm = mcolors.PowerNorm(1)\n    norm = mcolors.Normalize()\n    assert_array_almost_equal(norm(a), pnorm(a))\n\n    a = np.array([-0.5, 0, 2, 4, 8], dtype=float)\n    expected = [-1/16, 0, 1/16, 1/4, 1]\n    pnorm = mcolors.PowerNorm(2, vmin=0, vmax=8)\n    assert_array_almost_equal(pnorm(a), expected)\n    assert pnorm(a[0]) == expected[0]\n    assert pnorm(a[2]) == expected[2]\n    assert_array_almost_equal(a[1:], pnorm.inverse(pnorm(a))[1:])\n\n    # Clip = True\n    a = np.array([-0.5, 0, 1, 8, 16], dtype=float)\n    expected = [0, 0, 0, 1, 1]\n    # Clip = True when creating the norm\n    pnorm = mcolors.PowerNorm(2, vmin=2, vmax=8, clip=True)\n    assert_array_almost_equal(pnorm(a), expected)\n    assert pnorm(a[0]) == expected[0]\n    assert pnorm(a[-1]) == expected[-1]\n    # Clip = True at call time\n    pnorm = mcolors.PowerNorm(2, vmin=2, vmax=8, clip=False)\n    assert_array_almost_equal(pnorm(a, clip=True), expected)\n    assert pnorm(a[0], clip=True) == expected[0]\n    assert pnorm(a[-1], clip=True) == expected[-1]\n\n    # Check clip=True preserves masked values\n    a = np.ma.array([5, 2], mask=[True, False])\n    out = pnorm(a, clip=True)\n    assert_array_equal(out.mask, [True, False])", "source_start_line": 548, "tokens": ["def", "test_PowerNorm", "(", ")", ":", "a", "=", "np", ".", "array", "(", "[", "0", ",", "0.5", ",", "1", ",", "1.5", "]", ",", "dtype", "=", "float", ")", "pnorm", "=", "mcolors", ".", "PowerNorm", "(", "1", ")", "norm", "=", "mcolors", ".", "Normalize", "(", ")", "assert_array_almost_equal", "(", "norm", "(", "a", ")", ",", "pnorm", "(", "a", ")", ")", "a", "=", "np", ".", "array", "(", "[", "-", "0.5", ",", "0", ",", "2", ",", "4", ",", "8", "]", ",", "dtype", "=", "float", ")", "expected", "=", "[", "-", "1", "/", "16", ",", "0", ",", "1", "/", "16", ",", "1", "/", "4", ",", "1", "]", "pnorm", "=", "mcolors", ".", "PowerNorm", "(", "2", ",", "vmin", "=", "0", ",", "vmax", "=", "8", ")", "assert_array_almost_equal", "(", "pnorm", "(", "a", ")", ",", "expected", ")", "assert", "pnorm", "(", "a", "[", "0", "]", ")", "==", "expected", "[", "0", "]", "assert", "pnorm", "(", "a", "[", "2", "]", ")", "==", "expected", "[", "2", "]", "assert_array_almost_equal", "(", "a", "[", "1", ":", "]", ",", "pnorm", ".", "inverse", "(", "pnorm", "(", "a", ")", ")", "[", "1", ":", "]", ")", "a", "=", "np", ".", "array", "(", "[", "-", "0.5", ",", "0", ",", "1", ",", "8", ",", "16", "]", ",", "dtype", "=", "float", ")", "expected", "=", "[", "0", ",", "0", ",", "0", ",", "1", ",", "1", "]", "pnorm", "=", "mcolors", ".", "PowerNorm", "(", "2", ",", "vmin", "=", "2", ",", "vmax", "=", "8", ",", "clip", "=", "True", ")", "assert_array_almost_equal", "(", "pnorm", "(", "a", ")", ",", "expected", ")", "assert", "pnorm", "(", "a", "[", "0", "]", ")", "==", "expected", "[", "0", "]", "assert", "pnorm", "(", "a", "[", "-", "1", "]", ")", "==", "expected", "[", "-", "1", "]", "pnorm", "=", "mcolors", ".", "PowerNorm", "(", "2", ",", "vmin", "=", "2", ",", "vmax", "=", "8", ",", "clip", "=", "False", ")", "assert_array_almost_equal", "(", "pnorm", "(", "a", ",", "clip", "=", "True", ")", ",", "expected", ")", "assert", "pnorm", "(", "a", "[", "0", "]", ",", "clip", "=", "True", ")", "==", "expected", "[", "0", "]", "assert", "pnorm", "(", "a", "[", "-", "1", "]", ",", "clip", "=", "True", ")", "==", "expected", "[", "-", "1", "]", "a", "=", "np", ".", "ma", ".", "array", "(", "[", "5", ",", "2", "]", ",", "mask", "=", "[", "True", ",", "False", "]", ")", "out", "=", "pnorm", "(", "a", ",", "clip", "=", "True", ")", "assert_array_equal", "(", "out", ".", "mask", ",", "[", "True", ",", "False", "]", ")"], "to_mask": {"VAR": ["a", "expected", "norm", "out", "pnorm"], "METHOD": ["Normalize", "PowerNorm", "array", "assert_array_almost_equal", "assert_array_equal", "inverse", "norm", "pnorm"]}, "attention_idx_tokens": [75, 94], "patch": "@@ -555,7 +555,7 @@\n     assert_array_almost_equal(norm(a), pnorm(a))\n \n     a = np.array([-0.5, 0, 2, 4, 8], dtype=float)\n-    expected = [0, 0, 1/16, 1/4, 1]\n+    expected = [-1/16, 0, 1/16, 1/4, 1]", "ext_attention_idx_tokens": [75, 110], "uid": "aaee0f98", "question": "What happens to the inverse? On line 563, I see that it is tested, but excludes the value below `vmin`. But that was when it became 0 for everything, which could never be inverted uniquely; is it uniquely invertible now?", "code": "def test PowerNorm # Check an exponent of 1 gives same results as a normal linear # normalization Also implicitly checks that vmin vmax are # automatically initialized from first array input a np array [0 0 5 1 1 5] dtype float pnorm mcolors PowerNorm 1 norm mcolors Normalize assert array almost equal norm a pnorm a a np array [-0 5 0 2 4 8] dtype float expected [-1 16 0 1 16 1 4 1] pnorm mcolors PowerNorm 2 vmin 0 vmax 8 assert array almost equal pnorm a expected assert pnorm a[0] expected[0] assert pnorm a[2] expected[2] assert array almost equal a[1 ] pnorm inverse pnorm a [1 ] # Clip True a np array [-0 5 0 1 8 16] dtype float expected [0 0 0 1 1] # Clip True when creating the norm pnorm mcolors PowerNorm 2 vmin 2 vmax 8 clip True assert array almost equal pnorm a expected assert pnorm a[0] expected[0] assert pnorm a[-1] expected[-1] # Clip True at call time pnorm mcolors PowerNorm 2 vmin 2 vmax 8 clip False assert array almost equal pnorm a clip True expected assert pnorm a[0] clip True expected[0] assert pnorm a[-1] clip True expected[-1] # Check clip True preserves masked values a np ma array [5 2] mask [True False] out pnorm a clip True assert array equal out mask [True False]"}
{"message": "Do we need 10000 points? That seems a bit large, though I didn't check how slow the test was.", "timestamp": "2024-01-09T07:00:24Z", "file_name": "lib/matplotlib/tests/test_colors.py", "range": {"start_line": 601, "end_line": 601, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1445695856", "html_url": "https://github.com/matplotlib/matplotlib/pull/27589#discussion_r1445695856", "attention_area": "    data = np.arange(100*100).reshape(100, 100) + vmin", "file_path": "files/20/00/00000020.py", "old_file_path": "files/10/00/00000010.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -591,6 +595,15 @@ def test_PowerNorm_translation_invariance():\n     assert_array_almost_equal(pnorm(a - 2), expected)\n \n \n+def test_powernorm_cbar_limits():\n+    fig, ax = plt.subplots()\n+    vmin, vmax = 300, 1000\n+    data = np.arange(100*100).reshape(100, 100) + vmin", "source": "def test_powernorm_cbar_limits():\n    fig, ax = plt.subplots()\n    vmin, vmax = 300, 1000\n    data = np.arange(100*100).reshape(100, 100) + vmin\n    im = ax.imshow(data, norm=mcolors.PowerNorm(gamma=0.2, vmin=vmin, vmax=vmax))\n    cbar = fig.colorbar(im)\n    assert cbar.ax.get_ylim() == (vmin, vmax)", "source_start_line": 598, "tokens": ["def", "test_powernorm_cbar_limits", "(", ")", ":", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "vmin", ",", "vmax", "=", "300", ",", "1000", "data", "=", "np", ".", "arange", "(", "100", "*", "100", ")", ".", "reshape", "(", "100", ",", "100", ")", "+", "vmin", "im", "=", "ax", ".", "imshow", "(", "data", ",", "norm", "=", "mcolors", ".", "PowerNorm", "(", "gamma", "=", "0.2", ",", "vmin", "=", "vmin", ",", "vmax", "=", "vmax", ")", ")", "cbar", "=", "fig", ".", "colorbar", "(", "im", ")", "assert", "cbar", ".", "ax", ".", "get_ylim", "(", ")", "==", "(", "vmin", ",", "vmax", ")"], "to_mask": {"VAR": ["ax", "cbar", "data", "fig", "im", "vmax", "vmin"], "METHOD": ["PowerNorm", "arange", "colorbar", "get_ylim", "imshow", "reshape", "subplots"]}, "attention_idx_tokens": [21, 39], "patch": "@@ -591,6 +595,15 @@\n     assert_array_almost_equal(pnorm(a - 2), expected)\n \n \n+def test_powernorm_cbar_limits():\n+    fig, ax = plt.subplots()\n+    vmin, vmax = 300, 1000\n+    data = np.arange(100*100).reshape(100, 100) + vmin", "ext_attention_idx_tokens": [0, 88], "uid": "ef46b4b8", "question": "Do we need 10000 points? That seems a bit large, though I didn't check how slow the test was.", "code": "def test powernorm cbar limits fig ax plt subplots vmin vmax 300 1000 data np arange 100*100 reshape 100 100 + vmin im ax imshow data norm mcolors PowerNorm gamma 0 2 vmin vmin vmax vmax cbar fig colorbar im assert cbar ax get ylim vmin vmax"}
{"message": "It's a little bit unclear to me why this information is important/difference between steps and distance - is there a place where this is discussed? ", "timestamp": "2024-01-16T01:20:48Z", "file_name": "lib/matplotlib/streamplot.py", "range": {"start_line": 79, "end_line": 79, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1452836973", "html_url": "https://github.com/matplotlib/matplotlib/pull/27617#discussion_r1452836973", "attention_area": "        along the distance of the streamline.", "file_path": "files/48/00/00000048.py", "old_file_path": "files/49/00/00000049.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -73,6 +73,11 @@ def streamplot(axes, x, y, u, v, density=1, linewidth=None, color=None,\n         If False, forces streamlines to continue until they\n         leave the plot domain.  If True, they may be terminated if they\n         come too close to another streamline.\n+    n_arrows : int\n+        Number of arrows per streamline. The arrows are spaced equally along the steps\n+        each streamline takes. Note that this can be different to being spaced equally\n+        along the distance of the streamline.", "source": "def streamplot(axes, x, y, u, v, density=1, linewidth=None, color=None,\n               cmap=None, norm=None, arrowsize=1, arrowstyle='-|>',\n               minlength=0.1, transform=None, zorder=None, start_points=None,\n               maxlength=4.0, integration_direction='both',\n               broken_streamlines=True, *, n_arrows=1):\n    \"\"\"\n    Draw streamlines of a vector flow.\n\n    Parameters\n    ----------\n    x, y : 1D/2D arrays\n        Evenly spaced strictly increasing arrays to make a grid.  If 2D, all\n        rows of *x* must be equal and all columns of *y* must be equal; i.e.,\n        they must be as if generated by ``np.meshgrid(x_1d, y_1d)``.\n    u, v : 2D arrays\n        *x* and *y*-velocities. The number of rows and columns must match\n        the length of *y* and *x*, respectively.\n    density : float or (float, float)\n        Controls the closeness of streamlines. When ``density = 1``, the domain\n        is divided into a 30x30 grid. *density* linearly scales this grid.\n        Each cell in the grid can have, at most, one traversing streamline.\n        For different densities in each direction, use a tuple\n        (density_x, density_y).\n    linewidth : float or 2D array\n        The width of the streamlines. With a 2D array the line width can be\n        varied across the grid. The array must have the same shape as *u*\n        and *v*.\n    color : color or 2D array\n        The streamline color. If given an array, its values are converted to\n        colors using *cmap* and *norm*.  The array must have the same shape\n        as *u* and *v*.\n    cmap, norm\n        Data normalization and colormapping parameters for *color*; only used\n        if *color* is an array of floats. See `~.Axes.imshow` for a detailed\n        description.\n    arrowsize : float\n        Scaling factor for the arrow size.\n    arrowstyle : str\n        Arrow style specification.\n        See `~matplotlib.patches.FancyArrowPatch`.\n    minlength : float\n        Minimum length of streamline in axes coordinates.\n    start_points : (N, 2) array\n        Coordinates of starting points for the streamlines in data coordinates\n        (the same coordinates as the *x* and *y* arrays).\n    zorder : float\n        The zorder of the streamlines and arrows.\n        Artists with lower zorder values are drawn first.\n    maxlength : float\n        Maximum length of streamline in axes coordinates.\n    integration_direction : {'forward', 'backward', 'both'}, default: 'both'\n        Integrate the streamline in forward, backward or both directions.\n    data : indexable object, optional\n        DATA_PARAMETER_PLACEHOLDER\n    broken_streamlines : boolean, default: True\n        If False, forces streamlines to continue until they\n        leave the plot domain.  If True, they may be terminated if they\n        come too close to another streamline.\n    n_arrows : int\n        Number of arrows per streamline. The arrows are spaced equally along the steps\n        each streamline takes. Note that this can be different to being spaced equally\n        along the distance of the streamline.\n\n\n    Returns\n    -------\n    StreamplotSet\n        Container object with attributes\n\n        - ``lines``: `.LineCollection` of streamlines\n\n        - ``arrows``: `.PatchCollection` containing `.FancyArrowPatch`\n          objects representing the arrows half-way along streamlines.\n\n        This container will probably change in the future to allow changes\n        to the colormap, alpha, etc. for both lines and arrows, but these\n        changes should be backward compatible.\n    \"\"\"\n    grid = Grid(x, y)\n    mask = StreamMask(density)\n    dmap = DomainMap(grid, mask)\n\n    if n_arrows < 0:\n        raise ValueError(f\"The value of n_arrows must be >= 0, got {n_arrows=}\")\n\n    if zorder is None:\n        zorder = mlines.Line2D.zorder\n\n    # default to data coordinates\n    if transform is None:\n        transform = axes.transData\n\n    if color is None:\n        color = axes._get_lines.get_next_color()\n\n    if linewidth is None:\n        linewidth = mpl.rcParams['lines.linewidth']\n\n    line_kw = {}\n    arrow_kw = dict(arrowstyle=arrowstyle, mutation_scale=10 * arrowsize)\n\n    _api.check_in_list(['both', 'forward', 'backward'],\n                       integration_direction=integration_direction)\n\n    if integration_direction == 'both':\n        maxlength /= 2.\n\n    use_multicolor_lines = isinstance(color, np.ndarray)\n    if use_multicolor_lines:\n        if color.shape != grid.shape:\n            raise ValueError(\"If 'color' is given, it must match the shape of \"\n                             \"the (x, y) grid\")\n        line_colors = [[]]  # Empty entry allows concatenation of zero arrays.\n        color = np.ma.masked_invalid(color)\n    else:\n        line_kw['color'] = color\n        arrow_kw['color'] = color\n\n    if isinstance(linewidth, np.ndarray):\n        if linewidth.shape != grid.shape:\n            raise ValueError(\"If 'linewidth' is given, it must match the \"\n                             \"shape of the (x, y) grid\")\n        line_kw['linewidth'] = []\n    else:\n        line_kw['linewidth'] = linewidth\n        arrow_kw['linewidth'] = linewidth\n\n    line_kw['zorder'] = zorder\n    arrow_kw['zorder'] = zorder\n\n    # Sanity checks.\n    if u.shape != grid.shape or v.shape != grid.shape:\n        raise ValueError(\"'u' and 'v' must match the shape of the (x, y) grid\")\n\n    u = np.ma.masked_invalid(u)\n    v = np.ma.masked_invalid(v)\n\n    integrate = _get_integrator(u, v, dmap, minlength, maxlength,\n                                integration_direction)\n\n    trajectories = []\n    if start_points is None:\n        for xm, ym in _gen_starting_points(mask.shape):\n            if mask[ym, xm] == 0:\n                xg, yg = dmap.mask2grid(xm, ym)\n                t = integrate(xg, yg, broken_streamlines)\n                if t is not None:\n                    trajectories.append(t)\n    else:\n        sp2 = np.asanyarray(start_points, dtype=float).copy()\n\n        # Check if start_points are outside the data boundaries\n        for xs, ys in sp2:\n            if not (grid.x_origin <= xs <= grid.x_origin + grid.width and\n                    grid.y_origin <= ys <= grid.y_origin + grid.height):\n                raise ValueError(f\"Starting point ({xs}, {ys}) outside of \"\n                                 \"data boundaries\")\n\n        # Convert start_points from data to array coords\n        # Shift the seed points from the bottom left of the data so that\n        # data2grid works properly.\n        sp2[:, 0] -= grid.x_origin\n        sp2[:, 1] -= grid.y_origin\n\n        for xs, ys in sp2:\n            xg, yg = dmap.data2grid(xs, ys)\n            # Floating point issues can cause xg, yg to be slightly out of\n            # bounds for xs, ys on the upper boundaries. Because we have\n            # already checked that the starting points are within the original\n            # grid, clip the xg, yg to the grid to work around this issue\n            xg = np.clip(xg, 0, grid.nx - 1)\n            yg = np.clip(yg, 0, grid.ny - 1)\n\n            t = integrate(xg, yg, broken_streamlines)\n            if t is not None:\n                trajectories.append(t)\n\n    if use_multicolor_lines:\n        if norm is None:\n            norm = mcolors.Normalize(color.min(), color.max())\n        cmap = cm._ensure_cmap(cmap)\n\n    streamlines = []\n    arrows = []\n    for t in trajectories:\n        tgx, tgy = t.T\n        # Rescale from grid-coordinates to data-coordinates.\n        tx, ty = dmap.grid2data(tgx, tgy)\n        tx += grid.x_origin\n        ty += grid.y_origin\n\n        # Create multiple tiny segments if varying width or color is given\n        if isinstance(linewidth, np.ndarray) or use_multicolor_lines:\n            points = np.transpose([tx, ty]).reshape(-1, 1, 2)\n            streamlines.extend(np.hstack([points[:-1], points[1:]]))\n        else:\n            points = np.transpose([tx, ty])\n            streamlines.append(points)\n\n        # Distance along streamline\n        s = np.cumsum(np.hypot(np.diff(tx), np.diff(ty)))\n        if use_multicolor_lines:\n            color_values = interpgrid(color, tgx, tgy)[:-1]\n            line_colors.append(color_values)\n\n        # Add arrows along each trajectory.\n        for x in range(1, n_arrows+1):\n            # Get index of distance along streamline to place arrow\n            idx = np.searchsorted(s, s[-1] * (x/(n_arrows+1)))\n            arrow_tail = (tx[idx], ty[idx])\n            arrow_head = (np.mean(tx[idx:idx + 2]), np.mean(ty[idx:idx + 2]))\n\n            if isinstance(linewidth, np.ndarray):\n                line_widths = interpgrid(linewidth, tgx, tgy)[:-1]\n                line_kw['linewidth'].extend(line_widths)\n                arrow_kw['linewidth'] = line_widths[idx]\n\n            if use_multicolor_lines:\n                arrow_kw['color'] = cmap(norm(color_values[idx]))\n\n            p = patches.FancyArrowPatch(\n                arrow_tail, arrow_head, transform=transform, **arrow_kw)\n            arrows.append(p)\n\n    lc = mcollections.LineCollection(\n        streamlines, transform=transform, **line_kw)\n    lc.sticky_edges.x[:] = [grid.x_origin, grid.x_origin + grid.width]\n    lc.sticky_edges.y[:] = [grid.y_origin, grid.y_origin + grid.height]\n    if use_multicolor_lines:\n        lc.set_array(np.ma.hstack(line_colors))\n        lc.set_cmap(cmap)\n        lc.set_norm(norm)\n    axes.add_collection(lc)\n\n    ac = mcollections.PatchCollection(arrows)\n    # Adding the collection itself is broken; see #2341.\n    for p in arrows:\n        axes.add_patch(p)\n\n    axes.autoscale_view()\n    stream_container = StreamplotSet(lc, ac)\n    return stream_container", "source_start_line": 18, "tokens": ["def", "streamplot", "(", "axes", ",", "x", ",", "y", ",", "u", ",", "v", ",", "density", "=", "1", ",", "linewidth", "=", "None", ",", "color", "=", "None", ",", "cmap", "=", "None", ",", "norm", "=", "None", ",", "arrowsize", "=", "1", ",", "arrowstyle", "=", "'-|>'", ",", "minlength", "=", "0.1", ",", "transform", "=", "None", ",", "zorder", "=", "None", ",", "start_points", "=", "None", ",", "maxlength", "=", "4.0", ",", "integration_direction", "=", "'both'", ",", "broken_streamlines", "=", "True", ",", "*", ",", "n_arrows", "=", "1", ")", ":", "\"\"\"    Draw streamlines of a vector flow.    Parameters    ----------    x, y : 1D/2D arrays        Evenly spaced strictly increasing arrays to make a grid.  If 2D, all        rows of *x* must be equal and all columns of *y* must be equal; i.e.,        they must be as if generated by ``np.meshgrid(x_1d, y_1d)``.    u, v : 2D arrays        *x* and *y*-velocities. The number of rows and columns must match        the length of *y* and *x*, respectively.    density : float or (float, float)        Controls the closeness of streamlines. When ``density = 1``, the domain        is divided into a 30x30 grid. *density* linearly scales this grid.        Each cell in the grid can have, at most, one traversing streamline.        For different densities in each direction, use a tuple        (density_x, density_y).    linewidth : float or 2D array        The width of the streamlines. With a 2D array the line width can be        varied across the grid. The array must have the same shape as *u*        and *v*.    color : color or 2D array        The streamline color. If given an array, its values are converted to        colors using *cmap* and *norm*.  The array must have the same shape        as *u* and *v*.    cmap, norm        Data normalization and colormapping parameters for *color*; only used        if *color* is an array of floats. See `~.Axes.imshow` for a detailed        description.    arrowsize : float        Scaling factor for the arrow size.    arrowstyle : str        Arrow style specification.        See `~matplotlib.patches.FancyArrowPatch`.    minlength : float        Minimum length of streamline in axes coordinates.    start_points : (N, 2) array        Coordinates of starting points for the streamlines in data coordinates        (the same coordinates as the *x* and *y* arrays).    zorder : float        The zorder of the streamlines and arrows.        Artists with lower zorder values are drawn first.    maxlength : float        Maximum length of streamline in axes coordinates.    integration_direction : {'forward', 'backward', 'both'}, default: 'both'        Integrate the streamline in forward, backward or both directions.    data : indexable object, optional        DATA_PARAMETER_PLACEHOLDER    broken_streamlines : boolean, default: True        If False, forces streamlines to continue until they        leave the plot domain.  If True, they may be terminated if they        come too close to another streamline.    n_arrows : int        Number of arrows per streamline. The arrows are spaced equally along the steps        each streamline takes. Note that this can be different to being spaced equally        along the distance of the streamline.    Returns    -------    StreamplotSet        Container object with attributes        - ``lines``: `.LineCollection` of streamlines        - ``arrows``: `.PatchCollection` containing `.FancyArrowPatch`          objects representing the arrows half-way along streamlines.        This container will probably change in the future to allow changes        to the colormap, alpha, etc. for both lines and arrows, but these        changes should be backward compatible.    \"\"\"", "grid", "=", "Grid", "(", "x", ",", "y", ")", "mask", "=", "StreamMask", "(", "density", ")", "dmap", "=", "DomainMap", "(", "grid", ",", "mask", ")", "if", "n_arrows", "<", "0", ":", "raise", "ValueError", "(", "f\"", "{", "n_arrows", "=", "}", "\"", ")", "if", "zorder", "is", "None", ":", "zorder", "=", "mlines", ".", "Line2D", ".", "zorder", "if", "transform", "is", "None", ":", "transform", "=", "axes", ".", "transData", "if", "color", "is", "None", ":", "color", "=", "axes", ".", "_get_lines", ".", "get_next_color", "(", ")", "if", "linewidth", "is", "None", ":", "linewidth", "=", "mpl", ".", "rcParams", "[", "'lines.linewidth'", "]", "line_kw", "=", "{", "}", "arrow_kw", "=", "dict", "(", "arrowstyle", "=", "arrowstyle", ",", "mutation_scale", "=", "10", "*", "arrowsize", ")", "_api", ".", "check_in_list", "(", "[", "'both'", ",", "'forward'", ",", "'backward'", "]", ",", "integration_direction", "=", "integration_direction", ")", "if", "integration_direction", "==", "'both'", ":", "maxlength", "/=", "2.", "use_multicolor_lines", "=", "isinstance", "(", "color", ",", "np", ".", "ndarray", ")", "if", "use_multicolor_lines", ":", "if", "color", ".", "shape", "!=", "grid", ".", "shape", ":", "raise", "ValueError", "(", "\"If 'color' is given, it must match the shape of \"", "\"the (x, y) grid\"", ")", "line_colors", "=", "[", "[", "]", "]", "color", "=", "np", ".", "ma", ".", "masked_invalid", "(", "color", ")", "else", ":", "line_kw", "[", "'color'", "]", "=", "color", "arrow_kw", "[", "'color'", "]", "=", "color", "if", "isinstance", "(", "linewidth", ",", "np", ".", "ndarray", ")", ":", "if", "linewidth", ".", "shape", "!=", "grid", ".", "shape", ":", "raise", "ValueError", "(", "\"If 'linewidth' is given, it must match the \"", "\"shape of the (x, y) grid\"", ")", "line_kw", "[", "'linewidth'", "]", "=", "[", "]", "else", ":", "line_kw", "[", "'linewidth'", "]", "=", "linewidth", "arrow_kw", "[", "'linewidth'", "]", "=", "linewidth", "line_kw", "[", "'zorder'", "]", "=", "zorder", "arrow_kw", "[", "'zorder'", "]", "=", "zorder", "if", "u", ".", "shape", "!=", "grid", ".", "shape", "or", "v", ".", "shape", "!=", "grid", ".", "shape", ":", "raise", "ValueError", "(", "\"'u' and 'v' must match the shape of the (x, y) grid\"", ")", "u", "=", "np", ".", "ma", ".", "masked_invalid", "(", "u", ")", "v", "=", "np", ".", "ma", ".", "masked_invalid", "(", "v", ")", "integrate", "=", "_get_integrator", "(", "u", ",", "v", ",", "dmap", ",", "minlength", ",", "maxlength", ",", "integration_direction", ")", "trajectories", "=", "[", "]", "if", "start_points", "is", "None", ":", "for", "xm", ",", "ym", "in", "_gen_starting_points", "(", "mask", ".", "shape", ")", ":", "if", "mask", "[", "ym", ",", "xm", "]", "==", "0", ":", "xg", ",", "yg", "=", "dmap", ".", "mask2grid", "(", "xm", ",", "ym", ")", "t", "=", "integrate", "(", "xg", ",", "yg", ",", "broken_streamlines", ")", "if", "t", "is", "not", "None", ":", "trajectories", ".", "append", "(", "t", ")", "else", ":", "sp2", "=", "np", ".", "asanyarray", "(", "start_points", ",", "dtype", "=", "float", ")", ".", "copy", "(", ")", "for", "xs", ",", "ys", "in", "sp2", ":", "if", "not", "(", "grid", ".", "x_origin", "<=", "xs", "<=", "grid", ".", "x_origin", "+", "grid", ".", "width", "and", "grid", ".", "y_origin", "<=", "ys", "<=", "grid", ".", "y_origin", "+", "grid", ".", "height", ")", ":", "raise", "ValueError", "(", "f\"", "{", "xs", "}", "{", "ys", "}", "\"", "\"data boundaries\"", ")", "sp2", "[", ":", ",", "0", "]", "-=", "grid", ".", "x_origin", "sp2", "[", ":", ",", "1", "]", "-=", "grid", ".", "y_origin", "for", "xs", ",", "ys", "in", "sp2", ":", "xg", ",", "yg", "=", "dmap", ".", "data2grid", "(", "xs", ",", "ys", ")", "xg", "=", "np", ".", "clip", "(", "xg", ",", "0", ",", "grid", ".", "nx", "-", "1", ")", "yg", "=", "np", ".", "clip", "(", "yg", ",", "0", ",", "grid", ".", "ny", "-", "1", ")", "t", "=", "integrate", "(", "xg", ",", "yg", ",", "broken_streamlines", ")", "if", "t", "is", "not", "None", ":", "trajectories", ".", "append", "(", "t", ")", "if", "use_multicolor_lines", ":", "if", "norm", "is", "None", ":", "norm", "=", "mcolors", ".", "Normalize", "(", "color", ".", "min", "(", ")", ",", "color", ".", "max", "(", ")", ")", "cmap", "=", "cm", ".", "_ensure_cmap", "(", "cmap", ")", "streamlines", "=", "[", "]", "arrows", "=", "[", "]", "for", "t", "in", "trajectories", ":", "tgx", ",", "tgy", "=", "t", ".", "T", "tx", ",", "ty", "=", "dmap", ".", "grid2data", "(", "tgx", ",", "tgy", ")", "tx", "+=", "grid", ".", "x_origin", "ty", "+=", "grid", ".", "y_origin", "if", "isinstance", "(", "linewidth", ",", "np", ".", "ndarray", ")", "or", "use_multicolor_lines", ":", "points", "=", "np", ".", "transpose", "(", "[", "tx", ",", "ty", "]", ")", ".", "reshape", "(", "-", "1", ",", "1", ",", "2", ")", "streamlines", ".", "extend", "(", "np", ".", "hstack", "(", "[", "points", "[", ":", "-", "1", "]", ",", "points", "[", "1", ":", "]", "]", ")", ")", "else", ":", "points", "=", "np", ".", "transpose", "(", "[", "tx", ",", "ty", "]", ")", "streamlines", ".", "append", "(", "points", ")", "s", "=", "np", ".", "cumsum", "(", "np", ".", "hypot", "(", "np", ".", "diff", "(", "tx", ")", ",", "np", ".", "diff", "(", "ty", ")", ")", ")", "if", "use_multicolor_lines", ":", "color_values", "=", "interpgrid", "(", "color", ",", "tgx", ",", "tgy", ")", "[", ":", "-", "1", "]", "line_colors", ".", "append", "(", "color_values", ")", "for", "x", "in", "range", "(", "1", ",", "n_arrows", "+", "1", ")", ":", "idx", "=", "np", ".", "searchsorted", "(", "s", ",", "s", "[", "-", "1", "]", "*", "(", "x", "/", "(", "n_arrows", "+", "1", ")", ")", ")", "arrow_tail", "=", "(", "tx", "[", "idx", "]", ",", "ty", "[", "idx", "]", ")", "arrow_head", "=", "(", "np", ".", "mean", "(", "tx", "[", "idx", ":", "idx", "+", "2", "]", ")", ",", "np", ".", "mean", "(", "ty", "[", "idx", ":", "idx", "+", "2", "]", ")", ")", "if", "isinstance", "(", "linewidth", ",", "np", ".", "ndarray", ")", ":", "line_widths", "=", "interpgrid", "(", "linewidth", ",", "tgx", ",", "tgy", ")", "[", ":", "-", "1", "]", "line_kw", "[", "'linewidth'", "]", ".", "extend", "(", "line_widths", ")", "arrow_kw", "[", "'linewidth'", "]", "=", "line_widths", "[", "idx", "]", "if", "use_multicolor_lines", ":", "arrow_kw", "[", "'color'", "]", "=", "cmap", "(", "norm", "(", "color_values", "[", "idx", "]", ")", ")", "p", "=", "patches", ".", "FancyArrowPatch", "(", "arrow_tail", ",", "arrow_head", ",", "transform", "=", "transform", ",", "**", "arrow_kw", ")", "arrows", ".", "append", "(", "p", ")", "lc", "=", "mcollections", ".", "LineCollection", "(", "streamlines", ",", "transform", "=", "transform", ",", "**", "line_kw", ")", "lc", ".", "sticky_edges", ".", "x", "[", ":", "]", "=", "[", "grid", ".", "x_origin", ",", "grid", ".", "x_origin", "+", "grid", ".", "width", "]", "lc", ".", "sticky_edges", ".", "y", "[", ":", "]", "=", "[", "grid", ".", "y_origin", ",", "grid", ".", "y_origin", "+", "grid", ".", "height", "]", "if", "use_multicolor_lines", ":", "lc", ".", "set_array", "(", "np", ".", "ma", ".", "hstack", "(", "line_colors", ")", ")", "lc", ".", "set_cmap", "(", "cmap", ")", "lc", ".", "set_norm", "(", "norm", ")", "axes", ".", "add_collection", "(", "lc", ")", "ac", "=", "mcollections", ".", "PatchCollection", "(", "arrows", ")", "for", "p", "in", "arrows", ":", "axes", ".", "add_patch", "(", "p", ")", "axes", ".", "autoscale_view", "(", ")", "stream_container", "=", "StreamplotSet", "(", "lc", ",", "ac", ")", "return", "stream_container"], "to_mask": {"VAR": ["ac", "arrow_head", "arrow_kw", "arrow_tail", "arrows", "arrowsize", "arrowstyle", "axes", "broken_streamlines", "cmap", "color", "color_values", "density", "dmap", "grid", "idx", "integrate", "integration_direction", "lc", "line_colors", "line_kw", "line_widths", "linewidth", "mask", "maxlength", "minlength", "n_arrows", "norm", "p", "points", "s", "sp2", "start_points", "stream_container", "streamlines", "t", "tgx", "tgy", "trajectories", "transform", "tx", "ty", "u", "use_multicolor_lines", "v", "x", "xg", "xm", "xs", "y", "yg", "ym", "ys", "zorder"], "METHOD": ["DomainMap", "FancyArrowPatch", "Grid", "LineCollection", "Normalize", "PatchCollection", "StreamMask", "StreamplotSet", "ValueError", "_ensure_cmap", "_gen_starting_points", "_get_integrator", "add_collection", "add_patch", "append", "asanyarray", "autoscale_view", "check_in_list", "clip", "cmap", "copy", "cumsum", "data2grid", "dict", "diff", "extend", "get_next_color", "grid2data", "hstack", "hypot", "integrate", "interpgrid", "isinstance", "mask2grid", "masked_invalid", "max", "mean", "min", "norm", "range", "reshape", "searchsorted", "set_array", "set_cmap", "set_norm", "transpose"]}, "attention_idx_tokens": [null, null], "patch": "@@ -73,6 +73,11 @@\n         If False, forces streamlines to continue until they\n         leave the plot domain.  If True, they may be terminated if they\n         come too close to another streamline.\n+    n_arrows : int\n+        Number of arrows per streamline. The arrows are spaced equally along the steps\n+        each streamline takes. Note that this can be different to being spaced equally\n+        along the distance of the streamline.", "ext_attention_idx_tokens": [null, null], "uid": "75b98508", "question": "It's a little bit unclear to me why this information is important/difference between steps and distance - is there a place where this is discussed? ", "code": "def streamplot axes x y u v density 1 linewidth None color None cmap None norm None arrowsize 1 arrowstyle -|> minlength 0 1 transform None zorder None start points None maxlength 4 0 integration direction both broken streamlines True * n arrows 1 \"\"\" Draw streamlines of a vector flow Parameters ---------- x y 1D 2D arrays Evenly spaced strictly increasing arrays to make a grid If 2D all rows of *x* must be equal and all columns of *y* must be equal; i e they must be as if generated by ``np meshgrid x 1d y 1d `` u v 2D arrays *x* and *y*-velocities The number of rows and columns must match the length of *y* and *x* respectively density float or float float Controls the closeness of streamlines When ``density 1`` the domain is divided into a 30x30 grid *density* linearly scales this grid Each cell in the grid can have at most one traversing streamline For different densities in each direction use a tuple density x density y linewidth float or 2D array The width of the streamlines With a 2D array the line width can be varied across the grid The array must have the same shape as *u* and *v* color color or 2D array The streamline color If given an array its values are converted to colors using *cmap* and *norm* The array must have the same shape as *u* and *v* cmap norm Data normalization and colormapping parameters for *color*; only used if *color* is an array of floats See `~ Axes imshow` for a detailed description arrowsize float Scaling factor for the arrow size arrowstyle str Arrow style specification See `~matplotlib patches FancyArrowPatch` minlength float Minimum length of streamline in axes coordinates start points N 2 array Coordinates of starting points for the streamlines in data coordinates the same coordinates as the *x* and *y* arrays zorder float The zorder of the streamlines and arrows Artists with lower zorder values are drawn first maxlength float Maximum length of streamline in axes coordinates integration direction { forward backward both } default both Integrate the streamline in forward backward or both directions data indexable object optional DATA PARAMETER PLACEHOLDER broken streamlines boolean default True If False forces streamlines to continue until they leave the plot domain If True they may be terminated if they come too close to another streamline n arrows int Number of arrows per streamline The arrows are spaced equally along the steps each streamline takes Note that this can be different to being spaced equally along the distance of the streamline Returns ------- StreamplotSet Container object with attributes - ``lines`` ` LineCollection` of streamlines - ``arrows`` ` PatchCollection` containing ` FancyArrowPatch` objects representing the arrows half-way along streamlines This container will probably change in the future to allow changes to the colormap alpha etc for both lines and arrows but these changes should be backward compatible \"\"\" grid Grid x y mask StreamMask density dmap DomainMap grid mask if n arrows < 0 raise ValueError f\"The value of n arrows must be > 0 got {n arrows }\" if zorder is None zorder mlines Line2D zorder # default to data coordinates if transform is None transform axes transData if color is None color axes get lines get next color if linewidth is None linewidth mpl rcParams[ lines linewidth ] line kw {} arrow kw dict arrowstyle arrowstyle mutation scale 10 * arrowsize api check in list [ both forward backward ] integration direction integration direction if integration direction both maxlength 2 use multicolor lines isinstance color np ndarray if use multicolor lines if color shape ! grid shape raise ValueError \"If color is given it must match the shape of \" \"the x y grid\" line colors [[]] # Empty entry allows concatenation of zero arrays color np ma masked invalid color else line kw[ color ] color arrow kw[ color ] color if isinstance linewidth np ndarray if linewidth shape ! grid shape raise ValueError \"If linewidth is given it must match the \" \"shape of the x y grid\" line kw[ linewidth ] [] else line kw[ linewidth ] linewidth arrow kw[ linewidth ] linewidth line kw[ zorder ] zorder arrow kw[ zorder ] zorder # Sanity checks if u shape ! grid shape or v shape ! grid shape raise ValueError \" u and v must match the shape of the x y grid\" u np ma masked invalid u v np ma masked invalid v integrate get integrator u v dmap minlength maxlength integration direction trajectories [] if start points is None for xm ym in gen starting points mask shape if mask[ym xm] 0 xg yg dmap mask2grid xm ym t integrate xg yg broken streamlines if t is not None trajectories append t else sp2 np asanyarray start points dtype float copy # Check if start points are outside the data boundaries for xs ys in sp2 if not grid x origin < xs < grid x origin + grid width and grid y origin < ys < grid y origin + grid height raise ValueError f\"Starting point {xs} {ys} outside of \" \"data boundaries\" # Convert start points from data to array coords # Shift the seed points from the bottom left of the data so that # data2grid works properly sp2[ 0] - grid x origin sp2[ 1] - grid y origin for xs ys in sp2 xg yg dmap data2grid xs ys # Floating point issues can cause xg yg to be slightly out of # bounds for xs ys on the upper boundaries Because we have # already checked that the starting points are within the original # grid clip the xg yg to the grid to work around this issue xg np clip xg 0 grid nx - 1 yg np clip yg 0 grid ny - 1 t integrate xg yg broken streamlines if t is not None trajectories append t if use multicolor lines if norm is None norm mcolors Normalize color min color max cmap cm ensure cmap cmap streamlines [] arrows [] for t in trajectories tgx tgy t T # Rescale from grid-coordinates to data-coordinates tx ty dmap grid2data tgx tgy tx + grid x origin ty + grid y origin # Create multiple tiny segments if varying width or color is given if isinstance linewidth np ndarray or use multicolor lines points np transpose [tx ty] reshape -1 1 2 streamlines extend np hstack [points[ -1] points[1 ]] else points np transpose [tx ty] streamlines append points # Distance along streamline s np cumsum np hypot np diff tx np diff ty if use multicolor lines color values interpgrid color tgx tgy [ -1] line colors append color values # Add arrows along each trajectory for x in range 1 n arrows+1 # Get index of distance along streamline to place arrow idx np searchsorted s s[-1] * x n arrows+1 arrow tail tx[idx] ty[idx] arrow head np mean tx[idx idx + 2] np mean ty[idx idx + 2] if isinstance linewidth np ndarray line widths interpgrid linewidth tgx tgy [ -1] line kw[ linewidth ] extend line widths arrow kw[ linewidth ] line widths[idx] if use multicolor lines arrow kw[ color ] cmap norm color values[idx] p patches FancyArrowPatch arrow tail arrow head transform transform **arrow kw arrows append p lc mcollections LineCollection streamlines transform transform **line kw lc sticky edges x[ ] [grid x origin grid x origin + grid width] lc sticky edges y[ ] [grid y origin grid y origin + grid height] if use multicolor lines lc set array np ma hstack line colors lc set cmap cmap lc set norm norm axes add collection lc ac mcollections PatchCollection arrows # Adding the collection itself is broken; see #2341 for p in arrows axes add patch p axes autoscale view stream container StreamplotSet lc ac return stream container"}
{"message": "I put this in because before I worked out why not, it was a surprise to me that the arrows weren't visually equidistant along the streamline. Happy to drop this if it causes more confusion than it clears up, or try and clarify it a bit?", "timestamp": "2024-01-22T21:27:14Z", "file_name": "lib/matplotlib/streamplot.py", "range": {"start_line": 79, "end_line": 79, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1462442121", "html_url": "https://github.com/matplotlib/matplotlib/pull/27617#discussion_r1462442121", "attention_area": "        along the distance of the streamline.", "file_path": "files/48/00/00000048.py", "old_file_path": "files/49/00/00000049.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -73,6 +73,11 @@ def streamplot(axes, x, y, u, v, density=1, linewidth=None, color=None,\n         If False, forces streamlines to continue until they\n         leave the plot domain.  If True, they may be terminated if they\n         come too close to another streamline.\n+    n_arrows : int\n+        Number of arrows per streamline. The arrows are spaced equally along the steps\n+        each streamline takes. Note that this can be different to being spaced equally\n+        along the distance of the streamline.", "source": "def streamplot(axes, x, y, u, v, density=1, linewidth=None, color=None,\n               cmap=None, norm=None, arrowsize=1, arrowstyle='-|>',\n               minlength=0.1, transform=None, zorder=None, start_points=None,\n               maxlength=4.0, integration_direction='both',\n               broken_streamlines=True, *, n_arrows=1):\n    \"\"\"\n    Draw streamlines of a vector flow.\n\n    Parameters\n    ----------\n    x, y : 1D/2D arrays\n        Evenly spaced strictly increasing arrays to make a grid.  If 2D, all\n        rows of *x* must be equal and all columns of *y* must be equal; i.e.,\n        they must be as if generated by ``np.meshgrid(x_1d, y_1d)``.\n    u, v : 2D arrays\n        *x* and *y*-velocities. The number of rows and columns must match\n        the length of *y* and *x*, respectively.\n    density : float or (float, float)\n        Controls the closeness of streamlines. When ``density = 1``, the domain\n        is divided into a 30x30 grid. *density* linearly scales this grid.\n        Each cell in the grid can have, at most, one traversing streamline.\n        For different densities in each direction, use a tuple\n        (density_x, density_y).\n    linewidth : float or 2D array\n        The width of the streamlines. With a 2D array the line width can be\n        varied across the grid. The array must have the same shape as *u*\n        and *v*.\n    color : color or 2D array\n        The streamline color. If given an array, its values are converted to\n        colors using *cmap* and *norm*.  The array must have the same shape\n        as *u* and *v*.\n    cmap, norm\n        Data normalization and colormapping parameters for *color*; only used\n        if *color* is an array of floats. See `~.Axes.imshow` for a detailed\n        description.\n    arrowsize : float\n        Scaling factor for the arrow size.\n    arrowstyle : str\n        Arrow style specification.\n        See `~matplotlib.patches.FancyArrowPatch`.\n    minlength : float\n        Minimum length of streamline in axes coordinates.\n    start_points : (N, 2) array\n        Coordinates of starting points for the streamlines in data coordinates\n        (the same coordinates as the *x* and *y* arrays).\n    zorder : float\n        The zorder of the streamlines and arrows.\n        Artists with lower zorder values are drawn first.\n    maxlength : float\n        Maximum length of streamline in axes coordinates.\n    integration_direction : {'forward', 'backward', 'both'}, default: 'both'\n        Integrate the streamline in forward, backward or both directions.\n    data : indexable object, optional\n        DATA_PARAMETER_PLACEHOLDER\n    broken_streamlines : boolean, default: True\n        If False, forces streamlines to continue until they\n        leave the plot domain.  If True, they may be terminated if they\n        come too close to another streamline.\n    n_arrows : int\n        Number of arrows per streamline. The arrows are spaced equally along the steps\n        each streamline takes. Note that this can be different to being spaced equally\n        along the distance of the streamline.\n\n\n    Returns\n    -------\n    StreamplotSet\n        Container object with attributes\n\n        - ``lines``: `.LineCollection` of streamlines\n\n        - ``arrows``: `.PatchCollection` containing `.FancyArrowPatch`\n          objects representing the arrows half-way along streamlines.\n\n        This container will probably change in the future to allow changes\n        to the colormap, alpha, etc. for both lines and arrows, but these\n        changes should be backward compatible.\n    \"\"\"\n    grid = Grid(x, y)\n    mask = StreamMask(density)\n    dmap = DomainMap(grid, mask)\n\n    if n_arrows < 0:\n        raise ValueError(f\"The value of n_arrows must be >= 0, got {n_arrows=}\")\n\n    if zorder is None:\n        zorder = mlines.Line2D.zorder\n\n    # default to data coordinates\n    if transform is None:\n        transform = axes.transData\n\n    if color is None:\n        color = axes._get_lines.get_next_color()\n\n    if linewidth is None:\n        linewidth = mpl.rcParams['lines.linewidth']\n\n    line_kw = {}\n    arrow_kw = dict(arrowstyle=arrowstyle, mutation_scale=10 * arrowsize)\n\n    _api.check_in_list(['both', 'forward', 'backward'],\n                       integration_direction=integration_direction)\n\n    if integration_direction == 'both':\n        maxlength /= 2.\n\n    use_multicolor_lines = isinstance(color, np.ndarray)\n    if use_multicolor_lines:\n        if color.shape != grid.shape:\n            raise ValueError(\"If 'color' is given, it must match the shape of \"\n                             \"the (x, y) grid\")\n        line_colors = [[]]  # Empty entry allows concatenation of zero arrays.\n        color = np.ma.masked_invalid(color)\n    else:\n        line_kw['color'] = color\n        arrow_kw['color'] = color\n\n    if isinstance(linewidth, np.ndarray):\n        if linewidth.shape != grid.shape:\n            raise ValueError(\"If 'linewidth' is given, it must match the \"\n                             \"shape of the (x, y) grid\")\n        line_kw['linewidth'] = []\n    else:\n        line_kw['linewidth'] = linewidth\n        arrow_kw['linewidth'] = linewidth\n\n    line_kw['zorder'] = zorder\n    arrow_kw['zorder'] = zorder\n\n    # Sanity checks.\n    if u.shape != grid.shape or v.shape != grid.shape:\n        raise ValueError(\"'u' and 'v' must match the shape of the (x, y) grid\")\n\n    u = np.ma.masked_invalid(u)\n    v = np.ma.masked_invalid(v)\n\n    integrate = _get_integrator(u, v, dmap, minlength, maxlength,\n                                integration_direction)\n\n    trajectories = []\n    if start_points is None:\n        for xm, ym in _gen_starting_points(mask.shape):\n            if mask[ym, xm] == 0:\n                xg, yg = dmap.mask2grid(xm, ym)\n                t = integrate(xg, yg, broken_streamlines)\n                if t is not None:\n                    trajectories.append(t)\n    else:\n        sp2 = np.asanyarray(start_points, dtype=float).copy()\n\n        # Check if start_points are outside the data boundaries\n        for xs, ys in sp2:\n            if not (grid.x_origin <= xs <= grid.x_origin + grid.width and\n                    grid.y_origin <= ys <= grid.y_origin + grid.height):\n                raise ValueError(f\"Starting point ({xs}, {ys}) outside of \"\n                                 \"data boundaries\")\n\n        # Convert start_points from data to array coords\n        # Shift the seed points from the bottom left of the data so that\n        # data2grid works properly.\n        sp2[:, 0] -= grid.x_origin\n        sp2[:, 1] -= grid.y_origin\n\n        for xs, ys in sp2:\n            xg, yg = dmap.data2grid(xs, ys)\n            # Floating point issues can cause xg, yg to be slightly out of\n            # bounds for xs, ys on the upper boundaries. Because we have\n            # already checked that the starting points are within the original\n            # grid, clip the xg, yg to the grid to work around this issue\n            xg = np.clip(xg, 0, grid.nx - 1)\n            yg = np.clip(yg, 0, grid.ny - 1)\n\n            t = integrate(xg, yg, broken_streamlines)\n            if t is not None:\n                trajectories.append(t)\n\n    if use_multicolor_lines:\n        if norm is None:\n            norm = mcolors.Normalize(color.min(), color.max())\n        cmap = cm._ensure_cmap(cmap)\n\n    streamlines = []\n    arrows = []\n    for t in trajectories:\n        tgx, tgy = t.T\n        # Rescale from grid-coordinates to data-coordinates.\n        tx, ty = dmap.grid2data(tgx, tgy)\n        tx += grid.x_origin\n        ty += grid.y_origin\n\n        # Create multiple tiny segments if varying width or color is given\n        if isinstance(linewidth, np.ndarray) or use_multicolor_lines:\n            points = np.transpose([tx, ty]).reshape(-1, 1, 2)\n            streamlines.extend(np.hstack([points[:-1], points[1:]]))\n        else:\n            points = np.transpose([tx, ty])\n            streamlines.append(points)\n\n        # Distance along streamline\n        s = np.cumsum(np.hypot(np.diff(tx), np.diff(ty)))\n        if use_multicolor_lines:\n            color_values = interpgrid(color, tgx, tgy)[:-1]\n            line_colors.append(color_values)\n\n        # Add arrows along each trajectory.\n        for x in range(1, n_arrows+1):\n            # Get index of distance along streamline to place arrow\n            idx = np.searchsorted(s, s[-1] * (x/(n_arrows+1)))\n            arrow_tail = (tx[idx], ty[idx])\n            arrow_head = (np.mean(tx[idx:idx + 2]), np.mean(ty[idx:idx + 2]))\n\n            if isinstance(linewidth, np.ndarray):\n                line_widths = interpgrid(linewidth, tgx, tgy)[:-1]\n                line_kw['linewidth'].extend(line_widths)\n                arrow_kw['linewidth'] = line_widths[idx]\n\n            if use_multicolor_lines:\n                arrow_kw['color'] = cmap(norm(color_values[idx]))\n\n            p = patches.FancyArrowPatch(\n                arrow_tail, arrow_head, transform=transform, **arrow_kw)\n            arrows.append(p)\n\n    lc = mcollections.LineCollection(\n        streamlines, transform=transform, **line_kw)\n    lc.sticky_edges.x[:] = [grid.x_origin, grid.x_origin + grid.width]\n    lc.sticky_edges.y[:] = [grid.y_origin, grid.y_origin + grid.height]\n    if use_multicolor_lines:\n        lc.set_array(np.ma.hstack(line_colors))\n        lc.set_cmap(cmap)\n        lc.set_norm(norm)\n    axes.add_collection(lc)\n\n    ac = mcollections.PatchCollection(arrows)\n    # Adding the collection itself is broken; see #2341.\n    for p in arrows:\n        axes.add_patch(p)\n\n    axes.autoscale_view()\n    stream_container = StreamplotSet(lc, ac)\n    return stream_container", "source_start_line": 18, "tokens": ["def", "streamplot", "(", "axes", ",", "x", ",", "y", ",", "u", ",", "v", ",", "density", "=", "1", ",", "linewidth", "=", "None", ",", "color", "=", "None", ",", "cmap", "=", "None", ",", "norm", "=", "None", ",", "arrowsize", "=", "1", ",", "arrowstyle", "=", "'-|>'", ",", "minlength", "=", "0.1", ",", "transform", "=", "None", ",", "zorder", "=", "None", ",", "start_points", "=", "None", ",", "maxlength", "=", "4.0", ",", "integration_direction", "=", "'both'", ",", "broken_streamlines", "=", "True", ",", "*", ",", "n_arrows", "=", "1", ")", ":", "\"\"\"    Draw streamlines of a vector flow.    Parameters    ----------    x, y : 1D/2D arrays        Evenly spaced strictly increasing arrays to make a grid.  If 2D, all        rows of *x* must be equal and all columns of *y* must be equal; i.e.,        they must be as if generated by ``np.meshgrid(x_1d, y_1d)``.    u, v : 2D arrays        *x* and *y*-velocities. The number of rows and columns must match        the length of *y* and *x*, respectively.    density : float or (float, float)        Controls the closeness of streamlines. When ``density = 1``, the domain        is divided into a 30x30 grid. *density* linearly scales this grid.        Each cell in the grid can have, at most, one traversing streamline.        For different densities in each direction, use a tuple        (density_x, density_y).    linewidth : float or 2D array        The width of the streamlines. With a 2D array the line width can be        varied across the grid. The array must have the same shape as *u*        and *v*.    color : color or 2D array        The streamline color. If given an array, its values are converted to        colors using *cmap* and *norm*.  The array must have the same shape        as *u* and *v*.    cmap, norm        Data normalization and colormapping parameters for *color*; only used        if *color* is an array of floats. See `~.Axes.imshow` for a detailed        description.    arrowsize : float        Scaling factor for the arrow size.    arrowstyle : str        Arrow style specification.        See `~matplotlib.patches.FancyArrowPatch`.    minlength : float        Minimum length of streamline in axes coordinates.    start_points : (N, 2) array        Coordinates of starting points for the streamlines in data coordinates        (the same coordinates as the *x* and *y* arrays).    zorder : float        The zorder of the streamlines and arrows.        Artists with lower zorder values are drawn first.    maxlength : float        Maximum length of streamline in axes coordinates.    integration_direction : {'forward', 'backward', 'both'}, default: 'both'        Integrate the streamline in forward, backward or both directions.    data : indexable object, optional        DATA_PARAMETER_PLACEHOLDER    broken_streamlines : boolean, default: True        If False, forces streamlines to continue until they        leave the plot domain.  If True, they may be terminated if they        come too close to another streamline.    n_arrows : int        Number of arrows per streamline. The arrows are spaced equally along the steps        each streamline takes. Note that this can be different to being spaced equally        along the distance of the streamline.    Returns    -------    StreamplotSet        Container object with attributes        - ``lines``: `.LineCollection` of streamlines        - ``arrows``: `.PatchCollection` containing `.FancyArrowPatch`          objects representing the arrows half-way along streamlines.        This container will probably change in the future to allow changes        to the colormap, alpha, etc. for both lines and arrows, but these        changes should be backward compatible.    \"\"\"", "grid", "=", "Grid", "(", "x", ",", "y", ")", "mask", "=", "StreamMask", "(", "density", ")", "dmap", "=", "DomainMap", "(", "grid", ",", "mask", ")", "if", "n_arrows", "<", "0", ":", "raise", "ValueError", "(", "f\"", "{", "n_arrows", "=", "}", "\"", ")", "if", "zorder", "is", "None", ":", "zorder", "=", "mlines", ".", "Line2D", ".", "zorder", "if", "transform", "is", "None", ":", "transform", "=", "axes", ".", "transData", "if", "color", "is", "None", ":", "color", "=", "axes", ".", "_get_lines", ".", "get_next_color", "(", ")", "if", "linewidth", "is", "None", ":", "linewidth", "=", "mpl", ".", "rcParams", "[", "'lines.linewidth'", "]", "line_kw", "=", "{", "}", "arrow_kw", "=", "dict", "(", "arrowstyle", "=", "arrowstyle", ",", "mutation_scale", "=", "10", "*", "arrowsize", ")", "_api", ".", "check_in_list", "(", "[", "'both'", ",", "'forward'", ",", "'backward'", "]", ",", "integration_direction", "=", "integration_direction", ")", "if", "integration_direction", "==", "'both'", ":", "maxlength", "/=", "2.", "use_multicolor_lines", "=", "isinstance", "(", "color", ",", "np", ".", "ndarray", ")", "if", "use_multicolor_lines", ":", "if", "color", ".", "shape", "!=", "grid", ".", "shape", ":", "raise", "ValueError", "(", "\"If 'color' is given, it must match the shape of \"", "\"the (x, y) grid\"", ")", "line_colors", "=", "[", "[", "]", "]", "color", "=", "np", ".", "ma", ".", "masked_invalid", "(", "color", ")", "else", ":", "line_kw", "[", "'color'", "]", "=", "color", "arrow_kw", "[", "'color'", "]", "=", "color", "if", "isinstance", "(", "linewidth", ",", "np", ".", "ndarray", ")", ":", "if", "linewidth", ".", "shape", "!=", "grid", ".", "shape", ":", "raise", "ValueError", "(", "\"If 'linewidth' is given, it must match the \"", "\"shape of the (x, y) grid\"", ")", "line_kw", "[", "'linewidth'", "]", "=", "[", "]", "else", ":", "line_kw", "[", "'linewidth'", "]", "=", "linewidth", "arrow_kw", "[", "'linewidth'", "]", "=", "linewidth", "line_kw", "[", "'zorder'", "]", "=", "zorder", "arrow_kw", "[", "'zorder'", "]", "=", "zorder", "if", "u", ".", "shape", "!=", "grid", ".", "shape", "or", "v", ".", "shape", "!=", "grid", ".", "shape", ":", "raise", "ValueError", "(", "\"'u' and 'v' must match the shape of the (x, y) grid\"", ")", "u", "=", "np", ".", "ma", ".", "masked_invalid", "(", "u", ")", "v", "=", "np", ".", "ma", ".", "masked_invalid", "(", "v", ")", "integrate", "=", "_get_integrator", "(", "u", ",", "v", ",", "dmap", ",", "minlength", ",", "maxlength", ",", "integration_direction", ")", "trajectories", "=", "[", "]", "if", "start_points", "is", "None", ":", "for", "xm", ",", "ym", "in", "_gen_starting_points", "(", "mask", ".", "shape", ")", ":", "if", "mask", "[", "ym", ",", "xm", "]", "==", "0", ":", "xg", ",", "yg", "=", "dmap", ".", "mask2grid", "(", "xm", ",", "ym", ")", "t", "=", "integrate", "(", "xg", ",", "yg", ",", "broken_streamlines", ")", "if", "t", "is", "not", "None", ":", "trajectories", ".", "append", "(", "t", ")", "else", ":", "sp2", "=", "np", ".", "asanyarray", "(", "start_points", ",", "dtype", "=", "float", ")", ".", "copy", "(", ")", "for", "xs", ",", "ys", "in", "sp2", ":", "if", "not", "(", "grid", ".", "x_origin", "<=", "xs", "<=", "grid", ".", "x_origin", "+", "grid", ".", "width", "and", "grid", ".", "y_origin", "<=", "ys", "<=", "grid", ".", "y_origin", "+", "grid", ".", "height", ")", ":", "raise", "ValueError", "(", "f\"", "{", "xs", "}", "{", "ys", "}", "\"", "\"data boundaries\"", ")", "sp2", "[", ":", ",", "0", "]", "-=", "grid", ".", "x_origin", "sp2", "[", ":", ",", "1", "]", "-=", "grid", ".", "y_origin", "for", "xs", ",", "ys", "in", "sp2", ":", "xg", ",", "yg", "=", "dmap", ".", "data2grid", "(", "xs", ",", "ys", ")", "xg", "=", "np", ".", "clip", "(", "xg", ",", "0", ",", "grid", ".", "nx", "-", "1", ")", "yg", "=", "np", ".", "clip", "(", "yg", ",", "0", ",", "grid", ".", "ny", "-", "1", ")", "t", "=", "integrate", "(", "xg", ",", "yg", ",", "broken_streamlines", ")", "if", "t", "is", "not", "None", ":", "trajectories", ".", "append", "(", "t", ")", "if", "use_multicolor_lines", ":", "if", "norm", "is", "None", ":", "norm", "=", "mcolors", ".", "Normalize", "(", "color", ".", "min", "(", ")", ",", "color", ".", "max", "(", ")", ")", "cmap", "=", "cm", ".", "_ensure_cmap", "(", "cmap", ")", "streamlines", "=", "[", "]", "arrows", "=", "[", "]", "for", "t", "in", "trajectories", ":", "tgx", ",", "tgy", "=", "t", ".", "T", "tx", ",", "ty", "=", "dmap", ".", "grid2data", "(", "tgx", ",", "tgy", ")", "tx", "+=", "grid", ".", "x_origin", "ty", "+=", "grid", ".", "y_origin", "if", "isinstance", "(", "linewidth", ",", "np", ".", "ndarray", ")", "or", "use_multicolor_lines", ":", "points", "=", "np", ".", "transpose", "(", "[", "tx", ",", "ty", "]", ")", ".", "reshape", "(", "-", "1", ",", "1", ",", "2", ")", "streamlines", ".", "extend", "(", "np", ".", "hstack", "(", "[", "points", "[", ":", "-", "1", "]", ",", "points", "[", "1", ":", "]", "]", ")", ")", "else", ":", "points", "=", "np", ".", "transpose", "(", "[", "tx", ",", "ty", "]", ")", "streamlines", ".", "append", "(", "points", ")", "s", "=", "np", ".", "cumsum", "(", "np", ".", "hypot", "(", "np", ".", "diff", "(", "tx", ")", ",", "np", ".", "diff", "(", "ty", ")", ")", ")", "if", "use_multicolor_lines", ":", "color_values", "=", "interpgrid", "(", "color", ",", "tgx", ",", "tgy", ")", "[", ":", "-", "1", "]", "line_colors", ".", "append", "(", "color_values", ")", "for", "x", "in", "range", "(", "1", ",", "n_arrows", "+", "1", ")", ":", "idx", "=", "np", ".", "searchsorted", "(", "s", ",", "s", "[", "-", "1", "]", "*", "(", "x", "/", "(", "n_arrows", "+", "1", ")", ")", ")", "arrow_tail", "=", "(", "tx", "[", "idx", "]", ",", "ty", "[", "idx", "]", ")", "arrow_head", "=", "(", "np", ".", "mean", "(", "tx", "[", "idx", ":", "idx", "+", "2", "]", ")", ",", "np", ".", "mean", "(", "ty", "[", "idx", ":", "idx", "+", "2", "]", ")", ")", "if", "isinstance", "(", "linewidth", ",", "np", ".", "ndarray", ")", ":", "line_widths", "=", "interpgrid", "(", "linewidth", ",", "tgx", ",", "tgy", ")", "[", ":", "-", "1", "]", "line_kw", "[", "'linewidth'", "]", ".", "extend", "(", "line_widths", ")", "arrow_kw", "[", "'linewidth'", "]", "=", "line_widths", "[", "idx", "]", "if", "use_multicolor_lines", ":", "arrow_kw", "[", "'color'", "]", "=", "cmap", "(", "norm", "(", "color_values", "[", "idx", "]", ")", ")", "p", "=", "patches", ".", "FancyArrowPatch", "(", "arrow_tail", ",", "arrow_head", ",", "transform", "=", "transform", ",", "**", "arrow_kw", ")", "arrows", ".", "append", "(", "p", ")", "lc", "=", "mcollections", ".", "LineCollection", "(", "streamlines", ",", "transform", "=", "transform", ",", "**", "line_kw", ")", "lc", ".", "sticky_edges", ".", "x", "[", ":", "]", "=", "[", "grid", ".", "x_origin", ",", "grid", ".", "x_origin", "+", "grid", ".", "width", "]", "lc", ".", "sticky_edges", ".", "y", "[", ":", "]", "=", "[", "grid", ".", "y_origin", ",", "grid", ".", "y_origin", "+", "grid", ".", "height", "]", "if", "use_multicolor_lines", ":", "lc", ".", "set_array", "(", "np", ".", "ma", ".", "hstack", "(", "line_colors", ")", ")", "lc", ".", "set_cmap", "(", "cmap", ")", "lc", ".", "set_norm", "(", "norm", ")", "axes", ".", "add_collection", "(", "lc", ")", "ac", "=", "mcollections", ".", "PatchCollection", "(", "arrows", ")", "for", "p", "in", "arrows", ":", "axes", ".", "add_patch", "(", "p", ")", "axes", ".", "autoscale_view", "(", ")", "stream_container", "=", "StreamplotSet", "(", "lc", ",", "ac", ")", "return", "stream_container"], "to_mask": {"VAR": ["ac", "arrow_head", "arrow_kw", "arrow_tail", "arrows", "arrowsize", "arrowstyle", "axes", "broken_streamlines", "cmap", "color", "color_values", "density", "dmap", "grid", "idx", "integrate", "integration_direction", "lc", "line_colors", "line_kw", "line_widths", "linewidth", "mask", "maxlength", "minlength", "n_arrows", "norm", "p", "points", "s", "sp2", "start_points", "stream_container", "streamlines", "t", "tgx", "tgy", "trajectories", "transform", "tx", "ty", "u", "use_multicolor_lines", "v", "x", "xg", "xm", "xs", "y", "yg", "ym", "ys", "zorder"], "METHOD": ["DomainMap", "FancyArrowPatch", "Grid", "LineCollection", "Normalize", "PatchCollection", "StreamMask", "StreamplotSet", "ValueError", "_ensure_cmap", "_gen_starting_points", "_get_integrator", "add_collection", "add_patch", "append", "asanyarray", "autoscale_view", "check_in_list", "clip", "cmap", "copy", "cumsum", "data2grid", "dict", "diff", "extend", "get_next_color", "grid2data", "hstack", "hypot", "integrate", "interpgrid", "isinstance", "mask2grid", "masked_invalid", "max", "mean", "min", "norm", "range", "reshape", "searchsorted", "set_array", "set_cmap", "set_norm", "transpose"]}, "attention_idx_tokens": [null, null], "patch": "@@ -73,6 +73,11 @@\n         If False, forces streamlines to continue until they\n         leave the plot domain.  If True, they may be terminated if they\n         come too close to another streamline.\n+    n_arrows : int\n+        Number of arrows per streamline. The arrows are spaced equally along the steps\n+        each streamline takes. Note that this can be different to being spaced equally\n+        along the distance of the streamline.", "ext_attention_idx_tokens": [null, null], "uid": "4297b79f", "question": "I put this in because before I worked out why not, it was a surprise to me that the arrows weren't visually equidistant along the streamline. Happy to drop this if it causes more confusion than it clears up, or try and clarify it a bit?", "code": "def streamplot axes x y u v density 1 linewidth None color None cmap None norm None arrowsize 1 arrowstyle -|> minlength 0 1 transform None zorder None start points None maxlength 4 0 integration direction both broken streamlines True * n arrows 1 \"\"\" Draw streamlines of a vector flow Parameters ---------- x y 1D 2D arrays Evenly spaced strictly increasing arrays to make a grid If 2D all rows of *x* must be equal and all columns of *y* must be equal; i e they must be as if generated by ``np meshgrid x 1d y 1d `` u v 2D arrays *x* and *y*-velocities The number of rows and columns must match the length of *y* and *x* respectively density float or float float Controls the closeness of streamlines When ``density 1`` the domain is divided into a 30x30 grid *density* linearly scales this grid Each cell in the grid can have at most one traversing streamline For different densities in each direction use a tuple density x density y linewidth float or 2D array The width of the streamlines With a 2D array the line width can be varied across the grid The array must have the same shape as *u* and *v* color color or 2D array The streamline color If given an array its values are converted to colors using *cmap* and *norm* The array must have the same shape as *u* and *v* cmap norm Data normalization and colormapping parameters for *color*; only used if *color* is an array of floats See `~ Axes imshow` for a detailed description arrowsize float Scaling factor for the arrow size arrowstyle str Arrow style specification See `~matplotlib patches FancyArrowPatch` minlength float Minimum length of streamline in axes coordinates start points N 2 array Coordinates of starting points for the streamlines in data coordinates the same coordinates as the *x* and *y* arrays zorder float The zorder of the streamlines and arrows Artists with lower zorder values are drawn first maxlength float Maximum length of streamline in axes coordinates integration direction { forward backward both } default both Integrate the streamline in forward backward or both directions data indexable object optional DATA PARAMETER PLACEHOLDER broken streamlines boolean default True If False forces streamlines to continue until they leave the plot domain If True they may be terminated if they come too close to another streamline n arrows int Number of arrows per streamline The arrows are spaced equally along the steps each streamline takes Note that this can be different to being spaced equally along the distance of the streamline Returns ------- StreamplotSet Container object with attributes - ``lines`` ` LineCollection` of streamlines - ``arrows`` ` PatchCollection` containing ` FancyArrowPatch` objects representing the arrows half-way along streamlines This container will probably change in the future to allow changes to the colormap alpha etc for both lines and arrows but these changes should be backward compatible \"\"\" grid Grid x y mask StreamMask density dmap DomainMap grid mask if n arrows < 0 raise ValueError f\"The value of n arrows must be > 0 got {n arrows }\" if zorder is None zorder mlines Line2D zorder # default to data coordinates if transform is None transform axes transData if color is None color axes get lines get next color if linewidth is None linewidth mpl rcParams[ lines linewidth ] line kw {} arrow kw dict arrowstyle arrowstyle mutation scale 10 * arrowsize api check in list [ both forward backward ] integration direction integration direction if integration direction both maxlength 2 use multicolor lines isinstance color np ndarray if use multicolor lines if color shape ! grid shape raise ValueError \"If color is given it must match the shape of \" \"the x y grid\" line colors [[]] # Empty entry allows concatenation of zero arrays color np ma masked invalid color else line kw[ color ] color arrow kw[ color ] color if isinstance linewidth np ndarray if linewidth shape ! grid shape raise ValueError \"If linewidth is given it must match the \" \"shape of the x y grid\" line kw[ linewidth ] [] else line kw[ linewidth ] linewidth arrow kw[ linewidth ] linewidth line kw[ zorder ] zorder arrow kw[ zorder ] zorder # Sanity checks if u shape ! grid shape or v shape ! grid shape raise ValueError \" u and v must match the shape of the x y grid\" u np ma masked invalid u v np ma masked invalid v integrate get integrator u v dmap minlength maxlength integration direction trajectories [] if start points is None for xm ym in gen starting points mask shape if mask[ym xm] 0 xg yg dmap mask2grid xm ym t integrate xg yg broken streamlines if t is not None trajectories append t else sp2 np asanyarray start points dtype float copy # Check if start points are outside the data boundaries for xs ys in sp2 if not grid x origin < xs < grid x origin + grid width and grid y origin < ys < grid y origin + grid height raise ValueError f\"Starting point {xs} {ys} outside of \" \"data boundaries\" # Convert start points from data to array coords # Shift the seed points from the bottom left of the data so that # data2grid works properly sp2[ 0] - grid x origin sp2[ 1] - grid y origin for xs ys in sp2 xg yg dmap data2grid xs ys # Floating point issues can cause xg yg to be slightly out of # bounds for xs ys on the upper boundaries Because we have # already checked that the starting points are within the original # grid clip the xg yg to the grid to work around this issue xg np clip xg 0 grid nx - 1 yg np clip yg 0 grid ny - 1 t integrate xg yg broken streamlines if t is not None trajectories append t if use multicolor lines if norm is None norm mcolors Normalize color min color max cmap cm ensure cmap cmap streamlines [] arrows [] for t in trajectories tgx tgy t T # Rescale from grid-coordinates to data-coordinates tx ty dmap grid2data tgx tgy tx + grid x origin ty + grid y origin # Create multiple tiny segments if varying width or color is given if isinstance linewidth np ndarray or use multicolor lines points np transpose [tx ty] reshape -1 1 2 streamlines extend np hstack [points[ -1] points[1 ]] else points np transpose [tx ty] streamlines append points # Distance along streamline s np cumsum np hypot np diff tx np diff ty if use multicolor lines color values interpgrid color tgx tgy [ -1] line colors append color values # Add arrows along each trajectory for x in range 1 n arrows+1 # Get index of distance along streamline to place arrow idx np searchsorted s s[-1] * x n arrows+1 arrow tail tx[idx] ty[idx] arrow head np mean tx[idx idx + 2] np mean ty[idx idx + 2] if isinstance linewidth np ndarray line widths interpgrid linewidth tgx tgy [ -1] line kw[ linewidth ] extend line widths arrow kw[ linewidth ] line widths[idx] if use multicolor lines arrow kw[ color ] cmap norm color values[idx] p patches FancyArrowPatch arrow tail arrow head transform transform **arrow kw arrows append p lc mcollections LineCollection streamlines transform transform **line kw lc sticky edges x[ ] [grid x origin grid x origin + grid width] lc sticky edges y[ ] [grid y origin grid y origin + grid height] if use multicolor lines lc set array np ma hstack line colors lc set cmap cmap lc set norm norm axes add collection lc ac mcollections PatchCollection arrows # Adding the collection itself is broken; see #2341 for p in arrows axes add patch p axes autoscale view stream container StreamplotSet lc ac return stream container"}
{"message": "It's already there?", "timestamp": "2024-03-08T08:23:21Z", "file_name": "lib/matplotlib/axes/_axes.py", "range": {"start_line": 554, "end_line": 554, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1517385103", "html_url": "https://github.com/matplotlib/matplotlib/pull/25224#discussion_r1517385103", "attention_area": "    def secondary_xaxis(self, location, *, functions=None, transform=None, **kwargs):", "file_path": "files/65/01/00000165.py", "old_file_path": "files/33/02/00000233.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -551,7 +551,7 @@ def indicate_inset_zoom(self, inset_ax, **kwargs):\n         return self.indicate_inset(rect, inset_ax, **kwargs)\n \n     @_docstring.dedent_interpd\n-    def secondary_xaxis(self, location, *, functions=None, **kwargs):\n+    def secondary_xaxis(self, location, *, functions=None, transform=None, **kwargs):", "source": "def secondary_xaxis(self, location, *, functions=None, transform=None, **kwargs):\n        \"\"\"\n        Add a second x-axis to this `~.axes.Axes`.\n\n        For example if we want to have a second scale for the data plotted on\n        the xaxis.\n\n        %(_secax_docstring)s\n\n        Examples\n        --------\n        The main axis shows frequency, and the secondary axis shows period.\n\n        .. plot::\n\n            fig, ax = plt.subplots()\n            ax.loglog(range(1, 360, 5), range(1, 360, 5))\n            ax.set_xlabel('frequency [Hz]')\n\n            def invert(x):\n                # 1/x with special treatment of x == 0\n                x = np.array(x).astype(float)\n                near_zero = np.isclose(x, 0)\n                x[near_zero] = np.inf\n                x[~near_zero] = 1 / x[~near_zero]\n                return x\n\n            # the inverse of 1/x is itself\n            secax = ax.secondary_xaxis('top', functions=(invert, invert))\n            secax.set_xlabel('Period [s]')\n            plt.show()\n\n        To add a secondary axis relative to your data, you can pass a transform\n        to the new axis.\n\n        .. plot::\n\n            fig, ax = plt.subplots()\n            ax.plot(range(0, 5), range(-1, 4))\n\n            # Pass 'ax.transData' as a transform to place the axis\n            # relative to your data at y=0\n            secax = ax.secondary_xaxis(0, transform=ax.transData)\n        \"\"\"\n        if not (location in ['top', 'bottom'] or isinstance(location, Real)):\n            raise ValueError('secondary_xaxis location must be either '\n                             'a float or \"top\"/\"bottom\"')\n\n        secondary_ax = SecondaryAxis(self, 'x', location, functions,\n                                     transform, **kwargs)\n        self.add_child_axes(secondary_ax)\n        return secondary_ax", "source_start_line": 554, "tokens": ["def", "secondary_xaxis", "(", "self", ",", "location", ",", "*", ",", "functions", "=", "None", ",", "transform", "=", "None", ",", "**", "kwargs", ")", ":", "\"\"\"        Add a second x-axis to this `~.axes.Axes`.        For example if we want to have a second scale for the data plotted on        the xaxis.        %(_secax_docstring)s        Examples        --------        The main axis shows frequency, and the secondary axis shows period.        .. plot::            fig, ax = plt.subplots()            ax.loglog(range(1, 360, 5), range(1, 360, 5))            ax.set_xlabel('frequency [Hz]')            def invert(x):                # 1/x with special treatment of x == 0                x = np.array(x).astype(float)                near_zero = np.isclose(x, 0)                x[near_zero] = np.inf                x[~near_zero] = 1 / x[~near_zero]                return x            # the inverse of 1/x is itself            secax = ax.secondary_xaxis('top', functions=(invert, invert))            secax.set_xlabel('Period [s]')            plt.show()        To add a secondary axis relative to your data, you can pass a transform        to the new axis.        .. plot::            fig, ax = plt.subplots()            ax.plot(range(0, 5), range(-1, 4))            # Pass 'ax.transData' as a transform to place the axis            # relative to your data at y=0            secax = ax.secondary_xaxis(0, transform=ax.transData)        \"\"\"", "if", "not", "(", "location", "in", "[", "'top'", ",", "'bottom'", "]", "or", "isinstance", "(", "location", ",", "Real", ")", ")", ":", "raise", "ValueError", "(", "'secondary_xaxis location must be either '", "'a float or \"top\"/\"bottom\"'", ")", "secondary_ax", "=", "SecondaryAxis", "(", "self", ",", "'x'", ",", "location", ",", "functions", ",", "transform", ",", "**", "kwargs", ")", "self", ".", "add_child_axes", "(", "secondary_ax", ")", "return", "secondary_ax"], "to_mask": {"VAR": ["functions", "location", "secondary_ax", "self", "transform"], "METHOD": ["SecondaryAxis", "ValueError", "add_child_axes", "isinstance"]}, "attention_idx_tokens": [0, 20], "patch": "@@ -551,7 +551,7 @@\n         return self.indicate_inset(rect, inset_ax, **kwargs)\n \n     @_docstring.dedent_interpd\n-    def secondary_xaxis(self, location, *, functions=None, **kwargs):\n+    def secondary_xaxis(self, location, *, functions=None, transform=None, **kwargs):", "ext_attention_idx_tokens": [0, 21], "uid": "28b156b0", "question": "It's already there?", "code": "def secondary xaxis self location * functions None transform None **kwargs \"\"\" Add a second x-axis to this `~ axes Axes` For example if we want to have a second scale for the data plotted on the xaxis % secax docstring s Examples -------- The main axis shows frequency and the secondary axis shows period plot fig ax plt subplots ax loglog range 1 360 5 range 1 360 5 ax set xlabel frequency [Hz] def invert x # 1 x with special treatment of x 0 x np array x astype float near zero np isclose x 0 x[near zero] np inf x[~near zero] 1 x[~near zero] return x # the inverse of 1 x is itself secax ax secondary xaxis top functions invert invert secax set xlabel Period [s] plt show To add a secondary axis relative to your data you can pass a transform to the new axis plot fig ax plt subplots ax plot range 0 5 range -1 4 # Pass ax transData as a transform to place the axis # relative to your data at y 0 secax ax secondary xaxis 0 transform ax transData \"\"\" if not location in [ top bottom ] or isinstance location Real raise ValueError secondary xaxis location must be either a float or \"top\" \"bottom\" secondary ax SecondaryAxis self x location functions transform **kwargs self add child axes secondary ax return secondary ax"}
{"message": "They're both using `.get`?", "timestamp": "2024-03-27T08:53:04Z", "file_name": "lib/matplotlib/cbook.py", "range": {"start_line": 927, "end_line": 927, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1540693609", "html_url": "https://github.com/matplotlib/matplotlib/pull/25556#discussion_r1540693609", "attention_area": "        return sorted(siblings, key=self._mapping.get)", "file_path": "files/23/03/00000323.py", "old_file_path": "files/24/03/00000324.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -902,14 +917,14 @@ def __iter__(self):\n \n         The iterator is invalid if interleaved with calls to join().\n         \"\"\"\n-        unique_groups = {id(group): group for group in self._mapping.values()}\n+        unique_groups = {id(group): group for _, group in self._mapping.values()}\n         for group in unique_groups.values():\n-            yield [x for x in group]\n+            yield sorted(group, key=self._mapping.__getitem__)\n \n     def get_siblings(self, a):\n         \"\"\"Return all of the items joined with *a*, including itself.\"\"\"\n-        siblings = self._mapping.get(a, [a])\n-        return [x for x in siblings]\n+        _, siblings = self._mapping.get(a, (None, [a]))\n+        return sorted(siblings, key=self._mapping.get)", "source": "def get_siblings(self, a):\n        \"\"\"Return all of the items joined with *a*, including itself.\"\"\"\n        _, siblings = self._mapping.get(a, (None, [a]))\n        return sorted(siblings, key=self._mapping.get)", "source_start_line": 924, "tokens": ["def", "get_siblings", "(", "self", ",", "a", ")", ":", "\"\"\"Return all of the items joined with *a*, including itself.\"\"\"", "_", ",", "siblings", "=", "self", ".", "_mapping", ".", "get", "(", "a", ",", "(", "None", ",", "[", "a", "]", ")", ")", "return", "sorted", "(", "siblings", ",", "key", "=", "self", ".", "_mapping", ".", "get", ")"], "to_mask": {"VAR": ["_", "a", "self", "siblings"], "METHOD": ["get", "sorted"]}, "attention_idx_tokens": [29, 41], "patch": "@@ -902,14 +917,14 @@\n \n         The iterator is invalid if interleaved with calls to join().\n         \"\"\"\n-        unique_groups = {id(group): group for group in self._mapping.values()}\n+        unique_groups = {id(group): group for _, group in self._mapping.values()}\n         for group in unique_groups.values():\n-            yield [x for x in group]\n+            yield sorted(group, key=self._mapping.__getitem__)\n \n     def get_siblings(self, a):\n         \"\"\"Return all of the items joined with *a*, including itself.\"\"\"\n-        siblings = self._mapping.get(a, [a])\n-        return [x for x in siblings]\n+        _, siblings = self._mapping.get(a, (None, [a]))\n+        return sorted(siblings, key=self._mapping.get)", "ext_attention_idx_tokens": [0, 41], "uid": "ff3abf84", "question": "They're both using `.get`?", "code": "def get siblings self a \"\"\"Return all of the items joined with *a* including itself \"\"\" siblings self mapping get a None [a] return sorted siblings key self mapping get"}
{"message": "Right now it seems like the two bottom figures are identical?\r\n\r\nCan you change so that the x-scale has base 3 instead? In that way it may be easier to see that it actually makes a difference?", "timestamp": "2024-04-15T13:01:20Z", "file_name": "lib/matplotlib/tests/test_image.py", "range": {"start_line": 1426, "end_line": 1426, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1565757772", "html_url": "https://github.com/matplotlib/matplotlib/pull/27964#discussion_r1565757772", "attention_area": "            ax.set_yscale(\"log\", base=3)", "file_path": "files/80/03/00000380.py", "old_file_path": "files/81/03/00000381.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1406,6 +1406,27 @@ def test_nonuniform_and_pcolor():\n         ax.set(xlim=(0, 10))\n \n \n+@image_comparison([\"nonuniform_logscale.png\"], style=\"mpl20\")\n+def test_nonuniform_logscale():\n+    axs = plt.figure(figsize=(3, 3)).subplots(3)\n+\n+    for i in range(3):\n+        ax = axs[i]\n+        im = NonUniformImage(ax)\n+        im.set_data(np.arange(1, 4) ** 2, np.arange(1, 4) ** 2,\n+                    np.arange(9).reshape((3, 3)))\n+        ax.set_xlim(1, 9)\n+        ax.set_ylim(1, 9)\n+        ax.set_axis_off()\n+        if i == 1:\n+            ax.set_xscale(\"log\")\n+            ax.set_yscale(\"log\")\n+        if i == 2:\n+            ax.set_xscale(\"log\", base=2)\n+            ax.set_yscale(\"log\", base=3)", "source": "def test_nonuniform_logscale():\n    axs = plt.figure(figsize=(3, 3)).subplots(3)\n\n    for i in range(3):\n        ax = axs[i]\n        im = NonUniformImage(ax)\n        im.set_data(np.arange(1, 4) ** 2, np.arange(1, 4) ** 2,\n                    np.arange(9).reshape((3, 3)))\n        ax.set_xlim(1, 9)\n        ax.set_ylim(1, 9)\n        ax.set_axis_off()\n        if i == 1:\n            ax.set_xscale(\"log\")\n            ax.set_yscale(\"log\")\n        if i == 2:\n            ax.set_xscale(\"log\", base=2)\n            ax.set_yscale(\"log\", base=3)\n        ax.add_image(im)", "source_start_line": 1410, "tokens": ["def", "test_nonuniform_logscale", "(", ")", ":", "axs", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "3", ",", "3", ")", ")", ".", "subplots", "(", "3", ")", "for", "i", "in", "range", "(", "3", ")", ":", "ax", "=", "axs", "[", "i", "]", "im", "=", "NonUniformImage", "(", "ax", ")", "im", ".", "set_data", "(", "np", ".", "arange", "(", "1", ",", "4", ")", "**", "2", ",", "np", ".", "arange", "(", "1", ",", "4", ")", "**", "2", ",", "np", ".", "arange", "(", "9", ")", ".", "reshape", "(", "(", "3", ",", "3", ")", ")", ")", "ax", ".", "set_xlim", "(", "1", ",", "9", ")", "ax", ".", "set_ylim", "(", "1", ",", "9", ")", "ax", ".", "set_axis_off", "(", ")", "if", "i", "==", "1", ":", "ax", ".", "set_xscale", "(", "\"log\"", ")", "ax", ".", "set_yscale", "(", "\"log\"", ")", "if", "i", "==", "2", ":", "ax", ".", "set_xscale", "(", "\"log\"", ",", "base", "=", "2", ")", "ax", ".", "set_yscale", "(", "\"log\"", ",", "base", "=", "3", ")", "ax", ".", "add_image", "(", "im", ")"], "to_mask": {"VAR": ["ax", "axs", "i", "im"], "METHOD": ["NonUniformImage", "add_image", "arange", "figure", "range", "reshape", "set_axis_off", "set_data", "set_xlim", "set_xscale", "set_ylim", "set_yscale", "subplots"]}, "attention_idx_tokens": [139, 148], "patch": "@@ -1406,6 +1406,27 @@\n         ax.set(xlim=(0, 10))\n \n \n+@image_comparison([\"nonuniform_logscale.png\"], style=\"mpl20\")\n+def test_nonuniform_logscale():\n+    axs = plt.figure(figsize=(3, 3)).subplots(3)\n+\n+    for i in range(3):\n+        ax = axs[i]\n+        im = NonUniformImage(ax)\n+        im.set_data(np.arange(1, 4) ** 2, np.arange(1, 4) ** 2,\n+                    np.arange(9).reshape((3, 3)))\n+        ax.set_xlim(1, 9)\n+        ax.set_ylim(1, 9)\n+        ax.set_axis_off()\n+        if i == 1:\n+            ax.set_xscale(\"log\")\n+            ax.set_yscale(\"log\")\n+        if i == 2:\n+            ax.set_xscale(\"log\", base=2)\n+            ax.set_yscale(\"log\", base=3)", "ext_attention_idx_tokens": [0, 154], "uid": "e33bbf22", "question": "Right now it seems like the two bottom figures are identical?    Can you change so that the x-scale has base 3 instead? In that way it may be easier to see that it actually makes a difference?", "code": "def test nonuniform logscale axs plt figure figsize 3 3 subplots 3 for i in range 3 ax axs[i] im NonUniformImage ax im set data np arange 1 4 ** 2 np arange 1 4 ** 2 np arange 9 reshape 3 3 ax set xlim 1 9 ax set ylim 1 9 ax set axis off if i 1 ax set xscale \"log\" ax set yscale \"log\" if i 2 ax set xscale \"log\" base 2 ax set yscale \"log\" base 3 ax add image im"}
{"message": "These numbers seem too \"clean\" for a mouse movement? And why does elev equal roll and roll 0? Better to have test cases where values don\u2019t happen to cancel out. ", "timestamp": "2024-05-29T11:48:52Z", "file_name": "lib/mpl_toolkits/mplot3d/tests/test_axes3d.py", "range": {"start_line": 1845, "end_line": 1845, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1618744812", "html_url": "https://github.com/matplotlib/matplotlib/pull/28290#discussion_r1618744812", "attention_area": "        assert np.isclose(ax.roll, 0)", "file_path": "files/14/05/00000514.py", "old_file_path": "files/15/05/00000515.py", "filters": {"comment_message": false, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1774,21 +1832,17 @@ def test_rotate():\n         ax.view_init(0, 0, roll)\n         ax.figure.canvas.draw()\n \n-        # drag mouse horizontally to change azimuth\n-        dx = 0.1\n-        dy = 0.2\n+        # drag mouse horizontally to change orientation\n         ax._button_press(\n             mock_event(ax, button=MouseButton.LEFT, xdata=0, ydata=0))\n         ax._on_move(\n             mock_event(ax, button=MouseButton.LEFT,\n-                           xdata=dx*ax._pseudo_w, ydata=dy*ax._pseudo_h))\n+                           xdata=0.5*ax._pseudo_w, ydata=0*ax._pseudo_h))\n         ax.figure.canvas.draw()\n-        roll_radians = np.deg2rad(ax.roll)\n-        cs = np.cos(roll_radians)\n-        sn = np.sin(roll_radians)\n-        assert ax.elev == (-dy*180*cs + dx*180*sn)\n-        assert ax.azim == (-dy*180*sn - dx*180*cs)\n-        assert ax.roll == roll\n+\n+        assert np.isclose(ax.elev, roll)\n+        assert np.isclose(ax.azim, -90)\n+        assert np.isclose(ax.roll, 0)", "source": "def test_rotate():\n    \"\"\"Test rotating using the left mouse button.\"\"\"\n    for roll in [0, 30]:\n        fig = plt.figure()\n        ax = fig.add_subplot(1, 1, 1, projection='3d')\n        ax.view_init(0, 0, roll)\n        ax.figure.canvas.draw()\n\n        # drag mouse horizontally to change orientation\n        ax._button_press(\n            mock_event(ax, button=MouseButton.LEFT, xdata=0, ydata=0))\n        ax._on_move(\n            mock_event(ax, button=MouseButton.LEFT,\n                           xdata=0.5*ax._pseudo_w, ydata=0*ax._pseudo_h))\n        ax.figure.canvas.draw()\n\n        assert np.isclose(ax.elev, roll)\n        assert np.isclose(ax.azim, -90)\n        assert np.isclose(ax.roll, 0)", "source_start_line": 1827, "tokens": ["def", "test_rotate", "(", ")", ":", "\"\"\"Test rotating using the left mouse button.\"\"\"", "for", "roll", "in", "[", "0", ",", "30", "]", ":", "fig", "=", "plt", ".", "figure", "(", ")", "ax", "=", "fig", ".", "add_subplot", "(", "1", ",", "1", ",", "1", ",", "projection", "=", "'3d'", ")", "ax", ".", "view_init", "(", "0", ",", "0", ",", "roll", ")", "ax", ".", "figure", ".", "canvas", ".", "draw", "(", ")", "ax", ".", "_button_press", "(", "mock_event", "(", "ax", ",", "button", "=", "MouseButton", ".", "LEFT", ",", "xdata", "=", "0", ",", "ydata", "=", "0", ")", ")", "ax", ".", "_on_move", "(", "mock_event", "(", "ax", ",", "button", "=", "MouseButton", ".", "LEFT", ",", "xdata", "=", "0.5", "*", "ax", ".", "_pseudo_w", ",", "ydata", "=", "0", "*", "ax", ".", "_pseudo_h", ")", ")", "ax", ".", "figure", ".", "canvas", ".", "draw", "(", ")", "assert", "np", ".", "isclose", "(", "ax", ".", "elev", ",", "roll", ")", "assert", "np", ".", "isclose", "(", "ax", ".", "azim", ",", "-", "90", ")", "assert", "np", ".", "isclose", "(", "ax", ".", "roll", ",", "0", ")"], "to_mask": {"VAR": ["ax", "fig", "roll"], "METHOD": ["_button_press", "_on_move", "add_subplot", "draw", "figure", "isclose", "mock_event", "view_init"]}, "attention_idx_tokens": [143, 153], "patch": "@@ -1774,21 +1832,17 @@\n         ax.view_init(0, 0, roll)\n         ax.figure.canvas.draw()\n \n-        # drag mouse horizontally to change azimuth\n-        dx = 0.1\n-        dy = 0.2\n+        # drag mouse horizontally to change orientation\n         ax._button_press(\n             mock_event(ax, button=MouseButton.LEFT, xdata=0, ydata=0))\n         ax._on_move(\n             mock_event(ax, button=MouseButton.LEFT,\n-                           xdata=dx*ax._pseudo_w, ydata=dy*ax._pseudo_h))\n+                           xdata=0.5*ax._pseudo_w, ydata=0*ax._pseudo_h))\n         ax.figure.canvas.draw()\n-        roll_radians = np.deg2rad(ax.roll)\n-        cs = np.cos(roll_radians)\n-        sn = np.sin(roll_radians)\n-        assert ax.elev == (-dy*180*cs + dx*180*sn)\n-        assert ax.azim == (-dy*180*sn - dx*180*cs)\n-        assert ax.roll == roll\n+\n+        assert np.isclose(ax.elev, roll)\n+        assert np.isclose(ax.azim, -90)\n+        assert np.isclose(ax.roll, 0)", "ext_attention_idx_tokens": [57, 153], "uid": "fe51630a", "question": "These numbers seem too \"clean\" for a mouse movement? And why does elev equal roll and roll 0? Better to have test cases where values don\u2019t happen to cancel out. ", "code": "def test rotate \"\"\"Test rotating using the left mouse button \"\"\" for roll in [0 30] fig plt figure ax fig add subplot 1 1 1 projection 3d ax view init 0 0 roll ax figure canvas draw # drag mouse horizontally to change orientation ax button press mock event ax button MouseButton LEFT xdata 0 ydata 0 ax on move mock event ax button MouseButton LEFT xdata 0 5*ax pseudo w ydata 0*ax pseudo h ax figure canvas draw assert np isclose ax elev roll assert np isclose ax azim -90 assert np isclose ax roll 0"}
{"message": "> These numbers seem too \"clean\" for a mouse movement?\r\n\r\nWell, yes, but these angles are easy enough to understand what the result should be. For 'more arbitrary' numbers, it is hard to know the result, short of running the calculation. The test is more of a 'freezing any errors in place' than a validation.\r\n\r\n\r\n> And why does elev equal roll and roll 0?\r\n\r\nBecause dragging the mouse rotated the figure!\r\n", "timestamp": "2024-06-01T16:51:26Z", "file_name": "lib/mpl_toolkits/mplot3d/tests/test_axes3d.py", "range": {"start_line": 1845, "end_line": 1845, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1623250295", "html_url": "https://github.com/matplotlib/matplotlib/pull/28290#discussion_r1623250295", "attention_area": "        assert np.isclose(ax.roll, 0)", "file_path": "files/14/05/00000514.py", "old_file_path": "files/15/05/00000515.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1774,21 +1832,17 @@ def test_rotate():\n         ax.view_init(0, 0, roll)\n         ax.figure.canvas.draw()\n \n-        # drag mouse horizontally to change azimuth\n-        dx = 0.1\n-        dy = 0.2\n+        # drag mouse horizontally to change orientation\n         ax._button_press(\n             mock_event(ax, button=MouseButton.LEFT, xdata=0, ydata=0))\n         ax._on_move(\n             mock_event(ax, button=MouseButton.LEFT,\n-                           xdata=dx*ax._pseudo_w, ydata=dy*ax._pseudo_h))\n+                           xdata=0.5*ax._pseudo_w, ydata=0*ax._pseudo_h))\n         ax.figure.canvas.draw()\n-        roll_radians = np.deg2rad(ax.roll)\n-        cs = np.cos(roll_radians)\n-        sn = np.sin(roll_radians)\n-        assert ax.elev == (-dy*180*cs + dx*180*sn)\n-        assert ax.azim == (-dy*180*sn - dx*180*cs)\n-        assert ax.roll == roll\n+\n+        assert np.isclose(ax.elev, roll)\n+        assert np.isclose(ax.azim, -90)\n+        assert np.isclose(ax.roll, 0)", "source": "def test_rotate():\n    \"\"\"Test rotating using the left mouse button.\"\"\"\n    for roll in [0, 30]:\n        fig = plt.figure()\n        ax = fig.add_subplot(1, 1, 1, projection='3d')\n        ax.view_init(0, 0, roll)\n        ax.figure.canvas.draw()\n\n        # drag mouse horizontally to change orientation\n        ax._button_press(\n            mock_event(ax, button=MouseButton.LEFT, xdata=0, ydata=0))\n        ax._on_move(\n            mock_event(ax, button=MouseButton.LEFT,\n                           xdata=0.5*ax._pseudo_w, ydata=0*ax._pseudo_h))\n        ax.figure.canvas.draw()\n\n        assert np.isclose(ax.elev, roll)\n        assert np.isclose(ax.azim, -90)\n        assert np.isclose(ax.roll, 0)", "source_start_line": 1827, "tokens": ["def", "test_rotate", "(", ")", ":", "\"\"\"Test rotating using the left mouse button.\"\"\"", "for", "roll", "in", "[", "0", ",", "30", "]", ":", "fig", "=", "plt", ".", "figure", "(", ")", "ax", "=", "fig", ".", "add_subplot", "(", "1", ",", "1", ",", "1", ",", "projection", "=", "'3d'", ")", "ax", ".", "view_init", "(", "0", ",", "0", ",", "roll", ")", "ax", ".", "figure", ".", "canvas", ".", "draw", "(", ")", "ax", ".", "_button_press", "(", "mock_event", "(", "ax", ",", "button", "=", "MouseButton", ".", "LEFT", ",", "xdata", "=", "0", ",", "ydata", "=", "0", ")", ")", "ax", ".", "_on_move", "(", "mock_event", "(", "ax", ",", "button", "=", "MouseButton", ".", "LEFT", ",", "xdata", "=", "0.5", "*", "ax", ".", "_pseudo_w", ",", "ydata", "=", "0", "*", "ax", ".", "_pseudo_h", ")", ")", "ax", ".", "figure", ".", "canvas", ".", "draw", "(", ")", "assert", "np", ".", "isclose", "(", "ax", ".", "elev", ",", "roll", ")", "assert", "np", ".", "isclose", "(", "ax", ".", "azim", ",", "-", "90", ")", "assert", "np", ".", "isclose", "(", "ax", ".", "roll", ",", "0", ")"], "to_mask": {"VAR": ["ax", "fig", "roll"], "METHOD": ["_button_press", "_on_move", "add_subplot", "draw", "figure", "isclose", "mock_event", "view_init"]}, "attention_idx_tokens": [143, 153], "patch": "@@ -1774,21 +1832,17 @@\n         ax.view_init(0, 0, roll)\n         ax.figure.canvas.draw()\n \n-        # drag mouse horizontally to change azimuth\n-        dx = 0.1\n-        dy = 0.2\n+        # drag mouse horizontally to change orientation\n         ax._button_press(\n             mock_event(ax, button=MouseButton.LEFT, xdata=0, ydata=0))\n         ax._on_move(\n             mock_event(ax, button=MouseButton.LEFT,\n-                           xdata=dx*ax._pseudo_w, ydata=dy*ax._pseudo_h))\n+                           xdata=0.5*ax._pseudo_w, ydata=0*ax._pseudo_h))\n         ax.figure.canvas.draw()\n-        roll_radians = np.deg2rad(ax.roll)\n-        cs = np.cos(roll_radians)\n-        sn = np.sin(roll_radians)\n-        assert ax.elev == (-dy*180*cs + dx*180*sn)\n-        assert ax.azim == (-dy*180*sn - dx*180*cs)\n-        assert ax.roll == roll\n+\n+        assert np.isclose(ax.elev, roll)\n+        assert np.isclose(ax.azim, -90)\n+        assert np.isclose(ax.roll, 0)", "ext_attention_idx_tokens": [57, 153], "uid": "180e205d", "question": "> These numbers seem too \"clean\" for a mouse movement?    Well, yes, but these angles are easy enough to understand what the result should be. For 'more arbitrary' numbers, it is hard to know the result, short of running the calculation. The test is more of a 'freezing any errors in place' than a validation.      > And why does elev equal roll and roll 0?    Because dragging the mouse rotated the figure!  ", "code": "def test rotate \"\"\"Test rotating using the left mouse button \"\"\" for roll in [0 30] fig plt figure ax fig add subplot 1 1 1 projection 3d ax view init 0 0 roll ax figure canvas draw # drag mouse horizontally to change orientation ax button press mock event ax button MouseButton LEFT xdata 0 ydata 0 ax on move mock event ax button MouseButton LEFT xdata 0 5*ax pseudo w ydata 0*ax pseudo h ax figure canvas draw assert np isclose ax elev roll assert np isclose ax azim -90 assert np isclose ax roll 0"}
{"message": "I'm unclear how this relates to the context.\r\n\r\nWhat exactly do backend implementors implement? Do they reimplement this function?\r\nAlso, how do they check? Do they draw a text and additionally its bbox? Would a minimal example be helpful?", "timestamp": "2024-06-12T12:05:38Z", "file_name": "lib/matplotlib/backend_bases.py", "range": {"start_line": 593, "end_line": 593, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1636343391", "html_url": "https://github.com/matplotlib/matplotlib/pull/28380#discussion_r1636343391", "attention_area": "        # Note: Using the ``bbox`` property of Text objects, backend", "file_path": "files/58/05/00000558.py", "old_file_path": "files/59/05/00000559.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -604,6 +590,9 @@ def get_text_width_height_descent(self, s, prop, ismath):\n \n         Whitespace at the start and the end of *s* is included in the reported width.\n         \"\"\"\n+        # Note: Using the ``bbox`` property of Text objects, backend", "source": "def get_text_width_height_descent(self, s, prop, ismath):\n        \"\"\"\n        Get the width, height, and descent (offset from the bottom to the baseline), in\n        display coords, of the string *s* with `.FontProperties` *prop*.\n\n        Whitespace at the start and the end of *s* is included in the reported width.\n        \"\"\"\n        # Note: Using the ``bbox`` property of Text objects, backend\n        # implementers can check their bounding box calculations (which impact\n        # text layout).\n        fontsize = prop.get_size_in_points()\n\n        if ismath == 'TeX':\n            # todo: handle properties\n            return self.get_texmanager().get_text_width_height_descent(\n                s, fontsize, renderer=self)\n\n        dpi = self.points_to_pixels(72)\n        if ismath:\n            dims = self._text2path.mathtext_parser.parse(s, dpi, prop)\n            return dims[0:3]  # return width, height, descent\n\n        flags = self._text2path._get_hinting_flag()\n        font = self._text2path._get_font(prop)\n        font.set_size(fontsize, dpi)\n        # the width and height of unrotated string\n        font.set_text(s, 0.0, flags=flags)\n        w, h = font.get_width_height()\n        d = font.get_descent()\n        w /= 64.0  # convert from subpixels\n        h /= 64.0\n        d /= 64.0\n        return w, h, d", "source_start_line": 586, "tokens": ["def", "get_text_width_height_descent", "(", "self", ",", "s", ",", "prop", ",", "ismath", ")", ":", "\"\"\"        Get the width, height, and descent (offset from the bottom to the baseline), in        display coords, of the string *s* with `.FontProperties` *prop*.        Whitespace at the start and the end of *s* is included in the reported width.        \"\"\"", "fontsize", "=", "prop", ".", "get_size_in_points", "(", ")", "if", "ismath", "==", "'TeX'", ":", "return", "self", ".", "get_texmanager", "(", ")", ".", "get_text_width_height_descent", "(", "s", ",", "fontsize", ",", "renderer", "=", "self", ")", "dpi", "=", "self", ".", "points_to_pixels", "(", "72", ")", "if", "ismath", ":", "dims", "=", "self", ".", "_text2path", ".", "mathtext_parser", ".", "parse", "(", "s", ",", "dpi", ",", "prop", ")", "return", "dims", "[", "0", ":", "3", "]", "flags", "=", "self", ".", "_text2path", ".", "_get_hinting_flag", "(", ")", "font", "=", "self", ".", "_text2path", ".", "_get_font", "(", "prop", ")", "font", ".", "set_size", "(", "fontsize", ",", "dpi", ")", "font", ".", "set_text", "(", "s", ",", "0.0", ",", "flags", "=", "flags", ")", "w", ",", "h", "=", "font", ".", "get_width_height", "(", ")", "d", "=", "font", ".", "get_descent", "(", ")", "w", "/=", "64.0", "h", "/=", "64.0", "d", "/=", "64.0", "return", "w", ",", "h", ",", "d"], "to_mask": {"VAR": ["d", "dims", "dpi", "flags", "font", "fontsize", "h", "ismath", "prop", "s", "self", "w"], "METHOD": ["_get_font", "_get_hinting_flag", "get_descent", "get_size_in_points", "get_texmanager", "get_text_width_height_descent", "get_width_height", "parse", "points_to_pixels", "set_size", "set_text"]}, "attention_idx_tokens": [null, null], "patch": "@@ -604,6 +590,9 @@\n \n         Whitespace at the start and the end of *s* is included in the reported width.\n         \"\"\"\n+        # Note: Using the ``bbox`` property of Text objects, backend", "ext_attention_idx_tokens": [13, 19], "uid": "66fa9c7c", "question": "I'm unclear how this relates to the context.    What exactly do backend implementors implement? Do they reimplement this function?  Also, how do they check? Do they draw a text and additionally its bbox? Would a minimal example be helpful?", "code": "def get text width height descent self s prop ismath \"\"\" Get the width height and descent offset from the bottom to the baseline in display coords of the string *s* with ` FontProperties` *prop* Whitespace at the start and the end of *s* is included in the reported width \"\"\" # Note Using the ``bbox`` property of Text objects backend # implementers can check their bounding box calculations which impact # text layout fontsize prop get size in points if ismath TeX # todo handle properties return self get texmanager get text width height descent s fontsize renderer self dpi self points to pixels 72 if ismath dims self text2path mathtext parser parse s dpi prop return dims[0 3] # return width height descent flags self text2path get hinting flag font self text2path get font prop font set size fontsize dpi # the width and height of unrotated string font set text s 0 0 flags flags w h font get width height d font get descent w 64 0 # convert from subpixels h 64 0 d 64 0 return w h d"}
{"message": "what is this case? ", "timestamp": "2024-06-27T01:11:58Z", "file_name": "lib/matplotlib/colors.py", "range": {"start_line": 1366, "end_line": 1366, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1655696002", "html_url": "https://github.com/matplotlib/matplotlib/pull/28454#discussion_r1655696002", "attention_area": "", "file_path": "files/90/05/00000590.py", "old_file_path": "files/92/05/00000592.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1225,6 +1240,594 @@ def reversed(self, name=None):\n         return new_cmap\n \n \n+class MultivarColormap(ColormapBase):\n+    \"\"\"\n+    Class for holding multiple `~matplotlib.colors.Colormap` for use in a\n+    `~matplotlib.cm.VectorMappable` object\n+\n+    MultivarColormap does not support alpha in the constituent\n+    look up tables (ignored).\n+    \"\"\"\n+    def __init__(self, name, colormaps, combination_mode):\n+        \"\"\"\n+        Parameters\n+        ----------\n+        name : str\n+            The name of the colormap family.\n+        colormaps: list or tuple of `~matplotlib.colors.Colormap` objects\n+            The individual colormaps that are combined\n+        combination_mode: str, 'Add' or 'Sub'\n+            Describe how colormaps are combined in sRGB space\n+            'Add' -> additive\n+            'Sub' -> subtractive\n+        \"\"\"\n+        self.name = name\n+\n+        if not np.iterable(colormaps) or len(colormaps) == 1:\n+            raise ValueError(\"A MultivarColormap must have more than one colormap.\")\n+        for cmap in colormaps:\n+            if not issubclass(type(cmap), Colormap):\n+                raise ValueError(\"colormaps must be a list of objects that subclass\"\n+                                 \" Colormap, not strings or list of strings\")\n+\n+        self.colormaps = colormaps\n+        self.combination_mode = combination_mode\n+        self.n_variates = len(colormaps)\n+        self._rgba_bad = (0.0, 0.0, 0.0, 0.0)  # If bad, don't paint anything.\n+\n+    def __call__(self, X, alpha=None, bytes=False):\n+        r\"\"\"\n+        Parameters\n+        ----------\n+        X : tuple (X0, X1, ...) of length equal to the number of colormaps\n+            X0, X1 ...:\n+            float or int, `~numpy.ndarray` or scalar\n+            The data value(s) to convert to RGBA.\n+            For floats, *Xi...* should be in the interval ``[0.0, 1.0]`` to\n+            return the RGBA values ``X*100`` percent along the Colormap line.\n+            For integers, *Xi...*  should be in the interval ``[0, self[i].N)`` to\n+            return RGBA values *indexed* from colormap [i] with index ``Xi``, where\n+            self[i] is colormap i.\n+        alpha : float or array-like or None\n+            Alpha must be a scalar between 0 and 1, a sequence of such\n+            floats with shape matching Xi, or None.\n+        bytes : bool\n+            If False (default), the returned RGBA values will be floats in the\n+            interval ``[0, 1]`` otherwise they will be `numpy.uint8`\\s in the\n+            interval ``[0, 255]``.\n+\n+        Returns\n+        -------\n+        Tuple of RGBA values if X[0] is scalar, otherwise an array of\n+        RGBA values with a shape of ``X.shape + (4, )``.\n+        \"\"\"\n+\n+        if len(X) != len(self):\n+            raise ValueError(\n+                f'For the selected colormap the data must have a first dimension '\n+                f'{len(self)}, not {len(X)}')\n+        rgba, mask_bad = self[0](X[0], bytes=False, return_mask_bad=True)\n+        rgba = np.asarray(rgba)\n+        for c, xx in zip(self[1:], X[1:]):\n+            sub_rgba, sub_mask_bad = c(xx, bytes=False, return_mask_bad=True)\n+            sub_rgba = np.asarray(sub_rgba)\n+            rgba[..., :3] += sub_rgba[..., :3]  # add colors\n+            rgba[..., 3] *= sub_rgba[..., 3]  # multiply alpha\n+            mask_bad |= sub_mask_bad\n+\n+        if self.combination_mode == 'Sub':\n+            rgba[..., :3] -= len(self) - 1\n+\n+        rgba[mask_bad] = self.get_bad()\n+\n+        rgba = np.clip(rgba, 0, 1)\n+\n+        if alpha is not None:\n+            alpha = np.clip(alpha, 0, 1)\n+            if alpha.shape not in [(), np.array(X[0]).shape]:\n+                raise ValueError(\n+                    f\"alpha is array-like but its shape {alpha.shape} does \"\n+                    f\"not match that of X[0] {np.array(X[0]).shape}\")\n+            rgba[..., -1] *= alpha\n+\n+        if bytes:\n+            rgba = (rgba * 255).astype('uint8')\n+\n+        if not np.iterable(X[0]):\n+            rgba = tuple(rgba)\n+", "source": "def __eq__(self, other):\n        if not isinstance(other, MultivarColormap):\n            return False\n        if not len(self) == len(other):\n            return False\n        for c0, c1 in zip(self, other):\n            if not c0 == c1:\n                return False\n        if not all(self._rgba_bad == other._rgba_bad):\n            return False\n        if not self.combination_mode == other.combination_mode:\n            return False\n        return True", "source_start_line": 1353, "tokens": ["def", "__eq__", "(", "self", ",", "other", ")", ":", "if", "not", "isinstance", "(", "other", ",", "MultivarColormap", ")", ":", "return", "False", "if", "not", "len", "(", "self", ")", "==", "len", "(", "other", ")", ":", "return", "False", "for", "c0", ",", "c1", "in", "zip", "(", "self", ",", "other", ")", ":", "if", "not", "c0", "==", "c1", ":", "return", "False", "if", "not", "all", "(", "self", ".", "_rgba_bad", "==", "other", ".", "_rgba_bad", ")", ":", "return", "False", "if", "not", "self", ".", "combination_mode", "==", "other", ".", "combination_mode", ":", "return", "False", "return", "True"], "to_mask": {"VAR": ["c0", "c1", "other", "self"], "METHOD": ["all", "isinstance", "len", "zip"]}, "attention_idx_tokens": [null, null], "patch": "@@ -1225,6 +1240,594 @@\n         return new_cmap\n \n \n+class MultivarColormap(ColormapBase):\n+    \"\"\"\n+    Class for holding multiple `~matplotlib.colors.Colormap` for use in a\n+    `~matplotlib.cm.VectorMappable` object\n+\n+    MultivarColormap does not support alpha in the constituent\n+    look up tables (ignored).\n+    \"\"\"\n+    def __init__(self, name, colormaps, combination_mode):\n+        \"\"\"\n+        Parameters\n+        ----------\n+        name : str\n+            The name of the colormap family.\n+        colormaps: list or tuple of `~matplotlib.colors.Colormap` objects\n+            The individual colormaps that are combined\n+        combination_mode: str, 'Add' or 'Sub'\n+            Describe how colormaps are combined in sRGB space\n+            'Add' -> additive\n+            'Sub' -> subtractive\n+        \"\"\"\n+        self.name = name\n+\n+        if not np.iterable(colormaps) or len(colormaps) == 1:\n+            raise ValueError(\"A MultivarColormap must have more than one colormap.\")\n+        for cmap in colormaps:\n+            if not issubclass(type(cmap), Colormap):\n+                raise ValueError(\"colormaps must be a list of objects that subclass\"\n+                                 \" Colormap, not strings or list of strings\")\n+\n+        self.colormaps = colormaps\n+        self.combination_mode = combination_mode\n+        self.n_variates = len(colormaps)\n+        self._rgba_bad = (0.0, 0.0, 0.0, 0.0)  # If bad, don't paint anything.\n+\n+    def __call__(self, X, alpha=None, bytes=False):\n+        r\"\"\"\n+        Parameters\n+        ----------\n+        X : tuple (X0, X1, ...) of length equal to the number of colormaps\n+            X0, X1 ...:\n+            float or int, `~numpy.ndarray` or scalar\n+            The data value(s) to convert to RGBA.\n+            For floats, *Xi...* should be in the interval ``[0.0, 1.0]`` to\n+            return the RGBA values ``X*100`` percent along the Colormap line.\n+            For integers, *Xi...*  should be in the interval ``[0, self[i].N)`` to\n+            return RGBA values *indexed* from colormap [i] with index ``Xi``, where\n+            self[i] is colormap i.\n+        alpha : float or array-like or None\n+            Alpha must be a scalar between 0 and 1, a sequence of such\n+            floats with shape matching Xi, or None.\n+        bytes : bool\n+            If False (default), the returned RGBA values will be floats in the\n+            interval ``[0, 1]`` otherwise they will be `numpy.uint8`\\s in the\n+            interval ``[0, 255]``.\n+\n+        Returns\n+        -------\n+        Tuple of RGBA values if X[0] is scalar, otherwise an array of\n+        RGBA values with a shape of ``X.shape + (4, )``.\n+        \"\"\"\n+\n+        if len(X) != len(self):\n+            raise ValueError(\n+                f'For the selected colormap the data must have a first dimension '\n+                f'{len(self)}, not {len(X)}')\n+        rgba, mask_bad = self[0](X[0], bytes=False, return_mask_bad=True)\n+        rgba = np.asarray(rgba)\n+        for c, xx in zip(self[1:], X[1:]):\n+            sub_rgba, sub_mask_bad = c(xx, bytes=False, return_mask_bad=True)\n+            sub_rgba = np.asarray(sub_rgba)\n+            rgba[..., :3] += sub_rgba[..., :3]  # add colors\n+            rgba[..., 3] *= sub_rgba[..., 3]  # multiply alpha\n+            mask_bad |= sub_mask_bad\n+\n+        if self.combination_mode == 'Sub':\n+            rgba[..., :3] -= len(self) - 1\n+\n+        rgba[mask_bad] = self.get_bad()\n+\n+        rgba = np.clip(rgba, 0, 1)\n+\n+        if alpha is not None:\n+            alpha = np.clip(alpha, 0, 1)\n+            if alpha.shape not in [(), np.array(X[0]).shape]:\n+                raise ValueError(\n+                    f\"alpha is array-like but its shape {alpha.shape} does \"\n+                    f\"not match that of X[0] {np.array(X[0]).shape}\")\n+            rgba[..., -1] *= alpha\n+\n+        if bytes:\n+            rgba = (rgba * 255).astype('uint8')\n+\n+        if not np.iterable(X[0]):\n+            rgba = tuple(rgba)\n+\n+        return rgba\n+\n+    def copy(self):\n+        \"\"\"Return a copy of the multivarcolormap.\"\"\"\n+        return self.__copy__()\n+\n+    def __copy__(self):\n+        cls = self.__class__\n+        cmapobject = cls.__new__(cls)\n+        cmapobject.__dict__.update(self.__dict__)\n+        cmapobject.colormaps = [cm.copy() for cm in self.colormaps]\n+        cmapobject._rgba_bad = np.copy(self._rgba_bad)\n+        return cmapobject\n+\n+    def __eq__(self, other):\n+        if not isinstance(other, MultivarColormap):\n+            return False\n+        if not len(self) == len(other):\n+            return False\n+        for c0, c1 in zip(self, other):\n+            if not c0 == c1:\n+                return False\n+        if not all(self._rgba_bad == other._rgba_bad):\n+            return False\n+        if not self.combination_mode == other.combination_mode:\n+            return False\n+        return True\n+", "ext_attention_idx_tokens": [0, 81], "uid": "1cf5a938", "question": "what is this case? ", "code": "def eq self other if not isinstance other MultivarColormap return False if not len self len other return False for c0 c1 in zip self other if not c0 c1 return False if not all self rgba bad other rgba bad return False if not self combination mode other combination mode return False return True"}
{"message": "Also this has me wondering what's going on when we set \"none\" and if that's related to #28475", "timestamp": "2024-06-27T03:27:58Z", "file_name": "lib/matplotlib/tests/test_axes.py", "range": {"start_line": 4664, "end_line": 4664, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1656200061", "html_url": "https://github.com/matplotlib/matplotlib/pull/28073#discussion_r1656200061", "attention_area": "               for p in patches)", "file_path": "files/89/05/00000589.py", "old_file_path": "files/83/05/00000583.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -4603,56 +4603,68 @@ def test_hist_stacked_bar():\n     ax.legend(loc='upper right', bbox_to_anchor=(1.0, 1.0), ncols=1)\n \n \n+@pytest.mark.parametrize('kwargs', ({'facecolor': [\"b\", \"g\", \"r\"]},\n+                                    {'edgecolor': [\"b\", \"g\", \"r\"]},\n+                                    {'hatch': [\"/\", \"\\\\\", \".\"]},\n+                                    {'linestyle': [\"-\", \"--\", \":\"]},\n+                                    {'linewidth': [1, 1.5, 2]},\n+                                    {'color': [\"b\", \"g\", \"r\"]}))\n @check_figures_equal(extensions=[\"png\"])\n-def test_hist_vectorized_params(fig_test, fig_ref):\n+def test_hist_vectorized_params(fig_test, fig_ref, kwargs):\n     np.random.seed(19680801)\n     x = [np.random.randn(n) for n in [2000, 5000, 10000]]\n \n-    facecolor = [\"b\", \"g\", \"r\"]\n-    edgecolor = [\"b\", \"g\", \"r\"]\n-    hatch = [\"/\", \"\\\\\", \".\"]\n-    linestyle = [\"-\", \"--\", \":\"]\n-    linewidth = [1, 1.5, 2]\n-    colors = [\"b\", \"g\", \"r\"]\n-    ((axt1, axt2, axt3), (axt4, axt5, axt6)) = fig_test.subplots(2, 3)\n-    ((axr1, axr2, axr3), (axr4, axr5, axr6)) = fig_ref.subplots(2, 3)\n-\n-    _, bins, _ = axt1.hist(x, bins=10, histtype=\"stepfilled\", facecolor=facecolor)\n-\n-    for i, (xi, fc) in enumerate(zip(x, facecolor)):\n-        axr1.hist(xi, bins=bins, histtype=\"stepfilled\", facecolor=fc,\n-                  zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt2.hist(x, bins=10, histtype=\"step\", edgecolor=edgecolor)\n-\n-    for i, (xi, ec) in enumerate(zip(x, edgecolor)):\n-        axr2.hist(xi, bins=bins, histtype=\"step\", edgecolor=ec, zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt3.hist(x, bins=10, histtype=\"stepfilled\", hatch=hatch,\n-                            facecolor=facecolor)\n-\n-    for i, (xi, fc, ht) in enumerate(zip(x, facecolor, hatch)):\n-        axr3.hist(xi, bins=bins, histtype=\"stepfilled\", hatch=ht, facecolor=fc,\n-                  zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt4.hist(x, bins=10, histtype=\"step\", linestyle=linestyle,\n-                           edgecolor=edgecolor)\n-\n-    for i, (xi, ec, ls) in enumerate(zip(x, edgecolor, linestyle)):\n-        axr4.hist(xi, bins=bins, histtype=\"step\", linestyle=ls, edgecolor=ec,\n-                  zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt5.hist(x, bins=10, histtype=\"step\", linewidth=linewidth,\n-                           edgecolor=edgecolor)\n-\n-    for i, (xi, ec, lw) in enumerate(zip(x, edgecolor, linewidth)):\n-        axr5.hist(xi, bins=bins, histtype=\"step\", linewidth=lw, edgecolor=ec,\n-                  zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt6.hist(x, bins=10, histtype=\"stepfilled\", color=colors)\n-\n-    for i, (xi, c) in enumerate(zip(x, colors)):\n-        axr6.hist(xi, bins=bins, histtype=\"stepfilled\", color=c, zorder=(len(x)-i)/2)\n+    (axt1, axt2) = fig_test.subplots(2)\n+    (axr1, axr2) = fig_ref.subplots(2)\n+\n+    for histtype, axt, axr in [(\"stepfilled\", axt1, axr1), (\"step\", axt2, axr2)]:\n+        _, bins, _ = axt.hist(x, bins=10, histtype=histtype, **kwargs)\n+\n+        kw, values = next(iter(kwargs.items()))\n+        for i, (xi, value) in enumerate(zip(x, values)):\n+            axr.hist(xi, bins=bins, histtype=histtype, **{kw: value},\n+                     zorder=(len(x)-i)/2)\n+\n+\n+@pytest.mark.parametrize('kwargs, patch_face, patch_edge',\n+                         [({'histtype': 'stepfilled', 'color': 'r',\n+                            'facecolor': 'y', 'edgecolor': 'g'}, 'y', 'g'),\n+                          ({'histtype': 'step', 'color': 'r',\n+                            'facecolor': 'y', 'edgecolor': 'g'}, 'none', 'g'),\n+                          ({'histtype': 'stepfilled', 'color': 'r',\n+                            'edgecolor': 'g'}, 'r', 'g'),\n+                          ({'histtype': 'step', 'color': 'r',\n+                            'edgecolor': 'g'}, 'none', 'g'),\n+                          ({'histtype': 'stepfilled', 'color': 'r',\n+                            'facecolor': 'y'}, 'y', 'k'),\n+                          ({'histtype': 'step', 'color': 'r',\n+                            'facecolor': 'y'}, 'none', 'r'),\n+                          ({'histtype': 'stepfilled',\n+                            'facecolor': 'y', 'edgecolor': 'g'}, 'y', 'g'),\n+                          ({'histtype': 'step', 'facecolor': 'y',\n+                            'edgecolor': 'g'}, 'none', 'g'),\n+                          ({'histtype': 'stepfilled', 'color': 'r'}, 'r', 'k'),\n+                          ({'histtype': 'step', 'color': 'r'}, 'none', 'r'),\n+                          ({'histtype': 'stepfilled', 'facecolor': 'y'}, 'y', 'k'),\n+                          ({'histtype': 'step', 'facecolor': 'y'}, 'none', 'b'),\n+                          ({'histtype': 'stepfilled', 'edgecolor': 'g'}, 'b', 'g'),\n+                          ({'histtype': 'step', 'edgecolor': 'g'}, 'none', 'g'),\n+                          ({'histtype': 'stepfilled'}, 'b', 'k'),\n+                          ({'histtype': 'step'}, 'none', 'b')])\n+def test_hist_color_semantics(kwargs, patch_face, patch_edge):\n+    _, _, patches = plt.figure().subplots().hist([1, 2, 3], **kwargs)\n+    # When the expected edgecolor is blue, it corresponds to the\n+    # first color of the default color cycle\n+    # When the expected edgecolor is black, it corresponds to the\n+    # patch.edgecolor rcParam\n+    # When the expected facecolor is blue, it corresponds to the\n+    # patch.facecolor rcParam or the first color of the color cycle\n+    assert all(mcolors.same_color(p.get_facecolor(), patch_face)\n+               if patch_face != 'none' else p.get_facecolor()[3] == 0\n+               for p in patches)", "source": "def test_hist_color_semantics(kwargs, patch_face, patch_edge):\n    _, _, patches = plt.figure().subplots().hist([1, 2, 3], **kwargs)\n    # When the expected edgecolor is blue, it corresponds to the\n    # first color of the default color cycle\n    # When the expected edgecolor is black, it corresponds to the\n    # patch.edgecolor rcParam\n    # When the expected facecolor is blue, it corresponds to the\n    # patch.facecolor rcParam or the first color of the color cycle\n    assert all(mcolors.same_color(p.get_facecolor(), patch_face)\n               if patch_face != 'none' else p.get_facecolor()[3] == 0\n               for p in patches)\n    assert all(mcolors.same_color(p.get_edgecolor(), patch_edge)\n               if patch_edge != 'none' else p.get_edgecolor()[3] == 0\n               for p in patches)", "source_start_line": 4654, "tokens": ["def", "test_hist_color_semantics", "(", "kwargs", ",", "patch_face", ",", "patch_edge", ")", ":", "_", ",", "_", ",", "patches", "=", "plt", ".", "figure", "(", ")", ".", "subplots", "(", ")", ".", "hist", "(", "[", "1", ",", "2", ",", "3", "]", ",", "**", "kwargs", ")", "assert", "all", "(", "mcolors", ".", "same_color", "(", "p", ".", "get_facecolor", "(", ")", ",", "patch_face", ")", "if", "patch_face", "!=", "'none'", "else", "p", ".", "get_facecolor", "(", ")", "[", "3", "]", "==", "0", "for", "p", "in", "patches", ")", "assert", "all", "(", "mcolors", ".", "same_color", "(", "p", ".", "get_edgecolor", "(", ")", ",", "patch_edge", ")", "if", "patch_edge", "!=", "'none'", "else", "p", ".", "get_edgecolor", "(", ")", "[", "3", "]", "==", "0", "for", "p", "in", "patches", ")"], "to_mask": {"VAR": ["_", "kwargs", "patch_edge", "patch_face", "patches"], "METHOD": ["all", "figure", "get_edgecolor", "get_facecolor", "hist", "same_color", "subplots"]}, "attention_idx_tokens": [69, 73], "patch": "@@ -4603,56 +4603,68 @@\n     ax.legend(loc='upper right', bbox_to_anchor=(1.0, 1.0), ncols=1)\n \n \n+@pytest.mark.parametrize('kwargs', ({'facecolor': [\"b\", \"g\", \"r\"]},\n+                                    {'edgecolor': [\"b\", \"g\", \"r\"]},\n+                                    {'hatch': [\"/\", \"\\\\\", \".\"]},\n+                                    {'linestyle': [\"-\", \"--\", \":\"]},\n+                                    {'linewidth': [1, 1.5, 2]},\n+                                    {'color': [\"b\", \"g\", \"r\"]}))\n @check_figures_equal(extensions=[\"png\"])\n-def test_hist_vectorized_params(fig_test, fig_ref):\n+def test_hist_vectorized_params(fig_test, fig_ref, kwargs):\n     np.random.seed(19680801)\n     x = [np.random.randn(n) for n in [2000, 5000, 10000]]\n \n-    facecolor = [\"b\", \"g\", \"r\"]\n-    edgecolor = [\"b\", \"g\", \"r\"]\n-    hatch = [\"/\", \"\\\\\", \".\"]\n-    linestyle = [\"-\", \"--\", \":\"]\n-    linewidth = [1, 1.5, 2]\n-    colors = [\"b\", \"g\", \"r\"]\n-    ((axt1, axt2, axt3), (axt4, axt5, axt6)) = fig_test.subplots(2, 3)\n-    ((axr1, axr2, axr3), (axr4, axr5, axr6)) = fig_ref.subplots(2, 3)\n+    (axt1, axt2) = fig_test.subplots(2)\n+    (axr1, axr2) = fig_ref.subplots(2)\n \n-    _, bins, _ = axt1.hist(x, bins=10, histtype=\"stepfilled\", facecolor=facecolor)\n+    for histtype, axt, axr in [(\"stepfilled\", axt1, axr1), (\"step\", axt2, axr2)]:\n+        _, bins, _ = axt.hist(x, bins=10, histtype=histtype, **kwargs)\n \n-    for i, (xi, fc) in enumerate(zip(x, facecolor)):\n-        axr1.hist(xi, bins=bins, histtype=\"stepfilled\", facecolor=fc,\n-                  zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt2.hist(x, bins=10, histtype=\"step\", edgecolor=edgecolor)\n-\n-    for i, (xi, ec) in enumerate(zip(x, edgecolor)):\n-        axr2.hist(xi, bins=bins, histtype=\"step\", edgecolor=ec, zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt3.hist(x, bins=10, histtype=\"stepfilled\", hatch=hatch,\n-                            facecolor=facecolor)\n-\n-    for i, (xi, fc, ht) in enumerate(zip(x, facecolor, hatch)):\n-        axr3.hist(xi, bins=bins, histtype=\"stepfilled\", hatch=ht, facecolor=fc,\n-                  zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt4.hist(x, bins=10, histtype=\"step\", linestyle=linestyle,\n-                           edgecolor=edgecolor)\n-\n-    for i, (xi, ec, ls) in enumerate(zip(x, edgecolor, linestyle)):\n-        axr4.hist(xi, bins=bins, histtype=\"step\", linestyle=ls, edgecolor=ec,\n-                  zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt5.hist(x, bins=10, histtype=\"step\", linewidth=linewidth,\n-                           edgecolor=edgecolor)\n-\n-    for i, (xi, ec, lw) in enumerate(zip(x, edgecolor, linewidth)):\n-        axr5.hist(xi, bins=bins, histtype=\"step\", linewidth=lw, edgecolor=ec,\n-                  zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt6.hist(x, bins=10, histtype=\"stepfilled\", color=colors)\n-\n-    for i, (xi, c) in enumerate(zip(x, colors)):\n-        axr6.hist(xi, bins=bins, histtype=\"stepfilled\", color=c, zorder=(len(x)-i)/2)\n+        kw, values = next(iter(kwargs.items()))\n+        for i, (xi, value) in enumerate(zip(x, values)):\n+            axr.hist(xi, bins=bins, histtype=histtype, **{kw: value},\n+                     zorder=(len(x)-i)/2)\n+\n+\n+@pytest.mark.parametrize('kwargs, patch_face, patch_edge',\n+                         [({'histtype': 'stepfilled', 'color': 'r',\n+                            'facecolor': 'y', 'edgecolor': 'g'}, 'y', 'g'),\n+                          ({'histtype': 'step', 'color': 'r',\n+                            'facecolor': 'y', 'edgecolor': 'g'}, 'none', 'g'),\n+                          ({'histtype': 'stepfilled', 'color': 'r',\n+                            'edgecolor': 'g'}, 'r', 'g'),\n+                          ({'histtype': 'step', 'color': 'r',\n+                            'edgecolor': 'g'}, 'none', 'g'),\n+                          ({'histtype': 'stepfilled', 'color': 'r',\n+                            'facecolor': 'y'}, 'y', 'k'),\n+                          ({'histtype': 'step', 'color': 'r',\n+                            'facecolor': 'y'}, 'none', 'r'),\n+                          ({'histtype': 'stepfilled',\n+                            'facecolor': 'y', 'edgecolor': 'g'}, 'y', 'g'),\n+                          ({'histtype': 'step', 'facecolor': 'y',\n+                            'edgecolor': 'g'}, 'none', 'g'),\n+                          ({'histtype': 'stepfilled', 'color': 'r'}, 'r', 'k'),\n+                          ({'histtype': 'step', 'color': 'r'}, 'none', 'r'),\n+                          ({'histtype': 'stepfilled', 'facecolor': 'y'}, 'y', 'k'),\n+                          ({'histtype': 'step', 'facecolor': 'y'}, 'none', 'b'),\n+                          ({'histtype': 'stepfilled', 'edgecolor': 'g'}, 'b', 'g'),\n+                          ({'histtype': 'step', 'edgecolor': 'g'}, 'none', 'g'),\n+                          ({'histtype': 'stepfilled'}, 'b', 'k'),\n+                          ({'histtype': 'step'}, 'none', 'b')])\n+def test_hist_color_semantics(kwargs, patch_face, patch_edge):\n+    _, _, patches = plt.figure().subplots().hist([1, 2, 3], **kwargs)\n+    # When the expected edgecolor is blue, it corresponds to the\n+    # first color of the default color cycle\n+    # When the expected edgecolor is black, it corresponds to the\n+    # patch.edgecolor rcParam\n+    # When the expected facecolor is blue, it corresponds to the\n+    # patch.facecolor rcParam or the first color of the color cycle\n+    assert all(mcolors.same_color(p.get_facecolor(), patch_face)\n+               if patch_face != 'none' else p.get_facecolor()[3] == 0\n+               for p in patches)", "ext_attention_idx_tokens": [0, 108], "uid": "a1f20726", "question": "Also this has me wondering what's going on when we set \"none\" and if that's related to #28475", "code": "def test hist color semantics kwargs patch face patch edge patches plt figure subplots hist [1 2 3] **kwargs # When the expected edgecolor is blue it corresponds to the # first color of the default color cycle # When the expected edgecolor is black it corresponds to the # patch edgecolor rcParam # When the expected facecolor is blue it corresponds to the # patch facecolor rcParam or the first color of the color cycle assert all mcolors same color p get facecolor patch face if patch face ! none else p get facecolor [3] 0 for p in patches assert all mcolors same color p get edgecolor patch edge if patch edge ! none else p get edgecolor [3] 0 for p in patches"}
{"message": "> but it seemed like it would complicate things\n\nWhy? ", "timestamp": "2024-06-27T04:19:25Z", "file_name": "lib/matplotlib/tests/test_axes.py", "range": {"start_line": 4664, "end_line": 4664, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1656386816", "html_url": "https://github.com/matplotlib/matplotlib/pull/28073#discussion_r1656386816", "attention_area": "               for p in patches)", "file_path": "files/89/05/00000589.py", "old_file_path": "files/83/05/00000583.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -4603,56 +4603,68 @@ def test_hist_stacked_bar():\n     ax.legend(loc='upper right', bbox_to_anchor=(1.0, 1.0), ncols=1)\n \n \n+@pytest.mark.parametrize('kwargs', ({'facecolor': [\"b\", \"g\", \"r\"]},\n+                                    {'edgecolor': [\"b\", \"g\", \"r\"]},\n+                                    {'hatch': [\"/\", \"\\\\\", \".\"]},\n+                                    {'linestyle': [\"-\", \"--\", \":\"]},\n+                                    {'linewidth': [1, 1.5, 2]},\n+                                    {'color': [\"b\", \"g\", \"r\"]}))\n @check_figures_equal(extensions=[\"png\"])\n-def test_hist_vectorized_params(fig_test, fig_ref):\n+def test_hist_vectorized_params(fig_test, fig_ref, kwargs):\n     np.random.seed(19680801)\n     x = [np.random.randn(n) for n in [2000, 5000, 10000]]\n \n-    facecolor = [\"b\", \"g\", \"r\"]\n-    edgecolor = [\"b\", \"g\", \"r\"]\n-    hatch = [\"/\", \"\\\\\", \".\"]\n-    linestyle = [\"-\", \"--\", \":\"]\n-    linewidth = [1, 1.5, 2]\n-    colors = [\"b\", \"g\", \"r\"]\n-    ((axt1, axt2, axt3), (axt4, axt5, axt6)) = fig_test.subplots(2, 3)\n-    ((axr1, axr2, axr3), (axr4, axr5, axr6)) = fig_ref.subplots(2, 3)\n-\n-    _, bins, _ = axt1.hist(x, bins=10, histtype=\"stepfilled\", facecolor=facecolor)\n-\n-    for i, (xi, fc) in enumerate(zip(x, facecolor)):\n-        axr1.hist(xi, bins=bins, histtype=\"stepfilled\", facecolor=fc,\n-                  zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt2.hist(x, bins=10, histtype=\"step\", edgecolor=edgecolor)\n-\n-    for i, (xi, ec) in enumerate(zip(x, edgecolor)):\n-        axr2.hist(xi, bins=bins, histtype=\"step\", edgecolor=ec, zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt3.hist(x, bins=10, histtype=\"stepfilled\", hatch=hatch,\n-                            facecolor=facecolor)\n-\n-    for i, (xi, fc, ht) in enumerate(zip(x, facecolor, hatch)):\n-        axr3.hist(xi, bins=bins, histtype=\"stepfilled\", hatch=ht, facecolor=fc,\n-                  zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt4.hist(x, bins=10, histtype=\"step\", linestyle=linestyle,\n-                           edgecolor=edgecolor)\n-\n-    for i, (xi, ec, ls) in enumerate(zip(x, edgecolor, linestyle)):\n-        axr4.hist(xi, bins=bins, histtype=\"step\", linestyle=ls, edgecolor=ec,\n-                  zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt5.hist(x, bins=10, histtype=\"step\", linewidth=linewidth,\n-                           edgecolor=edgecolor)\n-\n-    for i, (xi, ec, lw) in enumerate(zip(x, edgecolor, linewidth)):\n-        axr5.hist(xi, bins=bins, histtype=\"step\", linewidth=lw, edgecolor=ec,\n-                  zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt6.hist(x, bins=10, histtype=\"stepfilled\", color=colors)\n-\n-    for i, (xi, c) in enumerate(zip(x, colors)):\n-        axr6.hist(xi, bins=bins, histtype=\"stepfilled\", color=c, zorder=(len(x)-i)/2)\n+    (axt1, axt2) = fig_test.subplots(2)\n+    (axr1, axr2) = fig_ref.subplots(2)\n+\n+    for histtype, axt, axr in [(\"stepfilled\", axt1, axr1), (\"step\", axt2, axr2)]:\n+        _, bins, _ = axt.hist(x, bins=10, histtype=histtype, **kwargs)\n+\n+        kw, values = next(iter(kwargs.items()))\n+        for i, (xi, value) in enumerate(zip(x, values)):\n+            axr.hist(xi, bins=bins, histtype=histtype, **{kw: value},\n+                     zorder=(len(x)-i)/2)\n+\n+\n+@pytest.mark.parametrize('kwargs, patch_face, patch_edge',\n+                         [({'histtype': 'stepfilled', 'color': 'r',\n+                            'facecolor': 'y', 'edgecolor': 'g'}, 'y', 'g'),\n+                          ({'histtype': 'step', 'color': 'r',\n+                            'facecolor': 'y', 'edgecolor': 'g'}, 'none', 'g'),\n+                          ({'histtype': 'stepfilled', 'color': 'r',\n+                            'edgecolor': 'g'}, 'r', 'g'),\n+                          ({'histtype': 'step', 'color': 'r',\n+                            'edgecolor': 'g'}, 'none', 'g'),\n+                          ({'histtype': 'stepfilled', 'color': 'r',\n+                            'facecolor': 'y'}, 'y', 'k'),\n+                          ({'histtype': 'step', 'color': 'r',\n+                            'facecolor': 'y'}, 'none', 'r'),\n+                          ({'histtype': 'stepfilled',\n+                            'facecolor': 'y', 'edgecolor': 'g'}, 'y', 'g'),\n+                          ({'histtype': 'step', 'facecolor': 'y',\n+                            'edgecolor': 'g'}, 'none', 'g'),\n+                          ({'histtype': 'stepfilled', 'color': 'r'}, 'r', 'k'),\n+                          ({'histtype': 'step', 'color': 'r'}, 'none', 'r'),\n+                          ({'histtype': 'stepfilled', 'facecolor': 'y'}, 'y', 'k'),\n+                          ({'histtype': 'step', 'facecolor': 'y'}, 'none', 'b'),\n+                          ({'histtype': 'stepfilled', 'edgecolor': 'g'}, 'b', 'g'),\n+                          ({'histtype': 'step', 'edgecolor': 'g'}, 'none', 'g'),\n+                          ({'histtype': 'stepfilled'}, 'b', 'k'),\n+                          ({'histtype': 'step'}, 'none', 'b')])\n+def test_hist_color_semantics(kwargs, patch_face, patch_edge):\n+    _, _, patches = plt.figure().subplots().hist([1, 2, 3], **kwargs)\n+    # When the expected edgecolor is blue, it corresponds to the\n+    # first color of the default color cycle\n+    # When the expected edgecolor is black, it corresponds to the\n+    # patch.edgecolor rcParam\n+    # When the expected facecolor is blue, it corresponds to the\n+    # patch.facecolor rcParam or the first color of the color cycle\n+    assert all(mcolors.same_color(p.get_facecolor(), patch_face)\n+               if patch_face != 'none' else p.get_facecolor()[3] == 0\n+               for p in patches)", "source": "def test_hist_color_semantics(kwargs, patch_face, patch_edge):\n    _, _, patches = plt.figure().subplots().hist([1, 2, 3], **kwargs)\n    # When the expected edgecolor is blue, it corresponds to the\n    # first color of the default color cycle\n    # When the expected edgecolor is black, it corresponds to the\n    # patch.edgecolor rcParam\n    # When the expected facecolor is blue, it corresponds to the\n    # patch.facecolor rcParam or the first color of the color cycle\n    assert all(mcolors.same_color(p.get_facecolor(), patch_face)\n               if patch_face != 'none' else p.get_facecolor()[3] == 0\n               for p in patches)\n    assert all(mcolors.same_color(p.get_edgecolor(), patch_edge)\n               if patch_edge != 'none' else p.get_edgecolor()[3] == 0\n               for p in patches)", "source_start_line": 4654, "tokens": ["def", "test_hist_color_semantics", "(", "kwargs", ",", "patch_face", ",", "patch_edge", ")", ":", "_", ",", "_", ",", "patches", "=", "plt", ".", "figure", "(", ")", ".", "subplots", "(", ")", ".", "hist", "(", "[", "1", ",", "2", ",", "3", "]", ",", "**", "kwargs", ")", "assert", "all", "(", "mcolors", ".", "same_color", "(", "p", ".", "get_facecolor", "(", ")", ",", "patch_face", ")", "if", "patch_face", "!=", "'none'", "else", "p", ".", "get_facecolor", "(", ")", "[", "3", "]", "==", "0", "for", "p", "in", "patches", ")", "assert", "all", "(", "mcolors", ".", "same_color", "(", "p", ".", "get_edgecolor", "(", ")", ",", "patch_edge", ")", "if", "patch_edge", "!=", "'none'", "else", "p", ".", "get_edgecolor", "(", ")", "[", "3", "]", "==", "0", "for", "p", "in", "patches", ")"], "to_mask": {"VAR": ["_", "kwargs", "patch_edge", "patch_face", "patches"], "METHOD": ["all", "figure", "get_edgecolor", "get_facecolor", "hist", "same_color", "subplots"]}, "attention_idx_tokens": [69, 73], "patch": "@@ -4603,56 +4603,68 @@\n     ax.legend(loc='upper right', bbox_to_anchor=(1.0, 1.0), ncols=1)\n \n \n+@pytest.mark.parametrize('kwargs', ({'facecolor': [\"b\", \"g\", \"r\"]},\n+                                    {'edgecolor': [\"b\", \"g\", \"r\"]},\n+                                    {'hatch': [\"/\", \"\\\\\", \".\"]},\n+                                    {'linestyle': [\"-\", \"--\", \":\"]},\n+                                    {'linewidth': [1, 1.5, 2]},\n+                                    {'color': [\"b\", \"g\", \"r\"]}))\n @check_figures_equal(extensions=[\"png\"])\n-def test_hist_vectorized_params(fig_test, fig_ref):\n+def test_hist_vectorized_params(fig_test, fig_ref, kwargs):\n     np.random.seed(19680801)\n     x = [np.random.randn(n) for n in [2000, 5000, 10000]]\n \n-    facecolor = [\"b\", \"g\", \"r\"]\n-    edgecolor = [\"b\", \"g\", \"r\"]\n-    hatch = [\"/\", \"\\\\\", \".\"]\n-    linestyle = [\"-\", \"--\", \":\"]\n-    linewidth = [1, 1.5, 2]\n-    colors = [\"b\", \"g\", \"r\"]\n-    ((axt1, axt2, axt3), (axt4, axt5, axt6)) = fig_test.subplots(2, 3)\n-    ((axr1, axr2, axr3), (axr4, axr5, axr6)) = fig_ref.subplots(2, 3)\n+    (axt1, axt2) = fig_test.subplots(2)\n+    (axr1, axr2) = fig_ref.subplots(2)\n \n-    _, bins, _ = axt1.hist(x, bins=10, histtype=\"stepfilled\", facecolor=facecolor)\n+    for histtype, axt, axr in [(\"stepfilled\", axt1, axr1), (\"step\", axt2, axr2)]:\n+        _, bins, _ = axt.hist(x, bins=10, histtype=histtype, **kwargs)\n \n-    for i, (xi, fc) in enumerate(zip(x, facecolor)):\n-        axr1.hist(xi, bins=bins, histtype=\"stepfilled\", facecolor=fc,\n-                  zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt2.hist(x, bins=10, histtype=\"step\", edgecolor=edgecolor)\n-\n-    for i, (xi, ec) in enumerate(zip(x, edgecolor)):\n-        axr2.hist(xi, bins=bins, histtype=\"step\", edgecolor=ec, zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt3.hist(x, bins=10, histtype=\"stepfilled\", hatch=hatch,\n-                            facecolor=facecolor)\n-\n-    for i, (xi, fc, ht) in enumerate(zip(x, facecolor, hatch)):\n-        axr3.hist(xi, bins=bins, histtype=\"stepfilled\", hatch=ht, facecolor=fc,\n-                  zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt4.hist(x, bins=10, histtype=\"step\", linestyle=linestyle,\n-                           edgecolor=edgecolor)\n-\n-    for i, (xi, ec, ls) in enumerate(zip(x, edgecolor, linestyle)):\n-        axr4.hist(xi, bins=bins, histtype=\"step\", linestyle=ls, edgecolor=ec,\n-                  zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt5.hist(x, bins=10, histtype=\"step\", linewidth=linewidth,\n-                           edgecolor=edgecolor)\n-\n-    for i, (xi, ec, lw) in enumerate(zip(x, edgecolor, linewidth)):\n-        axr5.hist(xi, bins=bins, histtype=\"step\", linewidth=lw, edgecolor=ec,\n-                  zorder=(len(x)-i)/2)\n-\n-    _, bins, _ = axt6.hist(x, bins=10, histtype=\"stepfilled\", color=colors)\n-\n-    for i, (xi, c) in enumerate(zip(x, colors)):\n-        axr6.hist(xi, bins=bins, histtype=\"stepfilled\", color=c, zorder=(len(x)-i)/2)\n+        kw, values = next(iter(kwargs.items()))\n+        for i, (xi, value) in enumerate(zip(x, values)):\n+            axr.hist(xi, bins=bins, histtype=histtype, **{kw: value},\n+                     zorder=(len(x)-i)/2)\n+\n+\n+@pytest.mark.parametrize('kwargs, patch_face, patch_edge',\n+                         [({'histtype': 'stepfilled', 'color': 'r',\n+                            'facecolor': 'y', 'edgecolor': 'g'}, 'y', 'g'),\n+                          ({'histtype': 'step', 'color': 'r',\n+                            'facecolor': 'y', 'edgecolor': 'g'}, 'none', 'g'),\n+                          ({'histtype': 'stepfilled', 'color': 'r',\n+                            'edgecolor': 'g'}, 'r', 'g'),\n+                          ({'histtype': 'step', 'color': 'r',\n+                            'edgecolor': 'g'}, 'none', 'g'),\n+                          ({'histtype': 'stepfilled', 'color': 'r',\n+                            'facecolor': 'y'}, 'y', 'k'),\n+                          ({'histtype': 'step', 'color': 'r',\n+                            'facecolor': 'y'}, 'none', 'r'),\n+                          ({'histtype': 'stepfilled',\n+                            'facecolor': 'y', 'edgecolor': 'g'}, 'y', 'g'),\n+                          ({'histtype': 'step', 'facecolor': 'y',\n+                            'edgecolor': 'g'}, 'none', 'g'),\n+                          ({'histtype': 'stepfilled', 'color': 'r'}, 'r', 'k'),\n+                          ({'histtype': 'step', 'color': 'r'}, 'none', 'r'),\n+                          ({'histtype': 'stepfilled', 'facecolor': 'y'}, 'y', 'k'),\n+                          ({'histtype': 'step', 'facecolor': 'y'}, 'none', 'b'),\n+                          ({'histtype': 'stepfilled', 'edgecolor': 'g'}, 'b', 'g'),\n+                          ({'histtype': 'step', 'edgecolor': 'g'}, 'none', 'g'),\n+                          ({'histtype': 'stepfilled'}, 'b', 'k'),\n+                          ({'histtype': 'step'}, 'none', 'b')])\n+def test_hist_color_semantics(kwargs, patch_face, patch_edge):\n+    _, _, patches = plt.figure().subplots().hist([1, 2, 3], **kwargs)\n+    # When the expected edgecolor is blue, it corresponds to the\n+    # first color of the default color cycle\n+    # When the expected edgecolor is black, it corresponds to the\n+    # patch.edgecolor rcParam\n+    # When the expected facecolor is blue, it corresponds to the\n+    # patch.facecolor rcParam or the first color of the color cycle\n+    assert all(mcolors.same_color(p.get_facecolor(), patch_face)\n+               if patch_face != 'none' else p.get_facecolor()[3] == 0\n+               for p in patches)", "ext_attention_idx_tokens": [0, 108], "uid": "77585372", "question": "> but it seemed like it would complicate things  Why? ", "code": "def test hist color semantics kwargs patch face patch edge patches plt figure subplots hist [1 2 3] **kwargs # When the expected edgecolor is blue it corresponds to the # first color of the default color cycle # When the expected edgecolor is black it corresponds to the # patch edgecolor rcParam # When the expected facecolor is blue it corresponds to the # patch facecolor rcParam or the first color of the color cycle assert all mcolors same color p get facecolor patch face if patch face ! none else p get facecolor [3] 0 for p in patches assert all mcolors same color p get edgecolor patch edge if patch edge ! none else p get edgecolor [3] 0 for p in patches"}
{"message": "Was this change supposed to be included?", "timestamp": "2024-07-18T16:58:16Z", "file_name": "lib/matplotlib/font_manager.py", "range": {"start_line": 269, "end_line": 269, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1683203330", "html_url": "https://github.com/matplotlib/matplotlib/pull/28504#discussion_r1683203330", "attention_area": "    try:", "file_path": "files/85/06/00000685.py", "old_file_path": "files/87/06/00000687.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -266,8 +266,11 @@ def _get_fontconfig_fonts():\n @lru_cache\n def _get_macos_fonts():\n     \"\"\"Cache and list the font paths known to ``system_profiler SPFontsDataType``.\"\"\"\n-    d, = plistlib.loads(\n-        subprocess.check_output([\"system_profiler\", \"-xml\", \"SPFontsDataType\"]))\n+    try:", "source": "def _get_macos_fonts():\n    \"\"\"Cache and list the font paths known to ``system_profiler SPFontsDataType``.\"\"\"\n    try:\n        d, = plistlib.loads(\n            subprocess.check_output([\"system_profiler\", \"-xml\", \"SPFontsDataType\"]))\n    except (OSError, subprocess.CalledProcessError, plistlib.InvalidFileException):\n        return []\n    return [Path(entry[\"path\"]) for entry in d[\"_items\"]]", "source_start_line": 267, "tokens": ["def", "_get_macos_fonts", "(", ")", ":", "\"\"\"Cache and list the font paths known to ``system_profiler SPFontsDataType``.\"\"\"", "try", ":", "d", ",", "=", "plistlib", ".", "loads", "(", "subprocess", ".", "check_output", "(", "[", "\"system_profiler\"", ",", "\"-xml\"", ",", "\"SPFontsDataType\"", "]", ")", ")", "except", "(", "OSError", ",", "subprocess", ".", "CalledProcessError", ",", "plistlib", ".", "InvalidFileException", ")", ":", "return", "[", "]", "return", "[", "Path", "(", "entry", "[", "\"path\"", "]", ")", "for", "entry", "in", "d", "[", "\"_items\"", "]", "]"], "to_mask": {"VAR": ["d"], "METHOD": ["Path", "check_output", "loads"]}, "attention_idx_tokens": [6, 7], "patch": "@@ -266,8 +266,11 @@\n @lru_cache\n def _get_macos_fonts():\n     \"\"\"Cache and list the font paths known to ``system_profiler SPFontsDataType``.\"\"\"\n-    d, = plistlib.loads(\n-        subprocess.check_output([\"system_profiler\", \"-xml\", \"SPFontsDataType\"]))\n+    try:", "ext_attention_idx_tokens": [6, 60], "uid": "986217b5", "question": "Was this change supposed to be included?", "code": "def get macos fonts \"\"\"Cache and list the font paths known to ``system profiler SPFontsDataType`` \"\"\" try d plistlib loads subprocess check output [\"system profiler\" \"-xml\" \"SPFontsDataType\"] except OSError subprocess CalledProcessError plistlib InvalidFileException return [] return [Path entry[\"path\"] for entry in d[\" items\"]]"}
{"message": "> Should we also see how `simplify=True` interacts with `remove_nans=True`? (see test above this)\r\n\r\nI am not sure what you meant by this. It would be helpful if you could elaborate a bit more.\r\n\r\n> Is there any issue if the first MOVETO is `(nan, nan)` and then we insert it here?\r\n\r\nHaving the first MOVETO as `(nan, nan)` causes it to never initialize the initial vertex, and it ends up closing the polygon to (0, 0) which is wrong.\r\n\r\nI think that in order to fix this, it could have a `m_has_init` so that when a CLOSEPOLY is encountered, it will be able to verify that the path has a finite initial point.\r\n```\r\n@@ -757,8 +759,15 @@ class PathSimplifier : protected EmbeddedQueue<9>\r\n                     _push(x, y);\r\n                 }\r\n                 m_after_moveto = true;\r\n-                m_last_startx = *x;\r\n-                m_last_starty = *y;\r\n+\r\n+                if (std::isfinite(*x) && std::isfinite(*y)) {\r\n+                    m_has_init = true;\r\n+                    m_initX = *x;\r\n+                    m_initY = *y;\r\n+                } else {\r\n+                    m_has_init = false;\r\n+                }\r\n+\r\n                 m_lastx = *x;\r\n                 m_lasty = *y;\r\n                 m_moveto = false;\r\n```\r\n```\r\n@@ -773,11 +780,11 @@ class PathSimplifier : protected EmbeddedQueue<9>\r\n             }\r\n             m_after_moveto = false;\r\n \r\n-            if(agg::is_close(cmd)) {\r\n+            if(agg::is_close(cmd) && m_has_init) {\r\n                 /* If we have to close the polygon, replace\r\n                    the vertex with the starting vertex */\r\n-                *x = m_last_startx;\r\n-                *y = m_last_starty;\r\n+                *x = m_initX;\r\n+                *y = m_initY;\r\n             }\r\n```\r\n\r\nRefactoring `m_last_startx` to `m_initX` might be better, as that seems to be the variable name in other path converters (such as `NanRemover`)", "timestamp": "2024-07-21T07:46:25Z", "file_name": "lib/matplotlib/tests/test_path.py", "range": {"start_line": 549, "end_line": 549, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1685672658", "html_url": "https://github.com/matplotlib/matplotlib/pull/28478#discussion_r1685672658", "attention_area": "    path_ref = Path([(0, 0), (1, 0), (1, 1), (40, 50)],", "file_path": "files/33/07/00000733.py", "old_file_path": "files/34/07/00000734.py", "filters": {"comment_message": false, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -541,3 +541,18 @@ def test_cleanup_closepoly():\n         cleaned = p.cleaned(remove_nans=True)\n         assert len(cleaned) == 1\n         assert cleaned.codes[0] == Path.STOP\n+\n+\n+def test_simplify_closepoly():\n+    # The values of the vertices in a CLOSEPOLY should always be ignored,\n+    # in favor of the most recent MOVETO's vertex values\n+    path_ref = Path([(0, 0), (1, 0), (1, 1), (40, 50)],", "source": "def test_simplify_closepoly():\n    # The values of the vertices in a CLOSEPOLY should always be ignored,\n    # in favor of the most recent MOVETO's vertex values\n    path_ref = Path([(0, 0), (1, 0), (1, 1), (40, 50)],\n                    [Path.MOVETO, Path.LINETO, Path.LINETO, Path.CLOSEPOLY])\n    path_test = Path([(0, 0), (1, 0), (1, 1), (np.nan, np.nan)],\n                     [Path.MOVETO, Path.LINETO, Path.LINETO, Path.CLOSEPOLY])\n\n    path_ref_simplified = path_ref.cleaned(simplify=True)\n    path_test_simplified = path_test.cleaned(simplify=True)\n\n    assert_array_equal(path_ref_simplified.vertices, path_test_simplified.vertices)\n    assert_array_equal(path_ref_simplified.codes, path_test_simplified.codes)", "source_start_line": 546, "tokens": ["def", "test_simplify_closepoly", "(", ")", ":", "path_ref", "=", "Path", "(", "[", "(", "0", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "1", ",", "1", ")", ",", "(", "40", ",", "50", ")", "]", ",", "[", "Path", ".", "MOVETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "CLOSEPOLY", "]", ")", "path_test", "=", "Path", "(", "[", "(", "0", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "1", ",", "1", ")", ",", "(", "np", ".", "nan", ",", "np", ".", "nan", ")", "]", ",", "[", "Path", ".", "MOVETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "CLOSEPOLY", "]", ")", "path_ref_simplified", "=", "path_ref", ".", "cleaned", "(", "simplify", "=", "True", ")", "path_test_simplified", "=", "path_test", ".", "cleaned", "(", "simplify", "=", "True", ")", "assert_array_equal", "(", "path_ref_simplified", ".", "vertices", ",", "path_test_simplified", ".", "vertices", ")", "assert_array_equal", "(", "path_ref_simplified", ".", "codes", ",", "path_test_simplified", ".", "codes", ")"], "to_mask": {"VAR": ["path_ref", "path_ref_simplified", "path_test", "path_test_simplified"], "METHOD": ["Path", "assert_array_equal", "cleaned"]}, "attention_idx_tokens": [5, 34], "patch": "@@ -541,3 +541,18 @@\n         cleaned = p.cleaned(remove_nans=True)\n         assert len(cleaned) == 1\n         assert cleaned.codes[0] == Path.STOP\n+\n+\n+def test_simplify_closepoly():\n+    # The values of the vertices in a CLOSEPOLY should always be ignored,\n+    # in favor of the most recent MOVETO's vertex values\n+    path_ref = Path([(0, 0), (1, 0), (1, 1), (40, 50)],", "ext_attention_idx_tokens": [0, 124], "uid": "4d212218", "question": "> Should we also see how `simplify=True` interacts with `remove_nans=True`? (see test above this)    I am not sure what you meant by this. It would be helpful if you could elaborate a bit more.    > Is there any issue if the first MOVETO is `(nan, nan)` and then we insert it here?    Having the first MOVETO as `(nan, nan)` causes it to never initialize the initial vertex, and it ends up closing the polygon to (0, 0) which is wrong.    I think that in order to fix this, it could have a `m_has_init` so that when a CLOSEPOLY is encountered, it will be able to verify that the path has a finite initial point.  ```  @@ -757,8 +759,15 @@ class PathSimplifier : protected EmbeddedQueue<9>                       _push(x, y);                   }                   m_after_moveto = true;  -                m_last_startx = *x;  -                m_last_starty = *y;  +  +                if (std::isfinite(*x) && std::isfinite(*y)) {  +                    m_has_init = true;  +                    m_initX = *x;  +                    m_initY = *y;  +                } else {  +                    m_has_init = false;  +                }  +                   m_lastx = *x;                   m_lasty = *y;                   m_moveto = false;  ```  ```  @@ -773,11 +780,11 @@ class PathSimplifier : protected EmbeddedQueue<9>               }               m_after_moveto = false;     -            if(agg::is_close(cmd)) {  +            if(agg::is_close(cmd) && m_has_init) {                   /* If we have to close the polygon, replace                      the vertex with the starting vertex */  -                *x = m_last_startx;  -                *y = m_last_starty;  +                *x = m_initX;  +                *y = m_initY;               }  ```    Refactoring `m_last_startx` to `m_initX` might be better, as that seems to be the variable name in other path converters (such as `NanRemover`)", "code": "def test simplify closepoly # The values of the vertices in a CLOSEPOLY should always be ignored # in favor of the most recent MOVETO s vertex values path ref Path [ 0 0 1 0 1 1 40 50 ] [Path MOVETO Path LINETO Path LINETO Path CLOSEPOLY] path test Path [ 0 0 1 0 1 1 np nan np nan ] [Path MOVETO Path LINETO Path LINETO Path CLOSEPOLY] path ref simplified path ref cleaned simplify True path test simplified path test cleaned simplify True assert array equal path ref simplified vertices path test simplified vertices assert array equal path ref simplified codes path test simplified codes"}
{"message": "> However, what about the failing pytests in path_simplification.py\r\nas mentioned in https://github.com/matplotlib/matplotlib/pull/28478#issuecomment-2241522679. Should I also modify them so as to fix the off by one errors?\r\n\r\nI forgot about needing to update those as well. Maybe it is best to just leave the assertion with the extra expected LINETO for now and then update all the off-by-one issues in a follow-up PR.", "timestamp": "2024-07-22T21:14:16Z", "file_name": "lib/matplotlib/tests/test_path.py", "range": {"start_line": 568, "end_line": 568, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1687149427", "html_url": "https://github.com/matplotlib/matplotlib/pull/28478#discussion_r1687149427", "attention_area": "                          (-1, 0), (-2, 0), (-2, 1), (-1, 0), (-1, 0), (0, 0)],", "file_path": "files/37/07/00000737.py", "old_file_path": "files/34/07/00000734.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -541,3 +541,35 @@ def test_cleanup_closepoly():\n         cleaned = p.cleaned(remove_nans=True)\n         assert len(cleaned) == 1\n         assert cleaned.codes[0] == Path.STOP\n+\n+\n+def test_simplify_closepoly():\n+    # The values of the vertices in a CLOSEPOLY should always be ignored,\n+    # in favor of the most recent MOVETO's vertex values\n+    paths = [Path([(1, 1), (2, 1), (2, 2), (np.nan, np.nan)],\n+                  [Path.MOVETO, Path.LINETO, Path.LINETO, Path.CLOSEPOLY]),\n+             Path([(1, 1), (2, 1), (2, 2), (40, 50)],\n+                  [Path.MOVETO, Path.LINETO, Path.LINETO, Path.CLOSEPOLY])]\n+    expected_path = Path([(1, 1), (2, 1), (2, 2), (1, 1), (1, 1), (0, 0)],\n+                         [Path.MOVETO, Path.LINETO, Path.LINETO, Path.LINETO,\n+                          Path.LINETO, Path.STOP])\n+\n+    for path in paths:\n+        simplified_path = path.cleaned(simplify=True)\n+        assert_array_equal(expected_path.vertices, simplified_path.vertices)\n+        assert_array_equal(expected_path.codes, simplified_path.codes)\n+\n+    # test that a compound path also works\n+    path = Path([(1, 1), (2, 1), (2, 2), (np.nan, np.nan),\n+                 (-1, 0), (-2, 0), (-2, 1), (np.nan, np.nan)],\n+                [Path.MOVETO, Path.LINETO, Path.LINETO, Path.CLOSEPOLY,\n+                 Path.MOVETO, Path.LINETO, Path.LINETO, Path.CLOSEPOLY])\n+    expected_path = Path([(1, 1), (2, 1), (2, 2), (1, 1),\n+                          (-1, 0), (-2, 0), (-2, 1), (-1, 0), (-1, 0), (0, 0)],", "source": "def test_simplify_closepoly():\n    # The values of the vertices in a CLOSEPOLY should always be ignored,\n    # in favor of the most recent MOVETO's vertex values\n    paths = [Path([(1, 1), (2, 1), (2, 2), (np.nan, np.nan)],\n                  [Path.MOVETO, Path.LINETO, Path.LINETO, Path.CLOSEPOLY]),\n             Path([(1, 1), (2, 1), (2, 2), (40, 50)],\n                  [Path.MOVETO, Path.LINETO, Path.LINETO, Path.CLOSEPOLY])]\n    expected_path = Path([(1, 1), (2, 1), (2, 2), (1, 1), (1, 1), (0, 0)],\n                         [Path.MOVETO, Path.LINETO, Path.LINETO, Path.LINETO,\n                          Path.LINETO, Path.STOP])\n\n    for path in paths:\n        simplified_path = path.cleaned(simplify=True)\n        assert_array_equal(expected_path.vertices, simplified_path.vertices)\n        assert_array_equal(expected_path.codes, simplified_path.codes)\n\n    # test that a compound path also works\n    path = Path([(1, 1), (2, 1), (2, 2), (np.nan, np.nan),\n                 (-1, 0), (-2, 0), (-2, 1), (np.nan, np.nan)],\n                [Path.MOVETO, Path.LINETO, Path.LINETO, Path.CLOSEPOLY,\n                 Path.MOVETO, Path.LINETO, Path.LINETO, Path.CLOSEPOLY])\n    expected_path = Path([(1, 1), (2, 1), (2, 2), (1, 1),\n                          (-1, 0), (-2, 0), (-2, 1), (-1, 0), (-1, 0), (0, 0)],\n                         [Path.MOVETO, Path.LINETO, Path.LINETO, Path.LINETO,\n                          Path.MOVETO, Path.LINETO, Path.LINETO, Path.LINETO,\n                          Path.LINETO, Path.STOP])\n\n    simplified_path = path.cleaned(simplify=True)\n    assert_array_equal(expected_path.vertices, simplified_path.vertices)\n    assert_array_equal(expected_path.codes, simplified_path.codes)", "source_start_line": 546, "tokens": ["def", "test_simplify_closepoly", "(", ")", ":", "paths", "=", "[", "Path", "(", "[", "(", "1", ",", "1", ")", ",", "(", "2", ",", "1", ")", ",", "(", "2", ",", "2", ")", ",", "(", "np", ".", "nan", ",", "np", ".", "nan", ")", "]", ",", "[", "Path", ".", "MOVETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "CLOSEPOLY", "]", ")", ",", "Path", "(", "[", "(", "1", ",", "1", ")", ",", "(", "2", ",", "1", ")", ",", "(", "2", ",", "2", ")", ",", "(", "40", ",", "50", ")", "]", ",", "[", "Path", ".", "MOVETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "CLOSEPOLY", "]", ")", "]", "expected_path", "=", "Path", "(", "[", "(", "1", ",", "1", ")", ",", "(", "2", ",", "1", ")", ",", "(", "2", ",", "2", ")", ",", "(", "1", ",", "1", ")", ",", "(", "1", ",", "1", ")", ",", "(", "0", ",", "0", ")", "]", ",", "[", "Path", ".", "MOVETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "STOP", "]", ")", "for", "path", "in", "paths", ":", "simplified_path", "=", "path", ".", "cleaned", "(", "simplify", "=", "True", ")", "assert_array_equal", "(", "expected_path", ".", "vertices", ",", "simplified_path", ".", "vertices", ")", "assert_array_equal", "(", "expected_path", ".", "codes", ",", "simplified_path", ".", "codes", ")", "path", "=", "Path", "(", "[", "(", "1", ",", "1", ")", ",", "(", "2", ",", "1", ")", ",", "(", "2", ",", "2", ")", ",", "(", "np", ".", "nan", ",", "np", ".", "nan", ")", ",", "(", "-", "1", ",", "0", ")", ",", "(", "-", "2", ",", "0", ")", ",", "(", "-", "2", ",", "1", ")", ",", "(", "np", ".", "nan", ",", "np", ".", "nan", ")", "]", ",", "[", "Path", ".", "MOVETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "CLOSEPOLY", ",", "Path", ".", "MOVETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "CLOSEPOLY", "]", ")", "expected_path", "=", "Path", "(", "[", "(", "1", ",", "1", ")", ",", "(", "2", ",", "1", ")", ",", "(", "2", ",", "2", ")", ",", "(", "1", ",", "1", ")", ",", "(", "-", "1", ",", "0", ")", ",", "(", "-", "2", ",", "0", ")", ",", "(", "-", "2", ",", "1", ")", ",", "(", "-", "1", ",", "0", ")", ",", "(", "-", "1", ",", "0", ")", ",", "(", "0", ",", "0", ")", "]", ",", "[", "Path", ".", "MOVETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "MOVETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "LINETO", ",", "Path", ".", "STOP", "]", ")", "simplified_path", "=", "path", ".", "cleaned", "(", "simplify", "=", "True", ")", "assert_array_equal", "(", "expected_path", ".", "vertices", ",", "simplified_path", ".", "vertices", ")", "assert_array_equal", "(", "expected_path", ".", "codes", ",", "simplified_path", ".", "codes", ")"], "to_mask": {"VAR": ["expected_path", "path", "paths", "simplified_path"], "METHOD": ["Path", "assert_array_equal", "cleaned"]}, "attention_idx_tokens": [337, 378], "patch": "@@ -541,3 +541,35 @@\n         cleaned = p.cleaned(remove_nans=True)\n         assert len(cleaned) == 1\n         assert cleaned.codes[0] == Path.STOP\n+\n+\n+def test_simplify_closepoly():\n+    # The values of the vertices in a CLOSEPOLY should always be ignored,\n+    # in favor of the most recent MOVETO's vertex values\n+    paths = [Path([(1, 1), (2, 1), (2, 2), (np.nan, np.nan)],\n+                  [Path.MOVETO, Path.LINETO, Path.LINETO, Path.CLOSEPOLY]),\n+             Path([(1, 1), (2, 1), (2, 2), (40, 50)],\n+                  [Path.MOVETO, Path.LINETO, Path.LINETO, Path.CLOSEPOLY])]\n+    expected_path = Path([(1, 1), (2, 1), (2, 2), (1, 1), (1, 1), (0, 0)],\n+                         [Path.MOVETO, Path.LINETO, Path.LINETO, Path.LINETO,\n+                          Path.LINETO, Path.STOP])\n+\n+    for path in paths:\n+        simplified_path = path.cleaned(simplify=True)\n+        assert_array_equal(expected_path.vertices, simplified_path.vertices)\n+        assert_array_equal(expected_path.codes, simplified_path.codes)\n+\n+    # test that a compound path also works\n+    path = Path([(1, 1), (2, 1), (2, 2), (np.nan, np.nan),\n+                 (-1, 0), (-2, 0), (-2, 1), (np.nan, np.nan)],\n+                [Path.MOVETO, Path.LINETO, Path.LINETO, Path.CLOSEPOLY,\n+                 Path.MOVETO, Path.LINETO, Path.LINETO, Path.CLOSEPOLY])\n+    expected_path = Path([(1, 1), (2, 1), (2, 2), (1, 1),\n+                          (-1, 0), (-2, 0), (-2, 1), (-1, 0), (-1, 0), (0, 0)],", "ext_attention_idx_tokens": [0, 430], "uid": "1e9b4bd4", "question": "> However, what about the failing pytests in path_simplification.py  as mentioned in https://github.com/matplotlib/matplotlib/pull/28478#issuecomment-2241522679. Should I also modify them so as to fix the off by one errors?    I forgot about needing to update those as well. Maybe it is best to just leave the assertion with the extra expected LINETO for now and then update all the off-by-one issues in a follow-up PR.", "code": "def test simplify closepoly # The values of the vertices in a CLOSEPOLY should always be ignored # in favor of the most recent MOVETO s vertex values paths [Path [ 1 1 2 1 2 2 np nan np nan ] [Path MOVETO Path LINETO Path LINETO Path CLOSEPOLY] Path [ 1 1 2 1 2 2 40 50 ] [Path MOVETO Path LINETO Path LINETO Path CLOSEPOLY] ] expected path Path [ 1 1 2 1 2 2 1 1 1 1 0 0 ] [Path MOVETO Path LINETO Path LINETO Path LINETO Path LINETO Path STOP] for path in paths simplified path path cleaned simplify True assert array equal expected path vertices simplified path vertices assert array equal expected path codes simplified path codes # test that a compound path also works path Path [ 1 1 2 1 2 2 np nan np nan -1 0 -2 0 -2 1 np nan np nan ] [Path MOVETO Path LINETO Path LINETO Path CLOSEPOLY Path MOVETO Path LINETO Path LINETO Path CLOSEPOLY] expected path Path [ 1 1 2 1 2 2 1 1 -1 0 -2 0 -2 1 -1 0 -1 0 0 0 ] [Path MOVETO Path LINETO Path LINETO Path LINETO Path MOVETO Path LINETO Path LINETO Path LINETO Path LINETO Path STOP] simplified path path cleaned simplify True assert array equal expected path vertices simplified path vertices assert array equal expected path codes simplified path codes"}
{"message": "This seems unrelated?", "timestamp": "2024-07-31T19:31:04Z", "file_name": "lib/matplotlib/collections.py", "range": {"start_line": 342, "end_line": 342, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1699006332", "html_url": "https://github.com/matplotlib/matplotlib/pull/27349#discussion_r1699006332", "attention_area": "        if np.ma.isMaskedArray(offsets):", "file_path": "files/25/08/00000825.py", "old_file_path": "files/26/08/00000826.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -339,7 +339,7 @@ def _prepare_points(self):\n             # This might have changed an ndarray into a masked array.\n             offset_trf = offset_trf.get_affine()\n \n-        if isinstance(offsets, np.ma.MaskedArray):\n+        if np.ma.isMaskedArray(offsets):", "source": "def _prepare_points(self):\n        # Helper for drawing and hit testing.\n\n        transform = self.get_transform()\n        offset_trf = self.get_offset_transform()\n        offsets = self.get_offsets()\n        paths = self.get_paths()\n\n        if self.have_units():\n            paths = []\n            for path in self.get_paths():\n                vertices = path.vertices\n                xs, ys = vertices[:, 0], vertices[:, 1]\n                xs = self.convert_xunits(xs)\n                ys = self.convert_yunits(ys)\n                paths.append(mpath.Path(np.column_stack([xs, ys]), path.codes))\n            xs = self.convert_xunits(offsets[:, 0])\n            ys = self.convert_yunits(offsets[:, 1])\n            offsets = np.ma.column_stack([xs, ys])\n\n        if not transform.is_affine:\n            paths = [transform.transform_path_non_affine(path)\n                     for path in paths]\n            transform = transform.get_affine()\n        if not offset_trf.is_affine:\n            offsets = offset_trf.transform_non_affine(offsets)\n            # This might have changed an ndarray into a masked array.\n            offset_trf = offset_trf.get_affine()\n\n        if np.ma.isMaskedArray(offsets):\n            offsets = offsets.filled(np.nan)\n            # Changing from a masked array to nan-filled ndarray\n            # is probably most efficient at this point.\n\n        return transform, offset_trf, offsets, paths", "source_start_line": 313, "tokens": ["def", "_prepare_points", "(", "self", ")", ":", "transform", "=", "self", ".", "get_transform", "(", ")", "offset_trf", "=", "self", ".", "get_offset_transform", "(", ")", "offsets", "=", "self", ".", "get_offsets", "(", ")", "paths", "=", "self", ".", "get_paths", "(", ")", "if", "self", ".", "have_units", "(", ")", ":", "paths", "=", "[", "]", "for", "path", "in", "self", ".", "get_paths", "(", ")", ":", "vertices", "=", "path", ".", "vertices", "xs", ",", "ys", "=", "vertices", "[", ":", ",", "0", "]", ",", "vertices", "[", ":", ",", "1", "]", "xs", "=", "self", ".", "convert_xunits", "(", "xs", ")", "ys", "=", "self", ".", "convert_yunits", "(", "ys", ")", "paths", ".", "append", "(", "mpath", ".", "Path", "(", "np", ".", "column_stack", "(", "[", "xs", ",", "ys", "]", ")", ",", "path", ".", "codes", ")", ")", "xs", "=", "self", ".", "convert_xunits", "(", "offsets", "[", ":", ",", "0", "]", ")", "ys", "=", "self", ".", "convert_yunits", "(", "offsets", "[", ":", ",", "1", "]", ")", "offsets", "=", "np", ".", "ma", ".", "column_stack", "(", "[", "xs", ",", "ys", "]", ")", "if", "not", "transform", ".", "is_affine", ":", "paths", "=", "[", "transform", ".", "transform_path_non_affine", "(", "path", ")", "for", "path", "in", "paths", "]", "transform", "=", "transform", ".", "get_affine", "(", ")", "if", "not", "offset_trf", ".", "is_affine", ":", "offsets", "=", "offset_trf", ".", "transform_non_affine", "(", "offsets", ")", "offset_trf", "=", "offset_trf", ".", "get_affine", "(", ")", "if", "np", ".", "ma", ".", "isMaskedArray", "(", "offsets", ")", ":", "offsets", "=", "offsets", ".", "filled", "(", "np", ".", "nan", ")", "return", "transform", ",", "offset_trf", ",", "offsets", ",", "paths"], "to_mask": {"VAR": ["offset_trf", "offsets", "path", "paths", "self", "transform", "vertices", "xs", "ys"], "METHOD": ["Path", "append", "column_stack", "convert_xunits", "convert_yunits", "filled", "get_affine", "get_offset_transform", "get_offsets", "get_paths", "get_transform", "have_units", "isMaskedArray", "transform_non_affine", "transform_path_non_affine"]}, "attention_idx_tokens": [204, 213], "patch": "@@ -339,7 +339,7 @@\n             # This might have changed an ndarray into a masked array.\n             offset_trf = offset_trf.get_affine()\n \n-        if isinstance(offsets, np.ma.MaskedArray):\n+        if np.ma.isMaskedArray(offsets):", "ext_attention_idx_tokens": [204, 223], "uid": "44147bb9", "question": "This seems unrelated?", "code": "def prepare points self # Helper for drawing and hit testing transform self get transform offset trf self get offset transform offsets self get offsets paths self get paths if self have units paths [] for path in self get paths vertices path vertices xs ys vertices[ 0] vertices[ 1] xs self convert xunits xs ys self convert yunits ys paths append mpath Path np column stack [xs ys] path codes xs self convert xunits offsets[ 0] ys self convert yunits offsets[ 1] offsets np ma column stack [xs ys] if not transform is affine paths [transform transform path non affine path for path in paths] transform transform get affine if not offset trf is affine offsets offset trf transform non affine offsets # This might have changed an ndarray into a masked array offset trf offset trf get affine if np ma isMaskedArray offsets offsets offsets filled np nan # Changing from a masked array to nan-filled ndarray # is probably most efficient at this point return transform offset trf offsets paths"}
{"message": "I see what this is likely for, but as these conditions appear uncovered by tests, I'm wondering what actually needed this change?", "timestamp": "2024-07-31T19:33:47Z", "file_name": "lib/matplotlib/text.py", "range": {"start_line": 760, "end_line": 760, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1699009174", "html_url": "https://github.com/matplotlib/matplotlib/pull/27349#discussion_r1699009174", "attention_area": "                y = np.nan", "file_path": "files/27/08/00000827.py", "old_file_path": "files/28/08/00000828.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -753,9 +753,16 @@ def draw(self, renderer):\n \n             # don't use self.get_position here, which refers to text\n             # position in Text:\n-            posx = float(self.convert_xunits(self._x))\n-            posy = float(self.convert_yunits(self._y))\n+            x, y = self._x, self._y\n+            if np.ma.is_masked(x):\n+                x = np.nan\n+            if np.ma.is_masked(y):\n+                y = np.nan", "source": "def draw(self, renderer):\n        # docstring inherited\n\n        if renderer is not None:\n            self._renderer = renderer\n        if not self.get_visible():\n            return\n        if self.get_text() == '':\n            return\n\n        renderer.open_group('text', self.get_gid())\n\n        with self._cm_set(text=self._get_wrapped_text()):\n            bbox, info, descent = self._get_layout(renderer)\n            trans = self.get_transform()\n\n            # don't use self.get_position here, which refers to text\n            # position in Text:\n            x, y = self._x, self._y\n            if np.ma.is_masked(x):\n                x = np.nan\n            if np.ma.is_masked(y):\n                y = np.nan\n            posx = float(self.convert_xunits(x))\n            posy = float(self.convert_yunits(y))\n            posx, posy = trans.transform((posx, posy))\n            if np.isnan(posx) or np.isnan(posy):\n                return  # don't throw a warning here\n            if not np.isfinite(posx) or not np.isfinite(posy):\n                _log.warning(\"posx and posy should be finite values\")\n                return\n            canvasw, canvash = renderer.get_canvas_width_height()\n\n            # Update the location and size of the bbox\n            # (`.patches.FancyBboxPatch`), and draw it.\n            if self._bbox_patch:\n                self.update_bbox_position_size(renderer)\n                self._bbox_patch.draw(renderer)\n\n            gc = renderer.new_gc()\n            gc.set_foreground(self.get_color())\n            gc.set_alpha(self.get_alpha())\n            gc.set_url(self._url)\n            gc.set_antialiased(self._antialiased)\n            self._set_gc_clip(gc)\n\n            angle = self.get_rotation()\n\n            for line, wh, x, y in info:\n\n                mtext = self if len(info) == 1 else None\n                x = x + posx\n                y = y + posy\n                if renderer.flipy():\n                    y = canvash - y\n                clean_line, ismath = self._preprocess_math(line)\n\n                if self.get_path_effects():\n                    from matplotlib.patheffects import PathEffectRenderer\n                    textrenderer = PathEffectRenderer(\n                        self.get_path_effects(), renderer)\n                else:\n                    textrenderer = renderer\n\n                if self.get_usetex():\n                    textrenderer.draw_tex(gc, x, y, clean_line,\n                                          self._fontproperties, angle,\n                                          mtext=mtext)\n                else:\n                    textrenderer.draw_text(gc, x, y, clean_line,\n                                           self._fontproperties, angle,\n                                           ismath=ismath, mtext=mtext)\n\n        gc.restore()\n        renderer.close_group('text')\n        self.stale = False", "source_start_line": 738, "tokens": ["def", "draw", "(", "self", ",", "renderer", ")", ":", "if", "renderer", "is", "not", "None", ":", "self", ".", "_renderer", "=", "renderer", "if", "not", "self", ".", "get_visible", "(", ")", ":", "return", "if", "self", ".", "get_text", "(", ")", "==", "''", ":", "return", "renderer", ".", "open_group", "(", "'text'", ",", "self", ".", "get_gid", "(", ")", ")", "with", "self", ".", "_cm_set", "(", "text", "=", "self", ".", "_get_wrapped_text", "(", ")", ")", ":", "bbox", ",", "info", ",", "descent", "=", "self", ".", "_get_layout", "(", "renderer", ")", "trans", "=", "self", ".", "get_transform", "(", ")", "x", ",", "y", "=", "self", ".", "_x", ",", "self", ".", "_y", "if", "np", ".", "ma", ".", "is_masked", "(", "x", ")", ":", "x", "=", "np", ".", "nan", "if", "np", ".", "ma", ".", "is_masked", "(", "y", ")", ":", "y", "=", "np", ".", "nan", "posx", "=", "float", "(", "self", ".", "convert_xunits", "(", "x", ")", ")", "posy", "=", "float", "(", "self", ".", "convert_yunits", "(", "y", ")", ")", "posx", ",", "posy", "=", "trans", ".", "transform", "(", "(", "posx", ",", "posy", ")", ")", "if", "np", ".", "isnan", "(", "posx", ")", "or", "np", ".", "isnan", "(", "posy", ")", ":", "return", "if", "not", "np", ".", "isfinite", "(", "posx", ")", "or", "not", "np", ".", "isfinite", "(", "posy", ")", ":", "_log", ".", "warning", "(", "\"posx and posy should be finite values\"", ")", "return", "canvasw", ",", "canvash", "=", "renderer", ".", "get_canvas_width_height", "(", ")", "if", "self", ".", "_bbox_patch", ":", "self", ".", "update_bbox_position_size", "(", "renderer", ")", "self", ".", "_bbox_patch", ".", "draw", "(", "renderer", ")", "gc", "=", "renderer", ".", "new_gc", "(", ")", "gc", ".", "set_foreground", "(", "self", ".", "get_color", "(", ")", ")", "gc", ".", "set_alpha", "(", "self", ".", "get_alpha", "(", ")", ")", "gc", ".", "set_url", "(", "self", ".", "_url", ")", "gc", ".", "set_antialiased", "(", "self", ".", "_antialiased", ")", "self", ".", "_set_gc_clip", "(", "gc", ")", "angle", "=", "self", ".", "get_rotation", "(", ")", "for", "line", ",", "wh", ",", "x", ",", "y", "in", "info", ":", "mtext", "=", "self", "if", "len", "(", "info", ")", "==", "1", "else", "None", "x", "=", "x", "+", "posx", "y", "=", "y", "+", "posy", "if", "renderer", ".", "flipy", "(", ")", ":", "y", "=", "canvash", "-", "y", "clean_line", ",", "ismath", "=", "self", ".", "_preprocess_math", "(", "line", ")", "if", "self", ".", "get_path_effects", "(", ")", ":", "from", "matplotlib", ".", "patheffects", "import", "PathEffectRenderer", "textrenderer", "=", "PathEffectRenderer", "(", "self", ".", "get_path_effects", "(", ")", ",", "renderer", ")", "else", ":", "textrenderer", "=", "renderer", "if", "self", ".", "get_usetex", "(", ")", ":", "textrenderer", ".", "draw_tex", "(", "gc", ",", "x", ",", "y", ",", "clean_line", ",", "self", ".", "_fontproperties", ",", "angle", ",", "mtext", "=", "mtext", ")", "else", ":", "textrenderer", ".", "draw_text", "(", "gc", ",", "x", ",", "y", ",", "clean_line", ",", "self", ".", "_fontproperties", ",", "angle", ",", "ismath", "=", "ismath", ",", "mtext", "=", "mtext", ")", "gc", ".", "restore", "(", ")", "renderer", ".", "close_group", "(", "'text'", ")", "self", ".", "stale", "=", "False"], "to_mask": {"VAR": ["_renderer", "angle", "bbox", "canvash", "canvasw", "clean_line", "descent", "gc", "info", "ismath", "line", "mtext", "posx", "posy", "renderer", "self", "stale", "textrenderer", "trans", "wh", "x", "y"], "METHOD": ["PathEffectRenderer", "_cm_set", "_get_layout", "_get_wrapped_text", "_preprocess_math", "_set_gc_clip", "close_group", "convert_xunits", "convert_yunits", "draw", "draw_tex", "draw_text", "flipy", "float", "get_alpha", "get_canvas_width_height", "get_color", "get_gid", "get_path_effects", "get_rotation", "get_text", "get_transform", "get_usetex", "get_visible", "is_masked", "isfinite", "isnan", "len", "new_gc", "open_group", "restore", "set_alpha", "set_antialiased", "set_foreground", "set_url", "transform", "update_bbox_position_size", "warning"]}, "attention_idx_tokens": [119, 123], "patch": "@@ -753,9 +753,16 @@\n \n             # don't use self.get_position here, which refers to text\n             # position in Text:\n-            posx = float(self.convert_xunits(self._x))\n-            posy = float(self.convert_yunits(self._y))\n+            x, y = self._x, self._y\n+            if np.ma.is_masked(x):\n+                x = np.nan\n+            if np.ma.is_masked(y):\n+                y = np.nan", "ext_attention_idx_tokens": [83, 192], "uid": "31b2be63", "question": "I see what this is likely for, but as these conditions appear uncovered by tests, I'm wondering what actually needed this change?", "code": "def draw self renderer # docstring inherited if renderer is not None self renderer renderer if not self get visible return if self get text return renderer open group text self get gid with self cm set text self get wrapped text bbox info descent self get layout renderer trans self get transform # don t use self get position here which refers to text # position in Text x y self x self y if np ma is masked x x np nan if np ma is masked y y np nan posx float self convert xunits x posy float self convert yunits y posx posy trans transform posx posy if np isnan posx or np isnan posy return # don t throw a warning here if not np isfinite posx or not np isfinite posy log warning \"posx and posy should be finite values\" return canvasw canvash renderer get canvas width height # Update the location and size of the bbox # ` patches FancyBboxPatch` and draw it if self bbox patch self update bbox position size renderer self bbox patch draw renderer gc renderer new gc gc set foreground self get color gc set alpha self get alpha gc set url self url gc set antialiased self antialiased self set gc clip gc angle self get rotation for line wh x y in info mtext self if len info 1 else None x x + posx y y + posy if renderer flipy y canvash - y clean line ismath self preprocess math line if self get path effects from matplotlib patheffects import PathEffectRenderer textrenderer PathEffectRenderer self get path effects renderer else textrenderer renderer if self get usetex textrenderer draw tex gc x y clean line self fontproperties angle mtext mtext else textrenderer draw text gc x y clean line self fontproperties angle ismath ismath mtext mtext gc restore renderer close group text self stale False"}
{"message": "I don't know why this change is needed now, but otherwise things randomly crash.", "timestamp": "2024-08-14T09:40:06Z", "file_name": "src/py_converters_11.h", "range": {"start_line": 185, "end_line": 185, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1716622641", "html_url": "https://github.com/matplotlib/matplotlib/pull/27011#discussion_r1716622641", "attention_area": "            if (!value.set(vertices.inc_ref().ptr(), codes.inc_ref().ptr(),", "file_path": "files/49/09/00000949.h", "old_file_path": "files/50/09/00000950.h", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -113,14 +177,14 @@ namespace PYBIND11_NAMESPACE { namespace detail {\n                 return true;\n             }\n \n-            auto vertices = src.attr(\"vertices\");\n-            auto codes = src.attr(\"codes\");\n+            py::object vertices = src.attr(\"vertices\");\n+            py::object codes = src.attr(\"codes\");\n             auto should_simplify = src.attr(\"should_simplify\").cast<bool>();\n             auto simplify_threshold = src.attr(\"simplify_threshold\").cast<double>();\n \n-            if (!value.set(vertices.ptr(), codes.ptr(),\n+            if (!value.set(vertices.inc_ref().ptr(), codes.inc_ref().ptr(),", "source": "bool load(handle src, bool) {\n            if (src.is_none()) {\n                return true;\n            }\n\n            py::object vertices = src.attr(\"vertices\");\n            py::object codes = src.attr(\"codes\");\n            auto should_simplify = src.attr(\"should_simplify\").cast<bool>();\n            auto simplify_threshold = src.attr(\"simplify_threshold\").cast<double>();\n\n            if (!value.set(vertices.inc_ref().ptr(), codes.inc_ref().ptr(),\n                           should_simplify, simplify_threshold)) {\n                throw py::error_already_set();\n            }\n\n            return true;\n        }", "source_start_line": 175, "tokens": ["bool", "load", "(", "handle", "src", ",", "bool", ")", "{", "if", "(", "src", ".", "is_none", "(", ")", ")", "{", "return", "true", ";", "}", "py", "::", "object", "vertices", "=", "src", ".", "attr", "(", "\"", "\"", ")", ";", "py", "::", "object", "codes", "=", "src", ".", "attr", "(", "\"", "\"", ")", ";", "auto", "should_simplify", "=", "src", ".", "attr", "(", "\"", "\"", ")", ".", "cast", "<", "bool", ">", "(", ")", ";", "auto", "simplify_threshold", "=", "src", ".", "attr", "(", "\"", "\"", ")", ".", "cast", "<", "double", ">", "(", ")", ";", "if", "(", "!", "value", ".", "set", "(", "vertices", ".", "inc_ref", "(", ")", ".", "ptr", "(", ")", ",", "codes", ".", "inc_ref", "(", ")", ".", "ptr", "(", ")", ",", "should_simplify", ",", "simplify_threshold", ")", ")", "{", "throw", "py", "::", "error_already_set", "(", ")", ";", "}", "return", "true", ";", "}"], "to_mask": {}, "attention_idx_tokens": [84, 110], "patch": "@@ -113,14 +177,14 @@\n                 return true;\n             }\n \n-            auto vertices = src.attr(\"vertices\");\n-            auto codes = src.attr(\"codes\");\n+            py::object vertices = src.attr(\"vertices\");\n+            py::object codes = src.attr(\"codes\");\n             auto should_simplify = src.attr(\"should_simplify\").cast<bool>();\n             auto simplify_threshold = src.attr(\"simplify_threshold\").cast<double>();\n \n-            if (!value.set(vertices.ptr(), codes.ptr(),\n+            if (!value.set(vertices.inc_ref().ptr(), codes.inc_ref().ptr(),", "ext_attention_idx_tokens": [22, 124], "uid": "9a4bda5a", "question": "I don't know why this change is needed now, but otherwise things randomly crash.", "code": "bool load handle src bool { if src is none { return true; } py object vertices src attr \"vertices\" ; py object codes src attr \"codes\" ; auto should simplify src attr \"should simplify\" cast<bool> ; auto simplify threshold src attr \"simplify threshold\" cast<double> ; if !value set vertices inc ref ptr codes inc ref ptr should simplify simplify threshold { throw py error already set ; } return true; }"}
{"message": "Where does 0.02 come from? Does it work well with different font sizes?", "timestamp": "2024-08-20T06:34:53Z", "file_name": "lib/matplotlib/_constrained_layout.py", "range": {"start_line": 148, "end_line": 148, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1722762187", "html_url": "https://github.com/matplotlib/matplotlib/pull/28734#discussion_r1722762187", "attention_area": "                        (x, layoutgrids[fig].get_inner_bbox().y1 + 0.02))", "file_path": "files/80/09/00000980.py", "old_file_path": "files/81/09/00000981.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -140,6 +140,13 @@ def do_constrained_layout(fig, h_pad, w_pad,\n                                     w_pad=w_pad, hspace=hspace, wspace=wspace)\n                 else:\n                     _api.warn_external(warn_collapsed)\n+\n+                if ((suptitle := fig._suptitle) is not None and\n+                        suptitle.get_in_layout() and suptitle._autopos):\n+                    x, _ = suptitle.get_position()\n+                    suptitle.set_position(\n+                        (x, layoutgrids[fig].get_inner_bbox().y1 + 0.02))", "source": "def do_constrained_layout(fig, h_pad, w_pad,\n                          hspace=None, wspace=None, rect=(0, 0, 1, 1),\n                          compress=False):\n    \"\"\"\n    Do the constrained_layout.  Called at draw time in\n     ``figure.constrained_layout()``\n\n    Parameters\n    ----------\n    fig : `~matplotlib.figure.Figure`\n        `.Figure` instance to do the layout in.\n\n    h_pad, w_pad : float\n      Padding around the Axes elements in figure-normalized units.\n\n    hspace, wspace : float\n       Fraction of the figure to dedicate to space between the\n       Axes.  These are evenly spread between the gaps between the Axes.\n       A value of 0.2 for a three-column layout would have a space\n       of 0.1 of the figure width between each column.\n       If h/wspace < h/w_pad, then the pads are used instead.\n\n    rect : tuple of 4 floats\n        Rectangle in figure coordinates to perform constrained layout in\n        [left, bottom, width, height], each from 0-1.\n\n    compress : bool\n        Whether to shift Axes so that white space in between them is\n        removed. This is useful for simple grids of fixed-aspect Axes (e.g.\n        a grid of images).\n\n    Returns\n    -------\n    layoutgrid : private debugging structure\n    \"\"\"\n\n    renderer = fig._get_renderer()\n    # make layoutgrid tree...\n    layoutgrids = make_layoutgrids(fig, None, rect=rect)\n    if not layoutgrids['hasgrids']:\n        _api.warn_external('There are no gridspecs with layoutgrids. '\n                           'Possibly did not call parent GridSpec with the'\n                           ' \"figure\" keyword')\n        return\n\n    for _ in range(2):\n        # do the algorithm twice.  This has to be done because decorations\n        # change size after the first re-position (i.e. x/yticklabels get\n        # larger/smaller).  This second reposition tends to be much milder,\n        # so doing twice makes things work OK.\n\n        # make margins for all the Axes and subfigures in the\n        # figure.  Add margins for colorbars...\n        make_layout_margins(layoutgrids, fig, renderer, h_pad=h_pad,\n                            w_pad=w_pad, hspace=hspace, wspace=wspace)\n        make_margin_suptitles(layoutgrids, fig, renderer, h_pad=h_pad,\n                              w_pad=w_pad)\n\n        # if a layout is such that a columns (or rows) margin has no\n        # constraints, we need to make all such instances in the grid\n        # match in margin size.\n        match_submerged_margins(layoutgrids, fig)\n\n        # update all the variables in the layout.\n        layoutgrids[fig].update_variables()\n\n        warn_collapsed = ('constrained_layout not applied because '\n                          'axes sizes collapsed to zero.  Try making '\n                          'figure larger or Axes decorations smaller.')\n        if check_no_collapsed_axes(layoutgrids, fig):\n            reposition_axes(layoutgrids, fig, renderer, h_pad=h_pad,\n                            w_pad=w_pad, hspace=hspace, wspace=wspace)\n            if compress:\n                layoutgrids = compress_fixed_aspect(layoutgrids, fig)\n                layoutgrids[fig].update_variables()\n                if check_no_collapsed_axes(layoutgrids, fig):\n                    reposition_axes(layoutgrids, fig, renderer, h_pad=h_pad,\n                                    w_pad=w_pad, hspace=hspace, wspace=wspace)\n                else:\n                    _api.warn_external(warn_collapsed)\n\n                if ((suptitle := fig._suptitle) is not None and\n                        suptitle.get_in_layout() and suptitle._autopos):\n                    x, _ = suptitle.get_position()\n                    suptitle.set_position(\n                        (x, layoutgrids[fig].get_inner_bbox().y1 + 0.02))\n                    suptitle.set_verticalalignment('bottom')\n        else:\n            _api.warn_external(warn_collapsed)\n        reset_margins(layoutgrids, fig)\n    return layoutgrids", "source_start_line": 63, "tokens": ["def", "do_constrained_layout", "(", "fig", ",", "h_pad", ",", "w_pad", ",", "hspace", "=", "None", ",", "wspace", "=", "None", ",", "rect", "=", "(", "0", ",", "0", ",", "1", ",", "1", ")", ",", "compress", "=", "False", ")", ":", "\"\"\"    Do the constrained_layout.  Called at draw time in     ``figure.constrained_layout()``    Parameters    ----------    fig : `~matplotlib.figure.Figure`        `.Figure` instance to do the layout in.    h_pad, w_pad : float      Padding around the Axes elements in figure-normalized units.    hspace, wspace : float       Fraction of the figure to dedicate to space between the       Axes.  These are evenly spread between the gaps between the Axes.       A value of 0.2 for a three-column layout would have a space       of 0.1 of the figure width between each column.       If h/wspace < h/w_pad, then the pads are used instead.    rect : tuple of 4 floats        Rectangle in figure coordinates to perform constrained layout in        [left, bottom, width, height], each from 0-1.    compress : bool        Whether to shift Axes so that white space in between them is        removed. This is useful for simple grids of fixed-aspect Axes (e.g.        a grid of images).    Returns    -------    layoutgrid : private debugging structure    \"\"\"", "renderer", "=", "fig", ".", "_get_renderer", "(", ")", "layoutgrids", "=", "make_layoutgrids", "(", "fig", ",", "None", ",", "rect", "=", "rect", ")", "if", "not", "layoutgrids", "[", "'hasgrids'", "]", ":", "_api", ".", "warn_external", "(", "'There are no gridspecs with layoutgrids. '", "'Possibly did not call parent GridSpec with the'", "' \"figure\" keyword'", ")", "return", "for", "_", "in", "range", "(", "2", ")", ":", "make_layout_margins", "(", "layoutgrids", ",", "fig", ",", "renderer", ",", "h_pad", "=", "h_pad", ",", "w_pad", "=", "w_pad", ",", "hspace", "=", "hspace", ",", "wspace", "=", "wspace", ")", "make_margin_suptitles", "(", "layoutgrids", ",", "fig", ",", "renderer", ",", "h_pad", "=", "h_pad", ",", "w_pad", "=", "w_pad", ")", "match_submerged_margins", "(", "layoutgrids", ",", "fig", ")", "layoutgrids", "[", "fig", "]", ".", "update_variables", "(", ")", "warn_collapsed", "=", "(", "'constrained_layout not applied because '", "'axes sizes collapsed to zero.  Try making '", "'figure larger or Axes decorations smaller.'", ")", "if", "check_no_collapsed_axes", "(", "layoutgrids", ",", "fig", ")", ":", "reposition_axes", "(", "layoutgrids", ",", "fig", ",", "renderer", ",", "h_pad", "=", "h_pad", ",", "w_pad", "=", "w_pad", ",", "hspace", "=", "hspace", ",", "wspace", "=", "wspace", ")", "if", "compress", ":", "layoutgrids", "=", "compress_fixed_aspect", "(", "layoutgrids", ",", "fig", ")", "layoutgrids", "[", "fig", "]", ".", "update_variables", "(", ")", "if", "check_no_collapsed_axes", "(", "layoutgrids", ",", "fig", ")", ":", "reposition_axes", "(", "layoutgrids", ",", "fig", ",", "renderer", ",", "h_pad", "=", "h_pad", ",", "w_pad", "=", "w_pad", ",", "hspace", "=", "hspace", ",", "wspace", "=", "wspace", ")", "else", ":", "_api", ".", "warn_external", "(", "warn_collapsed", ")", "if", "(", "(", "suptitle", ":=", "fig", ".", "_suptitle", ")", "is", "not", "None", "and", "suptitle", ".", "get_in_layout", "(", ")", "and", "suptitle", ".", "_autopos", ")", ":", "x", ",", "_", "=", "suptitle", ".", "get_position", "(", ")", "suptitle", ".", "set_position", "(", "(", "x", ",", "layoutgrids", "[", "fig", "]", ".", "get_inner_bbox", "(", ")", ".", "y1", "+", "0.02", ")", ")", "suptitle", ".", "set_verticalalignment", "(", "'bottom'", ")", "else", ":", "_api", ".", "warn_external", "(", "warn_collapsed", ")", "reset_margins", "(", "layoutgrids", ",", "fig", ")", "return", "layoutgrids"], "to_mask": {"VAR": ["_", "compress", "fig", "h_pad", "hspace", "layoutgrids", "rect", "renderer", "w_pad", "warn_collapsed", "wspace", "x"], "METHOD": ["_get_renderer", "check_no_collapsed_axes", "compress_fixed_aspect", "get_in_layout", "get_inner_bbox", "get_position", "make_layout_margins", "make_layoutgrids", "make_margin_suptitles", "match_submerged_margins", "range", "reposition_axes", "reset_margins", "set_position", "set_verticalalignment", "update_variables", "warn_external"]}, "attention_idx_tokens": [267, 283], "patch": "@@ -140,6 +140,13 @@\n                                     w_pad=w_pad, hspace=hspace, wspace=wspace)\n                 else:\n                     _api.warn_external(warn_collapsed)\n+\n+                if ((suptitle := fig._suptitle) is not None and\n+                        suptitle.get_in_layout() and suptitle._autopos):\n+                    x, _ = suptitle.get_position()\n+                    suptitle.set_position(\n+                        (x, layoutgrids[fig].get_inner_bbox().y1 + 0.02))", "ext_attention_idx_tokens": [230, 291], "uid": "91fa6a65", "question": "Where does 0.02 come from? Does it work well with different font sizes?", "code": "def do constrained layout fig h pad w pad hspace None wspace None rect 0 0 1 1 compress False \"\"\" Do the constrained layout Called at draw time in ``figure constrained layout `` Parameters ---------- fig `~matplotlib figure Figure` ` Figure` instance to do the layout in h pad w pad float Padding around the Axes elements in figure-normalized units hspace wspace float Fraction of the figure to dedicate to space between the Axes These are evenly spread between the gaps between the Axes A value of 0 2 for a three-column layout would have a space of 0 1 of the figure width between each column If h wspace < h w pad then the pads are used instead rect tuple of 4 floats Rectangle in figure coordinates to perform constrained layout in [left bottom width height] each from 0-1 compress bool Whether to shift Axes so that white space in between them is removed This is useful for simple grids of fixed-aspect Axes e g a grid of images Returns ------- layoutgrid private debugging structure \"\"\" renderer fig get renderer # make layoutgrid tree layoutgrids make layoutgrids fig None rect rect if not layoutgrids[ hasgrids ] api warn external There are no gridspecs with layoutgrids Possibly did not call parent GridSpec with the \"figure\" keyword return for in range 2 # do the algorithm twice This has to be done because decorations # change size after the first re-position i e x yticklabels get # larger smaller This second reposition tends to be much milder # so doing twice makes things work OK # make margins for all the Axes and subfigures in the # figure Add margins for colorbars make layout margins layoutgrids fig renderer h pad h pad w pad w pad hspace hspace wspace wspace make margin suptitles layoutgrids fig renderer h pad h pad w pad w pad # if a layout is such that a columns or rows margin has no # constraints we need to make all such instances in the grid # match in margin size match submerged margins layoutgrids fig # update all the variables in the layout layoutgrids[fig] update variables warn collapsed constrained layout not applied because axes sizes collapsed to zero Try making figure larger or Axes decorations smaller if check no collapsed axes layoutgrids fig reposition axes layoutgrids fig renderer h pad h pad w pad w pad hspace hspace wspace wspace if compress layoutgrids compress fixed aspect layoutgrids fig layoutgrids[fig] update variables if check no collapsed axes layoutgrids fig reposition axes layoutgrids fig renderer h pad h pad w pad w pad hspace hspace wspace wspace else api warn external warn collapsed if suptitle fig suptitle is not None and suptitle get in layout and suptitle autopos x suptitle get position suptitle set position x layoutgrids[fig] get inner bbox y1 + 0 02 suptitle set verticalalignment bottom else api warn external warn collapsed reset margins layoutgrids fig return layoutgrids"}
{"message": "shouldn't you know which connector this is b/c this is deterministic? basically why loop?", "timestamp": "2024-08-22T04:13:03Z", "file_name": "lib/matplotlib/tests/test_inset.py", "range": {"start_line": 109, "end_line": 109, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1726213235", "html_url": "https://github.com/matplotlib/matplotlib/pull/27996#discussion_r1726213235", "attention_area": "            break", "file_path": "files/11/10/00001011.py", "old_file_path": null, "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": true}, "language": "python", "replies": {}, "diff_hunk": "@@ -0,0 +1,109 @@\n+import platform\n+\n+import pytest\n+\n+import matplotlib.colors as mcolors\n+import matplotlib.pyplot as plt\n+from matplotlib.testing.decorators import image_comparison, check_figures_equal\n+\n+\n+def test_indicate_inset_no_args():\n+    fig, ax = plt.subplots()\n+    with pytest.raises(ValueError, match='At least one of bounds or inset_ax'):\n+        ax.indicate_inset()\n+\n+\n+@check_figures_equal(extensions=[\"png\"])\n+def test_zoom_inset_update_limits(fig_test, fig_ref):\n+    # Updating the inset axes limits should also update the indicator #19768\n+    ax_ref = fig_ref.add_subplot()\n+    ax_test = fig_test.add_subplot()\n+\n+    for ax in ax_ref, ax_test:\n+        ax.set_xlim([0, 5])\n+        ax.set_ylim([0, 5])\n+\n+    inset_ref = ax_ref.inset_axes([0.6, 0.6, 0.3, 0.3])\n+    inset_test = ax_test.inset_axes([0.6, 0.6, 0.3, 0.3])\n+\n+    inset_ref.set_xlim([1, 2])\n+    inset_ref.set_ylim([3, 4])\n+    ax_ref.indicate_inset_zoom(inset_ref)\n+\n+    ax_test.indicate_inset_zoom(inset_test)\n+    inset_test.set_xlim([1, 2])\n+    inset_test.set_ylim([3, 4])\n+\n+\n+def test_inset_indicator_update_styles():\n+    fig, ax = plt.subplots()\n+    inset = ax.inset_axes([0.6, 0.6, 0.3, 0.3])\n+    inset.set_xlim([0.2, 0.4])\n+    inset.set_ylim([0.2, 0.4])\n+\n+    indicator = ax.indicate_inset_zoom(\n+        inset, edgecolor='red', alpha=0.5, linewidth=2, linestyle='solid')\n+\n+    # Changing the rectangle styles should not affect the connectors.\n+    indicator.rectangle.set(color='blue', linestyle='dashed', linewidth=42, alpha=0.2)\n+    for conn in indicator.connectors:\n+        assert mcolors.same_color(conn.get_edgecolor()[:3], 'red')\n+        assert conn.get_alpha() == 0.5\n+        assert conn.get_linestyle() == 'solid'\n+        assert conn.get_linewidth() == 2\n+\n+    # Changing the indicator styles should affect both rectangle and connectors.\n+    indicator.set(color='green', linestyle='dotted', linewidth=7, alpha=0.8)\n+    assert mcolors.same_color(indicator.rectangle.get_facecolor()[:3], 'green')\n+    for patch in (*indicator.connectors, indicator.rectangle):\n+        assert mcolors.same_color(patch.get_edgecolor()[:3], 'green')\n+        assert patch.get_alpha() == 0.8\n+        assert patch.get_linestyle() == 'dotted'\n+        assert patch.get_linewidth() == 7\n+\n+    indicator.set_edgecolor('purple')\n+    for patch in (*indicator.connectors, indicator.rectangle):\n+        assert mcolors.same_color(patch.get_edgecolor()[:3], 'purple')\n+\n+    # This should also be true if connectors weren't created yet.\n+    indicator._connectors = []\n+    indicator.set(color='burlywood', linestyle='dashdot', linewidth=4, alpha=0.4)\n+    assert mcolors.same_color(indicator.rectangle.get_facecolor()[:3], 'burlywood')\n+    for patch in (*indicator.connectors, indicator.rectangle):\n+        assert mcolors.same_color(patch.get_edgecolor()[:3], 'burlywood')\n+        assert patch.get_alpha() == 0.4\n+        assert patch.get_linestyle() == 'dashdot'\n+        assert patch.get_linewidth() == 4\n+\n+    indicator._connectors = []\n+    indicator.set_edgecolor('thistle')\n+    for patch in (*indicator.connectors, indicator.rectangle):\n+        assert mcolors.same_color(patch.get_edgecolor()[:3], 'thistle')\n+\n+\n+def test_inset_indicator_zorder():\n+    fig, ax = plt.subplots()\n+    rect = [0.2, 0.2, 0.3, 0.4]\n+\n+    inset = ax.indicate_inset(rect)\n+    assert inset.get_zorder() == 4.99\n+\n+    inset = ax.indicate_inset(rect, zorder=42)\n+    assert inset.get_zorder() == 42\n+\n+\n+@image_comparison(['zoom_inset_connector_styles.png'], remove_text=True, style='mpl20',\n+                  tol=0.024 if platform.machine() == 'arm64' else 0)\n+def test_zoom_inset_connector_styles():\n+    fig, axs = plt.subplots(2)\n+    for ax in axs:\n+        ax.plot([1, 2, 3])\n+\n+    axs[1].set_xlim(0.5, 1.5)\n+    indicator = axs[0].indicate_inset_zoom(axs[1], linewidth=5)\n+    for conn in indicator.connectors:\n+        if conn.get_visible():\n+            # Make one visible connector a different style\n+            conn.set_linestyle('dashed')\n+            conn.set_color('blue')\n+            break", "source": "def test_zoom_inset_connector_styles():\n    fig, axs = plt.subplots(2)\n    for ax in axs:\n        ax.plot([1, 2, 3])\n\n    axs[1].set_xlim(0.5, 1.5)\n    indicator = axs[0].indicate_inset_zoom(axs[1], linewidth=5)\n    for conn in indicator.connectors:\n        if conn.get_visible():\n            # Make one visible connector a different style\n            conn.set_linestyle('dashed')\n            conn.set_color('blue')\n            break", "source_start_line": 97, "tokens": ["def", "test_zoom_inset_connector_styles", "(", ")", ":", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "2", ")", "for", "ax", "in", "axs", ":", "ax", ".", "plot", "(", "[", "1", ",", "2", ",", "3", "]", ")", "axs", "[", "1", "]", ".", "set_xlim", "(", "0.5", ",", "1.5", ")", "indicator", "=", "axs", "[", "0", "]", ".", "indicate_inset_zoom", "(", "axs", "[", "1", "]", ",", "linewidth", "=", "5", ")", "for", "conn", "in", "indicator", ".", "connectors", ":", "if", "conn", ".", "get_visible", "(", ")", ":", "conn", ".", "set_linestyle", "(", "'dashed'", ")", "conn", ".", "set_color", "(", "'blue'", ")", "break"], "to_mask": {"VAR": ["ax", "axs", "conn", "fig", "indicator"], "METHOD": ["get_visible", "indicate_inset_zoom", "plot", "set_color", "set_linestyle", "set_xlim", "subplots"]}, "attention_idx_tokens": [87, 87], "patch": "@@ -0,0 +1,109 @@\n+import platform\n+\n+import pytest\n+\n+import matplotlib.colors as mcolors\n+import matplotlib.pyplot as plt\n+from matplotlib.testing.decorators import image_comparison, check_figures_equal\n+\n+\n+def test_indicate_inset_no_args():\n+    fig, ax = plt.subplots()\n+    with pytest.raises(ValueError, match='At least one of bounds or inset_ax'):\n+        ax.indicate_inset()\n+\n+\n+@check_figures_equal(extensions=[\"png\"])\n+def test_zoom_inset_update_limits(fig_test, fig_ref):\n+    # Updating the inset axes limits should also update the indicator #19768\n+    ax_ref = fig_ref.add_subplot()\n+    ax_test = fig_test.add_subplot()\n+\n+    for ax in ax_ref, ax_test:\n+        ax.set_xlim([0, 5])\n+        ax.set_ylim([0, 5])\n+\n+    inset_ref = ax_ref.inset_axes([0.6, 0.6, 0.3, 0.3])\n+    inset_test = ax_test.inset_axes([0.6, 0.6, 0.3, 0.3])\n+\n+    inset_ref.set_xlim([1, 2])\n+    inset_ref.set_ylim([3, 4])\n+    ax_ref.indicate_inset_zoom(inset_ref)\n+\n+    ax_test.indicate_inset_zoom(inset_test)\n+    inset_test.set_xlim([1, 2])\n+    inset_test.set_ylim([3, 4])\n+\n+\n+def test_inset_indicator_update_styles():\n+    fig, ax = plt.subplots()\n+    inset = ax.inset_axes([0.6, 0.6, 0.3, 0.3])\n+    inset.set_xlim([0.2, 0.4])\n+    inset.set_ylim([0.2, 0.4])\n+\n+    indicator = ax.indicate_inset_zoom(\n+        inset, edgecolor='red', alpha=0.5, linewidth=2, linestyle='solid')\n+\n+    # Changing the rectangle styles should not affect the connectors.\n+    indicator.rectangle.set(color='blue', linestyle='dashed', linewidth=42, alpha=0.2)\n+    for conn in indicator.connectors:\n+        assert mcolors.same_color(conn.get_edgecolor()[:3], 'red')\n+        assert conn.get_alpha() == 0.5\n+        assert conn.get_linestyle() == 'solid'\n+        assert conn.get_linewidth() == 2\n+\n+    # Changing the indicator styles should affect both rectangle and connectors.\n+    indicator.set(color='green', linestyle='dotted', linewidth=7, alpha=0.8)\n+    assert mcolors.same_color(indicator.rectangle.get_facecolor()[:3], 'green')\n+    for patch in (*indicator.connectors, indicator.rectangle):\n+        assert mcolors.same_color(patch.get_edgecolor()[:3], 'green')\n+        assert patch.get_alpha() == 0.8\n+        assert patch.get_linestyle() == 'dotted'\n+        assert patch.get_linewidth() == 7\n+\n+    indicator.set_edgecolor('purple')\n+    for patch in (*indicator.connectors, indicator.rectangle):\n+        assert mcolors.same_color(patch.get_edgecolor()[:3], 'purple')\n+\n+    # This should also be true if connectors weren't created yet.\n+    indicator._connectors = []\n+    indicator.set(color='burlywood', linestyle='dashdot', linewidth=4, alpha=0.4)\n+    assert mcolors.same_color(indicator.rectangle.get_facecolor()[:3], 'burlywood')\n+    for patch in (*indicator.connectors, indicator.rectangle):\n+        assert mcolors.same_color(patch.get_edgecolor()[:3], 'burlywood')\n+        assert patch.get_alpha() == 0.4\n+        assert patch.get_linestyle() == 'dashdot'\n+        assert patch.get_linewidth() == 4\n+\n+    indicator._connectors = []\n+    indicator.set_edgecolor('thistle')\n+    for patch in (*indicator.connectors, indicator.rectangle):\n+        assert mcolors.same_color(patch.get_edgecolor()[:3], 'thistle')\n+\n+\n+def test_inset_indicator_zorder():\n+    fig, ax = plt.subplots()\n+    rect = [0.2, 0.2, 0.3, 0.4]\n+\n+    inset = ax.indicate_inset(rect)\n+    assert inset.get_zorder() == 4.99\n+\n+    inset = ax.indicate_inset(rect, zorder=42)\n+    assert inset.get_zorder() == 42\n+\n+\n+@image_comparison(['zoom_inset_connector_styles.png'], remove_text=True, style='mpl20',\n+                  tol=0.024 if platform.machine() == 'arm64' else 0)\n+def test_zoom_inset_connector_styles():\n+    fig, axs = plt.subplots(2)\n+    for ax in axs:\n+        ax.plot([1, 2, 3])\n+\n+    axs[1].set_xlim(0.5, 1.5)\n+    indicator = axs[0].indicate_inset_zoom(axs[1], linewidth=5)\n+    for conn in indicator.connectors:\n+        if conn.get_visible():\n+            # Make one visible connector a different style\n+            conn.set_linestyle('dashed')\n+            conn.set_color('blue')\n+            break", "ext_attention_idx_tokens": [0, 80], "uid": "21e55c90", "question": "shouldn't you know which connector this is b/c this is deterministic? basically why loop?", "code": "def test zoom inset connector styles fig axs plt subplots 2 for ax in axs ax plot [1 2 3] axs[1] set xlim 0 5 1 5 indicator axs[0] indicate inset zoom axs[1] linewidth 5 for conn in indicator connectors if conn get visible # Make one visible connector a different style conn set linestyle dashed conn set color blue break"}
{"message": "Is supported or is not supported?", "timestamp": "2024-09-21T06:29:42Z", "file_name": "lib/matplotlib/axis.py", "range": {"start_line": 1425, "end_line": 1425, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1769487509", "html_url": "https://github.com/matplotlib/matplotlib/pull/28584#discussion_r1769487509", "attention_area": "        \"\"\"Assigning legend labels is supported. Raises RuntimeError.\"\"\"", "file_path": "files/27/11/00001127.py", "old_file_path": "files/22/11/00001122.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1421,8 +1421,21 @@ def get_gridlines(self):\n         return cbook.silent_list('Line2D gridline',\n                                  [tick.gridline for tick in ticks])\n \n+    def set_label(self, s):\n+        \"\"\"Assigning legend labels is supported. Raises RuntimeError.\"\"\"", "source": "def set_label(self, s):\n        \"\"\"Assigning legend labels is supported. Raises RuntimeError.\"\"\"\n        raise RuntimeError(\n            \"A legend label cannot be assigned to an Axis. Did you mean to \"\n            \"set the axis label via set_label_text()?\")", "source_start_line": 1424, "tokens": ["def", "set_label", "(", "self", ",", "s", ")", ":", "\"\"\"Assigning legend labels is supported. Raises RuntimeError.\"\"\"", "raise", "RuntimeError", "(", "\"A legend label cannot be assigned to an Axis. Did you mean to \"", "\"set the axis label via set_label_text()?\"", ")"], "to_mask": {"VAR": ["s", "self"], "METHOD": ["RuntimeError"]}, "attention_idx_tokens": [8, 8], "patch": "@@ -1421,8 +1421,21 @@\n         return cbook.silent_list('Line2D gridline',\n                                  [tick.gridline for tick in ticks])\n \n+    def set_label(self, s):\n+        \"\"\"Assigning legend labels is supported. Raises RuntimeError.\"\"\"", "ext_attention_idx_tokens": [0, 14], "uid": "fdb6a0dc", "question": "Is supported or is not supported?", "code": "def set label self s \"\"\"Assigning legend labels is supported Raises RuntimeError \"\"\" raise RuntimeError \"A legend label cannot be assigned to an Axis Did you mean to \" \"set the axis label via set label text ?\""}
{"message": "This sentence appears to be incomplete?", "timestamp": "2024-10-10T04:38:48Z", "file_name": "lib/matplotlib/tests/test_ticker.py", "range": {"start_line": 1662, "end_line": 1662, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1794637597", "html_url": "https://github.com/matplotlib/matplotlib/pull/28495#discussion_r1794637597", "attention_area": "            # 0 is zero on all orders of magnitudes, no", "file_path": "files/90/11/00001190.py", "old_file_path": "files/92/11/00001192.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1594,6 +1594,79 @@ def test_engformatter_usetex_useMathText():\n         assert x_tick_label_text == ['$0$', '$500$', '$1$ k']\n \n \n+@pytest.mark.parametrize(\n+    'oom_center, oom_noise, oom_center_desired, oom_noise_desired', [\n+        (11, 1, 9, 0),\n+        (13, 7, 12, 6),\n+        (1, -2, 0, -3),\n+        (3, -2, 3, -3),\n+        (5, -3, 3, -3),\n+        (2, -3, 0, -3),\n+        # The following sets of parameters demonstrates that when oom_center-1\n+        # and oom_noise-2 equal a standard 3*N oom, we get that\n+        # oom_noise_desired < oom_noise\n+        (10, 2, 9, 3),\n+        (1, -7, 0, -6),\n+        (2, -4, 0, -3),\n+        (1, -4, 0, -3),\n+        # Tests where oom_center <= oom_noise, those are probably covered by the\n+        # part where formatter.offset != 0\n+        (4,  4, 0, 3),\n+        (1,  4, 0, 3),\n+        (1,  3, 0, 3),\n+        (1,  2, 0, 0),\n+        (1,  1, 0, 0),\n+    ]\n+)\n+def test_engformatter_offset_oom(\n+    oom_center,\n+    oom_noise,\n+    oom_center_desired,\n+    oom_noise_desired\n+):\n+    UNIT = \"eV\"\n+    # Doesn't really matter here, but should be of order of magnitude ~= 1\n+    r = range(-5, 7)\n+    fig, ax = plt.subplots()\n+    # Use some random ugly number\n+    data_offset = 2.7149*10**oom_center\n+    ydata = data_offset + np.array(r, dtype=float)*10**oom_noise\n+    ax.plot(ydata)\n+    formatter = mticker.EngFormatter(useOffset=True, unit=UNIT)\n+    # So that offset strings will always have the same size\n+    formatter.ENG_PREFIXES[0] = \"_\"\n+    ax.yaxis.set_major_formatter(formatter)\n+    fig.canvas.draw()\n+    offsetGot = formatter.get_offset()\n+    ticksGot = [labl.get_text() for labl in ax.get_yticklabels()]\n+    # Predicting whether offset should be 0 or not is essentially testing\n+    # ScalarFormatter._compute_offset . This function is pretty complex and it\n+    # would be nice to test it, but this is out of scope for this test which\n+    # only makes sure that offset text and the ticks gets the correct unit\n+    # prefixes and the ticks.\n+    if formatter.offset:\n+        prefix_noise_got = offsetGot[2]\n+        prefix_noise_desired = formatter.ENG_PREFIXES[oom_noise_desired]\n+        prefix_center_got = offsetGot[-1-len(UNIT)]\n+        prefix_center_desired = formatter.ENG_PREFIXES[oom_center_desired]\n+        assert prefix_noise_desired == prefix_noise_got\n+        assert prefix_center_desired == prefix_center_got\n+        # Make sure the ticks didn't get the UNIT\n+        for tick in ticksGot:\n+            assert UNIT not in tick\n+    else:\n+        assert oom_center_desired == 0\n+        assert offsetGot == \"\"\n+        # Make sure the ticks contain now the prefixes\n+        for tick in ticksGot:\n+            # 0 is zero on all orders of magnitudes, no", "source": "def test_engformatter_offset_oom(\n    oom_center,\n    oom_noise,\n    oom_center_desired,\n    oom_noise_desired\n):\n    UNIT = \"eV\"\n    # Doesn't really matter here, but should be of order of magnitude ~= 1\n    r = range(-5, 7)\n    fig, ax = plt.subplots()\n    # Use some random ugly number\n    data_offset = 2.7149*10**oom_center\n    ydata = data_offset + np.array(r, dtype=float)*10**oom_noise\n    ax.plot(ydata)\n    formatter = mticker.EngFormatter(useOffset=True, unit=UNIT)\n    # So that offset strings will always have the same size\n    formatter.ENG_PREFIXES[0] = \"_\"\n    ax.yaxis.set_major_formatter(formatter)\n    fig.canvas.draw()\n    offsetGot = formatter.get_offset()\n    ticksGot = [labl.get_text() for labl in ax.get_yticklabels()]\n    # Predicting whether offset should be 0 or not is essentially testing\n    # ScalarFormatter._compute_offset . This function is pretty complex and it\n    # would be nice to test it, but this is out of scope for this test which\n    # only makes sure that offset text and the ticks gets the correct unit\n    # prefixes and the ticks.\n    if formatter.offset:\n        prefix_noise_got = offsetGot[2]\n        prefix_noise_desired = formatter.ENG_PREFIXES[oom_noise_desired]\n        prefix_center_got = offsetGot[-1-len(UNIT)]\n        prefix_center_desired = formatter.ENG_PREFIXES[oom_center_desired]\n        assert prefix_noise_desired == prefix_noise_got\n        assert prefix_center_desired == prefix_center_got\n        # Make sure the ticks didn't get the UNIT\n        for tick in ticksGot:\n            assert UNIT not in tick\n    else:\n        assert oom_center_desired == 0\n        assert offsetGot == \"\"\n        # Make sure the ticks contain now the prefixes\n        for tick in ticksGot:\n            # 0 is zero on all orders of magnitudes, no\n            if tick[0] == \"0\":\n                prefixIdx = 0\n            else:\n                prefixIdx = oom_noise_desired\n            assert tick.endswith(formatter.ENG_PREFIXES[prefixIdx] + UNIT)", "source_start_line": 1621, "tokens": ["def", "test_engformatter_offset_oom", "(", "oom_center", ",", "oom_noise", ",", "oom_center_desired", ",", "oom_noise_desired", ")", ":", "UNIT", "=", "\"eV\"", "r", "=", "range", "(", "-", "5", ",", "7", ")", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "data_offset", "=", "2.7149", "*", "10", "**", "oom_center", "ydata", "=", "data_offset", "+", "np", ".", "array", "(", "r", ",", "dtype", "=", "float", ")", "*", "10", "**", "oom_noise", "ax", ".", "plot", "(", "ydata", ")", "formatter", "=", "mticker", ".", "EngFormatter", "(", "useOffset", "=", "True", ",", "unit", "=", "UNIT", ")", "formatter", ".", "ENG_PREFIXES", "[", "0", "]", "=", "\"_\"", "ax", ".", "yaxis", ".", "set_major_formatter", "(", "formatter", ")", "fig", ".", "canvas", ".", "draw", "(", ")", "offsetGot", "=", "formatter", ".", "get_offset", "(", ")", "ticksGot", "=", "[", "labl", ".", "get_text", "(", ")", "for", "labl", "in", "ax", ".", "get_yticklabels", "(", ")", "]", "if", "formatter", ".", "offset", ":", "prefix_noise_got", "=", "offsetGot", "[", "2", "]", "prefix_noise_desired", "=", "formatter", ".", "ENG_PREFIXES", "[", "oom_noise_desired", "]", "prefix_center_got", "=", "offsetGot", "[", "-", "1", "-", "len", "(", "UNIT", ")", "]", "prefix_center_desired", "=", "formatter", ".", "ENG_PREFIXES", "[", "oom_center_desired", "]", "assert", "prefix_noise_desired", "==", "prefix_noise_got", "assert", "prefix_center_desired", "==", "prefix_center_got", "for", "tick", "in", "ticksGot", ":", "assert", "UNIT", "not", "in", "tick", "else", ":", "assert", "oom_center_desired", "==", "0", "assert", "offsetGot", "==", "\"\"", "for", "tick", "in", "ticksGot", ":", "if", "tick", "[", "0", "]", "==", "\"0\"", ":", "prefixIdx", "=", "0", "else", ":", "prefixIdx", "=", "oom_noise_desired", "assert", "tick", ".", "endswith", "(", "formatter", ".", "ENG_PREFIXES", "[", "prefixIdx", "]", "+", "UNIT", ")"], "to_mask": {"VAR": ["UNIT", "ax", "data_offset", "fig", "formatter", "offsetGot", "oom_center", "oom_center_desired", "oom_noise", "oom_noise_desired", "prefixIdx", "prefix_center_desired", "prefix_center_got", "prefix_noise_desired", "prefix_noise_got", "r", "tick", "ticksGot", "ydata"], "METHOD": ["EngFormatter", "array", "draw", "endswith", "get_offset", "get_text", "get_yticklabels", "len", "plot", "range", "set_major_formatter", "subplots"]}, "attention_idx_tokens": [null, null], "patch": "@@ -1594,6 +1594,79 @@\n         assert x_tick_label_text == ['$0$', '$500$', '$1$ k']\n \n \n+@pytest.mark.parametrize(\n+    'oom_center, oom_noise, oom_center_desired, oom_noise_desired', [\n+        (11, 1, 9, 0),\n+        (13, 7, 12, 6),\n+        (1, -2, 0, -3),\n+        (3, -2, 3, -3),\n+        (5, -3, 3, -3),\n+        (2, -3, 0, -3),\n+        # The following sets of parameters demonstrates that when oom_center-1\n+        # and oom_noise-2 equal a standard 3*N oom, we get that\n+        # oom_noise_desired < oom_noise\n+        (10, 2, 9, 3),\n+        (1, -7, 0, -6),\n+        (2, -4, 0, -3),\n+        (1, -4, 0, -3),\n+        # Tests where oom_center <= oom_noise, those are probably covered by the\n+        # part where formatter.offset != 0\n+        (4,  4, 0, 3),\n+        (1,  4, 0, 3),\n+        (1,  3, 0, 3),\n+        (1,  2, 0, 0),\n+        (1,  1, 0, 0),\n+    ]\n+)\n+def test_engformatter_offset_oom(\n+    oom_center,\n+    oom_noise,\n+    oom_center_desired,\n+    oom_noise_desired\n+):\n+    UNIT = \"eV\"\n+    # Doesn't really matter here, but should be of order of magnitude ~= 1\n+    r = range(-5, 7)\n+    fig, ax = plt.subplots()\n+    # Use some random ugly number\n+    data_offset = 2.7149*10**oom_center\n+    ydata = data_offset + np.array(r, dtype=float)*10**oom_noise\n+    ax.plot(ydata)\n+    formatter = mticker.EngFormatter(useOffset=True, unit=UNIT)\n+    # So that offset strings will always have the same size\n+    formatter.ENG_PREFIXES[0] = \"_\"\n+    ax.yaxis.set_major_formatter(formatter)\n+    fig.canvas.draw()\n+    offsetGot = formatter.get_offset()\n+    ticksGot = [labl.get_text() for labl in ax.get_yticklabels()]\n+    # Predicting whether offset should be 0 or not is essentially testing\n+    # ScalarFormatter._compute_offset . This function is pretty complex and it\n+    # would be nice to test it, but this is out of scope for this test which\n+    # only makes sure that offset text and the ticks gets the correct unit\n+    # prefixes and the ticks.\n+    if formatter.offset:\n+        prefix_noise_got = offsetGot[2]\n+        prefix_noise_desired = formatter.ENG_PREFIXES[oom_noise_desired]\n+        prefix_center_got = offsetGot[-1-len(UNIT)]\n+        prefix_center_desired = formatter.ENG_PREFIXES[oom_center_desired]\n+        assert prefix_noise_desired == prefix_noise_got\n+        assert prefix_center_desired == prefix_center_got\n+        # Make sure the ticks didn't get the UNIT\n+        for tick in ticksGot:\n+            assert UNIT not in tick\n+    else:\n+        assert oom_center_desired == 0\n+        assert offsetGot == \"\"\n+        # Make sure the ticks contain now the prefixes\n+        for tick in ticksGot:\n+            # 0 is zero on all orders of magnitudes, no", "ext_attention_idx_tokens": [0, 226], "uid": "c4285e25", "question": "This sentence appears to be incomplete?", "code": "def test engformatter offset oom oom center oom noise oom center desired oom noise desired UNIT \"eV\" # Doesn t really matter here but should be of order of magnitude ~ 1 r range -5 7 fig ax plt subplots # Use some random ugly number data offset 2 7149*10**oom center ydata data offset + np array r dtype float *10**oom noise ax plot ydata formatter mticker EngFormatter useOffset True unit UNIT # So that offset strings will always have the same size formatter ENG PREFIXES[0] \" \" ax yaxis set major formatter formatter fig canvas draw offsetGot formatter get offset ticksGot [labl get text for labl in ax get yticklabels ] # Predicting whether offset should be 0 or not is essentially testing # ScalarFormatter compute offset This function is pretty complex and it # would be nice to test it but this is out of scope for this test which # only makes sure that offset text and the ticks gets the correct unit # prefixes and the ticks if formatter offset prefix noise got offsetGot[2] prefix noise desired formatter ENG PREFIXES[oom noise desired] prefix center got offsetGot[-1-len UNIT ] prefix center desired formatter ENG PREFIXES[oom center desired] assert prefix noise desired prefix noise got assert prefix center desired prefix center got # Make sure the ticks didn t get the UNIT for tick in ticksGot assert UNIT not in tick else assert oom center desired 0 assert offsetGot \"\" # Make sure the ticks contain now the prefixes for tick in ticksGot # 0 is zero on all orders of magnitudes no if tick[0] \"0\" prefixIdx 0 else prefixIdx oom noise desired assert tick endswith formatter ENG PREFIXES[prefixIdx] + UNIT"}
{"message": "> Why a raw string?\r\n\r\nNot an aware choice - it is a remnant from old code.", "timestamp": "2024-10-12T21:09:34Z", "file_name": "lib/matplotlib/ticker.py", "range": {"start_line": 1483, "end_line": 1483, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1797777165", "html_url": "https://github.com/matplotlib/matplotlib/pull/28495#discussion_r1797777165", "attention_area": "                s = fr'${sciNotStr}{offsetStr}$'", "file_path": "files/86/11/00001186.py", "old_file_path": "files/87/11/00001187.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1390,76 +1407,123 @@ def __init__(self, unit=\"\", places=None, sep=\" \", *, usetex=None,\n         useMathText : bool, default: :rc:`axes.formatter.use_mathtext`\n             To enable/disable the use mathtext for rendering the numbers in\n             the formatter.\n+        useOffset : bool or float, default: False\n+            Whether to use offset notation with :math:`10^{3*N}` based prefixes.\n+            This features allows showing an offset with standard SI order of\n+            magnitude prefix near the axis. Offset is computed similarly to\n+            how `ScalarFormatter` computes it internally, but here you are\n+            guaranteed to get an offset which will make the tick labels exceed\n+            3 digits. See also `.set_useOffset`.\n+\n+        .. versionadded:: 3.10\n         \"\"\"\n         self.unit = unit\n         self.places = places\n         self.sep = sep\n-        self.set_usetex(usetex)\n-        self.set_useMathText(useMathText)\n-\n-    def get_usetex(self):\n-        return self._usetex\n-\n-    def set_usetex(self, val):\n-        if val is None:\n-            self._usetex = mpl.rcParams['text.usetex']\n-        else:\n-            self._usetex = val\n-\n-    usetex = property(fget=get_usetex, fset=set_usetex)\n-\n-    def get_useMathText(self):\n-        return self._useMathText\n+        super().__init__(\n+            useOffset=useOffset,\n+            useMathText=useMathText,\n+            useLocale=False,\n+            usetex=usetex,\n+        )\n \n-    def set_useMathText(self, val):\n-        if val is None:\n-            self._useMathText = mpl.rcParams['axes.formatter.use_mathtext']\n+    def __call__(self, x, pos=None):\n+        \"\"\"\n+        Return the format for tick value *x* at position *pos*. If there is no\n+        currently offset in the data, it returns the best engineering formatting\n+        that fits the given argument, independently.\n+        \"\"\"\n+        if len(self.locs) == 0 or self.offset == 0:\n+            return self.fix_minus(self.format_data(x))\n         else:\n-            self._useMathText = val\n+            xp = (x - self.offset) / (10. ** self.orderOfMagnitude)\n+            if abs(xp) < 1e-8:\n+                xp = 0\n+            return self._format_maybe_minus_and_locale(self.format, xp)\n \n-    useMathText = property(fget=get_useMathText, fset=set_useMathText)\n+    def set_locs(self, locs):\n+        # docstring inherited\n+        self.locs = locs\n+        if len(self.locs) > 0:\n+            vmin, vmax = sorted(self.axis.get_view_interval())\n+            if self._useOffset:\n+                self._compute_offset()\n+                if self.offset != 0:\n+                    # We don't want to use the offset computed by\n+                    # self._compute_offset because it rounds the offset unaware\n+                    # of our engineering prefixes preference, and this can\n+                    # cause ticks with 4+ digits to appear. These ticks are\n+                    # slightly less readable, so if offset is justified\n+                    # (decided by self._compute_offset) we set it to better\n+                    # value:\n+                    self.offset = round((vmin + vmax)/2, 3)\n+            # Use log1000 to use engineers' oom standards\n+            self.orderOfMagnitude = math.floor(math.log(vmax - vmin, 1000))*3\n+            self._set_format()\n \n-    def __call__(self, x, pos=None):\n-        s = f\"{self.format_eng(x)}{self.unit}\"\n-        # Remove the trailing separator when there is neither prefix nor unit\n-        if self.sep and s.endswith(self.sep):\n-            s = s[:-len(self.sep)]\n-        return self.fix_minus(s)\n+    # Simplify a bit ScalarFormatter.get_offset: We always want to use\n+    # self.format_data. Also we want to return a non-empty string only if there\n+    # is an offset, no matter what is self.orderOfMagnitude. if there is an\n+    # offset OTH, self.orderOfMagnitude is consulted. This behavior is verified\n+    # in `test_ticker.py`.\n+    def get_offset(self):\n+        # docstring inherited\n+        if len(self.locs) == 0:\n+            return ''\n+        if self.offset:\n+            offsetStr = ''\n+            if self.offset:\n+                offsetStr = self.format_data(self.offset)\n+                if self.offset > 0:\n+                    offsetStr = '+' + offsetStr\n+            sciNotStr = self.format_data(10 ** self.orderOfMagnitude)\n+            if self._useMathText or self._usetex:\n+                if sciNotStr != '':\n+                    sciNotStr = r'\\times%s' % sciNotStr\n+                s = fr'${sciNotStr}{offsetStr}$'", "source": "def get_offset(self):\n        # docstring inherited\n        if len(self.locs) == 0:\n            return ''\n        if self.offset:\n            offsetStr = ''\n            if self.offset:\n                offsetStr = self.format_data(self.offset)\n                if self.offset > 0:\n                    offsetStr = '+' + offsetStr\n            sciNotStr = self.format_data(10 ** self.orderOfMagnitude)\n            if self._useMathText or self._usetex:\n                if sciNotStr != '':\n                    sciNotStr = r'\\times%s' % sciNotStr\n                s = fr'${sciNotStr}{offsetStr}$'\n            else:\n                s = ''.join((sciNotStr, offsetStr))\n            return self.fix_minus(s)\n        return ''", "source_start_line": 1469, "tokens": ["def", "get_offset", "(", "self", ")", ":", "if", "len", "(", "self", ".", "locs", ")", "==", "0", ":", "return", "''", "if", "self", ".", "offset", ":", "offsetStr", "=", "''", "if", "self", ".", "offset", ":", "offsetStr", "=", "self", ".", "format_data", "(", "self", ".", "offset", ")", "if", "self", ".", "offset", ">", "0", ":", "offsetStr", "=", "'+'", "+", "offsetStr", "sciNotStr", "=", "self", ".", "format_data", "(", "10", "**", "self", ".", "orderOfMagnitude", ")", "if", "self", ".", "_useMathText", "or", "self", ".", "_usetex", ":", "if", "sciNotStr", "!=", "''", ":", "sciNotStr", "=", "r'\\times%s'", "%", "sciNotStr", "s", "=", "fr'", "{", "sciNotStr", "}", "{", "offsetStr", "}", "'", "else", ":", "s", "=", "''", ".", "join", "(", "(", "sciNotStr", ",", "offsetStr", ")", ")", "return", "self", ".", "fix_minus", "(", "s", ")", "return", "''"], "to_mask": {"VAR": ["offsetStr", "s", "sciNotStr", "self"], "METHOD": ["fix_minus", "format_data", "join", "len"]}, "attention_idx_tokens": [84, 93], "patch": "@@ -1390,76 +1407,123 @@\n         useMathText : bool, default: :rc:`axes.formatter.use_mathtext`\n             To enable/disable the use mathtext for rendering the numbers in\n             the formatter.\n+        useOffset : bool or float, default: False\n+            Whether to use offset notation with :math:`10^{3*N}` based prefixes.\n+            This features allows showing an offset with standard SI order of\n+            magnitude prefix near the axis. Offset is computed similarly to\n+            how `ScalarFormatter` computes it internally, but here you are\n+            guaranteed to get an offset which will make the tick labels exceed\n+            3 digits. See also `.set_useOffset`.\n+\n+        .. versionadded:: 3.10\n         \"\"\"\n         self.unit = unit\n         self.places = places\n         self.sep = sep\n-        self.set_usetex(usetex)\n-        self.set_useMathText(useMathText)\n-\n-    def get_usetex(self):\n-        return self._usetex\n-\n-    def set_usetex(self, val):\n-        if val is None:\n-            self._usetex = mpl.rcParams['text.usetex']\n-        else:\n-            self._usetex = val\n+        super().__init__(\n+            useOffset=useOffset,\n+            useMathText=useMathText,\n+            useLocale=False,\n+            usetex=usetex,\n+        )\n \n-    usetex = property(fget=get_usetex, fset=set_usetex)\n-\n-    def get_useMathText(self):\n-        return self._useMathText\n-\n-    def set_useMathText(self, val):\n-        if val is None:\n-            self._useMathText = mpl.rcParams['axes.formatter.use_mathtext']\n+    def __call__(self, x, pos=None):\n+        \"\"\"\n+        Return the format for tick value *x* at position *pos*. If there is no\n+        currently offset in the data, it returns the best engineering formatting\n+        that fits the given argument, independently.\n+        \"\"\"\n+        if len(self.locs) == 0 or self.offset == 0:\n+            return self.fix_minus(self.format_data(x))\n         else:\n-            self._useMathText = val\n+            xp = (x - self.offset) / (10. ** self.orderOfMagnitude)\n+            if abs(xp) < 1e-8:\n+                xp = 0\n+            return self._format_maybe_minus_and_locale(self.format, xp)\n \n-    useMathText = property(fget=get_useMathText, fset=set_useMathText)\n+    def set_locs(self, locs):\n+        # docstring inherited\n+        self.locs = locs\n+        if len(self.locs) > 0:\n+            vmin, vmax = sorted(self.axis.get_view_interval())\n+            if self._useOffset:\n+                self._compute_offset()\n+                if self.offset != 0:\n+                    # We don't want to use the offset computed by\n+                    # self._compute_offset because it rounds the offset unaware\n+                    # of our engineering prefixes preference, and this can\n+                    # cause ticks with 4+ digits to appear. These ticks are\n+                    # slightly less readable, so if offset is justified\n+                    # (decided by self._compute_offset) we set it to better\n+                    # value:\n+                    self.offset = round((vmin + vmax)/2, 3)\n+            # Use log1000 to use engineers' oom standards\n+            self.orderOfMagnitude = math.floor(math.log(vmax - vmin, 1000))*3\n+            self._set_format()\n \n-    def __call__(self, x, pos=None):\n-        s = f\"{self.format_eng(x)}{self.unit}\"\n-        # Remove the trailing separator when there is neither prefix nor unit\n-        if self.sep and s.endswith(self.sep):\n-            s = s[:-len(self.sep)]\n-        return self.fix_minus(s)\n+    # Simplify a bit ScalarFormatter.get_offset: We always want to use\n+    # self.format_data. Also we want to return a non-empty string only if there\n+    # is an offset, no matter what is self.orderOfMagnitude. if there is an\n+    # offset OTH, self.orderOfMagnitude is consulted. This behavior is verified\n+    # in `test_ticker.py`.\n+    def get_offset(self):\n+        # docstring inherited\n+        if len(self.locs) == 0:\n+            return ''\n+        if self.offset:\n+            offsetStr = ''\n+            if self.offset:\n+                offsetStr = self.format_data(self.offset)\n+                if self.offset > 0:\n+                    offsetStr = '+' + offsetStr\n+            sciNotStr = self.format_data(10 ** self.orderOfMagnitude)\n+            if self._useMathText or self._usetex:\n+                if sciNotStr != '':\n+                    sciNotStr = r'\\times%s' % sciNotStr\n+                s = fr'${sciNotStr}{offsetStr}$'", "ext_attention_idx_tokens": [0, 116], "uid": "3164b369", "question": "> Why a raw string?    Not an aware choice - it is a remnant from old code.", "code": "def get offset self # docstring inherited if len self locs 0 return if self offset offsetStr if self offset offsetStr self format data self offset if self offset > 0 offsetStr + + offsetStr sciNotStr self format data 10 ** self orderOfMagnitude if self useMathText or self usetex if sciNotStr ! sciNotStr r \\times%s % sciNotStr s fr ${sciNotStr}{offsetStr}$ else s join sciNotStr offsetStr return self fix minus s return"}
{"message": "> That pytest's assertion rewriting isn't showing you a breakdown of the results is a bug, and `--showlocals` is a reasonable workaround, but I wouldn't leave a comment about it.\r\n\r\nWhat do you mean by pytest's assertion rewriting?", "timestamp": "2024-10-23T06:18:21Z", "file_name": "lib/matplotlib/tests/test_ticker.py", "range": {"start_line": 1646, "end_line": 1646, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1811945532", "html_url": "https://github.com/matplotlib/matplotlib/pull/28495#discussion_r1811945532", "attention_area": "        # view their values with pytest --showlocals.", "file_path": "files/35/12/00001235.py", "old_file_path": "files/32/12/00001232.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1591,6 +1591,79 @@ def test_engformatter_usetex_useMathText():\n         assert x_tick_label_text == ['$0$', '$500$', '$1$ k']\n \n \n+@pytest.mark.parametrize(\n+    'oom_center, oom_noise, oom_center_desired, oom_noise_desired', [\n+        (11, 1, 9, 0),\n+        (13, 7, 12, 6),\n+        (1, -2, 0, -3),\n+        (3, -2, 3, -3),\n+        (5, -3, 3, -3),\n+        (2, -3, 0, -3),\n+        # The following sets of parameters demonstrates that when oom_center-1\n+        # and oom_noise-2 equal a standard 3*N oom, we get that\n+        # oom_noise_desired < oom_noise\n+        (10, 2, 9, 3),\n+        (1, -7, 0, -6),\n+        (2, -4, 0, -3),\n+        (1, -4, 0, -3),\n+        # Tests where oom_center <= oom_noise, those are probably covered by the\n+        # part where formatter.offset != 0\n+        (4,  4, 0, 3),\n+        (1,  4, 0, 3),\n+        (1,  3, 0, 3),\n+        (1,  2, 0, 0),\n+        (1,  1, 0, 0),\n+    ]\n+)\n+def test_engformatter_offset_oom(\n+    oom_center,\n+    oom_noise,\n+    oom_center_desired,\n+    oom_noise_desired\n+):\n+    UNIT = \"eV\"\n+    # Doesn't really matter here, but should be of order of magnitude ~= 1\n+    fig, ax = plt.subplots()\n+    # Use some random ugly number\n+    data_offset = 2.7149*10**oom_center\n+    ydata = data_offset + np.arange(-5, 7, dtype=float)*10**oom_noise\n+    ax.plot(ydata)\n+    formatter = mticker.EngFormatter(useOffset=True, unit=UNIT)\n+    # So that offset strings will always have the same size\n+    formatter.ENG_PREFIXES[0] = \"_\"\n+    ax.yaxis.set_major_formatter(formatter)\n+    fig.canvas.draw()\n+    offset_got = formatter.get_offset()\n+    ticks_got = [labl.get_text() for labl in ax.get_yticklabels()]\n+    # Predicting whether offset should be 0 or not is essentially testing\n+    # ScalarFormatter._compute_offset . This function is pretty complex and it\n+    # would be nice to test it, but this is out of scope for this test which\n+    # only makes sure that offset text and the ticks gets the correct unit\n+    # prefixes and the ticks.\n+    if formatter.offset:\n+        # These prefix_ variables are used only once, so we could have inlined\n+        # them all, but it is more comfortable in case of tests breakages to\n+        # view their values with pytest --showlocals.", "source": "def test_engformatter_offset_oom(\n    oom_center,\n    oom_noise,\n    oom_center_desired,\n    oom_noise_desired\n):\n    UNIT = \"eV\"\n    # Doesn't really matter here, but should be of order of magnitude ~= 1\n    fig, ax = plt.subplots()\n    # Use some random ugly number\n    data_offset = 2.7149*10**oom_center\n    ydata = data_offset + np.arange(-5, 7, dtype=float)*10**oom_noise\n    ax.plot(ydata)\n    formatter = mticker.EngFormatter(useOffset=True, unit=UNIT)\n    # So that offset strings will always have the same size\n    formatter.ENG_PREFIXES[0] = \"_\"\n    ax.yaxis.set_major_formatter(formatter)\n    fig.canvas.draw()\n    offset_got = formatter.get_offset()\n    ticks_got = [labl.get_text() for labl in ax.get_yticklabels()]\n    # Predicting whether offset should be 0 or not is essentially testing\n    # ScalarFormatter._compute_offset . This function is pretty complex and it\n    # would be nice to test it, but this is out of scope for this test which\n    # only makes sure that offset text and the ticks gets the correct unit\n    # prefixes and the ticks.\n    if formatter.offset:\n        # These prefix_ variables are used only once, so we could have inlined\n        # them all, but it is more comfortable in case of tests breakages to\n        # view their values with pytest --showlocals.\n        prefix_noise_got = offset_got[2]\n        prefix_noise_desired = formatter.ENG_PREFIXES[oom_noise_desired]\n        prefix_center_got = offset_got[-1-len(UNIT)]\n        prefix_center_desired = formatter.ENG_PREFIXES[oom_center_desired]\n        assert prefix_noise_desired == prefix_noise_got\n        assert prefix_center_desired == prefix_center_got\n        # Make sure the ticks didn't get the UNIT\n        for tick in ticks_got:\n            assert UNIT not in tick\n    else:\n        assert oom_center_desired == 0\n        assert offset_got == \"\"\n        # Make sure the ticks contain now the prefixes\n        for tick in ticks_got:\n            # 0 is zero on all orders of magnitudes, no matter what is\n            # oom_noise_desired\n            prefix_idx = 0 if tick[0] == \"0\" else oom_noise_desired\n            assert tick.endswith(formatter.ENG_PREFIXES[prefix_idx] + UNIT)", "source_start_line": 1618, "tokens": ["def", "test_engformatter_offset_oom", "(", "oom_center", ",", "oom_noise", ",", "oom_center_desired", ",", "oom_noise_desired", ")", ":", "UNIT", "=", "\"eV\"", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "data_offset", "=", "2.7149", "*", "10", "**", "oom_center", "ydata", "=", "data_offset", "+", "np", ".", "arange", "(", "-", "5", ",", "7", ",", "dtype", "=", "float", ")", "*", "10", "**", "oom_noise", "ax", ".", "plot", "(", "ydata", ")", "formatter", "=", "mticker", ".", "EngFormatter", "(", "useOffset", "=", "True", ",", "unit", "=", "UNIT", ")", "formatter", ".", "ENG_PREFIXES", "[", "0", "]", "=", "\"_\"", "ax", ".", "yaxis", ".", "set_major_formatter", "(", "formatter", ")", "fig", ".", "canvas", ".", "draw", "(", ")", "offset_got", "=", "formatter", ".", "get_offset", "(", ")", "ticks_got", "=", "[", "labl", ".", "get_text", "(", ")", "for", "labl", "in", "ax", ".", "get_yticklabels", "(", ")", "]", "if", "formatter", ".", "offset", ":", "prefix_noise_got", "=", "offset_got", "[", "2", "]", "prefix_noise_desired", "=", "formatter", ".", "ENG_PREFIXES", "[", "oom_noise_desired", "]", "prefix_center_got", "=", "offset_got", "[", "-", "1", "-", "len", "(", "UNIT", ")", "]", "prefix_center_desired", "=", "formatter", ".", "ENG_PREFIXES", "[", "oom_center_desired", "]", "assert", "prefix_noise_desired", "==", "prefix_noise_got", "assert", "prefix_center_desired", "==", "prefix_center_got", "for", "tick", "in", "ticks_got", ":", "assert", "UNIT", "not", "in", "tick", "else", ":", "assert", "oom_center_desired", "==", "0", "assert", "offset_got", "==", "\"\"", "for", "tick", "in", "ticks_got", ":", "prefix_idx", "=", "0", "if", "tick", "[", "0", "]", "==", "\"0\"", "else", "oom_noise_desired", "assert", "tick", ".", "endswith", "(", "formatter", ".", "ENG_PREFIXES", "[", "prefix_idx", "]", "+", "UNIT", ")"], "to_mask": {"VAR": ["UNIT", "ax", "data_offset", "fig", "formatter", "offset_got", "oom_center", "oom_center_desired", "oom_noise", "oom_noise_desired", "prefix_center_desired", "prefix_center_got", "prefix_idx", "prefix_noise_desired", "prefix_noise_got", "tick", "ticks_got", "ydata"], "METHOD": ["EngFormatter", "arange", "draw", "endswith", "get_offset", "get_text", "get_yticklabels", "len", "plot", "set_major_formatter", "subplots"]}, "attention_idx_tokens": [null, null], "patch": "@@ -1591,6 +1591,79 @@\n         assert x_tick_label_text == ['$0$', '$500$', '$1$ k']\n \n \n+@pytest.mark.parametrize(\n+    'oom_center, oom_noise, oom_center_desired, oom_noise_desired', [\n+        (11, 1, 9, 0),\n+        (13, 7, 12, 6),\n+        (1, -2, 0, -3),\n+        (3, -2, 3, -3),\n+        (5, -3, 3, -3),\n+        (2, -3, 0, -3),\n+        # The following sets of parameters demonstrates that when oom_center-1\n+        # and oom_noise-2 equal a standard 3*N oom, we get that\n+        # oom_noise_desired < oom_noise\n+        (10, 2, 9, 3),\n+        (1, -7, 0, -6),\n+        (2, -4, 0, -3),\n+        (1, -4, 0, -3),\n+        # Tests where oom_center <= oom_noise, those are probably covered by the\n+        # part where formatter.offset != 0\n+        (4,  4, 0, 3),\n+        (1,  4, 0, 3),\n+        (1,  3, 0, 3),\n+        (1,  2, 0, 0),\n+        (1,  1, 0, 0),\n+    ]\n+)\n+def test_engformatter_offset_oom(\n+    oom_center,\n+    oom_noise,\n+    oom_center_desired,\n+    oom_noise_desired\n+):\n+    UNIT = \"eV\"\n+    # Doesn't really matter here, but should be of order of magnitude ~= 1\n+    fig, ax = plt.subplots()\n+    # Use some random ugly number\n+    data_offset = 2.7149*10**oom_center\n+    ydata = data_offset + np.arange(-5, 7, dtype=float)*10**oom_noise\n+    ax.plot(ydata)\n+    formatter = mticker.EngFormatter(useOffset=True, unit=UNIT)\n+    # So that offset strings will always have the same size\n+    formatter.ENG_PREFIXES[0] = \"_\"\n+    ax.yaxis.set_major_formatter(formatter)\n+    fig.canvas.draw()\n+    offset_got = formatter.get_offset()\n+    ticks_got = [labl.get_text() for labl in ax.get_yticklabels()]\n+    # Predicting whether offset should be 0 or not is essentially testing\n+    # ScalarFormatter._compute_offset . This function is pretty complex and it\n+    # would be nice to test it, but this is out of scope for this test which\n+    # only makes sure that offset text and the ticks gets the correct unit\n+    # prefixes and the ticks.\n+    if formatter.offset:\n+        # These prefix_ variables are used only once, so we could have inlined\n+        # them all, but it is more comfortable in case of tests breakages to\n+        # view their values with pytest --showlocals.", "ext_attention_idx_tokens": [0, 216], "uid": "c02c0353", "question": "> That pytest's assertion rewriting isn't showing you a breakdown of the results is a bug, and `--showlocals` is a reasonable workaround, but I wouldn't leave a comment about it.    What do you mean by pytest's assertion rewriting?", "code": "def test engformatter offset oom oom center oom noise oom center desired oom noise desired UNIT \"eV\" # Doesn t really matter here but should be of order of magnitude ~ 1 fig ax plt subplots # Use some random ugly number data offset 2 7149*10**oom center ydata data offset + np arange -5 7 dtype float *10**oom noise ax plot ydata formatter mticker EngFormatter useOffset True unit UNIT # So that offset strings will always have the same size formatter ENG PREFIXES[0] \" \" ax yaxis set major formatter formatter fig canvas draw offset got formatter get offset ticks got [labl get text for labl in ax get yticklabels ] # Predicting whether offset should be 0 or not is essentially testing # ScalarFormatter compute offset This function is pretty complex and it # would be nice to test it but this is out of scope for this test which # only makes sure that offset text and the ticks gets the correct unit # prefixes and the ticks if formatter offset # These prefix variables are used only once so we could have inlined # them all but it is more comfortable in case of tests breakages to # view their values with pytest --showlocals prefix noise got offset got[2] prefix noise desired formatter ENG PREFIXES[oom noise desired] prefix center got offset got[-1-len UNIT ] prefix center desired formatter ENG PREFIXES[oom center desired] assert prefix noise desired prefix noise got assert prefix center desired prefix center got # Make sure the ticks didn t get the UNIT for tick in ticks got assert UNIT not in tick else assert oom center desired 0 assert offset got \"\" # Make sure the ticks contain now the prefixes for tick in ticks got # 0 is zero on all orders of magnitudes no matter what is # oom noise desired prefix idx 0 if tick[0] \"0\" else oom noise desired assert tick endswith formatter ENG PREFIXES[prefix idx] + UNIT"}
{"message": "This is vague and confusing.  Either there is a plan, in which case explain, or just state the possible issues a user may experience here?  \r\n\r\nI'm also not clear why this is \"provisional\" at all? Do you mean it may go away again?  Why would that happen?  ", "timestamp": "2024-10-29T17:36:02Z", "file_name": "lib/matplotlib/__init__.py", "range": {"start_line": 1317, "end_line": 1317, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1821284622", "html_url": "https://github.com/matplotlib/matplotlib/pull/29039#discussion_r1821284622", "attention_area": "", "file_path": "files/80/12/00001280.py", "old_file_path": "files/81/12/00001281.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1296,15 +1296,37 @@ def use(backend, *, force=True):\n     rcParams['backend'] = os.environ.get('MPLBACKEND')\n \n \n-def get_backend():\n+def get_backend(*, resolve=True):\n     \"\"\"\n     Return the name of the current backend.\n \n+    Parameters\n+    ----------\n+    resolve : bool, default: True\n+        Whether to trigger backend resolution if no backend has been\n+        selected so far. If True, this ensures that a valid backend\n+        is returned. If False, this returns None if no backend has been\n+        selected so far.\n+\n+        .. admonition:: Provisional resolve flag\n+\n+           The *resolve* flag is introduced provisionally in the anticipation\n+           of backend resolution refactoring. We don't guarantee API stability\n+           for now, but if all plays out well, the provisional availability\n+           will prolong the range of supported releases for the migration period.\n+", "source": "def get_backend(*, resolve=True):\n    \"\"\"\n    Return the name of the current backend.\n\n    Parameters\n    ----------\n    resolve : bool, default: True\n        Whether to trigger backend resolution if no backend has been\n        selected so far. If True, this ensures that a valid backend\n        is returned. If False, this returns None if no backend has been\n        selected so far.\n\n        .. admonition:: Provisional resolve flag\n\n           The *resolve* flag is introduced provisionally in the anticipation\n           of backend resolution refactoring. We don't guarantee API stability\n           for now, but if all plays out well, the provisional availability\n           will prolong the range of supported releases for the migration period.\n\n    See Also\n    --------\n    matplotlib.use\n    \"\"\"\n    if resolve:\n        return rcParams['backend']\n    else:\n        backend = rcParams._get('backend')\n        if backend is rcsetup._auto_backend_sentinel():\n            return None\n        else:\n            return backend", "source_start_line": 1299, "tokens": ["def", "get_backend", "(", "*", ",", "resolve", "=", "True", ")", ":", "\"\"\"    Return the name of the current backend.    Parameters    ----------    resolve : bool, default: True        Whether to trigger backend resolution if no backend has been        selected so far. If True, this ensures that a valid backend        is returned. If False, this returns None if no backend has been        selected so far.        .. admonition:: Provisional resolve flag           The *resolve* flag is introduced provisionally in the anticipation           of backend resolution refactoring. We don't guarantee API stability           for now, but if all plays out well, the provisional availability           will prolong the range of supported releases for the migration period.    See Also    --------    matplotlib.use    \"\"\"", "if", "resolve", ":", "return", "rcParams", "[", "'backend'", "]", "else", ":", "backend", "=", "rcParams", ".", "_get", "(", "'backend'", ")", "if", "backend", "is", "rcsetup", ".", "_auto_backend_sentinel", "(", ")", ":", "return", "None", "else", ":", "return", "backend"], "to_mask": {"VAR": ["backend", "resolve"], "METHOD": ["_auto_backend_sentinel", "_get"]}, "attention_idx_tokens": [null, null], "patch": "@@ -1296,15 +1296,37 @@\n     rcParams['backend'] = os.environ.get('MPLBACKEND')\n \n \n-def get_backend():\n+def get_backend(*, resolve=True):\n     \"\"\"\n     Return the name of the current backend.\n \n+    Parameters\n+    ----------\n+    resolve : bool, default: True\n+        Whether to trigger backend resolution if no backend has been\n+        selected so far. If True, this ensures that a valid backend\n+        is returned. If False, this returns None if no backend has been\n+        selected so far.\n+\n+        .. admonition:: Provisional resolve flag\n+\n+           The *resolve* flag is introduced provisionally in the anticipation\n+           of backend resolution refactoring. We don't guarantee API stability\n+           for now, but if all plays out well, the provisional availability\n+           will prolong the range of supported releases for the migration period.\n+", "ext_attention_idx_tokens": [0, 43], "uid": "8f2f566c", "question": "This is vague and confusing.  Either there is a plan, in which case explain, or just state the possible issues a user may experience here?      I'm also not clear why this is \"provisional\" at all? Do you mean it may go away again?  Why would that happen?  ", "code": "def get backend * resolve True \"\"\" Return the name of the current backend Parameters ---------- resolve bool default True Whether to trigger backend resolution if no backend has been selected so far If True this ensures that a valid backend is returned If False this returns None if no backend has been selected so far admonition Provisional resolve flag The *resolve* flag is introduced provisionally in the anticipation of backend resolution refactoring We don t guarantee API stability for now but if all plays out well the provisional availability will prolong the range of supported releases for the migration period See Also -------- matplotlib use \"\"\" if resolve return rcParams[ backend ] else backend rcParams get backend if backend is rcsetup auto backend sentinel return None else return backend"}
{"message": "I think \"resolve\" makes sense here?  `get_backend` means \"tell me what backend I'm using\".  \"resolve\" means choose one so it is not unresolved.   That this is the default behaviour of `get_backend` is the design decision we are trying to reverse?", "timestamp": "2024-10-29T17:43:29Z", "file_name": "lib/matplotlib/__init__.py", "range": {"start_line": 1299, "end_line": 1299, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1821294825", "html_url": "https://github.com/matplotlib/matplotlib/pull/29039#discussion_r1821294825", "attention_area": "def get_backend(*, resolve=True):", "file_path": "files/80/12/00001280.py", "old_file_path": "files/81/12/00001281.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1296,15 +1296,37 @@ def use(backend, *, force=True):\n     rcParams['backend'] = os.environ.get('MPLBACKEND')\n \n \n-def get_backend():\n+def get_backend(*, resolve=True):", "source": "def get_backend(*, resolve=True):\n    \"\"\"\n    Return the name of the current backend.\n\n    Parameters\n    ----------\n    resolve : bool, default: True\n        Whether to trigger backend resolution if no backend has been\n        selected so far. If True, this ensures that a valid backend\n        is returned. If False, this returns None if no backend has been\n        selected so far.\n\n        .. admonition:: Provisional resolve flag\n\n           The *resolve* flag is introduced provisionally in the anticipation\n           of backend resolution refactoring. We don't guarantee API stability\n           for now, but if all plays out well, the provisional availability\n           will prolong the range of supported releases for the migration period.\n\n    See Also\n    --------\n    matplotlib.use\n    \"\"\"\n    if resolve:\n        return rcParams['backend']\n    else:\n        backend = rcParams._get('backend')\n        if backend is rcsetup._auto_backend_sentinel():\n            return None\n        else:\n            return backend", "source_start_line": 1299, "tokens": ["def", "get_backend", "(", "*", ",", "resolve", "=", "True", ")", ":", "\"\"\"    Return the name of the current backend.    Parameters    ----------    resolve : bool, default: True        Whether to trigger backend resolution if no backend has been        selected so far. If True, this ensures that a valid backend        is returned. If False, this returns None if no backend has been        selected so far.        .. admonition:: Provisional resolve flag           The *resolve* flag is introduced provisionally in the anticipation           of backend resolution refactoring. We don't guarantee API stability           for now, but if all plays out well, the provisional availability           will prolong the range of supported releases for the migration period.    See Also    --------    matplotlib.use    \"\"\"", "if", "resolve", ":", "return", "rcParams", "[", "'backend'", "]", "else", ":", "backend", "=", "rcParams", ".", "_get", "(", "'backend'", ")", "if", "backend", "is", "rcsetup", ".", "_auto_backend_sentinel", "(", ")", ":", "return", "None", "else", ":", "return", "backend"], "to_mask": {"VAR": ["backend", "resolve"], "METHOD": ["_auto_backend_sentinel", "_get"]}, "attention_idx_tokens": [0, 9], "patch": "@@ -1296,15 +1296,37 @@\n     rcParams['backend'] = os.environ.get('MPLBACKEND')\n \n \n-def get_backend():\n+def get_backend(*, resolve=True):", "ext_attention_idx_tokens": [0, 43], "uid": "6d6b564d", "question": "I think \"resolve\" makes sense here?  `get_backend` means \"tell me what backend I'm using\".  \"resolve\" means choose one so it is not unresolved.   That this is the default behaviour of `get_backend` is the design decision we are trying to reverse?", "code": "def get backend * resolve True \"\"\" Return the name of the current backend Parameters ---------- resolve bool default True Whether to trigger backend resolution if no backend has been selected so far If True this ensures that a valid backend is returned If False this returns None if no backend has been selected so far admonition Provisional resolve flag The *resolve* flag is introduced provisionally in the anticipation of backend resolution refactoring We don t guarantee API stability for now but if all plays out well the provisional availability will prolong the range of supported releases for the migration period See Also -------- matplotlib use \"\"\" if resolve return rcParams[ backend ] else backend rcParams get backend if backend is rcsetup auto backend sentinel return None else return backend"}
{"message": "> That this is the default behaviour of `get_backend` is the design decision we are trying to reverse?\r\n\r\nThis is not a complete sentence (or rather 1.5 sentences :smile:). Not sure I understand what you're asking, but I'll try to answer anyway. The first goal is to provide a high-level API for \"get the current backend, but don't resolve if there is no current backend\". One currently has to rely on the semi-public `rcParams._get('backend')`, but https://github.com/matplotlib/matplotlib/issues/26406#issuecomment-2442816302 plans to get away from handling backend logic in rcParams. Therefore, `get_backend(resolve=False)` will be the replacement for `rcParams._get('backend')`.\r\nWhether or not the default should eventually change or not is a separate discussion that can be had later. It does not interfere with this PR.", "timestamp": "2024-10-29T20:48:58Z", "file_name": "lib/matplotlib/__init__.py", "range": {"start_line": 1299, "end_line": 1299, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1821513747", "html_url": "https://github.com/matplotlib/matplotlib/pull/29039#discussion_r1821513747", "attention_area": "def get_backend(*, resolve=True):", "file_path": "files/80/12/00001280.py", "old_file_path": "files/81/12/00001281.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1296,15 +1296,37 @@ def use(backend, *, force=True):\n     rcParams['backend'] = os.environ.get('MPLBACKEND')\n \n \n-def get_backend():\n+def get_backend(*, resolve=True):", "source": "def get_backend(*, resolve=True):\n    \"\"\"\n    Return the name of the current backend.\n\n    Parameters\n    ----------\n    resolve : bool, default: True\n        Whether to trigger backend resolution if no backend has been\n        selected so far. If True, this ensures that a valid backend\n        is returned. If False, this returns None if no backend has been\n        selected so far.\n\n        .. admonition:: Provisional resolve flag\n\n           The *resolve* flag is introduced provisionally in the anticipation\n           of backend resolution refactoring. We don't guarantee API stability\n           for now, but if all plays out well, the provisional availability\n           will prolong the range of supported releases for the migration period.\n\n    See Also\n    --------\n    matplotlib.use\n    \"\"\"\n    if resolve:\n        return rcParams['backend']\n    else:\n        backend = rcParams._get('backend')\n        if backend is rcsetup._auto_backend_sentinel():\n            return None\n        else:\n            return backend", "source_start_line": 1299, "tokens": ["def", "get_backend", "(", "*", ",", "resolve", "=", "True", ")", ":", "\"\"\"    Return the name of the current backend.    Parameters    ----------    resolve : bool, default: True        Whether to trigger backend resolution if no backend has been        selected so far. If True, this ensures that a valid backend        is returned. If False, this returns None if no backend has been        selected so far.        .. admonition:: Provisional resolve flag           The *resolve* flag is introduced provisionally in the anticipation           of backend resolution refactoring. We don't guarantee API stability           for now, but if all plays out well, the provisional availability           will prolong the range of supported releases for the migration period.    See Also    --------    matplotlib.use    \"\"\"", "if", "resolve", ":", "return", "rcParams", "[", "'backend'", "]", "else", ":", "backend", "=", "rcParams", ".", "_get", "(", "'backend'", ")", "if", "backend", "is", "rcsetup", ".", "_auto_backend_sentinel", "(", ")", ":", "return", "None", "else", ":", "return", "backend"], "to_mask": {"VAR": ["backend", "resolve"], "METHOD": ["_auto_backend_sentinel", "_get"]}, "attention_idx_tokens": [0, 9], "patch": "@@ -1296,15 +1296,37 @@\n     rcParams['backend'] = os.environ.get('MPLBACKEND')\n \n \n-def get_backend():\n+def get_backend(*, resolve=True):", "ext_attention_idx_tokens": [0, 43], "uid": "561d3dc2", "question": "> That this is the default behaviour of `get_backend` is the design decision we are trying to reverse?    This is not a complete sentence (or rather 1.5 sentences :smile:). Not sure I understand what you're asking, but I'll try to answer anyway. The first goal is to provide a high-level API for \"get the current backend, but don't resolve if there is no current backend\". One currently has to rely on the semi-public `rcParams._get('backend')`, but https://github.com/matplotlib/matplotlib/issues/26406#issuecomment-2442816302 plans to get away from handling backend logic in rcParams. Therefore, `get_backend(resolve=False)` will be the replacement for `rcParams._get('backend')`.  Whether or not the default should eventually change or not is a separate discussion that can be had later. It does not interfere with this PR.", "code": "def get backend * resolve True \"\"\" Return the name of the current backend Parameters ---------- resolve bool default True Whether to trigger backend resolution if no backend has been selected so far If True this ensures that a valid backend is returned If False this returns None if no backend has been selected so far admonition Provisional resolve flag The *resolve* flag is introduced provisionally in the anticipation of backend resolution refactoring We don t guarantee API stability for now but if all plays out well the provisional availability will prolong the range of supported releases for the migration period See Also -------- matplotlib use \"\"\" if resolve return rcParams[ backend ] else backend rcParams get backend if backend is rcsetup auto backend sentinel return None else return backend"}
{"message": "what are the **kwargs forwarded to?", "timestamp": "2024-11-04T01:00:13Z", "file_name": "lib/matplotlib/tri/_tripcolor.py", "range": {"start_line": 65, "end_line": 65, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1827110412", "html_url": "https://github.com/matplotlib/matplotlib/pull/29065#discussion_r1827110412", "attention_area": "", "file_path": "files/98/12/00001298.py", "old_file_path": "files/99/12/00001299.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -54,8 +55,25 @@ def tripcolor(ax, *args, alpha=1.0, norm=None, cmap=None, vmin=None,\n         values used for each triangle are from the mean c of the triangle's\n         three points. If *shading* is 'gouraud' then color values must be\n         defined at points.\n-    other_parameters\n-        All other parameters are the same as for `~.Axes.pcolor`.\n+    %(cmap_doc)s\n+\n+    %(norm_doc)s\n+\n+    %(vmin_vmax_doc)s\n+\n+    %(colorizer_doc)s\n+", "source": "def tripcolor(ax, *args, alpha=1.0, norm=None, cmap=None, vmin=None,\n              vmax=None, shading='flat', facecolors=None, **kwargs):\n    \"\"\"\n    Create a pseudocolor plot of an unstructured triangular grid.\n\n    Call signatures::\n\n      tripcolor(triangulation, c, *, ...)\n      tripcolor(x, y, c, *, [triangles=triangles], [mask=mask], ...)\n\n    The triangular grid can be specified either by passing a `.Triangulation`\n    object as the first parameter, or by passing the points *x*, *y* and\n    optionally the *triangles* and a *mask*. See `.Triangulation` for an\n    explanation of these parameters.\n\n    It is possible to pass the triangles positionally, i.e.\n    ``tripcolor(x, y, triangles, c, ...)``. However, this is discouraged.\n    For more clarity, pass *triangles* via keyword argument.\n\n    If neither of *triangulation* or *triangles* are given, the triangulation\n    is calculated on the fly. In this case, it does not make sense to provide\n    colors at the triangle faces via *c* or *facecolors* because there are\n    multiple possible triangulations for a group of points and you don't know\n    which triangles will be constructed.\n\n    Parameters\n    ----------\n    triangulation : `.Triangulation`\n        An already created triangular grid.\n    x, y, triangles, mask\n        Parameters defining the triangular grid. See `.Triangulation`.\n        This is mutually exclusive with specifying *triangulation*.\n    c : array-like\n        The color values, either for the points or for the triangles. Which one\n        is automatically inferred from the length of *c*, i.e. does it match\n        the number of points or the number of triangles. If there are the same\n        number of points and triangles in the triangulation it is assumed that\n        color values are defined at points; to force the use of color values at\n        triangles use the keyword argument ``facecolors=c`` instead of just\n        ``c``.\n        This parameter is position-only.\n    facecolors : array-like, optional\n        Can be used alternatively to *c* to specify colors at the triangle\n        faces. This parameter takes precedence over *c*.\n    shading : {'flat', 'gouraud'}, default: 'flat'\n        If  'flat' and the color values *c* are defined at points, the color\n        values used for each triangle are from the mean c of the triangle's\n        three points. If *shading* is 'gouraud' then color values must be\n        defined at points.\n    %(cmap_doc)s\n\n    %(norm_doc)s\n\n    %(vmin_vmax_doc)s\n\n    %(colorizer_doc)s\n\n    Returns\n    -------\n    `~matplotlib.collections.PolyCollection` or `~matplotlib.collections.TriMesh`\n        The result depends on *shading*: For ``shading='flat'`` the result is a\n        `.PolyCollection`, for ``shading='gouraud'`` the result is a `.TriMesh`.\n\n    Other Parameters\n    ----------------\n    **kwargs : `~matplotlib.collections.Collection` properties\n\n        %(Collection:kwdoc)s\n    \"\"\"\n    _api.check_in_list(['flat', 'gouraud'], shading=shading)\n\n    tri, args, kwargs = Triangulation.get_from_args_and_kwargs(*args, **kwargs)\n\n    # Parse the color to be in one of (the other variable will be None):\n    # - facecolors: if specified at the triangle faces\n    # - point_colors: if specified at the points\n    if facecolors is not None:\n        if args:\n            _api.warn_external(\n                \"Positional parameter c has no effect when the keyword \"\n                \"facecolors is given\")\n        point_colors = None\n        if len(facecolors) != len(tri.triangles):\n            raise ValueError(\"The length of facecolors must match the number \"\n                             \"of triangles\")\n    else:\n        # Color from positional parameter c\n        if not args:\n            raise TypeError(\n                \"tripcolor() missing 1 required positional argument: 'c'; or \"\n                \"1 required keyword-only argument: 'facecolors'\")\n        elif len(args) > 1:\n            raise TypeError(f\"Unexpected positional parameters: {args[1:]!r}\")\n        c = np.asarray(args[0])\n        if len(c) == len(tri.x):\n            # having this before the len(tri.triangles) comparison gives\n            # precedence to nodes if there are as many nodes as triangles\n            point_colors = c\n            facecolors = None\n        elif len(c) == len(tri.triangles):\n            point_colors = None\n            facecolors = c\n        else:\n            raise ValueError('The length of c must match either the number '\n                             'of points or the number of triangles')\n\n    # Handling of linewidths, shading, edgecolors and antialiased as\n    # in Axes.pcolor\n    linewidths = (0.25,)\n    if 'linewidth' in kwargs:\n        kwargs['linewidths'] = kwargs.pop('linewidth')\n    kwargs.setdefault('linewidths', linewidths)\n\n    edgecolors = 'none'\n    if 'edgecolor' in kwargs:\n        kwargs['edgecolors'] = kwargs.pop('edgecolor')\n    ec = kwargs.setdefault('edgecolors', edgecolors)\n\n    if 'antialiased' in kwargs:\n        kwargs['antialiaseds'] = kwargs.pop('antialiased')\n    if 'antialiaseds' not in kwargs and ec.lower() == \"none\":\n        kwargs['antialiaseds'] = False\n\n    if shading == 'gouraud':\n        if facecolors is not None:\n            raise ValueError(\n                \"shading='gouraud' can only be used when the colors \"\n                \"are specified at the points, not at the faces.\")\n        collection = TriMesh(tri, alpha=alpha, array=point_colors,\n                             cmap=cmap, norm=norm, **kwargs)\n    else:  # 'flat'\n        # Vertices of triangles.\n        maskedTris = tri.get_masked_triangles()\n        verts = np.stack((tri.x[maskedTris], tri.y[maskedTris]), axis=-1)\n\n        # Color values.\n        if facecolors is None:\n            # One color per triangle, the mean of the 3 vertex color values.\n            colors = point_colors[maskedTris].mean(axis=1)\n        elif tri.mask is not None:\n            # Remove color values of masked triangles.\n            colors = facecolors[~tri.mask]\n        else:\n            colors = facecolors\n        collection = PolyCollection(verts, alpha=alpha, array=colors,\n                                    cmap=cmap, norm=norm, **kwargs)\n\n    collection._scale_norm(norm, vmin, vmax)\n    ax.grid(False)\n\n    minx = tri.x.min()\n    maxx = tri.x.max()\n    miny = tri.y.min()\n    maxy = tri.y.max()\n    corners = (minx, miny), (maxx, maxy)\n    ax.update_datalim(corners)\n    ax.autoscale_view()\n    ax.add_collection(collection)\n    return collection", "source_start_line": 9, "tokens": ["def", "tripcolor", "(", "ax", ",", "*", "args", ",", "alpha", "=", "1.0", ",", "norm", "=", "None", ",", "cmap", "=", "None", ",", "vmin", "=", "None", ",", "vmax", "=", "None", ",", "shading", "=", "'flat'", ",", "facecolors", "=", "None", ",", "**", "kwargs", ")", ":", "\"\"\"    Create a pseudocolor plot of an unstructured triangular grid.    Call signatures::      tripcolor(triangulation, c, *, ...)      tripcolor(x, y, c, *, [triangles=triangles], [mask=mask], ...)    The triangular grid can be specified either by passing a `.Triangulation`    object as the first parameter, or by passing the points *x*, *y* and    optionally the *triangles* and a *mask*. See `.Triangulation` for an    explanation of these parameters.    It is possible to pass the triangles positionally, i.e.    ``tripcolor(x, y, triangles, c, ...)``. However, this is discouraged.    For more clarity, pass *triangles* via keyword argument.    If neither of *triangulation* or *triangles* are given, the triangulation    is calculated on the fly. In this case, it does not make sense to provide    colors at the triangle faces via *c* or *facecolors* because there are    multiple possible triangulations for a group of points and you don't know    which triangles will be constructed.    Parameters    ----------    triangulation : `.Triangulation`        An already created triangular grid.    x, y, triangles, mask        Parameters defining the triangular grid. See `.Triangulation`.        This is mutually exclusive with specifying *triangulation*.    c : array-like        The color values, either for the points or for the triangles. Which one        is automatically inferred from the length of *c*, i.e. does it match        the number of points or the number of triangles. If there are the same        number of points and triangles in the triangulation it is assumed that        color values are defined at points; to force the use of color values at        triangles use the keyword argument ``facecolors=c`` instead of just        ``c``.        This parameter is position-only.    facecolors : array-like, optional        Can be used alternatively to *c* to specify colors at the triangle        faces. This parameter takes precedence over *c*.    shading : {'flat', 'gouraud'}, default: 'flat'        If  'flat' and the color values *c* are defined at points, the color        values used for each triangle are from the mean c of the triangle's        three points. If *shading* is 'gouraud' then color values must be        defined at points.    %(cmap_doc)s    %(norm_doc)s    %(vmin_vmax_doc)s    %(colorizer_doc)s    Returns    -------    `~matplotlib.collections.PolyCollection` or `~matplotlib.collections.TriMesh`        The result depends on *shading*: For ``shading='flat'`` the result is a        `.PolyCollection`, for ``shading='gouraud'`` the result is a `.TriMesh`.    Other Parameters    ----------------    **kwargs : `~matplotlib.collections.Collection` properties        %(Collection:kwdoc)s    \"\"\"", "_api", ".", "check_in_list", "(", "[", "'flat'", ",", "'gouraud'", "]", ",", "shading", "=", "shading", ")", "tri", ",", "args", ",", "kwargs", "=", "Triangulation", ".", "get_from_args_and_kwargs", "(", "*", "args", ",", "**", "kwargs", ")", "if", "facecolors", "is", "not", "None", ":", "if", "args", ":", "_api", ".", "warn_external", "(", "\"Positional parameter c has no effect when the keyword \"", "\"facecolors is given\"", ")", "point_colors", "=", "None", "if", "len", "(", "facecolors", ")", "!=", "len", "(", "tri", ".", "triangles", ")", ":", "raise", "ValueError", "(", "\"The length of facecolors must match the number \"", "\"of triangles\"", ")", "else", ":", "if", "not", "args", ":", "raise", "TypeError", "(", "\"tripcolor() missing 1 required positional argument: 'c'; or \"", "\"1 required keyword-only argument: 'facecolors'\"", ")", "elif", "len", "(", "args", ")", ">", "1", ":", "raise", "TypeError", "(", "f\"", "{", "args", "[", "1", ":", "]", "!r", "}", "\"", ")", "c", "=", "np", ".", "asarray", "(", "args", "[", "0", "]", ")", "if", "len", "(", "c", ")", "==", "len", "(", "tri", ".", "x", ")", ":", "point_colors", "=", "c", "facecolors", "=", "None", "elif", "len", "(", "c", ")", "==", "len", "(", "tri", ".", "triangles", ")", ":", "point_colors", "=", "None", "facecolors", "=", "c", "else", ":", "raise", "ValueError", "(", "'The length of c must match either the number '", "'of points or the number of triangles'", ")", "linewidths", "=", "(", "0.25", ",", ")", "if", "'linewidth'", "in", "kwargs", ":", "kwargs", "[", "'linewidths'", "]", "=", "kwargs", ".", "pop", "(", "'linewidth'", ")", "kwargs", ".", "setdefault", "(", "'linewidths'", ",", "linewidths", ")", "edgecolors", "=", "'none'", "if", "'edgecolor'", "in", "kwargs", ":", "kwargs", "[", "'edgecolors'", "]", "=", "kwargs", ".", "pop", "(", "'edgecolor'", ")", "ec", "=", "kwargs", ".", "setdefault", "(", "'edgecolors'", ",", "edgecolors", ")", "if", "'antialiased'", "in", "kwargs", ":", "kwargs", "[", "'antialiaseds'", "]", "=", "kwargs", ".", "pop", "(", "'antialiased'", ")", "if", "'antialiaseds'", "not", "in", "kwargs", "and", "ec", ".", "lower", "(", ")", "==", "\"none\"", ":", "kwargs", "[", "'antialiaseds'", "]", "=", "False", "if", "shading", "==", "'gouraud'", ":", "if", "facecolors", "is", "not", "None", ":", "raise", "ValueError", "(", "\"shading='gouraud' can only be used when the colors \"", "\"are specified at the points, not at the faces.\"", ")", "collection", "=", "TriMesh", "(", "tri", ",", "alpha", "=", "alpha", ",", "array", "=", "point_colors", ",", "cmap", "=", "cmap", ",", "norm", "=", "norm", ",", "**", "kwargs", ")", "else", ":", "maskedTris", "=", "tri", ".", "get_masked_triangles", "(", ")", "verts", "=", "np", ".", "stack", "(", "(", "tri", ".", "x", "[", "maskedTris", "]", ",", "tri", ".", "y", "[", "maskedTris", "]", ")", ",", "axis", "=", "-", "1", ")", "if", "facecolors", "is", "None", ":", "colors", "=", "point_colors", "[", "maskedTris", "]", ".", "mean", "(", "axis", "=", "1", ")", "elif", "tri", ".", "mask", "is", "not", "None", ":", "colors", "=", "facecolors", "[", "~", "tri", ".", "mask", "]", "else", ":", "colors", "=", "facecolors", "collection", "=", "PolyCollection", "(", "verts", ",", "alpha", "=", "alpha", ",", "array", "=", "colors", ",", "cmap", "=", "cmap", ",", "norm", "=", "norm", ",", "**", "kwargs", ")", "collection", ".", "_scale_norm", "(", "norm", ",", "vmin", ",", "vmax", ")", "ax", ".", "grid", "(", "False", ")", "minx", "=", "tri", ".", "x", ".", "min", "(", ")", "maxx", "=", "tri", ".", "x", ".", "max", "(", ")", "miny", "=", "tri", ".", "y", ".", "min", "(", ")", "maxy", "=", "tri", ".", "y", ".", "max", "(", ")", "corners", "=", "(", "minx", ",", "miny", ")", ",", "(", "maxx", ",", "maxy", ")", "ax", ".", "update_datalim", "(", "corners", ")", "ax", ".", "autoscale_view", "(", ")", "ax", ".", "add_collection", "(", "collection", ")", "return", "collection"], "to_mask": {"VAR": ["alpha", "args", "ax", "c", "cmap", "collection", "colors", "corners", "ec", "edgecolors", "facecolors", "kwargs", "linewidths", "maskedTris", "maxx", "maxy", "minx", "miny", "norm", "point_colors", "shading", "tri", "verts", "vmax", "vmin"], "METHOD": ["PolyCollection", "TriMesh", "TypeError", "ValueError", "_scale_norm", "add_collection", "asarray", "autoscale_view", "check_in_list", "get_from_args_and_kwargs", "get_masked_triangles", "grid", "len", "lower", "max", "mean", "min", "pop", "setdefault", "stack", "update_datalim", "warn_external"]}, "attention_idx_tokens": [null, null], "patch": "@@ -54,8 +55,25 @@\n         values used for each triangle are from the mean c of the triangle's\n         three points. If *shading* is 'gouraud' then color values must be\n         defined at points.\n-    other_parameters\n-        All other parameters are the same as for `~.Axes.pcolor`.\n+    %(cmap_doc)s\n+\n+    %(norm_doc)s\n+\n+    %(vmin_vmax_doc)s\n+\n+    %(colorizer_doc)s\n+", "ext_attention_idx_tokens": [null, null], "uid": "ee98b99b", "question": "what are the **kwargs forwarded to?", "code": "def tripcolor ax *args alpha 1 0 norm None cmap None vmin None vmax None shading flat facecolors None **kwargs \"\"\" Create a pseudocolor plot of an unstructured triangular grid Call signatures tripcolor triangulation c * tripcolor x y c * [triangles triangles] [mask mask] The triangular grid can be specified either by passing a ` Triangulation` object as the first parameter or by passing the points *x* *y* and optionally the *triangles* and a *mask* See ` Triangulation` for an explanation of these parameters It is possible to pass the triangles positionally i e ``tripcolor x y triangles c `` However this is discouraged For more clarity pass *triangles* via keyword argument If neither of *triangulation* or *triangles* are given the triangulation is calculated on the fly In this case it does not make sense to provide colors at the triangle faces via *c* or *facecolors* because there are multiple possible triangulations for a group of points and you don t know which triangles will be constructed Parameters ---------- triangulation ` Triangulation` An already created triangular grid x y triangles mask Parameters defining the triangular grid See ` Triangulation` This is mutually exclusive with specifying *triangulation* c array-like The color values either for the points or for the triangles Which one is automatically inferred from the length of *c* i e does it match the number of points or the number of triangles If there are the same number of points and triangles in the triangulation it is assumed that color values are defined at points; to force the use of color values at triangles use the keyword argument ``facecolors c`` instead of just ``c`` This parameter is position-only facecolors array-like optional Can be used alternatively to *c* to specify colors at the triangle faces This parameter takes precedence over *c* shading { flat gouraud } default flat If flat and the color values *c* are defined at points the color values used for each triangle are from the mean c of the triangle s three points If *shading* is gouraud then color values must be defined at points % cmap doc s % norm doc s % vmin vmax doc s % colorizer doc s Returns ------- `~matplotlib collections PolyCollection` or `~matplotlib collections TriMesh` The result depends on *shading* For ``shading flat `` the result is a ` PolyCollection` for ``shading gouraud `` the result is a ` TriMesh` Other Parameters ---------------- **kwargs `~matplotlib collections Collection` properties % Collection kwdoc s \"\"\" api check in list [ flat gouraud ] shading shading tri args kwargs Triangulation get from args and kwargs *args **kwargs # Parse the color to be in one of the other variable will be None # - facecolors if specified at the triangle faces # - point colors if specified at the points if facecolors is not None if args api warn external \"Positional parameter c has no effect when the keyword \" \"facecolors is given\" point colors None if len facecolors ! len tri triangles raise ValueError \"The length of facecolors must match the number \" \"of triangles\" else # Color from positional parameter c if not args raise TypeError \"tripcolor missing 1 required positional argument c ; or \" \"1 required keyword-only argument facecolors \" elif len args > 1 raise TypeError f\"Unexpected positional parameters {args[1 ]!r}\" c np asarray args[0] if len c len tri x # having this before the len tri triangles comparison gives # precedence to nodes if there are as many nodes as triangles point colors c facecolors None elif len c len tri triangles point colors None facecolors c else raise ValueError The length of c must match either the number of points or the number of triangles # Handling of linewidths shading edgecolors and antialiased as # in Axes pcolor linewidths 0 25 if linewidth in kwargs kwargs[ linewidths ] kwargs pop linewidth kwargs setdefault linewidths linewidths edgecolors none if edgecolor in kwargs kwargs[ edgecolors ] kwargs pop edgecolor ec kwargs setdefault edgecolors edgecolors if antialiased in kwargs kwargs[ antialiaseds ] kwargs pop antialiased if antialiaseds not in kwargs and ec lower \"none\" kwargs[ antialiaseds ] False if shading gouraud if facecolors is not None raise ValueError \"shading gouraud can only be used when the colors \" \"are specified at the points not at the faces \" collection TriMesh tri alpha alpha array point colors cmap cmap norm norm **kwargs else # flat # Vertices of triangles maskedTris tri get masked triangles verts np stack tri x[maskedTris] tri y[maskedTris] axis -1 # Color values if facecolors is None # One color per triangle the mean of the 3 vertex color values colors point colors[maskedTris] mean axis 1 elif tri mask is not None # Remove color values of masked triangles colors facecolors[~tri mask] else colors facecolors collection PolyCollection verts alpha alpha array colors cmap cmap norm norm **kwargs collection scale norm norm vmin vmax ax grid False minx tri x min maxx tri x max miny tri y min maxy tri y max corners minx miny maxx maxy ax update datalim corners ax autoscale view ax add collection collection return collection"}
{"message": "Oh sorry now I see it after the return - is that standard? ", "timestamp": "2024-11-04T03:26:49Z", "file_name": "lib/matplotlib/tri/_tripcolor.py", "range": {"start_line": 65, "end_line": 65, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1827152202", "html_url": "https://github.com/matplotlib/matplotlib/pull/29065#discussion_r1827152202", "attention_area": "", "file_path": "files/98/12/00001298.py", "old_file_path": "files/99/12/00001299.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -54,8 +55,25 @@ def tripcolor(ax, *args, alpha=1.0, norm=None, cmap=None, vmin=None,\n         values used for each triangle are from the mean c of the triangle's\n         three points. If *shading* is 'gouraud' then color values must be\n         defined at points.\n-    other_parameters\n-        All other parameters are the same as for `~.Axes.pcolor`.\n+    %(cmap_doc)s\n+\n+    %(norm_doc)s\n+\n+    %(vmin_vmax_doc)s\n+\n+    %(colorizer_doc)s\n+", "source": "def tripcolor(ax, *args, alpha=1.0, norm=None, cmap=None, vmin=None,\n              vmax=None, shading='flat', facecolors=None, **kwargs):\n    \"\"\"\n    Create a pseudocolor plot of an unstructured triangular grid.\n\n    Call signatures::\n\n      tripcolor(triangulation, c, *, ...)\n      tripcolor(x, y, c, *, [triangles=triangles], [mask=mask], ...)\n\n    The triangular grid can be specified either by passing a `.Triangulation`\n    object as the first parameter, or by passing the points *x*, *y* and\n    optionally the *triangles* and a *mask*. See `.Triangulation` for an\n    explanation of these parameters.\n\n    It is possible to pass the triangles positionally, i.e.\n    ``tripcolor(x, y, triangles, c, ...)``. However, this is discouraged.\n    For more clarity, pass *triangles* via keyword argument.\n\n    If neither of *triangulation* or *triangles* are given, the triangulation\n    is calculated on the fly. In this case, it does not make sense to provide\n    colors at the triangle faces via *c* or *facecolors* because there are\n    multiple possible triangulations for a group of points and you don't know\n    which triangles will be constructed.\n\n    Parameters\n    ----------\n    triangulation : `.Triangulation`\n        An already created triangular grid.\n    x, y, triangles, mask\n        Parameters defining the triangular grid. See `.Triangulation`.\n        This is mutually exclusive with specifying *triangulation*.\n    c : array-like\n        The color values, either for the points or for the triangles. Which one\n        is automatically inferred from the length of *c*, i.e. does it match\n        the number of points or the number of triangles. If there are the same\n        number of points and triangles in the triangulation it is assumed that\n        color values are defined at points; to force the use of color values at\n        triangles use the keyword argument ``facecolors=c`` instead of just\n        ``c``.\n        This parameter is position-only.\n    facecolors : array-like, optional\n        Can be used alternatively to *c* to specify colors at the triangle\n        faces. This parameter takes precedence over *c*.\n    shading : {'flat', 'gouraud'}, default: 'flat'\n        If  'flat' and the color values *c* are defined at points, the color\n        values used for each triangle are from the mean c of the triangle's\n        three points. If *shading* is 'gouraud' then color values must be\n        defined at points.\n    %(cmap_doc)s\n\n    %(norm_doc)s\n\n    %(vmin_vmax_doc)s\n\n    %(colorizer_doc)s\n\n    Returns\n    -------\n    `~matplotlib.collections.PolyCollection` or `~matplotlib.collections.TriMesh`\n        The result depends on *shading*: For ``shading='flat'`` the result is a\n        `.PolyCollection`, for ``shading='gouraud'`` the result is a `.TriMesh`.\n\n    Other Parameters\n    ----------------\n    **kwargs : `~matplotlib.collections.Collection` properties\n\n        %(Collection:kwdoc)s\n    \"\"\"\n    _api.check_in_list(['flat', 'gouraud'], shading=shading)\n\n    tri, args, kwargs = Triangulation.get_from_args_and_kwargs(*args, **kwargs)\n\n    # Parse the color to be in one of (the other variable will be None):\n    # - facecolors: if specified at the triangle faces\n    # - point_colors: if specified at the points\n    if facecolors is not None:\n        if args:\n            _api.warn_external(\n                \"Positional parameter c has no effect when the keyword \"\n                \"facecolors is given\")\n        point_colors = None\n        if len(facecolors) != len(tri.triangles):\n            raise ValueError(\"The length of facecolors must match the number \"\n                             \"of triangles\")\n    else:\n        # Color from positional parameter c\n        if not args:\n            raise TypeError(\n                \"tripcolor() missing 1 required positional argument: 'c'; or \"\n                \"1 required keyword-only argument: 'facecolors'\")\n        elif len(args) > 1:\n            raise TypeError(f\"Unexpected positional parameters: {args[1:]!r}\")\n        c = np.asarray(args[0])\n        if len(c) == len(tri.x):\n            # having this before the len(tri.triangles) comparison gives\n            # precedence to nodes if there are as many nodes as triangles\n            point_colors = c\n            facecolors = None\n        elif len(c) == len(tri.triangles):\n            point_colors = None\n            facecolors = c\n        else:\n            raise ValueError('The length of c must match either the number '\n                             'of points or the number of triangles')\n\n    # Handling of linewidths, shading, edgecolors and antialiased as\n    # in Axes.pcolor\n    linewidths = (0.25,)\n    if 'linewidth' in kwargs:\n        kwargs['linewidths'] = kwargs.pop('linewidth')\n    kwargs.setdefault('linewidths', linewidths)\n\n    edgecolors = 'none'\n    if 'edgecolor' in kwargs:\n        kwargs['edgecolors'] = kwargs.pop('edgecolor')\n    ec = kwargs.setdefault('edgecolors', edgecolors)\n\n    if 'antialiased' in kwargs:\n        kwargs['antialiaseds'] = kwargs.pop('antialiased')\n    if 'antialiaseds' not in kwargs and ec.lower() == \"none\":\n        kwargs['antialiaseds'] = False\n\n    if shading == 'gouraud':\n        if facecolors is not None:\n            raise ValueError(\n                \"shading='gouraud' can only be used when the colors \"\n                \"are specified at the points, not at the faces.\")\n        collection = TriMesh(tri, alpha=alpha, array=point_colors,\n                             cmap=cmap, norm=norm, **kwargs)\n    else:  # 'flat'\n        # Vertices of triangles.\n        maskedTris = tri.get_masked_triangles()\n        verts = np.stack((tri.x[maskedTris], tri.y[maskedTris]), axis=-1)\n\n        # Color values.\n        if facecolors is None:\n            # One color per triangle, the mean of the 3 vertex color values.\n            colors = point_colors[maskedTris].mean(axis=1)\n        elif tri.mask is not None:\n            # Remove color values of masked triangles.\n            colors = facecolors[~tri.mask]\n        else:\n            colors = facecolors\n        collection = PolyCollection(verts, alpha=alpha, array=colors,\n                                    cmap=cmap, norm=norm, **kwargs)\n\n    collection._scale_norm(norm, vmin, vmax)\n    ax.grid(False)\n\n    minx = tri.x.min()\n    maxx = tri.x.max()\n    miny = tri.y.min()\n    maxy = tri.y.max()\n    corners = (minx, miny), (maxx, maxy)\n    ax.update_datalim(corners)\n    ax.autoscale_view()\n    ax.add_collection(collection)\n    return collection", "source_start_line": 9, "tokens": ["def", "tripcolor", "(", "ax", ",", "*", "args", ",", "alpha", "=", "1.0", ",", "norm", "=", "None", ",", "cmap", "=", "None", ",", "vmin", "=", "None", ",", "vmax", "=", "None", ",", "shading", "=", "'flat'", ",", "facecolors", "=", "None", ",", "**", "kwargs", ")", ":", "\"\"\"    Create a pseudocolor plot of an unstructured triangular grid.    Call signatures::      tripcolor(triangulation, c, *, ...)      tripcolor(x, y, c, *, [triangles=triangles], [mask=mask], ...)    The triangular grid can be specified either by passing a `.Triangulation`    object as the first parameter, or by passing the points *x*, *y* and    optionally the *triangles* and a *mask*. See `.Triangulation` for an    explanation of these parameters.    It is possible to pass the triangles positionally, i.e.    ``tripcolor(x, y, triangles, c, ...)``. However, this is discouraged.    For more clarity, pass *triangles* via keyword argument.    If neither of *triangulation* or *triangles* are given, the triangulation    is calculated on the fly. In this case, it does not make sense to provide    colors at the triangle faces via *c* or *facecolors* because there are    multiple possible triangulations for a group of points and you don't know    which triangles will be constructed.    Parameters    ----------    triangulation : `.Triangulation`        An already created triangular grid.    x, y, triangles, mask        Parameters defining the triangular grid. See `.Triangulation`.        This is mutually exclusive with specifying *triangulation*.    c : array-like        The color values, either for the points or for the triangles. Which one        is automatically inferred from the length of *c*, i.e. does it match        the number of points or the number of triangles. If there are the same        number of points and triangles in the triangulation it is assumed that        color values are defined at points; to force the use of color values at        triangles use the keyword argument ``facecolors=c`` instead of just        ``c``.        This parameter is position-only.    facecolors : array-like, optional        Can be used alternatively to *c* to specify colors at the triangle        faces. This parameter takes precedence over *c*.    shading : {'flat', 'gouraud'}, default: 'flat'        If  'flat' and the color values *c* are defined at points, the color        values used for each triangle are from the mean c of the triangle's        three points. If *shading* is 'gouraud' then color values must be        defined at points.    %(cmap_doc)s    %(norm_doc)s    %(vmin_vmax_doc)s    %(colorizer_doc)s    Returns    -------    `~matplotlib.collections.PolyCollection` or `~matplotlib.collections.TriMesh`        The result depends on *shading*: For ``shading='flat'`` the result is a        `.PolyCollection`, for ``shading='gouraud'`` the result is a `.TriMesh`.    Other Parameters    ----------------    **kwargs : `~matplotlib.collections.Collection` properties        %(Collection:kwdoc)s    \"\"\"", "_api", ".", "check_in_list", "(", "[", "'flat'", ",", "'gouraud'", "]", ",", "shading", "=", "shading", ")", "tri", ",", "args", ",", "kwargs", "=", "Triangulation", ".", "get_from_args_and_kwargs", "(", "*", "args", ",", "**", "kwargs", ")", "if", "facecolors", "is", "not", "None", ":", "if", "args", ":", "_api", ".", "warn_external", "(", "\"Positional parameter c has no effect when the keyword \"", "\"facecolors is given\"", ")", "point_colors", "=", "None", "if", "len", "(", "facecolors", ")", "!=", "len", "(", "tri", ".", "triangles", ")", ":", "raise", "ValueError", "(", "\"The length of facecolors must match the number \"", "\"of triangles\"", ")", "else", ":", "if", "not", "args", ":", "raise", "TypeError", "(", "\"tripcolor() missing 1 required positional argument: 'c'; or \"", "\"1 required keyword-only argument: 'facecolors'\"", ")", "elif", "len", "(", "args", ")", ">", "1", ":", "raise", "TypeError", "(", "f\"", "{", "args", "[", "1", ":", "]", "!r", "}", "\"", ")", "c", "=", "np", ".", "asarray", "(", "args", "[", "0", "]", ")", "if", "len", "(", "c", ")", "==", "len", "(", "tri", ".", "x", ")", ":", "point_colors", "=", "c", "facecolors", "=", "None", "elif", "len", "(", "c", ")", "==", "len", "(", "tri", ".", "triangles", ")", ":", "point_colors", "=", "None", "facecolors", "=", "c", "else", ":", "raise", "ValueError", "(", "'The length of c must match either the number '", "'of points or the number of triangles'", ")", "linewidths", "=", "(", "0.25", ",", ")", "if", "'linewidth'", "in", "kwargs", ":", "kwargs", "[", "'linewidths'", "]", "=", "kwargs", ".", "pop", "(", "'linewidth'", ")", "kwargs", ".", "setdefault", "(", "'linewidths'", ",", "linewidths", ")", "edgecolors", "=", "'none'", "if", "'edgecolor'", "in", "kwargs", ":", "kwargs", "[", "'edgecolors'", "]", "=", "kwargs", ".", "pop", "(", "'edgecolor'", ")", "ec", "=", "kwargs", ".", "setdefault", "(", "'edgecolors'", ",", "edgecolors", ")", "if", "'antialiased'", "in", "kwargs", ":", "kwargs", "[", "'antialiaseds'", "]", "=", "kwargs", ".", "pop", "(", "'antialiased'", ")", "if", "'antialiaseds'", "not", "in", "kwargs", "and", "ec", ".", "lower", "(", ")", "==", "\"none\"", ":", "kwargs", "[", "'antialiaseds'", "]", "=", "False", "if", "shading", "==", "'gouraud'", ":", "if", "facecolors", "is", "not", "None", ":", "raise", "ValueError", "(", "\"shading='gouraud' can only be used when the colors \"", "\"are specified at the points, not at the faces.\"", ")", "collection", "=", "TriMesh", "(", "tri", ",", "alpha", "=", "alpha", ",", "array", "=", "point_colors", ",", "cmap", "=", "cmap", ",", "norm", "=", "norm", ",", "**", "kwargs", ")", "else", ":", "maskedTris", "=", "tri", ".", "get_masked_triangles", "(", ")", "verts", "=", "np", ".", "stack", "(", "(", "tri", ".", "x", "[", "maskedTris", "]", ",", "tri", ".", "y", "[", "maskedTris", "]", ")", ",", "axis", "=", "-", "1", ")", "if", "facecolors", "is", "None", ":", "colors", "=", "point_colors", "[", "maskedTris", "]", ".", "mean", "(", "axis", "=", "1", ")", "elif", "tri", ".", "mask", "is", "not", "None", ":", "colors", "=", "facecolors", "[", "~", "tri", ".", "mask", "]", "else", ":", "colors", "=", "facecolors", "collection", "=", "PolyCollection", "(", "verts", ",", "alpha", "=", "alpha", ",", "array", "=", "colors", ",", "cmap", "=", "cmap", ",", "norm", "=", "norm", ",", "**", "kwargs", ")", "collection", ".", "_scale_norm", "(", "norm", ",", "vmin", ",", "vmax", ")", "ax", ".", "grid", "(", "False", ")", "minx", "=", "tri", ".", "x", ".", "min", "(", ")", "maxx", "=", "tri", ".", "x", ".", "max", "(", ")", "miny", "=", "tri", ".", "y", ".", "min", "(", ")", "maxy", "=", "tri", ".", "y", ".", "max", "(", ")", "corners", "=", "(", "minx", ",", "miny", ")", ",", "(", "maxx", ",", "maxy", ")", "ax", ".", "update_datalim", "(", "corners", ")", "ax", ".", "autoscale_view", "(", ")", "ax", ".", "add_collection", "(", "collection", ")", "return", "collection"], "to_mask": {"VAR": ["alpha", "args", "ax", "c", "cmap", "collection", "colors", "corners", "ec", "edgecolors", "facecolors", "kwargs", "linewidths", "maskedTris", "maxx", "maxy", "minx", "miny", "norm", "point_colors", "shading", "tri", "verts", "vmax", "vmin"], "METHOD": ["PolyCollection", "TriMesh", "TypeError", "ValueError", "_scale_norm", "add_collection", "asarray", "autoscale_view", "check_in_list", "get_from_args_and_kwargs", "get_masked_triangles", "grid", "len", "lower", "max", "mean", "min", "pop", "setdefault", "stack", "update_datalim", "warn_external"]}, "attention_idx_tokens": [null, null], "patch": "@@ -54,8 +55,25 @@\n         values used for each triangle are from the mean c of the triangle's\n         three points. If *shading* is 'gouraud' then color values must be\n         defined at points.\n-    other_parameters\n-        All other parameters are the same as for `~.Axes.pcolor`.\n+    %(cmap_doc)s\n+\n+    %(norm_doc)s\n+\n+    %(vmin_vmax_doc)s\n+\n+    %(colorizer_doc)s\n+", "ext_attention_idx_tokens": [null, null], "uid": "e6439889", "question": "Oh sorry now I see it after the return - is that standard? ", "code": "def tripcolor ax *args alpha 1 0 norm None cmap None vmin None vmax None shading flat facecolors None **kwargs \"\"\" Create a pseudocolor plot of an unstructured triangular grid Call signatures tripcolor triangulation c * tripcolor x y c * [triangles triangles] [mask mask] The triangular grid can be specified either by passing a ` Triangulation` object as the first parameter or by passing the points *x* *y* and optionally the *triangles* and a *mask* See ` Triangulation` for an explanation of these parameters It is possible to pass the triangles positionally i e ``tripcolor x y triangles c `` However this is discouraged For more clarity pass *triangles* via keyword argument If neither of *triangulation* or *triangles* are given the triangulation is calculated on the fly In this case it does not make sense to provide colors at the triangle faces via *c* or *facecolors* because there are multiple possible triangulations for a group of points and you don t know which triangles will be constructed Parameters ---------- triangulation ` Triangulation` An already created triangular grid x y triangles mask Parameters defining the triangular grid See ` Triangulation` This is mutually exclusive with specifying *triangulation* c array-like The color values either for the points or for the triangles Which one is automatically inferred from the length of *c* i e does it match the number of points or the number of triangles If there are the same number of points and triangles in the triangulation it is assumed that color values are defined at points; to force the use of color values at triangles use the keyword argument ``facecolors c`` instead of just ``c`` This parameter is position-only facecolors array-like optional Can be used alternatively to *c* to specify colors at the triangle faces This parameter takes precedence over *c* shading { flat gouraud } default flat If flat and the color values *c* are defined at points the color values used for each triangle are from the mean c of the triangle s three points If *shading* is gouraud then color values must be defined at points % cmap doc s % norm doc s % vmin vmax doc s % colorizer doc s Returns ------- `~matplotlib collections PolyCollection` or `~matplotlib collections TriMesh` The result depends on *shading* For ``shading flat `` the result is a ` PolyCollection` for ``shading gouraud `` the result is a ` TriMesh` Other Parameters ---------------- **kwargs `~matplotlib collections Collection` properties % Collection kwdoc s \"\"\" api check in list [ flat gouraud ] shading shading tri args kwargs Triangulation get from args and kwargs *args **kwargs # Parse the color to be in one of the other variable will be None # - facecolors if specified at the triangle faces # - point colors if specified at the points if facecolors is not None if args api warn external \"Positional parameter c has no effect when the keyword \" \"facecolors is given\" point colors None if len facecolors ! len tri triangles raise ValueError \"The length of facecolors must match the number \" \"of triangles\" else # Color from positional parameter c if not args raise TypeError \"tripcolor missing 1 required positional argument c ; or \" \"1 required keyword-only argument facecolors \" elif len args > 1 raise TypeError f\"Unexpected positional parameters {args[1 ]!r}\" c np asarray args[0] if len c len tri x # having this before the len tri triangles comparison gives # precedence to nodes if there are as many nodes as triangles point colors c facecolors None elif len c len tri triangles point colors None facecolors c else raise ValueError The length of c must match either the number of points or the number of triangles # Handling of linewidths shading edgecolors and antialiased as # in Axes pcolor linewidths 0 25 if linewidth in kwargs kwargs[ linewidths ] kwargs pop linewidth kwargs setdefault linewidths linewidths edgecolors none if edgecolor in kwargs kwargs[ edgecolors ] kwargs pop edgecolor ec kwargs setdefault edgecolors edgecolors if antialiased in kwargs kwargs[ antialiaseds ] kwargs pop antialiased if antialiaseds not in kwargs and ec lower \"none\" kwargs[ antialiaseds ] False if shading gouraud if facecolors is not None raise ValueError \"shading gouraud can only be used when the colors \" \"are specified at the points not at the faces \" collection TriMesh tri alpha alpha array point colors cmap cmap norm norm **kwargs else # flat # Vertices of triangles maskedTris tri get masked triangles verts np stack tri x[maskedTris] tri y[maskedTris] axis -1 # Color values if facecolors is None # One color per triangle the mean of the 3 vertex color values colors point colors[maskedTris] mean axis 1 elif tri mask is not None # Remove color values of masked triangles colors facecolors[~tri mask] else colors facecolors collection PolyCollection verts alpha alpha array colors cmap cmap norm norm **kwargs collection scale norm norm vmin vmax ax grid False minx tri x min maxx tri x max miny tri y min maxy tri y max corners minx miny maxx maxy ax update datalim corners ax autoscale view ax add collection collection return collection"}
{"message": "What do you mean by standard?", "timestamp": "2024-11-04T06:21:11Z", "file_name": "lib/matplotlib/tri/_tripcolor.py", "range": {"start_line": 65, "end_line": 65, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1827235778", "html_url": "https://github.com/matplotlib/matplotlib/pull/29065#discussion_r1827235778", "attention_area": "", "file_path": "files/98/12/00001298.py", "old_file_path": "files/99/12/00001299.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -54,8 +55,25 @@ def tripcolor(ax, *args, alpha=1.0, norm=None, cmap=None, vmin=None,\n         values used for each triangle are from the mean c of the triangle's\n         three points. If *shading* is 'gouraud' then color values must be\n         defined at points.\n-    other_parameters\n-        All other parameters are the same as for `~.Axes.pcolor`.\n+    %(cmap_doc)s\n+\n+    %(norm_doc)s\n+\n+    %(vmin_vmax_doc)s\n+\n+    %(colorizer_doc)s\n+", "source": "def tripcolor(ax, *args, alpha=1.0, norm=None, cmap=None, vmin=None,\n              vmax=None, shading='flat', facecolors=None, **kwargs):\n    \"\"\"\n    Create a pseudocolor plot of an unstructured triangular grid.\n\n    Call signatures::\n\n      tripcolor(triangulation, c, *, ...)\n      tripcolor(x, y, c, *, [triangles=triangles], [mask=mask], ...)\n\n    The triangular grid can be specified either by passing a `.Triangulation`\n    object as the first parameter, or by passing the points *x*, *y* and\n    optionally the *triangles* and a *mask*. See `.Triangulation` for an\n    explanation of these parameters.\n\n    It is possible to pass the triangles positionally, i.e.\n    ``tripcolor(x, y, triangles, c, ...)``. However, this is discouraged.\n    For more clarity, pass *triangles* via keyword argument.\n\n    If neither of *triangulation* or *triangles* are given, the triangulation\n    is calculated on the fly. In this case, it does not make sense to provide\n    colors at the triangle faces via *c* or *facecolors* because there are\n    multiple possible triangulations for a group of points and you don't know\n    which triangles will be constructed.\n\n    Parameters\n    ----------\n    triangulation : `.Triangulation`\n        An already created triangular grid.\n    x, y, triangles, mask\n        Parameters defining the triangular grid. See `.Triangulation`.\n        This is mutually exclusive with specifying *triangulation*.\n    c : array-like\n        The color values, either for the points or for the triangles. Which one\n        is automatically inferred from the length of *c*, i.e. does it match\n        the number of points or the number of triangles. If there are the same\n        number of points and triangles in the triangulation it is assumed that\n        color values are defined at points; to force the use of color values at\n        triangles use the keyword argument ``facecolors=c`` instead of just\n        ``c``.\n        This parameter is position-only.\n    facecolors : array-like, optional\n        Can be used alternatively to *c* to specify colors at the triangle\n        faces. This parameter takes precedence over *c*.\n    shading : {'flat', 'gouraud'}, default: 'flat'\n        If  'flat' and the color values *c* are defined at points, the color\n        values used for each triangle are from the mean c of the triangle's\n        three points. If *shading* is 'gouraud' then color values must be\n        defined at points.\n    %(cmap_doc)s\n\n    %(norm_doc)s\n\n    %(vmin_vmax_doc)s\n\n    %(colorizer_doc)s\n\n    Returns\n    -------\n    `~matplotlib.collections.PolyCollection` or `~matplotlib.collections.TriMesh`\n        The result depends on *shading*: For ``shading='flat'`` the result is a\n        `.PolyCollection`, for ``shading='gouraud'`` the result is a `.TriMesh`.\n\n    Other Parameters\n    ----------------\n    **kwargs : `~matplotlib.collections.Collection` properties\n\n        %(Collection:kwdoc)s\n    \"\"\"\n    _api.check_in_list(['flat', 'gouraud'], shading=shading)\n\n    tri, args, kwargs = Triangulation.get_from_args_and_kwargs(*args, **kwargs)\n\n    # Parse the color to be in one of (the other variable will be None):\n    # - facecolors: if specified at the triangle faces\n    # - point_colors: if specified at the points\n    if facecolors is not None:\n        if args:\n            _api.warn_external(\n                \"Positional parameter c has no effect when the keyword \"\n                \"facecolors is given\")\n        point_colors = None\n        if len(facecolors) != len(tri.triangles):\n            raise ValueError(\"The length of facecolors must match the number \"\n                             \"of triangles\")\n    else:\n        # Color from positional parameter c\n        if not args:\n            raise TypeError(\n                \"tripcolor() missing 1 required positional argument: 'c'; or \"\n                \"1 required keyword-only argument: 'facecolors'\")\n        elif len(args) > 1:\n            raise TypeError(f\"Unexpected positional parameters: {args[1:]!r}\")\n        c = np.asarray(args[0])\n        if len(c) == len(tri.x):\n            # having this before the len(tri.triangles) comparison gives\n            # precedence to nodes if there are as many nodes as triangles\n            point_colors = c\n            facecolors = None\n        elif len(c) == len(tri.triangles):\n            point_colors = None\n            facecolors = c\n        else:\n            raise ValueError('The length of c must match either the number '\n                             'of points or the number of triangles')\n\n    # Handling of linewidths, shading, edgecolors and antialiased as\n    # in Axes.pcolor\n    linewidths = (0.25,)\n    if 'linewidth' in kwargs:\n        kwargs['linewidths'] = kwargs.pop('linewidth')\n    kwargs.setdefault('linewidths', linewidths)\n\n    edgecolors = 'none'\n    if 'edgecolor' in kwargs:\n        kwargs['edgecolors'] = kwargs.pop('edgecolor')\n    ec = kwargs.setdefault('edgecolors', edgecolors)\n\n    if 'antialiased' in kwargs:\n        kwargs['antialiaseds'] = kwargs.pop('antialiased')\n    if 'antialiaseds' not in kwargs and ec.lower() == \"none\":\n        kwargs['antialiaseds'] = False\n\n    if shading == 'gouraud':\n        if facecolors is not None:\n            raise ValueError(\n                \"shading='gouraud' can only be used when the colors \"\n                \"are specified at the points, not at the faces.\")\n        collection = TriMesh(tri, alpha=alpha, array=point_colors,\n                             cmap=cmap, norm=norm, **kwargs)\n    else:  # 'flat'\n        # Vertices of triangles.\n        maskedTris = tri.get_masked_triangles()\n        verts = np.stack((tri.x[maskedTris], tri.y[maskedTris]), axis=-1)\n\n        # Color values.\n        if facecolors is None:\n            # One color per triangle, the mean of the 3 vertex color values.\n            colors = point_colors[maskedTris].mean(axis=1)\n        elif tri.mask is not None:\n            # Remove color values of masked triangles.\n            colors = facecolors[~tri.mask]\n        else:\n            colors = facecolors\n        collection = PolyCollection(verts, alpha=alpha, array=colors,\n                                    cmap=cmap, norm=norm, **kwargs)\n\n    collection._scale_norm(norm, vmin, vmax)\n    ax.grid(False)\n\n    minx = tri.x.min()\n    maxx = tri.x.max()\n    miny = tri.y.min()\n    maxy = tri.y.max()\n    corners = (minx, miny), (maxx, maxy)\n    ax.update_datalim(corners)\n    ax.autoscale_view()\n    ax.add_collection(collection)\n    return collection", "source_start_line": 9, "tokens": ["def", "tripcolor", "(", "ax", ",", "*", "args", ",", "alpha", "=", "1.0", ",", "norm", "=", "None", ",", "cmap", "=", "None", ",", "vmin", "=", "None", ",", "vmax", "=", "None", ",", "shading", "=", "'flat'", ",", "facecolors", "=", "None", ",", "**", "kwargs", ")", ":", "\"\"\"    Create a pseudocolor plot of an unstructured triangular grid.    Call signatures::      tripcolor(triangulation, c, *, ...)      tripcolor(x, y, c, *, [triangles=triangles], [mask=mask], ...)    The triangular grid can be specified either by passing a `.Triangulation`    object as the first parameter, or by passing the points *x*, *y* and    optionally the *triangles* and a *mask*. See `.Triangulation` for an    explanation of these parameters.    It is possible to pass the triangles positionally, i.e.    ``tripcolor(x, y, triangles, c, ...)``. However, this is discouraged.    For more clarity, pass *triangles* via keyword argument.    If neither of *triangulation* or *triangles* are given, the triangulation    is calculated on the fly. In this case, it does not make sense to provide    colors at the triangle faces via *c* or *facecolors* because there are    multiple possible triangulations for a group of points and you don't know    which triangles will be constructed.    Parameters    ----------    triangulation : `.Triangulation`        An already created triangular grid.    x, y, triangles, mask        Parameters defining the triangular grid. See `.Triangulation`.        This is mutually exclusive with specifying *triangulation*.    c : array-like        The color values, either for the points or for the triangles. Which one        is automatically inferred from the length of *c*, i.e. does it match        the number of points or the number of triangles. If there are the same        number of points and triangles in the triangulation it is assumed that        color values are defined at points; to force the use of color values at        triangles use the keyword argument ``facecolors=c`` instead of just        ``c``.        This parameter is position-only.    facecolors : array-like, optional        Can be used alternatively to *c* to specify colors at the triangle        faces. This parameter takes precedence over *c*.    shading : {'flat', 'gouraud'}, default: 'flat'        If  'flat' and the color values *c* are defined at points, the color        values used for each triangle are from the mean c of the triangle's        three points. If *shading* is 'gouraud' then color values must be        defined at points.    %(cmap_doc)s    %(norm_doc)s    %(vmin_vmax_doc)s    %(colorizer_doc)s    Returns    -------    `~matplotlib.collections.PolyCollection` or `~matplotlib.collections.TriMesh`        The result depends on *shading*: For ``shading='flat'`` the result is a        `.PolyCollection`, for ``shading='gouraud'`` the result is a `.TriMesh`.    Other Parameters    ----------------    **kwargs : `~matplotlib.collections.Collection` properties        %(Collection:kwdoc)s    \"\"\"", "_api", ".", "check_in_list", "(", "[", "'flat'", ",", "'gouraud'", "]", ",", "shading", "=", "shading", ")", "tri", ",", "args", ",", "kwargs", "=", "Triangulation", ".", "get_from_args_and_kwargs", "(", "*", "args", ",", "**", "kwargs", ")", "if", "facecolors", "is", "not", "None", ":", "if", "args", ":", "_api", ".", "warn_external", "(", "\"Positional parameter c has no effect when the keyword \"", "\"facecolors is given\"", ")", "point_colors", "=", "None", "if", "len", "(", "facecolors", ")", "!=", "len", "(", "tri", ".", "triangles", ")", ":", "raise", "ValueError", "(", "\"The length of facecolors must match the number \"", "\"of triangles\"", ")", "else", ":", "if", "not", "args", ":", "raise", "TypeError", "(", "\"tripcolor() missing 1 required positional argument: 'c'; or \"", "\"1 required keyword-only argument: 'facecolors'\"", ")", "elif", "len", "(", "args", ")", ">", "1", ":", "raise", "TypeError", "(", "f\"", "{", "args", "[", "1", ":", "]", "!r", "}", "\"", ")", "c", "=", "np", ".", "asarray", "(", "args", "[", "0", "]", ")", "if", "len", "(", "c", ")", "==", "len", "(", "tri", ".", "x", ")", ":", "point_colors", "=", "c", "facecolors", "=", "None", "elif", "len", "(", "c", ")", "==", "len", "(", "tri", ".", "triangles", ")", ":", "point_colors", "=", "None", "facecolors", "=", "c", "else", ":", "raise", "ValueError", "(", "'The length of c must match either the number '", "'of points or the number of triangles'", ")", "linewidths", "=", "(", "0.25", ",", ")", "if", "'linewidth'", "in", "kwargs", ":", "kwargs", "[", "'linewidths'", "]", "=", "kwargs", ".", "pop", "(", "'linewidth'", ")", "kwargs", ".", "setdefault", "(", "'linewidths'", ",", "linewidths", ")", "edgecolors", "=", "'none'", "if", "'edgecolor'", "in", "kwargs", ":", "kwargs", "[", "'edgecolors'", "]", "=", "kwargs", ".", "pop", "(", "'edgecolor'", ")", "ec", "=", "kwargs", ".", "setdefault", "(", "'edgecolors'", ",", "edgecolors", ")", "if", "'antialiased'", "in", "kwargs", ":", "kwargs", "[", "'antialiaseds'", "]", "=", "kwargs", ".", "pop", "(", "'antialiased'", ")", "if", "'antialiaseds'", "not", "in", "kwargs", "and", "ec", ".", "lower", "(", ")", "==", "\"none\"", ":", "kwargs", "[", "'antialiaseds'", "]", "=", "False", "if", "shading", "==", "'gouraud'", ":", "if", "facecolors", "is", "not", "None", ":", "raise", "ValueError", "(", "\"shading='gouraud' can only be used when the colors \"", "\"are specified at the points, not at the faces.\"", ")", "collection", "=", "TriMesh", "(", "tri", ",", "alpha", "=", "alpha", ",", "array", "=", "point_colors", ",", "cmap", "=", "cmap", ",", "norm", "=", "norm", ",", "**", "kwargs", ")", "else", ":", "maskedTris", "=", "tri", ".", "get_masked_triangles", "(", ")", "verts", "=", "np", ".", "stack", "(", "(", "tri", ".", "x", "[", "maskedTris", "]", ",", "tri", ".", "y", "[", "maskedTris", "]", ")", ",", "axis", "=", "-", "1", ")", "if", "facecolors", "is", "None", ":", "colors", "=", "point_colors", "[", "maskedTris", "]", ".", "mean", "(", "axis", "=", "1", ")", "elif", "tri", ".", "mask", "is", "not", "None", ":", "colors", "=", "facecolors", "[", "~", "tri", ".", "mask", "]", "else", ":", "colors", "=", "facecolors", "collection", "=", "PolyCollection", "(", "verts", ",", "alpha", "=", "alpha", ",", "array", "=", "colors", ",", "cmap", "=", "cmap", ",", "norm", "=", "norm", ",", "**", "kwargs", ")", "collection", ".", "_scale_norm", "(", "norm", ",", "vmin", ",", "vmax", ")", "ax", ".", "grid", "(", "False", ")", "minx", "=", "tri", ".", "x", ".", "min", "(", ")", "maxx", "=", "tri", ".", "x", ".", "max", "(", ")", "miny", "=", "tri", ".", "y", ".", "min", "(", ")", "maxy", "=", "tri", ".", "y", ".", "max", "(", ")", "corners", "=", "(", "minx", ",", "miny", ")", ",", "(", "maxx", ",", "maxy", ")", "ax", ".", "update_datalim", "(", "corners", ")", "ax", ".", "autoscale_view", "(", ")", "ax", ".", "add_collection", "(", "collection", ")", "return", "collection"], "to_mask": {"VAR": ["alpha", "args", "ax", "c", "cmap", "collection", "colors", "corners", "ec", "edgecolors", "facecolors", "kwargs", "linewidths", "maskedTris", "maxx", "maxy", "minx", "miny", "norm", "point_colors", "shading", "tri", "verts", "vmax", "vmin"], "METHOD": ["PolyCollection", "TriMesh", "TypeError", "ValueError", "_scale_norm", "add_collection", "asarray", "autoscale_view", "check_in_list", "get_from_args_and_kwargs", "get_masked_triangles", "grid", "len", "lower", "max", "mean", "min", "pop", "setdefault", "stack", "update_datalim", "warn_external"]}, "attention_idx_tokens": [null, null], "patch": "@@ -54,8 +55,25 @@\n         values used for each triangle are from the mean c of the triangle's\n         three points. If *shading* is 'gouraud' then color values must be\n         defined at points.\n-    other_parameters\n-        All other parameters are the same as for `~.Axes.pcolor`.\n+    %(cmap_doc)s\n+\n+    %(norm_doc)s\n+\n+    %(vmin_vmax_doc)s\n+\n+    %(colorizer_doc)s\n+", "ext_attention_idx_tokens": [null, null], "uid": "240a14ad", "question": "What do you mean by standard?", "code": "def tripcolor ax *args alpha 1 0 norm None cmap None vmin None vmax None shading flat facecolors None **kwargs \"\"\" Create a pseudocolor plot of an unstructured triangular grid Call signatures tripcolor triangulation c * tripcolor x y c * [triangles triangles] [mask mask] The triangular grid can be specified either by passing a ` Triangulation` object as the first parameter or by passing the points *x* *y* and optionally the *triangles* and a *mask* See ` Triangulation` for an explanation of these parameters It is possible to pass the triangles positionally i e ``tripcolor x y triangles c `` However this is discouraged For more clarity pass *triangles* via keyword argument If neither of *triangulation* or *triangles* are given the triangulation is calculated on the fly In this case it does not make sense to provide colors at the triangle faces via *c* or *facecolors* because there are multiple possible triangulations for a group of points and you don t know which triangles will be constructed Parameters ---------- triangulation ` Triangulation` An already created triangular grid x y triangles mask Parameters defining the triangular grid See ` Triangulation` This is mutually exclusive with specifying *triangulation* c array-like The color values either for the points or for the triangles Which one is automatically inferred from the length of *c* i e does it match the number of points or the number of triangles If there are the same number of points and triangles in the triangulation it is assumed that color values are defined at points; to force the use of color values at triangles use the keyword argument ``facecolors c`` instead of just ``c`` This parameter is position-only facecolors array-like optional Can be used alternatively to *c* to specify colors at the triangle faces This parameter takes precedence over *c* shading { flat gouraud } default flat If flat and the color values *c* are defined at points the color values used for each triangle are from the mean c of the triangle s three points If *shading* is gouraud then color values must be defined at points % cmap doc s % norm doc s % vmin vmax doc s % colorizer doc s Returns ------- `~matplotlib collections PolyCollection` or `~matplotlib collections TriMesh` The result depends on *shading* For ``shading flat `` the result is a ` PolyCollection` for ``shading gouraud `` the result is a ` TriMesh` Other Parameters ---------------- **kwargs `~matplotlib collections Collection` properties % Collection kwdoc s \"\"\" api check in list [ flat gouraud ] shading shading tri args kwargs Triangulation get from args and kwargs *args **kwargs # Parse the color to be in one of the other variable will be None # - facecolors if specified at the triangle faces # - point colors if specified at the points if facecolors is not None if args api warn external \"Positional parameter c has no effect when the keyword \" \"facecolors is given\" point colors None if len facecolors ! len tri triangles raise ValueError \"The length of facecolors must match the number \" \"of triangles\" else # Color from positional parameter c if not args raise TypeError \"tripcolor missing 1 required positional argument c ; or \" \"1 required keyword-only argument facecolors \" elif len args > 1 raise TypeError f\"Unexpected positional parameters {args[1 ]!r}\" c np asarray args[0] if len c len tri x # having this before the len tri triangles comparison gives # precedence to nodes if there are as many nodes as triangles point colors c facecolors None elif len c len tri triangles point colors None facecolors c else raise ValueError The length of c must match either the number of points or the number of triangles # Handling of linewidths shading edgecolors and antialiased as # in Axes pcolor linewidths 0 25 if linewidth in kwargs kwargs[ linewidths ] kwargs pop linewidth kwargs setdefault linewidths linewidths edgecolors none if edgecolor in kwargs kwargs[ edgecolors ] kwargs pop edgecolor ec kwargs setdefault edgecolors edgecolors if antialiased in kwargs kwargs[ antialiaseds ] kwargs pop antialiased if antialiaseds not in kwargs and ec lower \"none\" kwargs[ antialiaseds ] False if shading gouraud if facecolors is not None raise ValueError \"shading gouraud can only be used when the colors \" \"are specified at the points not at the faces \" collection TriMesh tri alpha alpha array point colors cmap cmap norm norm **kwargs else # flat # Vertices of triangles maskedTris tri get masked triangles verts np stack tri x[maskedTris] tri y[maskedTris] axis -1 # Color values if facecolors is None # One color per triangle the mean of the 3 vertex color values colors point colors[maskedTris] mean axis 1 elif tri mask is not None # Remove color values of masked triangles colors facecolors[~tri mask] else colors facecolors collection PolyCollection verts alpha alpha array colors cmap cmap norm norm **kwargs collection scale norm norm vmin vmax ax grid False minx tri x min maxx tri x max miny tri y min maxy tri y max corners minx miny maxx maxy ax update datalim corners ax autoscale view ax add collection collection return collection"}
{"message": "This appears to be plotting a straight line that is unrelated to the table.  Can you explain why it is here?  If not, take it out.", "timestamp": "2024-12-10T21:26:52Z", "file_name": "lib/matplotlib/tests/test_table.py", "range": {"start_line": 282, "end_line": 282, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1878878302", "html_url": "https://github.com/matplotlib/matplotlib/pull/29258#discussion_r1878878302", "attention_area": "    ax.plot(np.linspace(0, 10, 100), np.linspace(0, 10, 100) + 1)", "file_path": "files/90/13/00001390.py", "old_file_path": "files/91/13/00001391.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -270,3 +270,24 @@ def test_table_dataframe(pd):\n     for r, (index, row) in enumerate(df.iterrows()):\n         for c, col in enumerate(df.columns if r == 0 else row.values):\n             assert table[r if r == 0 else r+1, c].get_text().get_text() == str(col)\n+\n+\n+# Test function for fontsize in table\n+def test_table_fontsize():\n+    # Data for plotting\n+    tableData = [['a', 1], ['b', 1]]\n+    # Create the figure and axis objects\n+    fig, ax = plt.subplots()\n+    # Plot the data (although we are focusing on the table)\n+    ax.plot(np.linspace(0, 10, 100), np.linspace(0, 10, 100) + 1)", "source": "def test_table_fontsize():\n    # Data for plotting\n    tableData = [['a', 1], ['b', 1]]\n    # Create the figure and axis objects\n    fig, ax = plt.subplots()\n    # Plot the data (although we are focusing on the table)\n    ax.plot(np.linspace(0, 10, 100), np.linspace(0, 10, 100) + 1)\n    # Add a table with fontsize=30\n    t = ax.table(\n        cellText=tableData,\n        loc='top',\n        cellLoc='center',\n        fontsize=30\n    )\n    # Retrieve the font size from a specific cell (e.g., cell (0, 0))\n    cell_fontsize = t[(0, 0)].get_fontsize()\n    # Assert that the fontsize is correctly set to 30\n    assert cell_fontsize == 30, f\"Expected fontsize 30, but got {cell_fontsize}\"", "source_start_line": 276, "tokens": ["def", "test_table_fontsize", "(", ")", ":", "tableData", "=", "[", "[", "'a'", ",", "1", "]", ",", "[", "'b'", ",", "1", "]", "]", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "ax", ".", "plot", "(", "np", ".", "linspace", "(", "0", ",", "10", ",", "100", ")", ",", "np", ".", "linspace", "(", "0", ",", "10", ",", "100", ")", "+", "1", ")", "t", "=", "ax", ".", "table", "(", "cellText", "=", "tableData", ",", "loc", "=", "'top'", ",", "cellLoc", "=", "'center'", ",", "fontsize", "=", "30", ")", "cell_fontsize", "=", "t", "[", "(", "0", ",", "0", ")", "]", ".", "get_fontsize", "(", ")", "assert", "cell_fontsize", "==", "30", ",", "f\"", "{", "cell_fontsize", "}", "\""], "to_mask": {"VAR": ["ax", "cell_fontsize", "fig", "t", "tableData"], "METHOD": ["get_fontsize", "linspace", "plot", "subplots", "table"]}, "attention_idx_tokens": [29, 56], "patch": "@@ -270,3 +270,24 @@\n     for r, (index, row) in enumerate(df.iterrows()):\n         for c, col in enumerate(df.columns if r == 0 else row.values):\n             assert table[r if r == 0 else r+1, c].get_text().get_text() == str(col)\n+\n+\n+# Test function for fontsize in table\n+def test_table_fontsize():\n+    # Data for plotting\n+    tableData = [['a', 1], ['b', 1]]\n+    # Create the figure and axis objects\n+    fig, ax = plt.subplots()\n+    # Plot the data (although we are focusing on the table)\n+    ax.plot(np.linspace(0, 10, 100), np.linspace(0, 10, 100) + 1)", "ext_attention_idx_tokens": [0, 92], "uid": "23d59abc", "question": "This appears to be plotting a straight line that is unrelated to the table.  Can you explain why it is here?  If not, take it out.", "code": "def test table fontsize # Data for plotting tableData [[ a 1] [ b 1]] # Create the figure and axis objects fig ax plt subplots # Plot the data although we are focusing on the table ax plot np linspace 0 10 100 np linspace 0 10 100 + 1 # Add a table with fontsize 30 t ax table cellText tableData loc top cellLoc center fontsize 30 # Retrieve the font size from a specific cell e g cell 0 0 cell fontsize t[ 0 0 ] get fontsize # Assert that the fontsize is correctly set to 30 assert cell fontsize 30 f\"Expected fontsize 30 but got {cell fontsize}\""}
{"message": "Is this follow-up PR already open?", "timestamp": "2024-12-19T03:40:55Z", "file_name": "lib/matplotlib/collections.py", "range": {"start_line": 179, "end_line": 179, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1891090943", "html_url": "https://github.com/matplotlib/matplotlib/pull/28104#discussion_r1891090943", "attention_area": "        # and will be replaced by a proper mechanism in a follow-up PR.", "file_path": "files/24/14/00001424.py", "old_file_path": "files/25/14/00001425.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -174,7 +174,13 @@ def __init__(self, *,\n         self._face_is_mapped = None\n         self._edge_is_mapped = None\n         self._mapped_colors = None  # calculated in update_scalarmappable\n-        self._hatch_color = mcolors.to_rgba(mpl.rcParams['hatch.color'])\n+\n+        # Temporary logic to set hatchcolor. This eager resolution is temporary\n+        # and will be replaced by a proper mechanism in a follow-up PR.", "source": "def __init__(self, *,\n                 edgecolors=None,\n                 facecolors=None,\n                 linewidths=None,\n                 linestyles='solid',\n                 capstyle=None,\n                 joinstyle=None,\n                 antialiaseds=None,\n                 offsets=None,\n                 offset_transform=None,\n                 norm=None,  # optional for ScalarMappable\n                 cmap=None,  # ditto\n                 colorizer=None,\n                 pickradius=5.0,\n                 hatch=None,\n                 urls=None,\n                 zorder=1,\n                 **kwargs\n                 ):\n        \"\"\"\n        Parameters\n        ----------\n        edgecolors : :mpltype:`color` or list of colors, default: :rc:`patch.edgecolor`\n            Edge color for each patch making up the collection. The special\n            value 'face' can be passed to make the edgecolor match the\n            facecolor.\n        facecolors : :mpltype:`color` or list of colors, default: :rc:`patch.facecolor`\n            Face color for each patch making up the collection.\n        linewidths : float or list of floats, default: :rc:`patch.linewidth`\n            Line width for each patch making up the collection.\n        linestyles : str or tuple or list thereof, default: 'solid'\n            Valid strings are ['solid', 'dashed', 'dashdot', 'dotted', '-',\n            '--', '-.', ':']. Dash tuples should be of the form::\n\n                (offset, onoffseq),\n\n            where *onoffseq* is an even length tuple of on and off ink lengths\n            in points. For examples, see\n            :doc:`/gallery/lines_bars_and_markers/linestyles`.\n        capstyle : `.CapStyle`-like, default: 'butt'\n            Style to use for capping lines for all paths in the collection.\n            Allowed values are %(CapStyle)s.\n        joinstyle : `.JoinStyle`-like, default: 'round'\n            Style to use for joining lines for all paths in the collection.\n            Allowed values are %(JoinStyle)s.\n        antialiaseds : bool or list of bool, default: :rc:`patch.antialiased`\n            Whether each patch in the collection should be drawn with\n            antialiasing.\n        offsets : (float, float) or list thereof, default: (0, 0)\n            A vector by which to translate each patch after rendering (default\n            is no translation). The translation is performed in screen (pixel)\n            coordinates (i.e. after the Artist's transform is applied).\n        offset_transform : `~.Transform`, default: `.IdentityTransform`\n            A single transform which will be applied to each *offsets* vector\n            before it is used.\n        cmap, norm\n            Data normalization and colormapping parameters. See\n            `.ScalarMappable` for a detailed description.\n        hatch : str, optional\n            Hatching pattern to use in filled paths, if any. Valid strings are\n            ['/', '\\\\', '|', '-', '+', 'x', 'o', 'O', '.', '*']. See\n            :doc:`/gallery/shapes_and_collections/hatch_style_reference` for\n            the meaning of each hatch type.\n        pickradius : float, default: 5.0\n            If ``pickradius <= 0``, then `.Collection.contains` will return\n            ``True`` whenever the test point is inside of one of the polygons\n            formed by the control points of a Path in the Collection. On the\n            other hand, if it is greater than 0, then we instead check if the\n            test point is contained in a stroke of width ``2*pickradius``\n            following any of the Paths in the Collection.\n        urls : list of str, default: None\n            A URL for each patch to link to once drawn. Currently only works\n            for the SVG backend. See :doc:`/gallery/misc/hyperlinks_sgskip` for\n            examples.\n        zorder : float, default: 1\n            The drawing order, shared by all Patches in the Collection. See\n            :doc:`/gallery/misc/zorder_demo` for all defaults and examples.\n        **kwargs\n            Remaining keyword arguments will be used to set properties as\n            ``Collection.set_{key}(val)`` for each key-value pair in *kwargs*.\n        \"\"\"\n\n        super().__init__(self._get_colorizer(cmap, norm, colorizer))\n        # list of un-scaled dash patterns\n        # this is needed scaling the dash pattern by linewidth\n        self._us_linestyles = [(0, None)]\n        # list of dash patterns\n        self._linestyles = [(0, None)]\n        # list of unbroadcast/scaled linewidths\n        self._us_lw = [0]\n        self._linewidths = [0]\n\n        self._gapcolor = None  # Currently only used by LineCollection.\n\n        # Flags set by _set_mappable_flags: are colors from mapping an array?\n        self._face_is_mapped = None\n        self._edge_is_mapped = None\n        self._mapped_colors = None  # calculated in update_scalarmappable\n\n        # Temporary logic to set hatchcolor. This eager resolution is temporary\n        # and will be replaced by a proper mechanism in a follow-up PR.\n        hatch_color = mpl.rcParams['hatch.color']\n        if hatch_color == 'edge':\n            hatch_color = mpl.rcParams['patch.edgecolor']\n        self._hatch_color = mcolors.to_rgba(hatch_color)\n        self._hatch_linewidth = mpl.rcParams['hatch.linewidth']\n        self.set_facecolor(facecolors)\n        self.set_edgecolor(edgecolors)\n        self.set_linewidth(linewidths)\n        self.set_linestyle(linestyles)\n        self.set_antialiased(antialiaseds)\n        self.set_pickradius(pickradius)\n        self.set_urls(urls)\n        self.set_hatch(hatch)\n        self.set_zorder(zorder)\n\n        if capstyle:\n            self.set_capstyle(capstyle)\n        else:\n            self._capstyle = None\n\n        if joinstyle:\n            self.set_joinstyle(joinstyle)\n        else:\n            self._joinstyle = None\n\n        if offsets is not None:\n            offsets = np.asanyarray(offsets, float)\n            # Broadcast (2,) -> (1, 2) but nothing else.\n            if offsets.shape == (2,):\n                offsets = offsets[None, :]\n\n        self._offsets = offsets\n        self._offset_transform = offset_transform\n\n        self._path_effects = None\n        self._internal_update(kwargs)\n        self._paths = None", "source_start_line": 79, "tokens": ["def", "__init__", "(", "self", ",", "*", ",", "edgecolors", "=", "None", ",", "facecolors", "=", "None", ",", "linewidths", "=", "None", ",", "linestyles", "=", "'solid'", ",", "capstyle", "=", "None", ",", "joinstyle", "=", "None", ",", "antialiaseds", "=", "None", ",", "offsets", "=", "None", ",", "offset_transform", "=", "None", ",", "norm", "=", "None", ",", "cmap", "=", "None", ",", "colorizer", "=", "None", ",", "pickradius", "=", "5.0", ",", "hatch", "=", "None", ",", "urls", "=", "None", ",", "zorder", "=", "1", ",", "**", "kwargs", ")", ":", "\"\"\"        Parameters        ----------        edgecolors : :mpltype:`color` or list of colors, default: :rc:`patch.edgecolor`            Edge color for each patch making up the collection. The special            value 'face' can be passed to make the edgecolor match the            facecolor.        facecolors : :mpltype:`color` or list of colors, default: :rc:`patch.facecolor`            Face color for each patch making up the collection.        linewidths : float or list of floats, default: :rc:`patch.linewidth`            Line width for each patch making up the collection.        linestyles : str or tuple or list thereof, default: 'solid'            Valid strings are ['solid', 'dashed', 'dashdot', 'dotted', '-',            '--', '-.', ':']. Dash tuples should be of the form::                (offset, onoffseq),            where *onoffseq* is an even length tuple of on and off ink lengths            in points. For examples, see            :doc:`/gallery/lines_bars_and_markers/linestyles`.        capstyle : `.CapStyle`-like, default: 'butt'            Style to use for capping lines for all paths in the collection.            Allowed values are %(CapStyle)s.        joinstyle : `.JoinStyle`-like, default: 'round'            Style to use for joining lines for all paths in the collection.            Allowed values are %(JoinStyle)s.        antialiaseds : bool or list of bool, default: :rc:`patch.antialiased`            Whether each patch in the collection should be drawn with            antialiasing.        offsets : (float, float) or list thereof, default: (0, 0)            A vector by which to translate each patch after rendering (default            is no translation). The translation is performed in screen (pixel)            coordinates (i.e. after the Artist's transform is applied).        offset_transform : `~.Transform`, default: `.IdentityTransform`            A single transform which will be applied to each *offsets* vector            before it is used.        cmap, norm            Data normalization and colormapping parameters. See            `.ScalarMappable` for a detailed description.        hatch : str, optional            Hatching pattern to use in filled paths, if any. Valid strings are            ['/', '\\\\', '|', '-', '+', 'x', 'o', 'O', '.', '*']. See            :doc:`/gallery/shapes_and_collections/hatch_style_reference` for            the meaning of each hatch type.        pickradius : float, default: 5.0            If ``pickradius <= 0``, then `.Collection.contains` will return            ``True`` whenever the test point is inside of one of the polygons            formed by the control points of a Path in the Collection. On the            other hand, if it is greater than 0, then we instead check if the            test point is contained in a stroke of width ``2*pickradius``            following any of the Paths in the Collection.        urls : list of str, default: None            A URL for each patch to link to once drawn. Currently only works            for the SVG backend. See :doc:`/gallery/misc/hyperlinks_sgskip` for            examples.        zorder : float, default: 1            The drawing order, shared by all Patches in the Collection. See            :doc:`/gallery/misc/zorder_demo` for all defaults and examples.        **kwargs            Remaining keyword arguments will be used to set properties as            ``Collection.set_{key}(val)`` for each key-value pair in *kwargs*.        \"\"\"", "super", "(", ")", ".", "__init__", "(", "self", ".", "_get_colorizer", "(", "cmap", ",", "norm", ",", "colorizer", ")", ")", "self", ".", "_us_linestyles", "=", "[", "(", "0", ",", "None", ")", "]", "self", ".", "_linestyles", "=", "[", "(", "0", ",", "None", ")", "]", "self", ".", "_us_lw", "=", "[", "0", "]", "self", ".", "_linewidths", "=", "[", "0", "]", "self", ".", "_gapcolor", "=", "None", "self", ".", "_face_is_mapped", "=", "None", "self", ".", "_edge_is_mapped", "=", "None", "self", ".", "_mapped_colors", "=", "None", "hatch_color", "=", "mpl", ".", "rcParams", "[", "'hatch.color'", "]", "if", "hatch_color", "==", "'edge'", ":", "hatch_color", "=", "mpl", ".", "rcParams", "[", "'patch.edgecolor'", "]", "self", ".", "_hatch_color", "=", "mcolors", ".", "to_rgba", "(", "hatch_color", ")", "self", ".", "_hatch_linewidth", "=", "mpl", ".", "rcParams", "[", "'hatch.linewidth'", "]", "self", ".", "set_facecolor", "(", "facecolors", ")", "self", ".", "set_edgecolor", "(", "edgecolors", ")", "self", ".", "set_linewidth", "(", "linewidths", ")", "self", ".", "set_linestyle", "(", "linestyles", ")", "self", ".", "set_antialiased", "(", "antialiaseds", ")", "self", ".", "set_pickradius", "(", "pickradius", ")", "self", ".", "set_urls", "(", "urls", ")", "self", ".", "set_hatch", "(", "hatch", ")", "self", ".", "set_zorder", "(", "zorder", ")", "if", "capstyle", ":", "self", ".", "set_capstyle", "(", "capstyle", ")", "else", ":", "self", ".", "_capstyle", "=", "None", "if", "joinstyle", ":", "self", ".", "set_joinstyle", "(", "joinstyle", ")", "else", ":", "self", ".", "_joinstyle", "=", "None", "if", "offsets", "is", "not", "None", ":", "offsets", "=", "np", ".", "asanyarray", "(", "offsets", ",", "float", ")", "if", "offsets", ".", "shape", "==", "(", "2", ",", ")", ":", "offsets", "=", "offsets", "[", "None", ",", ":", "]", "self", ".", "_offsets", "=", "offsets", "self", ".", "_offset_transform", "=", "offset_transform", "self", ".", "_path_effects", "=", "None", "self", ".", "_internal_update", "(", "kwargs", ")", "self", ".", "_paths", "=", "None"], "to_mask": {"VAR": ["_capstyle", "_edge_is_mapped", "_face_is_mapped", "_gapcolor", "_hatch_color", "_hatch_linewidth", "_joinstyle", "_linestyles", "_linewidths", "_mapped_colors", "_offset_transform", "_offsets", "_path_effects", "_paths", "_us_linestyles", "_us_lw", "antialiaseds", "capstyle", "cmap", "colorizer", "edgecolors", "facecolors", "hatch", "hatch_color", "joinstyle", "linestyles", "linewidths", "norm", "offset_transform", "offsets", "pickradius", "self", "urls", "zorder"], "METHOD": ["__init__", "_get_colorizer", "_internal_update", "asanyarray", "set_antialiased", "set_capstyle", "set_edgecolor", "set_facecolor", "set_hatch", "set_joinstyle", "set_linestyle", "set_linewidth", "set_pickradius", "set_urls", "set_zorder", "super", "to_rgba"]}, "attention_idx_tokens": [null, null], "patch": "@@ -174,7 +174,13 @@\n         self._face_is_mapped = None\n         self._edge_is_mapped = None\n         self._mapped_colors = None  # calculated in update_scalarmappable\n-        self._hatch_color = mcolors.to_rgba(mpl.rcParams['hatch.color'])\n+\n+        # Temporary logic to set hatchcolor. This eager resolution is temporary\n+        # and will be replaced by a proper mechanism in a follow-up PR.", "ext_attention_idx_tokens": [149, 189], "uid": "719f88b7", "question": "Is this follow-up PR already open?", "code": "def init self * edgecolors None facecolors None linewidths None linestyles solid capstyle None joinstyle None antialiaseds None offsets None offset transform None norm None # optional for ScalarMappable cmap None # ditto colorizer None pickradius 5 0 hatch None urls None zorder 1 **kwargs \"\"\" Parameters ---------- edgecolors mpltype `color` or list of colors default rc `patch edgecolor` Edge color for each patch making up the collection The special value face can be passed to make the edgecolor match the facecolor facecolors mpltype `color` or list of colors default rc `patch facecolor` Face color for each patch making up the collection linewidths float or list of floats default rc `patch linewidth` Line width for each patch making up the collection linestyles str or tuple or list thereof default solid Valid strings are [ solid dashed dashdot dotted - -- - ] Dash tuples should be of the form offset onoffseq where *onoffseq* is an even length tuple of on and off ink lengths in points For examples see doc ` gallery lines bars and markers linestyles` capstyle ` CapStyle`-like default butt Style to use for capping lines for all paths in the collection Allowed values are % CapStyle s joinstyle ` JoinStyle`-like default round Style to use for joining lines for all paths in the collection Allowed values are % JoinStyle s antialiaseds bool or list of bool default rc `patch antialiased` Whether each patch in the collection should be drawn with antialiasing offsets float float or list thereof default 0 0 A vector by which to translate each patch after rendering default is no translation The translation is performed in screen pixel coordinates i e after the Artist s transform is applied offset transform `~ Transform` default ` IdentityTransform` A single transform which will be applied to each *offsets* vector before it is used cmap norm Data normalization and colormapping parameters See ` ScalarMappable` for a detailed description hatch str optional Hatching pattern to use in filled paths if any Valid strings are [ \\\\ | - + x o O * ] See doc ` gallery shapes and collections hatch style reference` for the meaning of each hatch type pickradius float default 5 0 If ``pickradius < 0`` then ` Collection contains` will return ``True`` whenever the test point is inside of one of the polygons formed by the control points of a Path in the Collection On the other hand if it is greater than 0 then we instead check if the test point is contained in a stroke of width ``2*pickradius`` following any of the Paths in the Collection urls list of str default None A URL for each patch to link to once drawn Currently only works for the SVG backend See doc ` gallery misc hyperlinks sgskip` for examples zorder float default 1 The drawing order shared by all Patches in the Collection See doc ` gallery misc zorder demo` for all defaults and examples **kwargs Remaining keyword arguments will be used to set properties as ``Collection set {key} val `` for each key-value pair in *kwargs* \"\"\" super init self get colorizer cmap norm colorizer # list of un-scaled dash patterns # this is needed scaling the dash pattern by linewidth self us linestyles [ 0 None ] # list of dash patterns self linestyles [ 0 None ] # list of unbroadcast scaled linewidths self us lw [0] self linewidths [0] self gapcolor None # Currently only used by LineCollection # Flags set by set mappable flags are colors from mapping an array? self face is mapped None self edge is mapped None self mapped colors None # calculated in update scalarmappable # Temporary logic to set hatchcolor This eager resolution is temporary # and will be replaced by a proper mechanism in a follow-up PR hatch color mpl rcParams[ hatch color ] if hatch color edge hatch color mpl rcParams[ patch edgecolor ] self hatch color mcolors to rgba hatch color self hatch linewidth mpl rcParams[ hatch linewidth ] self set facecolor facecolors self set edgecolor edgecolors self set linewidth linewidths self set linestyle linestyles self set antialiased antialiaseds self set pickradius pickradius self set urls urls self set hatch hatch self set zorder zorder if capstyle self set capstyle capstyle else self capstyle None if joinstyle self set joinstyle joinstyle else self joinstyle None if offsets is not None offsets np asanyarray offsets float # Broadcast 2 -> 1 2 but nothing else if offsets shape 2 offsets offsets[None ] self offsets offsets self offset transform offset transform self path effects None self internal update kwargs self paths None"}
{"message": "discussed this on the call today and is this being done to maintain backward compatibility if someone sets edgecolor to `None` and doesn't define `hatchcolor` or `hatch.color` to ensure that something gets drawn? \r\n\r\nmy thinking is that that should return a warning \"Setting a hatch but hatch and edgecolor are none\" but we shouldn't special case a fallback (that also may not work if patch.edgecolor is \"none\")", "timestamp": "2024-12-19T20:30:39Z", "file_name": "lib/matplotlib/patches.py", "range": {"start_line": 348, "end_line": 348, "start_character": 0, "end_character": 0}, "project": "matplotlib/matplotlib", "api_url": "https://api.github.com/repos/matplotlib/matplotlib/pulls/comments/1893104402", "html_url": "https://github.com/matplotlib/matplotlib/pull/28104#discussion_r1893104402", "attention_area": "            return self.get_edgecolor()", "file_path": "files/26/14/00001426.py", "old_file_path": "files/17/14/00001417.py", "filters": {"comment_message": true, "patchset": false, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -338,6 +340,14 @@ def get_facecolor(self):\n         \"\"\"Return the face color.\"\"\"\n         return self._facecolor\n \n+    def get_hatchcolor(self):\n+        \"\"\"Return the hatch color.\"\"\"\n+        if self._hatch_color == 'edge':\n+            if self._edgecolor[3] == 0:  # fully transparent\n+                return colors.to_rgba(mpl.rcParams['patch.edgecolor'])\n+            return self.get_edgecolor()", "source": "def get_hatchcolor(self):\n        \"\"\"Return the hatch color.\"\"\"\n        if self._hatch_color == 'edge':\n            if self._edgecolor[3] == 0:  # fully transparent\n                return colors.to_rgba(mpl.rcParams['patch.edgecolor'])\n            return self.get_edgecolor()\n        return self._hatch_color", "source_start_line": 343, "tokens": ["def", "get_hatchcolor", "(", "self", ")", ":", "\"\"\"Return the hatch color.\"\"\"", "if", "self", ".", "_hatch_color", "==", "'edge'", ":", "if", "self", ".", "_edgecolor", "[", "3", "]", "==", "0", ":", "return", "colors", ".", "to_rgba", "(", "mpl", ".", "rcParams", "[", "'patch.edgecolor'", "]", ")", "return", "self", ".", "get_edgecolor", "(", ")", "return", "self", ".", "_hatch_color"], "to_mask": {"VAR": ["self"], "METHOD": ["get_edgecolor", "to_rgba"]}, "attention_idx_tokens": [36, 41], "patch": "@@ -338,6 +340,14 @@\n         \"\"\"Return the face color.\"\"\"\n         return self._facecolor\n \n+    def get_hatchcolor(self):\n+        \"\"\"Return the hatch color.\"\"\"\n+        if self._hatch_color == 'edge':\n+            if self._edgecolor[3] == 0:  # fully transparent\n+                return colors.to_rgba(mpl.rcParams['patch.edgecolor'])\n+            return self.get_edgecolor()", "ext_attention_idx_tokens": [0, 45], "uid": "5b8ec775", "question": "discussed this on the call today and is this being done to maintain backward compatibility if someone sets edgecolor to `None` and doesn't define `hatchcolor` or `hatch.color` to ensure that something gets drawn?     my thinking is that that should return a warning \"Setting a hatch but hatch and edgecolor are none\" but we shouldn't special case a fallback (that also may not work if patch.edgecolor is \"none\")", "code": "def get hatchcolor self \"\"\"Return the hatch color \"\"\" if self hatch color edge if self edgecolor[3] 0 # fully transparent return colors to rgba mpl rcParams[ patch edgecolor ] return self get edgecolor return self hatch color"}
{"message": "Is this true for XLA as well?", "timestamp": "2024-01-04T16:36:19Z", "file_name": "tensorflow/python/ops/embedding_ops.py", "range": {"start_line": 311, "end_line": 311, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1442000826", "html_url": "https://github.com/tensorflow/tensorflow/pull/62734#discussion_r1442000826", "attention_area": "      Caution: On CPU, if an out of bound id is found, an error is raised.", "file_path": "files/04/00/00000004.py", "old_file_path": "files/05/00/00000005.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -307,6 +307,10 @@ def embedding_lookup(\n       element must be appropriately sized for the given `partition_strategy`.\n     ids: A `Tensor` or a 'RaggedTensor' with type `int32` or `int64` containing\n       the ids to be looked up in `params`.\n+      \n+      Caution: On CPU, if an out of bound id is found, an error is raised.", "source": "def embedding_lookup(\n    params,\n    ids,\n    partition_strategy=\"mod\",\n    name=None,\n    validate_indices=True,  # pylint: disable=unused-argument\n    max_norm=None):\n  \"\"\"Looks up embeddings for the given `ids` from a list of tensors.\n\n  This function is used to perform parallel lookups on the list of tensors in\n  `params`.  It is a generalization of `tf.gather`, where `params` is\n  interpreted as a partitioning of a large embedding tensor.  `params` may be\n  a `PartitionedVariable` as returned by using `tf.compat.v1.get_variable()`\n  with a partitioner.\n\n  If `len(params) > 1`, each element `id` of `ids` is partitioned between\n  the elements of `params` according to the `partition_strategy`.\n  In all strategies, if the id space does not evenly divide the number of\n  partitions, each of the first `(max_id + 1) % len(params)` partitions will\n  be assigned one more id.\n\n  If `partition_strategy` is `\"mod\"`, we assign each id to partition\n  `p = id % len(params)`. For instance,\n  13 ids are split across 5 partitions as:\n  `[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]`\n\n  If `partition_strategy` is `\"div\"`, we assign ids to partitions in a\n  contiguous manner. In this case, 13 ids are split across 5 partitions as:\n  `[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]`\n\n  If the input ids are ragged tensors, partition variables are not supported and\n  the partition strategy and the max_norm are ignored.\n  The results of the lookup are concatenated into a dense\n  tensor. The returned tensor has shape `shape(ids) + shape(params)[1:]`.\n\n  Args:\n    params: A single tensor representing the complete embedding tensor, or a\n      list of P tensors all of same shape except for the first dimension,\n      representing sharded embedding tensors.  Alternatively, a\n      `PartitionedVariable`, created by partitioning along dimension 0. Each\n      element must be appropriately sized for the given `partition_strategy`.\n    ids: A `Tensor` or a 'RaggedTensor' with type `int32` or `int64` containing\n      the ids to be looked up in `params`.\n      \n      Caution: On CPU, if an out of bound id is found, an error is raised.\n      On GPU, if an out of bound id is found, a 0 is stored in the\n      corresponding output value.\n    partition_strategy: A string specifying the partitioning strategy, relevant\n      if `len(params) > 1`. Currently `\"div\"` and `\"mod\"` are supported. Default\n      is `\"mod\"`.\n    name: A name for the operation (optional).\n    validate_indices: DEPRECATED. If this operation is assigned to CPU, values\n      in `indices` are always validated to be within range.  If assigned to GPU,\n      out-of-bound indices result in safe but unspecified behavior, which may\n      include raising an error.\n    max_norm: If not `None`, each embedding is clipped if its l2-norm is larger\n      than this value.\n\n  Returns:\n    A `Tensor` or a 'RaggedTensor', depending on the input, with the same type\n    as the tensors in `params`.\n\n  Raises:\n    ValueError: If `params` is empty.\n  \"\"\"\n\n  \"\"\"\n    **Behavior Difference between CPU and GPU**\n\n    Please note that when using `tf.nn.embedding_lookup` on a GPU, if an out-of-bound \n    index is encountered, a value of 0 will be stored in the corresponding output value. \n    On the other hand, when using `tf.nn.embedding_lookup` on a CPU, an error will be \n    returned if an out-of-bound index is found.\n\n    This behavior difference can impact the results of your computation, especially when \n    dealing with indices that may go beyond the bounds of the tensor. \n    Make sure to be mindful of this distinction when using the `tf.nn.embedding_lookup` \n    function in your computations.\n\n    **Usage Example**\n\n    Here's an example demonstrating how to use `tf.nn.embedding_lookup`:\n\n    ```python\n    import tensorflow as tf\n\n    # Example embedding matrix and indices\n    embedding_matrix = tf.constant([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])\n    indices = tf.constant([1, 0, 2])\n\n    # Perform embedding lookup\n    embeddings = tf.nn.embedding_lookup(embedding_matrix, indices)\n\n    # Print the result\n    print(\"Embeddings:\")\n    print(embeddings.numpy())\n    ```\n    \"\"\"\n\n  return _embedding_lookup_and_transform(\n      params=params,\n      ids=ids,\n      partition_strategy=partition_strategy,\n      name=name,\n      max_norm=max_norm,\n      transform_fn=None)", "source_start_line": 267, "tokens": ["def", "embedding_lookup", "(", "params", ",", "ids", ",", "partition_strategy", "=", "\"mod\"", ",", "name", "=", "None", ",", "validate_indices", "=", "True", ",", "max_norm", "=", "None", ")", ":", "\"\"\"Looks up embeddings for the given `ids` from a list of tensors.  This function is used to perform parallel lookups on the list of tensors in  `params`.  It is a generalization of `tf.gather`, where `params` is  interpreted as a partitioning of a large embedding tensor.  `params` may be  a `PartitionedVariable` as returned by using `tf.compat.v1.get_variable()`  with a partitioner.  If `len(params) > 1`, each element `id` of `ids` is partitioned between  the elements of `params` according to the `partition_strategy`.  In all strategies, if the id space does not evenly divide the number of  partitions, each of the first `(max_id + 1) % len(params)` partitions will  be assigned one more id.  If `partition_strategy` is `\"mod\"`, we assign each id to partition  `p = id % len(params)`. For instance,  13 ids are split across 5 partitions as:  `[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]`  If `partition_strategy` is `\"div\"`, we assign ids to partitions in a  contiguous manner. In this case, 13 ids are split across 5 partitions as:  `[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]`  If the input ids are ragged tensors, partition variables are not supported and  the partition strategy and the max_norm are ignored.  The results of the lookup are concatenated into a dense  tensor. The returned tensor has shape `shape(ids) + shape(params)[1:]`.  Args:    params: A single tensor representing the complete embedding tensor, or a      list of P tensors all of same shape except for the first dimension,      representing sharded embedding tensors.  Alternatively, a      `PartitionedVariable`, created by partitioning along dimension 0. Each      element must be appropriately sized for the given `partition_strategy`.    ids: A `Tensor` or a 'RaggedTensor' with type `int32` or `int64` containing      the ids to be looked up in `params`.            Caution: On CPU, if an out of bound id is found, an error is raised.      On GPU, if an out of bound id is found, a 0 is stored in the      corresponding output value.    partition_strategy: A string specifying the partitioning strategy, relevant      if `len(params) > 1`. Currently `\"div\"` and `\"mod\"` are supported. Default      is `\"mod\"`.    name: A name for the operation (optional).    validate_indices: DEPRECATED. If this operation is assigned to CPU, values      in `indices` are always validated to be within range.  If assigned to GPU,      out-of-bound indices result in safe but unspecified behavior, which may      include raising an error.    max_norm: If not `None`, each embedding is clipped if its l2-norm is larger      than this value.  Returns:    A `Tensor` or a 'RaggedTensor', depending on the input, with the same type    as the tensors in `params`.  Raises:    ValueError: If `params` is empty.  \"\"\"", "\"\"\"    **Behavior Difference between CPU and GPU**    Please note that when using `tf.nn.embedding_lookup` on a GPU, if an out-of-bound     index is encountered, a value of 0 will be stored in the corresponding output value.     On the other hand, when using `tf.nn.embedding_lookup` on a CPU, an error will be     returned if an out-of-bound index is found.    This behavior difference can impact the results of your computation, especially when     dealing with indices that may go beyond the bounds of the tensor.     Make sure to be mindful of this distinction when using the `tf.nn.embedding_lookup`     function in your computations.    **Usage Example**    Here's an example demonstrating how to use `tf.nn.embedding_lookup`:    ```python    import tensorflow as tf    # Example embedding matrix and indices    embedding_matrix = tf.constant([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])    indices = tf.constant([1, 0, 2])    # Perform embedding lookup    embeddings = tf.nn.embedding_lookup(embedding_matrix, indices)    # Print the result    print(\"Embeddings:\")    print(embeddings.numpy())    ```    \"\"\"", "return", "_embedding_lookup_and_transform", "(", "params", "=", "params", ",", "ids", "=", "ids", ",", "partition_strategy", "=", "partition_strategy", ",", "name", "=", "name", ",", "max_norm", "=", "max_norm", ",", "transform_fn", "=", "None", ")"], "to_mask": {"VAR": ["ids", "max_norm", "name", "params", "partition_strategy", "validate_indices"], "METHOD": ["_embedding_lookup_and_transform"]}, "attention_idx_tokens": [null, null], "patch": "@@ -307,6 +307,10 @@\n       element must be appropriately sized for the given `partition_strategy`.\n     ids: A `Tensor` or a 'RaggedTensor' with type `int32` or `int64` containing\n       the ids to be looked up in `params`.\n+      \n+      Caution: On CPU, if an out of bound id is found, an error is raised.", "ext_attention_idx_tokens": [null, null], "uid": "97f9a26c", "question": "Is this true for XLA as well?", "code": "def embedding lookup params ids partition strategy \"mod\" name None validate indices True # pylint disable unused-argument max norm None \"\"\"Looks up embeddings for the given `ids` from a list of tensors This function is used to perform parallel lookups on the list of tensors in `params` It is a generalization of `tf gather` where `params` is interpreted as a partitioning of a large embedding tensor `params` may be a `PartitionedVariable` as returned by using `tf compat v1 get variable ` with a partitioner If `len params > 1` each element `id` of `ids` is partitioned between the elements of `params` according to the `partition strategy` In all strategies if the id space does not evenly divide the number of partitions each of the first ` max id + 1 % len params ` partitions will be assigned one more id If `partition strategy` is `\"mod\"` we assign each id to partition `p id % len params ` For instance 13 ids are split across 5 partitions as `[[0 5 10] [1 6 11] [2 7 12] [3 8] [4 9]]` If `partition strategy` is `\"div\"` we assign ids to partitions in a contiguous manner In this case 13 ids are split across 5 partitions as `[[0 1 2] [3 4 5] [6 7 8] [9 10] [11 12]]` If the input ids are ragged tensors partition variables are not supported and the partition strategy and the max norm are ignored The results of the lookup are concatenated into a dense tensor The returned tensor has shape `shape ids + shape params [1 ]` Args params A single tensor representing the complete embedding tensor or a list of P tensors all of same shape except for the first dimension representing sharded embedding tensors Alternatively a `PartitionedVariable` created by partitioning along dimension 0 Each element must be appropriately sized for the given `partition strategy` ids A `Tensor` or a RaggedTensor with type `int32` or `int64` containing the ids to be looked up in `params` Caution On CPU if an out of bound id is found an error is raised On GPU if an out of bound id is found a 0 is stored in the corresponding output value partition strategy A string specifying the partitioning strategy relevant if `len params > 1` Currently `\"div\"` and `\"mod\"` are supported Default is `\"mod\"` name A name for the operation optional validate indices DEPRECATED If this operation is assigned to CPU values in `indices` are always validated to be within range If assigned to GPU out-of-bound indices result in safe but unspecified behavior which may include raising an error max norm If not `None` each embedding is clipped if its l2-norm is larger than this value Returns A `Tensor` or a RaggedTensor depending on the input with the same type as the tensors in `params` Raises ValueError If `params` is empty \"\"\" \"\"\" **Behavior Difference between CPU and GPU** Please note that when using `tf nn embedding lookup` on a GPU if an out-of-bound index is encountered a value of 0 will be stored in the corresponding output value On the other hand when using `tf nn embedding lookup` on a CPU an error will be returned if an out-of-bound index is found This behavior difference can impact the results of your computation especially when dealing with indices that may go beyond the bounds of the tensor Make sure to be mindful of this distinction when using the `tf nn embedding lookup` function in your computations **Usage Example** Here s an example demonstrating how to use `tf nn embedding lookup` ```python import tensorflow as tf # Example embedding matrix and indices embedding matrix tf constant [[0 1 0 2] [0 3 0 4] [0 5 0 6]] indices tf constant [1 0 2] # Perform embedding lookup embeddings tf nn embedding lookup embedding matrix indices # Print the result print \"Embeddings \" print embeddings numpy ``` \"\"\" return embedding lookup and transform params params ids ids partition strategy partition strategy name name max norm max norm transform fn None"}
{"message": "That means is this caution note is suffice?\r\n\r\n**Caution**: Out-of-bounds indices will result in undefined behavior, which will differ between devices and backends.", "timestamp": "2024-01-09T04:15:34Z", "file_name": "tensorflow/python/ops/embedding_ops.py", "range": {"start_line": 313, "end_line": 313, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1445608217", "html_url": "https://github.com/tensorflow/tensorflow/pull/62734#discussion_r1445608217", "attention_area": "      output value.With XLA, for both CPU and GPU, all out of bound ids are", "file_path": "files/11/00/00000011.py", "old_file_path": "files/05/00/00000005.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -307,6 +307,12 @@ def embedding_lookup(\n       element must be appropriately sized for the given `partition_strategy`.\n     ids: A `Tensor` or a 'RaggedTensor' with type `int32` or `int64` containing\n       the ids to be looked up in `params`.\n+      \n+      Caution: Without XLA,on CPU, if an out of bound id is found, an error is raised.\n+      On GPU, if an out of bound id is found, a 0 is stored in the corresponding\n+      output value.With XLA, for both CPU and GPU, all out of bound ids are", "source": "def embedding_lookup(\n    params,\n    ids,\n    partition_strategy=\"mod\",\n    name=None,\n    validate_indices=True,  # pylint: disable=unused-argument\n    max_norm=None):\n  \"\"\"Looks up embeddings for the given `ids` from a list of tensors.\n\n  This function is used to perform parallel lookups on the list of tensors in\n  `params`.  It is a generalization of `tf.gather`, where `params` is\n  interpreted as a partitioning of a large embedding tensor.  `params` may be\n  a `PartitionedVariable` as returned by using `tf.compat.v1.get_variable()`\n  with a partitioner.\n\n  If `len(params) > 1`, each element `id` of `ids` is partitioned between\n  the elements of `params` according to the `partition_strategy`.\n  In all strategies, if the id space does not evenly divide the number of\n  partitions, each of the first `(max_id + 1) % len(params)` partitions will\n  be assigned one more id.\n\n  If `partition_strategy` is `\"mod\"`, we assign each id to partition\n  `p = id % len(params)`. For instance,\n  13 ids are split across 5 partitions as:\n  `[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]`\n\n  If `partition_strategy` is `\"div\"`, we assign ids to partitions in a\n  contiguous manner. In this case, 13 ids are split across 5 partitions as:\n  `[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]`\n\n  If the input ids are ragged tensors, partition variables are not supported and\n  the partition strategy and the max_norm are ignored.\n  The results of the lookup are concatenated into a dense\n  tensor. The returned tensor has shape `shape(ids) + shape(params)[1:]`.\n\n  Args:\n    params: A single tensor representing the complete embedding tensor, or a\n      list of P tensors all of same shape except for the first dimension,\n      representing sharded embedding tensors.  Alternatively, a\n      `PartitionedVariable`, created by partitioning along dimension 0. Each\n      element must be appropriately sized for the given `partition_strategy`.\n    ids: A `Tensor` or a 'RaggedTensor' with type `int32` or `int64` containing\n      the ids to be looked up in `params`.\n      \n      Caution: Without XLA,on CPU, if an out of bound id is found, an error is raised.\n      On GPU, if an out of bound id is found, a 0 is stored in the corresponding\n      output value.With XLA, for both CPU and GPU, all out of bound ids are\n      replaced with maximum of `ids` inferred from the input `params` and\n      corresponding value will be taken into output.\n    partition_strategy: A string specifying the partitioning strategy, relevant\n      if `len(params) > 1`. Currently `\"div\"` and `\"mod\"` are supported. Default\n      is `\"mod\"`.\n    name: A name for the operation (optional).\n    validate_indices: DEPRECATED. If this operation is assigned to CPU, values\n      in `indices` are always validated to be within range.  If assigned to GPU,\n      out-of-bound indices result in safe but unspecified behavior, which may\n      include raising an error.\n    max_norm: If not `None`, each embedding is clipped if its l2-norm is larger\n      than this value.\n\n  Returns:\n    A `Tensor` or a 'RaggedTensor', depending on the input, with the same type\n    as the tensors in `params`.\n\n  Raises:\n    ValueError: If `params` is empty.\n  \"\"\"\n\n  \"\"\"\n    **Behavior Difference between CPU and GPU**\n\n    Please note that when using `tf.nn.embedding_lookup` on a GPU, if an out-of-bound \n    index is encountered, a value of 0 will be stored in the corresponding output value. \n    On the other hand, when using `tf.nn.embedding_lookup` on a CPU, an error will be \n    returned if an out-of-bound index is found.\n\n    This behavior difference can impact the results of your computation, especially when \n    dealing with indices that may go beyond the bounds of the tensor. \n    Make sure to be mindful of this distinction when using the `tf.nn.embedding_lookup` \n    function in your computations.\n\n    **Usage Example**\n\n    Here's an example demonstrating how to use `tf.nn.embedding_lookup`:\n\n    ```python\n    import tensorflow as tf\n\n    # Example embedding matrix and indices\n    embedding_matrix = tf.constant([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])\n    indices = tf.constant([1, 0, 2])\n\n    # Perform embedding lookup\n    embeddings = tf.nn.embedding_lookup(embedding_matrix, indices)\n\n    # Print the result\n    print(\"Embeddings:\")\n    print(embeddings.numpy())\n    ```\n    \"\"\"\n\n  return _embedding_lookup_and_transform(\n      params=params,\n      ids=ids,\n      partition_strategy=partition_strategy,\n      name=name,\n      max_norm=max_norm,\n      transform_fn=None)", "source_start_line": 267, "tokens": ["def", "embedding_lookup", "(", "params", ",", "ids", ",", "partition_strategy", "=", "\"mod\"", ",", "name", "=", "None", ",", "validate_indices", "=", "True", ",", "max_norm", "=", "None", ")", ":", "\"\"\"Looks up embeddings for the given `ids` from a list of tensors.  This function is used to perform parallel lookups on the list of tensors in  `params`.  It is a generalization of `tf.gather`, where `params` is  interpreted as a partitioning of a large embedding tensor.  `params` may be  a `PartitionedVariable` as returned by using `tf.compat.v1.get_variable()`  with a partitioner.  If `len(params) > 1`, each element `id` of `ids` is partitioned between  the elements of `params` according to the `partition_strategy`.  In all strategies, if the id space does not evenly divide the number of  partitions, each of the first `(max_id + 1) % len(params)` partitions will  be assigned one more id.  If `partition_strategy` is `\"mod\"`, we assign each id to partition  `p = id % len(params)`. For instance,  13 ids are split across 5 partitions as:  `[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]`  If `partition_strategy` is `\"div\"`, we assign ids to partitions in a  contiguous manner. In this case, 13 ids are split across 5 partitions as:  `[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]`  If the input ids are ragged tensors, partition variables are not supported and  the partition strategy and the max_norm are ignored.  The results of the lookup are concatenated into a dense  tensor. The returned tensor has shape `shape(ids) + shape(params)[1:]`.  Args:    params: A single tensor representing the complete embedding tensor, or a      list of P tensors all of same shape except for the first dimension,      representing sharded embedding tensors.  Alternatively, a      `PartitionedVariable`, created by partitioning along dimension 0. Each      element must be appropriately sized for the given `partition_strategy`.    ids: A `Tensor` or a 'RaggedTensor' with type `int32` or `int64` containing      the ids to be looked up in `params`.            Caution: Without XLA,on CPU, if an out of bound id is found, an error is raised.      On GPU, if an out of bound id is found, a 0 is stored in the corresponding      output value.With XLA, for both CPU and GPU, all out of bound ids are      replaced with maximum of `ids` inferred from the input `params` and      corresponding value will be taken into output.    partition_strategy: A string specifying the partitioning strategy, relevant      if `len(params) > 1`. Currently `\"div\"` and `\"mod\"` are supported. Default      is `\"mod\"`.    name: A name for the operation (optional).    validate_indices: DEPRECATED. If this operation is assigned to CPU, values      in `indices` are always validated to be within range.  If assigned to GPU,      out-of-bound indices result in safe but unspecified behavior, which may      include raising an error.    max_norm: If not `None`, each embedding is clipped if its l2-norm is larger      than this value.  Returns:    A `Tensor` or a 'RaggedTensor', depending on the input, with the same type    as the tensors in `params`.  Raises:    ValueError: If `params` is empty.  \"\"\"", "\"\"\"    **Behavior Difference between CPU and GPU**    Please note that when using `tf.nn.embedding_lookup` on a GPU, if an out-of-bound     index is encountered, a value of 0 will be stored in the corresponding output value.     On the other hand, when using `tf.nn.embedding_lookup` on a CPU, an error will be     returned if an out-of-bound index is found.    This behavior difference can impact the results of your computation, especially when     dealing with indices that may go beyond the bounds of the tensor.     Make sure to be mindful of this distinction when using the `tf.nn.embedding_lookup`     function in your computations.    **Usage Example**    Here's an example demonstrating how to use `tf.nn.embedding_lookup`:    ```python    import tensorflow as tf    # Example embedding matrix and indices    embedding_matrix = tf.constant([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])    indices = tf.constant([1, 0, 2])    # Perform embedding lookup    embeddings = tf.nn.embedding_lookup(embedding_matrix, indices)    # Print the result    print(\"Embeddings:\")    print(embeddings.numpy())    ```    \"\"\"", "return", "_embedding_lookup_and_transform", "(", "params", "=", "params", ",", "ids", "=", "ids", ",", "partition_strategy", "=", "partition_strategy", ",", "name", "=", "name", ",", "max_norm", "=", "max_norm", ",", "transform_fn", "=", "None", ")"], "to_mask": {"VAR": ["ids", "max_norm", "name", "params", "partition_strategy", "validate_indices"], "METHOD": ["_embedding_lookup_and_transform"]}, "attention_idx_tokens": [null, null], "patch": "@@ -307,6 +307,12 @@\n       element must be appropriately sized for the given `partition_strategy`.\n     ids: A `Tensor` or a 'RaggedTensor' with type `int32` or `int64` containing\n       the ids to be looked up in `params`.\n+      \n+      Caution: Without XLA,on CPU, if an out of bound id is found, an error is raised.\n+      On GPU, if an out of bound id is found, a 0 is stored in the corresponding\n+      output value.With XLA, for both CPU and GPU, all out of bound ids are", "ext_attention_idx_tokens": [null, null], "uid": "416c6970", "question": "That means is this caution note is suffice?    **Caution**: Out-of-bounds indices will result in undefined behavior, which will differ between devices and backends.", "code": "def embedding lookup params ids partition strategy \"mod\" name None validate indices True # pylint disable unused-argument max norm None \"\"\"Looks up embeddings for the given `ids` from a list of tensors This function is used to perform parallel lookups on the list of tensors in `params` It is a generalization of `tf gather` where `params` is interpreted as a partitioning of a large embedding tensor `params` may be a `PartitionedVariable` as returned by using `tf compat v1 get variable ` with a partitioner If `len params > 1` each element `id` of `ids` is partitioned between the elements of `params` according to the `partition strategy` In all strategies if the id space does not evenly divide the number of partitions each of the first ` max id + 1 % len params ` partitions will be assigned one more id If `partition strategy` is `\"mod\"` we assign each id to partition `p id % len params ` For instance 13 ids are split across 5 partitions as `[[0 5 10] [1 6 11] [2 7 12] [3 8] [4 9]]` If `partition strategy` is `\"div\"` we assign ids to partitions in a contiguous manner In this case 13 ids are split across 5 partitions as `[[0 1 2] [3 4 5] [6 7 8] [9 10] [11 12]]` If the input ids are ragged tensors partition variables are not supported and the partition strategy and the max norm are ignored The results of the lookup are concatenated into a dense tensor The returned tensor has shape `shape ids + shape params [1 ]` Args params A single tensor representing the complete embedding tensor or a list of P tensors all of same shape except for the first dimension representing sharded embedding tensors Alternatively a `PartitionedVariable` created by partitioning along dimension 0 Each element must be appropriately sized for the given `partition strategy` ids A `Tensor` or a RaggedTensor with type `int32` or `int64` containing the ids to be looked up in `params` Caution Without XLA on CPU if an out of bound id is found an error is raised On GPU if an out of bound id is found a 0 is stored in the corresponding output value With XLA for both CPU and GPU all out of bound ids are replaced with maximum of `ids` inferred from the input `params` and corresponding value will be taken into output partition strategy A string specifying the partitioning strategy relevant if `len params > 1` Currently `\"div\"` and `\"mod\"` are supported Default is `\"mod\"` name A name for the operation optional validate indices DEPRECATED If this operation is assigned to CPU values in `indices` are always validated to be within range If assigned to GPU out-of-bound indices result in safe but unspecified behavior which may include raising an error max norm If not `None` each embedding is clipped if its l2-norm is larger than this value Returns A `Tensor` or a RaggedTensor depending on the input with the same type as the tensors in `params` Raises ValueError If `params` is empty \"\"\" \"\"\" **Behavior Difference between CPU and GPU** Please note that when using `tf nn embedding lookup` on a GPU if an out-of-bound index is encountered a value of 0 will be stored in the corresponding output value On the other hand when using `tf nn embedding lookup` on a CPU an error will be returned if an out-of-bound index is found This behavior difference can impact the results of your computation especially when dealing with indices that may go beyond the bounds of the tensor Make sure to be mindful of this distinction when using the `tf nn embedding lookup` function in your computations **Usage Example** Here s an example demonstrating how to use `tf nn embedding lookup` ```python import tensorflow as tf # Example embedding matrix and indices embedding matrix tf constant [[0 1 0 2] [0 3 0 4] [0 5 0 6]] indices tf constant [1 0 2] # Perform embedding lookup embeddings tf nn embedding lookup embedding matrix indices # Print the result print \"Embeddings \" print embeddings numpy ``` \"\"\" return embedding lookup and transform params params ids ids partition strategy partition strategy name name max norm max norm transform fn None"}
{"message": "> Why only qint8? What about for other signed quantized types T?\r\n> \r\n> If the issue is that:\r\n> \r\n> > I found that when T = qint8\r\n> > Windows: std::is_signed::value is false\r\n> > Linux: std::is_signed::value is true\r\n> \r\n> then _that_ should be fixed.\r\n\r\nI have added other quantized types as well in the last commit.\r\n\r\nRegarding the earlier issue, it was with compiler (MSVC at the time Google CI test failed earlier). I am not sure if Google has moved to Clang or not. Therefore, I am not sure if compiler needs to be fixed or not.", "timestamp": "2024-04-23T20:39:22Z", "file_name": "tensorflow/core/kernels/mkl/mkl_quantize_op.cc", "range": {"start_line": 499, "end_line": 499, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1576867109", "html_url": "https://github.com/tensorflow/tensorflow/pull/66082#discussion_r1576867109", "attention_area": "      const bool is_signed = std::is_same<T, qint8>();", "file_path": "files/80/00/00000080.cc", "old_file_path": "files/81/00/00000081.cc", "filters": {"comment_message": true, "patchset": true, "first_in_thread": false, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -509,12 +484,19 @@ class MklQuantizeV2Op : public OpKernel {\n     AllocateOutputSetMklShape(ctx, 2, &output_max_tensor, max_tf_shape,\n                               max_mkl_shape, native_format);\n \n+    // Create the oneDNN wrapper over Eigen threadpool and set max threads\n+    // in oneDNN.\n+    Eigen::ThreadPoolInterface* eigen_interface =\n+        EigenThreadPoolFromTfContext(ctx);\n+    tsl::OneDnnThreadPool eigen_tp(eigen_interface,\n+                                   ThreadPoolUseCallerThread());\n+\n     float scale_factor = 0;\n     if (mode_ == QUANTIZE_MODE_SCALED) {\n       // Estimating scales for quantization.\n       const int num_bits = sizeof(T) * 8;\n       const float max_abs = std::max(std::abs(min_range), std::abs(max_range));\n-      const bool is_signed = std::is_signed<T>::value;\n+      const bool is_signed = std::is_same<T, qint8>();", "source": "void Compute(OpKernelContext* ctx) override {\n    const unsigned int src_idx = 0;\n    const Tensor& input = ctx->input(src_idx);\n    const float input_min_range = ctx->input(1).scalar<float>()();\n    const float input_max_range = ctx->input(2).scalar<float>()();\n    float min_range = std::min(0.0f, input_min_range);\n    float max_range;\n    OP_REQUIRES(ctx, (input_max_range >= input_min_range),\n                absl::InvalidArgumentError(\n                    \"input_max_range must be larger than input_min_range.\"));\n\n    // When the minimum and maximum ranges are too close together, nudge them\n    // apart by a small value so that they are slightly different. This helps\n    // us avoid creating ill-formed buffers where all quantized values map to\n    // the same float number. These kinds of buffers cause problems for\n    // downstream ops when they need to do calculations on them.\n    // We pick the value by making sure that zero is not more than 100x the\n    // overall range from the maximum, so that the value can be easily\n    // represented when we promote the quantized value to a higher\n    // intermediate bit depth, since that's a common requirement.\n    const float epsilon = std::max(1.0f, std::max(fabsf(input_min_range),\n                                                  fabsf(input_max_range))) *\n                          ensure_minimum_range_;\n    max_range = std::max(input_max_range, min_range + epsilon);\n    // Clamping the max_range to zero since max_range can also be negative.\n    max_range = std::max(0.0f, max_range);\n    auto cpu_engine = engine(engine::kind::cpu, 0);\n    const Tensor& src_tensor = MklGetInput(ctx, src_idx);\n    MklDnnShape src_mkl_shape;\n    GetMklShape(ctx, src_idx, &src_mkl_shape, native_format);\n    auto src_tf_shape = src_mkl_shape.IsMklTensor() ? src_mkl_shape.GetTfShape()\n                                                    : src_tensor.shape();\n    auto src_dims = src_mkl_shape.IsMklTensor()\n                        ? src_mkl_shape.GetSizesAsMklDnnDims()\n                        : TFShapeToMklDnnDims(src_tensor.shape());\n    auto output_dims = src_dims;\n    // Set the dst layout to be the best mkl layout based on dims and type.\n    memory::format_tag dst_layout_type;\n    switch (src_tf_shape.dims()) {\n      case 0:\n        ComputeScalar(ctx, min_range, max_range);\n        return;\n      case 1:\n        dst_layout_type = memory::format_tag::x;\n        break;\n      case 2:\n        dst_layout_type = memory::format_tag::nc;\n        break;\n      case 3:\n        dst_layout_type = memory::format_tag::tnc;\n        break;\n      case 4:\n        dst_layout_type = memory::format_tag::nhwc;\n        break;\n      case 5:\n        dst_layout_type = memory::format_tag::ndhwc;\n        break;\n      default:\n        OP_REQUIRES_OK(ctx,\n                       absl::AbortedError(\"Input dims must be <= 5 and >= 1\"));\n        return;\n    }\n    // Create reorder memory for src, dst: both are defined in mkl_util.h,\n    // they are wrapper\n    MklDnnData<S> src(&cpu_engine);\n    MklDnnData<T> dst(&cpu_engine);\n#ifdef ENABLE_ONEDNN_V3\n    MklDnnData<float> scale(&cpu_engine);\n#endif  // ENABLE_ONEDNN_V3\n\n    auto src_md =\n        src_mkl_shape.IsMklTensor()\n            ? src_mkl_shape.GetMklLayout()\n            : memory::desc(src_dims, MklDnnType<S>(), dst_layout_type);\n\n    src.SetUsrMem(src_md, &src_tensor);\n    memory::desc dst_md =\n        memory::desc(src_dims, MklDnnType<T>(), dst_layout_type);\n\n    // Standard shape assignments for layout pass\n    MklDnnShape output_mkl_shape;\n    TensorShape output_tf_shape;\n    if (src_mkl_shape.IsMklTensor()) {\n      output_mkl_shape.SetMklTensor(true);\n      output_mkl_shape.SET_MKL_LAYOUT(dst_md);\n      output_mkl_shape.SetElemType(MklDnnType<T>());\n      output_mkl_shape.SetTfLayout(src_mkl_shape.GetDimension(),\n                                   src_mkl_shape.GetSizesAsMklDnnDims(),\n                                   src_mkl_shape.GetTfDataFormat());\n      output_tf_shape.AddDim(dst_md.get_size() / sizeof(T));\n    } else {\n      output_mkl_shape.SetMklTensor(false);\n      output_tf_shape = MklDnnDimsToTFShape(output_dims);\n    }\n\n    Tensor* output_tensor = nullptr;\n    AllocateOutputSetMklShape(ctx, 0, &output_tensor, output_tf_shape,\n                              output_mkl_shape, native_format);\n    dst.SetUsrMem(dst_md, output_tensor);\n\n    TensorShape min_tf_shape = {};\n    MklDnnShape min_mkl_shape;\n    min_mkl_shape.SetMklTensor(false);\n    Tensor* output_min_tensor = nullptr;\n    AllocateOutputSetMklShape(ctx, 1, &output_min_tensor, min_tf_shape,\n                              min_mkl_shape, native_format);\n    TensorShape max_tf_shape = {};\n    MklDnnShape max_mkl_shape;\n    max_mkl_shape.SetMklTensor(false);\n    Tensor* output_max_tensor = nullptr;\n    AllocateOutputSetMklShape(ctx, 2, &output_max_tensor, max_tf_shape,\n                              max_mkl_shape, native_format);\n\n    // Create the oneDNN wrapper over Eigen threadpool and set max threads\n    // in oneDNN.\n    Eigen::ThreadPoolInterface* eigen_interface =\n        EigenThreadPoolFromTfContext(ctx);\n    tsl::OneDnnThreadPool eigen_tp(eigen_interface,\n                                   ThreadPoolUseCallerThread());\n\n    float scale_factor = 0;\n    if (mode_ == QUANTIZE_MODE_SCALED) {\n      // Estimating scales for quantization.\n      const int num_bits = sizeof(T) * 8;\n      const float max_abs = std::max(std::abs(min_range), std::abs(max_range));\n      const bool is_signed = std::is_same<T, qint8>();\n      float target_range;\n      if (is_signed) {\n        max_range = max_abs;\n        min_range = -max_abs;\n        // If it is signed, we try to keep 0.0 being 0 and drop one bucket. For\n        // example, if it is 8 bits, we have the range [-127, 127]. So for input\n        // range of [-x, x], the scale should be 254/(2*x).\n        target_range = static_cast<float>((uint64_t{1} << num_bits) - 1) / 2.;\n      } else {\n        max_range = max_abs;\n        min_range = 0.0;\n        // If it is unsigned and num_bits == 8, the range with 8 bits is [0,\n        // 255].  If the input range is [0, x], then the scale is 255/x instead\n        // of 254 as in the case above.\n        target_range = static_cast<float>((uint64_t{1} << num_bits) - 1);\n      }\n      scale_factor = target_range / max_abs;\n\n#ifdef ENABLE_ONEDNN_V3\n      auto scale_md =\n          memory::desc({1}, MklDnnType<float>(), memory::format_tag::x);\n      MklReorderWithScaleFwdParams fwdParams(src_dims, src_md, dst_md,\n                                             scale_md);\n      Tensor scale_tensor;\n      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DT_FLOAT, {1}, &scale_tensor));\n      scale_tensor.flat<float>()(0) = scale_factor;\n      scale.SetUsrMem(scale_md, &scale_tensor);\n#else\n      MklReorderWithScaleFwdParams fwdParams(src_dims, src_md, dst_md);\n#endif  // ENABLE_ONEDNN_V3\n      fwdParams.dtypes.append(typeid(S).name());\n      fwdParams.dtypes.append(typeid(T).name());\n      fwdParams.post_op_params.name = \"scale\";\n      fwdParams.post_op_params.param.push_back(scale_factor);\n\n      MklReorderWithScalePrimitive* reorder_prim =\n          MklReorderWithScalePrimitiveFactory<T>::Get(\n              src.GetUsrMem(), dst.GetUsrMem(), fwdParams);\n\n      std::shared_ptr<stream> cpu_stream;\n      cpu_stream.reset(CreateStream(&eigen_tp, reorder_prim->GetEngine()));\n      reorder_prim->Execute(src.GetUsrMemDataHandle(),\n                            dst.GetUsrMemDataHandle(),\n#ifdef ENABLE_ONEDNN_V3\n                            scale.GetUsrMemDataHandle(),\n#endif  // ENABLE_ONEDNN_V3\n                            cpu_stream);\n    } else if (mode_ == QUANTIZE_MODE_MIN_FIRST) {\n      using namespace dnnl;\n      std::shared_ptr<stream> cpu_stream;\n      cpu_stream.reset(CreateStream(&eigen_tp, cpu_engine));\n\n      auto shift = static_cast<S>(-min_range);\n      memory::dims shift_dims(src_tf_shape.dims(), 1);\n      auto shift_md =\n          memory::desc(shift_dims, MklDnnType<S>(), dst_layout_type);\n      memory shift_mem(shift_md, cpu_engine, (void*)(&shift));\n\n      primitive_attr attr;\n      std::vector<float> src_0_scale{255.0f / (max_range - min_range)};\n      std::vector<float> src_1_scale{255.0f / (max_range - min_range)};\n#ifdef ENABLE_ONEDNN_V3\n      attr.set_scales_mask(DNNL_ARG_SRC_0, 0);\n      attr.set_scales_mask(DNNL_ARG_SRC_1, 0);\n      auto binary_pd = binary::primitive_desc(cpu_engine, algorithm::binary_add,\n                                              src_md, shift_md, dst_md, attr);\n#else\n      attr.set_scales(DNNL_ARG_SRC_0, 0, src_0_scale);\n      attr.set_scales(DNNL_ARG_SRC_1, 0, src_1_scale);\n      auto binary_d =\n          binary::desc(algorithm::binary_add, src_md, shift_md, dst_md);\n      auto binary_pd = binary::primitive_desc(binary_d, attr, cpu_engine);\n#endif  // ENABLE_ONEDNN_V3\n\n      auto binary_prim = binary(binary_pd);\n      auto src_0_scale_mem =\n          memory({{1}, MklDnnType<float>(), memory::format_tag::x}, cpu_engine,\n                 src_0_scale.data());\n      auto src_1_scale_mem =\n          memory({{1}, MklDnnType<float>(), memory::format_tag::x}, cpu_engine,\n                 src_1_scale.data());\n      std::unordered_map<int, memory> net_args{\n          {DNNL_ARG_SRC_0, *src.GetUsrMem()},\n          {DNNL_ARG_SRC_1, shift_mem},\n          {DNNL_ARG_DST, *dst.GetUsrMem()},\n#ifdef ENABLE_ONEDNN_V3\n          {DNNL_ARG_ATTR_SCALES | DNNL_ARG_SRC_0, src_0_scale_mem},\n          { DNNL_ARG_ATTR_SCALES | DNNL_ARG_SRC_1,\n            src_1_scale_mem }\n#endif\n      };\n      binary_prim.execute(*cpu_stream, net_args);\n    } else {\n      OP_REQUIRES(ctx, false,\n                  absl::UnimplementedError(\n                      \"Supported modes are MIN_FIRST and SCALED only.\"));\n    }\n\n    output_min_tensor->scalar<float>()() = min_range;\n    output_max_tensor->scalar<float>()() = max_range;\n  }", "source_start_line": 374, "tokens": ["void", "Compute", "(", "OpKernelContext", "*", "ctx", ")", "override", "{", "const", "unsigned", "int", "src_idx", "=", "0", ";", "const", "Tensor", "&", "input", "=", "ctx", "->", "input", "(", "src_idx", ")", ";", "const", "float", "input_min_range", "=", "ctx", "->", "input", "(", "1", ")", ".", "scalar", "<", "float", ">", "(", ")", "(", ")", ";", "const", "float", "input_max_range", "=", "ctx", "->", "input", "(", "2", ")", ".", "scalar", "<", "float", ">", "(", ")", "(", ")", ";", "float", "min_range", "=", "std", "::", "min", "(", "0.0f", ",", "input_min_range", ")", ";", "float", "max_range", ";", "OP_REQUIRES", "(", "ctx", ",", "(", "input_max_range", ">=", "input_min_range", ")", ",", "absl", "::", "InvalidArgumentError", "(", "\"", "\"", ")", ")", ";", "const", "float", "epsilon", "=", "std", "::", "max", "(", "1.0f", ",", "std", "::", "max", "(", "fabsf", "(", "input_min_range", ")", ",", "fabsf", "(", "input_max_range", ")", ")", ")", "*", "ensure_minimum_range_", ";", "max_range", "=", "std", "::", "max", "(", "input_max_range", ",", "min_range", "+", "epsilon", ")", ";", "max_range", "=", "std", "::", "max", "(", "0.0f", ",", "max_range", ")", ";", "auto", "cpu_engine", "=", "engine", "(", "engine", "::", "kind", "::", "cpu", ",", "0", ")", ";", "const", "Tensor", "&", "src_tensor", "=", "MklGetInput", "(", "ctx", ",", "src_idx", ")", ";", "MklDnnShape", "src_mkl_shape", ";", "GetMklShape", "(", "ctx", ",", "src_idx", ",", "&", "src_mkl_shape", ",", "native_format", ")", ";", "auto", "src_tf_shape", "=", "src_mkl_shape", ".", "IsMklTensor", "(", ")", "?", "src_mkl_shape", ".", "GetTfShape", "(", ")", ":", "src_tensor", ".", "shape", "(", ")", ";", "auto", "src_dims", "=", "src_mkl_shape", ".", "IsMklTensor", "(", ")", "?", "src_mkl_shape", ".", "GetSizesAsMklDnnDims", "(", ")", ":", "TFShapeToMklDnnDims", "(", "src_tensor", ".", "shape", "(", ")", ")", ";", "auto", "output_dims", "=", "src_dims", ";", "memory", "::", "format_tag", "dst_layout_type", ";", "switch", "(", "src_tf_shape", ".", "dims", "(", ")", ")", "{", "case", "0", ":", "ComputeScalar", "(", "ctx", ",", "min_range", ",", "max_range", ")", ";", "return", ";", "case", "1", ":", "dst_layout_type", "=", "memory", "::", "format_tag", "::", "x", ";", "break", ";", "case", "2", ":", "dst_layout_type", "=", "memory", "::", "format_tag", "::", "nc", ";", "break", ";", "case", "3", ":", "dst_layout_type", "=", "memory", "::", "format_tag", "::", "tnc", ";", "break", ";", "case", "4", ":", "dst_layout_type", "=", "memory", "::", "format_tag", "::", "nhwc", ";", "break", ";", "case", "5", ":", "dst_layout_type", "=", "memory", "::", "format_tag", "::", "ndhwc", ";", "break", ";", "default", ":", "OP_REQUIRES_OK", "(", "ctx", ",", "absl", "::", "AbortedError", "(", "\"", "\"", ")", ")", ";", "return", ";", "}", "MklDnnData", "<", "S", ">", "src", "(", "&", "cpu_engine", ")", ";", "MklDnnData", "<", "T", ">", "dst", "(", "&", "cpu_engine", ")", ";", "#ifdef", "ENABLE_ONEDNN_V3", "MklDnnData", "<", "float", ">", "scale", "(", "&", "cpu_engine", ")", ";", "#endif", "auto", "src_md", "=", "src_mkl_shape", ".", "IsMklTensor", "(", ")", "?", "src_mkl_shape", ".", "GetMklLayout", "(", ")", ":", "memory", "::", "desc", "(", "src_dims", ",", "MklDnnType", "<", "S", ">", "(", ")", ",", "dst_layout_type", ")", ";", "src", ".", "SetUsrMem", "(", "src_md", ",", "&", "src_tensor", ")", ";", "memory", "::", "desc", "dst_md", "=", "memory", "::", "desc", "(", "src_dims", ",", "MklDnnType", "<", "T", ">", "(", ")", ",", "dst_layout_type", ")", ";", "MklDnnShape", "output_mkl_shape", ";", "TensorShape", "output_tf_shape", ";", "if", "(", "src_mkl_shape", ".", "IsMklTensor", "(", ")", ")", "{", "output_mkl_shape", ".", "SetMklTensor", "(", "true", ")", ";", "output_mkl_shape", ".", "SET_MKL_LAYOUT", "(", "dst_md", ")", ";", "output_mkl_shape", ".", "SetElemType", "(", "MklDnnType", "<", "T", ">", "(", ")", ")", ";", "output_mkl_shape", ".", "SetTfLayout", "(", "src_mkl_shape", ".", "GetDimension", "(", ")", ",", "src_mkl_shape", ".", "GetSizesAsMklDnnDims", "(", ")", ",", "src_mkl_shape", ".", "GetTfDataFormat", "(", ")", ")", ";", "output_tf_shape", ".", "AddDim", "(", "dst_md", ".", "get_size", "(", ")", "/", "sizeof", "(", "T", ")", ")", ";", "}", "else", "{", "output_mkl_shape", ".", "SetMklTensor", "(", "false", ")", ";", "output_tf_shape", "=", "MklDnnDimsToTFShape", "(", "output_dims", ")", ";", "}", "Tensor", "*", "output_tensor", "=", "nullptr", ";", "AllocateOutputSetMklShape", "(", "ctx", ",", "0", ",", "&", "output_tensor", ",", "output_tf_shape", ",", "output_mkl_shape", ",", "native_format", ")", ";", "dst", ".", "SetUsrMem", "(", "dst_md", ",", "output_tensor", ")", ";", "TensorShape", "min_tf_shape", "=", "{", "}", ";", "MklDnnShape", "min_mkl_shape", ";", "min_mkl_shape", ".", "SetMklTensor", "(", "false", ")", ";", "Tensor", "*", "output_min_tensor", "=", "nullptr", ";", "AllocateOutputSetMklShape", "(", "ctx", ",", "1", ",", "&", "output_min_tensor", ",", "min_tf_shape", ",", "min_mkl_shape", ",", "native_format", ")", ";", "TensorShape", "max_tf_shape", "=", "{", "}", ";", "MklDnnShape", "max_mkl_shape", ";", "max_mkl_shape", ".", "SetMklTensor", "(", "false", ")", ";", "Tensor", "*", "output_max_tensor", "=", "nullptr", ";", "AllocateOutputSetMklShape", "(", "ctx", ",", "2", ",", "&", "output_max_tensor", ",", "max_tf_shape", ",", "max_mkl_shape", ",", "native_format", ")", ";", "Eigen", "::", "ThreadPoolInterface", "*", "eigen_interface", "=", "EigenThreadPoolFromTfContext", "(", "ctx", ")", ";", "tsl", "::", "OneDnnThreadPool", "eigen_tp", "(", "eigen_interface", ",", "ThreadPoolUseCallerThread", "(", ")", ")", ";", "float", "scale_factor", "=", "0", ";", "if", "(", "mode_", "==", "QUANTIZE_MODE_SCALED", ")", "{", "const", "int", "num_bits", "=", "sizeof", "(", "T", ")", "*", "8", ";", "const", "float", "max_abs", "=", "std", "::", "max", "(", "std", "::", "abs", "(", "min_range", ")", ",", "std", "::", "abs", "(", "max_range", ")", ")", ";", "const", "bool", "is_signed", "=", "std", "::", "is_same", "<", "T", ",", "qint8", ">", "(", ")", ";", "float", "target_range", ";", "if", "(", "is_signed", ")", "{", "max_range", "=", "max_abs", ";", "min_range", "=", "-", "max_abs", ";", "target_range", "=", "static_cast", "<", "float", ">", "(", "(", "uint64_t", "{", "1", "}", "<<", "num_bits", ")", "-", "1", ")", "/", "2.", ";", "}", "else", "{", "max_range", "=", "max_abs", ";", "min_range", "=", "0.0", ";", "target_range", "=", "static_cast", "<", "float", ">", "(", "(", "uint64_t", "{", "1", "}", "<<", "num_bits", ")", "-", "1", ")", ";", "}", "scale_factor", "=", "target_range", "/", "max_abs", ";", "#ifdef", "ENABLE_ONEDNN_V3", "auto", "scale_md", "=", "memory", "::", "desc", "(", "{", "1", "}", ",", "MklDnnType", "<", "float", ">", "(", ")", ",", "memory", "::", "format_tag", "::", "x", ")", ";", "MklReorderWithScaleFwdParams", "fwdParams", "(", "src_dims", ",", "src_md", ",", "dst_md", ",", "scale_md", ")", ";", "Tensor", "scale_tensor", ";", "OP_REQUIRES_OK", "(", "ctx", ",", "ctx", "->", "allocate_temp", "(", "DT_FLOAT", ",", "{", "1", "}", ",", "&", "scale_tensor", ")", ")", ";", "scale_tensor", ".", "flat", "<", "float", ">", "(", ")", "(", "0", ")", "=", "scale_factor", ";", "scale", ".", "SetUsrMem", "(", "scale_md", ",", "&", "scale_tensor", ")", ";", "#else", "MklReorderWithScaleFwdParams", "fwdParams", "(", "src_dims", ",", "src_md", ",", "dst_md", ")", ";", "#endif", "fwdParams", ".", "dtypes", ".", "append", "(", "typeid", "(", "S", ")", ".", "name", "(", ")", ")", ";", "fwdParams", ".", "dtypes", ".", "append", "(", "typeid", "(", "T", ")", ".", "name", "(", ")", ")", ";", "fwdParams", ".", "post_op_params", ".", "name", "=", "\"", "\"", ";", "fwdParams", ".", "post_op_params", ".", "param", ".", "push_back", "(", "scale_factor", ")", ";", "MklReorderWithScalePrimitive", "*", "reorder_prim", "=", "MklReorderWithScalePrimitiveFactory", "<", "T", ">", "::", "Get", "(", "src", ".", "GetUsrMem", "(", ")", ",", "dst", ".", "GetUsrMem", "(", ")", ",", "fwdParams", ")", ";", "std", "::", "shared_ptr", "<", "stream", ">", "cpu_stream", ";", "cpu_stream", ".", "reset", "(", "CreateStream", "(", "&", "eigen_tp", ",", "reorder_prim", "->", "GetEngine", "(", ")", ")", ")", ";", "reorder_prim", "->", "Execute", "(", "src", ".", "GetUsrMemDataHandle", "(", ")", ",", "dst", ".", "GetUsrMemDataHandle", "(", ")", ",", "#ifdef", "ENABLE_ONEDNN_V3", "scale", ".", "GetUsrMemDataHandle", "(", ")", ",", "#endif", "cpu_stream", ")", ";", "}", "else", "if", "(", "mode_", "==", "QUANTIZE_MODE_MIN_FIRST", ")", "{", "using", "namespace", "dnnl", ";", "std", "::", "shared_ptr", "<", "stream", ">", "cpu_stream", ";", "cpu_stream", ".", "reset", "(", "CreateStream", "(", "&", "eigen_tp", ",", "cpu_engine", ")", ")", ";", "auto", "shift", "=", "static_cast", "<", "S", ">", "(", "-", "min_range", ")", ";", "memory", "::", "dims", "shift_dims", "(", "src_tf_shape", ".", "dims", "(", ")", ",", "1", ")", ";", "auto", "shift_md", "=", "memory", "::", "desc", "(", "shift_dims", ",", "MklDnnType", "<", "S", ">", "(", ")", ",", "dst_layout_type", ")", ";", "memory", "shift_mem", "(", "shift_md", ",", "cpu_engine", ",", "(", "void", "*", ")", "(", "&", "shift", ")", ")", ";", "primitive_attr", "attr", ";", "std", "::", "vector", "<", "float", ">", "src_0_scale", "{", "255.0f", "/", "(", "max_range", "-", "min_range", ")", "}", ";", "std", "::", "vector", "<", "float", ">", "src_1_scale", "{", "255.0f", "/", "(", "max_range", "-", "min_range", ")", "}", ";", "#ifdef", "ENABLE_ONEDNN_V3", "attr", ".", "set_scales_mask", "(", "DNNL_ARG_SRC_0", ",", "0", ")", ";", "attr", ".", "set_scales_mask", "(", "DNNL_ARG_SRC_1", ",", "0", ")", ";", "auto", "binary_pd", "=", "binary", "::", "primitive_desc", "(", "cpu_engine", ",", "algorithm", "::", "binary_add", ",", "src_md", ",", "shift_md", ",", "dst_md", ",", "attr", ")", ";", "#else", "attr", ".", "set_scales", "(", "DNNL_ARG_SRC_0", ",", "0", ",", "src_0_scale", ")", ";", "attr", ".", "set_scales", "(", "DNNL_ARG_SRC_1", ",", "0", ",", "src_1_scale", ")", ";", "auto", "binary_d", "=", "binary", "::", "desc", "(", "algorithm", "::", "binary_add", ",", "src_md", ",", "shift_md", ",", "dst_md", ")", ";", "auto", "binary_pd", "=", "binary", "::", "primitive_desc", "(", "binary_d", ",", "attr", ",", "cpu_engine", ")", ";", "#endif", "auto", "binary_prim", "=", "binary", "(", "binary_pd", ")", ";", "auto", "src_0_scale_mem", "=", "memory", "(", "{", "{", "1", "}", ",", "MklDnnType", "<", "float", ">", "(", ")", ",", "memory", "::", "format_tag", "::", "x", "}", ",", "cpu_engine", ",", "src_0_scale", ".", "data", "(", ")", ")", ";", "auto", "src_1_scale_mem", "=", "memory", "(", "{", "{", "1", "}", ",", "MklDnnType", "<", "float", ">", "(", ")", ",", "memory", "::", "format_tag", "::", "x", "}", ",", "cpu_engine", ",", "src_1_scale", ".", "data", "(", ")", ")", ";", "std", "::", "unordered_map", "<", "int", ",", "memory", ">", "net_args", "{", "{", "DNNL_ARG_SRC_0", ",", "*", "src", ".", "GetUsrMem", "(", ")", "}", ",", "{", "DNNL_ARG_SRC_1", ",", "shift_mem", "}", ",", "{", "DNNL_ARG_DST", ",", "*", "dst", ".", "GetUsrMem", "(", ")", "}", ",", "#ifdef", "ENABLE_ONEDNN_V3", "{", "DNNL_ARG_ATTR_SCALES", "|", "DNNL_ARG_SRC_0", ",", "src_0_scale_mem", "}", ",", "{", "DNNL_ARG_ATTR_SCALES", "|", "DNNL_ARG_SRC_1", ",", "src_1_scale_mem", "}", "#endif", "}", ";", "binary_prim", ".", "execute", "(", "*", "cpu_stream", ",", "net_args", ")", ";", "}", "else", "{", "OP_REQUIRES", "(", "ctx", ",", "false", ",", "absl", "::", "UnimplementedError", "(", "\"", "\"", ")", ")", ";", "}", "output_min_tensor", "->", "scalar", "<", "float", ">", "(", ")", "(", ")", "=", "min_range", ";", "output_max_tensor", "->", "scalar", "<", "float", ">", "(", ")", "(", ")", "=", "max_range", ";", "}"], "to_mask": {}, "attention_idx_tokens": [725, 739], "patch": "@@ -509,12 +484,19 @@\n     AllocateOutputSetMklShape(ctx, 2, &output_max_tensor, max_tf_shape,\n                               max_mkl_shape, native_format);\n \n+    // Create the oneDNN wrapper over Eigen threadpool and set max threads\n+    // in oneDNN.\n+    Eigen::ThreadPoolInterface* eigen_interface =\n+        EigenThreadPoolFromTfContext(ctx);\n+    tsl::OneDnnThreadPool eigen_tp(eigen_interface,\n+                                   ThreadPoolUseCallerThread());\n+\n     float scale_factor = 0;\n     if (mode_ == QUANTIZE_MODE_SCALED) {\n       // Estimating scales for quantization.\n       const int num_bits = sizeof(T) * 8;\n       const float max_abs = std::max(std::abs(min_range), std::abs(max_range));\n-      const bool is_signed = std::is_signed<T>::value;\n+      const bool is_signed = std::is_same<T, qint8>();", "ext_attention_idx_tokens": [656, 742], "uid": "973d379e", "question": "> Why only qint8? What about for other signed quantized types T?  >   > If the issue is that:  >   > > I found that when T = qint8  > > Windows: std::is_signed::value is false  > > Linux: std::is_signed::value is true  >   > then _that_ should be fixed.    I have added other quantized types as well in the last commit.    Regarding the earlier issue, it was with compiler (MSVC at the time Google CI test failed earlier). I am not sure if Google has moved to Clang or not. Therefore, I am not sure if compiler needs to be fixed or not.", "code": "void Compute OpKernelContext* ctx override { const unsigned int src idx 0; const Tensor& input ctx->input src idx ; const float input min range ctx->input 1 scalar<float> ; const float input max range ctx->input 2 scalar<float> ; float min range std min 0 0f input min range ; float max range; OP REQUIRES ctx input max range > input min range absl InvalidArgumentError \"input max range must be larger than input min range \" ; When the minimum and maximum ranges are too close together nudge them apart by a small value so that they are slightly different This helps us avoid creating ill-formed buffers where all quantized values map to the same float number These kinds of buffers cause problems for downstream ops when they need to do calculations on them We pick the value by making sure that zero is not more than 100x the overall range from the maximum so that the value can be easily represented when we promote the quantized value to a higher intermediate bit depth since that s a common requirement const float epsilon std max 1 0f std max fabsf input min range fabsf input max range * ensure minimum range ; max range std max input max range min range + epsilon ; Clamping the max range to zero since max range can also be negative max range std max 0 0f max range ; auto cpu engine engine engine kind cpu 0 ; const Tensor& src tensor MklGetInput ctx src idx ; MklDnnShape src mkl shape; GetMklShape ctx src idx &src mkl shape native format ; auto src tf shape src mkl shape IsMklTensor ? src mkl shape GetTfShape src tensor shape ; auto src dims src mkl shape IsMklTensor ? src mkl shape GetSizesAsMklDnnDims TFShapeToMklDnnDims src tensor shape ; auto output dims src dims; Set the dst layout to be the best mkl layout based on dims and type memory format tag dst layout type; switch src tf shape dims { case 0 ComputeScalar ctx min range max range ; return; case 1 dst layout type memory format tag x; break; case 2 dst layout type memory format tag nc; break; case 3 dst layout type memory format tag tnc; break; case 4 dst layout type memory format tag nhwc; break; case 5 dst layout type memory format tag ndhwc; break; default OP REQUIRES OK ctx absl AbortedError \"Input dims must be < 5 and > 1\" ; return; } Create reorder memory for src dst both are defined in mkl util h they are wrapper MklDnnData<S> src &cpu engine ; MklDnnData<T> dst &cpu engine ; #ifdef ENABLE ONEDNN V3 MklDnnData<float> scale &cpu engine ; #endif ENABLE ONEDNN V3 auto src md src mkl shape IsMklTensor ? src mkl shape GetMklLayout memory desc src dims MklDnnType<S> dst layout type ; src SetUsrMem src md &src tensor ; memory desc dst md memory desc src dims MklDnnType<T> dst layout type ; Standard shape assignments for layout pass MklDnnShape output mkl shape; TensorShape output tf shape; if src mkl shape IsMklTensor { output mkl shape SetMklTensor true ; output mkl shape SET MKL LAYOUT dst md ; output mkl shape SetElemType MklDnnType<T> ; output mkl shape SetTfLayout src mkl shape GetDimension src mkl shape GetSizesAsMklDnnDims src mkl shape GetTfDataFormat ; output tf shape AddDim dst md get size sizeof T ; } else { output mkl shape SetMklTensor false ; output tf shape MklDnnDimsToTFShape output dims ; } Tensor* output tensor nullptr; AllocateOutputSetMklShape ctx 0 &output tensor output tf shape output mkl shape native format ; dst SetUsrMem dst md output tensor ; TensorShape min tf shape {}; MklDnnShape min mkl shape; min mkl shape SetMklTensor false ; Tensor* output min tensor nullptr; AllocateOutputSetMklShape ctx 1 &output min tensor min tf shape min mkl shape native format ; TensorShape max tf shape {}; MklDnnShape max mkl shape; max mkl shape SetMklTensor false ; Tensor* output max tensor nullptr; AllocateOutputSetMklShape ctx 2 &output max tensor max tf shape max mkl shape native format ; Create the oneDNN wrapper over Eigen threadpool and set max threads in oneDNN Eigen ThreadPoolInterface* eigen interface EigenThreadPoolFromTfContext ctx ; tsl OneDnnThreadPool eigen tp eigen interface ThreadPoolUseCallerThread ; float scale factor 0; if mode QUANTIZE MODE SCALED { Estimating scales for quantization const int num bits sizeof T * 8; const float max abs std max std abs min range std abs max range ; const bool is signed std is same<T qint8> ; float target range; if is signed { max range max abs; min range -max abs; If it is signed we try to keep 0 0 being 0 and drop one bucket For example if it is 8 bits we have the range [-127 127] So for input range of [-x x] the scale should be 254 2*x target range static cast<float> uint64 t{1} << num bits - 1 2 ; } else { max range max abs; min range 0 0; If it is unsigned and num bits 8 the range with 8 bits is [0 255] If the input range is [0 x] then the scale is 255 x instead of 254 as in the case above target range static cast<float> uint64 t{1} << num bits - 1 ; } scale factor target range max abs; #ifdef ENABLE ONEDNN V3 auto scale md memory desc {1} MklDnnType<float> memory format tag x ; MklReorderWithScaleFwdParams fwdParams src dims src md dst md scale md ; Tensor scale tensor; OP REQUIRES OK ctx ctx->allocate temp DT FLOAT {1} &scale tensor ; scale tensor flat<float> 0 scale factor; scale SetUsrMem scale md &scale tensor ; #else MklReorderWithScaleFwdParams fwdParams src dims src md dst md ; #endif ENABLE ONEDNN V3 fwdParams dtypes append typeid S name ; fwdParams dtypes append typeid T name ; fwdParams post op params name \"scale\"; fwdParams post op params param push back scale factor ; MklReorderWithScalePrimitive* reorder prim MklReorderWithScalePrimitiveFactory<T> Get src GetUsrMem dst GetUsrMem fwdParams ; std shared ptr<stream> cpu stream; cpu stream reset CreateStream &eigen tp reorder prim->GetEngine ; reorder prim->Execute src GetUsrMemDataHandle dst GetUsrMemDataHandle #ifdef ENABLE ONEDNN V3 scale GetUsrMemDataHandle #endif ENABLE ONEDNN V3 cpu stream ; } else if mode QUANTIZE MODE MIN FIRST { using namespace dnnl; std shared ptr<stream> cpu stream; cpu stream reset CreateStream &eigen tp cpu engine ; auto shift static cast<S> -min range ; memory dims shift dims src tf shape dims 1 ; auto shift md memory desc shift dims MklDnnType<S> dst layout type ; memory shift mem shift md cpu engine void* &shift ; primitive attr attr; std vector<float> src 0 scale{255 0f max range - min range }; std vector<float> src 1 scale{255 0f max range - min range }; #ifdef ENABLE ONEDNN V3 attr set scales mask DNNL ARG SRC 0 0 ; attr set scales mask DNNL ARG SRC 1 0 ; auto binary pd binary primitive desc cpu engine algorithm binary add src md shift md dst md attr ; #else attr set scales DNNL ARG SRC 0 0 src 0 scale ; attr set scales DNNL ARG SRC 1 0 src 1 scale ; auto binary d binary desc algorithm binary add src md shift md dst md ; auto binary pd binary primitive desc binary d attr cpu engine ; #endif ENABLE ONEDNN V3 auto binary prim binary binary pd ; auto src 0 scale mem memory {{1} MklDnnType<float> memory format tag x} cpu engine src 0 scale data ; auto src 1 scale mem memory {{1} MklDnnType<float> memory format tag x} cpu engine src 1 scale data ; std unordered map<int memory> net args{ {DNNL ARG SRC 0 *src GetUsrMem } {DNNL ARG SRC 1 shift mem} {DNNL ARG DST *dst GetUsrMem } #ifdef ENABLE ONEDNN V3 {DNNL ARG ATTR SCALES | DNNL ARG SRC 0 src 0 scale mem} { DNNL ARG ATTR SCALES | DNNL ARG SRC 1 src 1 scale mem } #endif }; binary prim execute *cpu stream net args ; } else { OP REQUIRES ctx false absl UnimplementedError \"Supported modes are MIN FIRST and SCALED only \" ; } output min tensor->scalar<float> min range; output max tensor->scalar<float> max range; }"}
{"message": "Why did you change this?", "timestamp": "2024-12-07T09:42:46Z", "file_name": "tensorflow/core/kernels/multinomial_op.cc", "range": {"start_line": 156, "end_line": 156, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1874386696", "html_url": "https://github.com/tensorflow/tensorflow/pull/64651#discussion_r1874386696", "attention_area": "                absl::InvalidArgumentError(absl::StrCat(\"logits should be a matrix, got shape \",", "file_path": "files/37/01/00000137.cc", "old_file_path": "files/75/00/00000075.cc", "filters": {"comment_message": true, "patchset": false, "first_in_thread": true, "valid_patch": false}, "language": "cpp", "replies": {}, "diff_hunk": "@@ -153,30 +153,30 @@ class MultinomialOp : public OpKernel {\n   void DoCompute(OpKernelContext* ctx, const Tensor& logits_t,\n                  const Tensor& num_samples_t, GuardedPhiloxRandom* generator) {\n     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(logits_t.shape()),\n-                errors::InvalidArgument(\"logits should be a matrix, got shape \",\n-                                        logits_t.shape().DebugString()));\n+                absl::InvalidArgumentError(absl::StrCat(\"logits should be a matrix, got shape \",", "source": "void DoCompute(OpKernelContext* ctx, const Tensor& logits_t,\n                 const Tensor& num_samples_t, GuardedPhiloxRandom* generator) {\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(logits_t.shape()),\n                absl::InvalidArgumentError(absl::StrCat(\"logits should be a matrix, got shape \",\n                                        logits_t.shape().DebugString())));\n    OP_REQUIRES(\n        ctx, TensorShapeUtils::IsScalar(num_samples_t.shape()),\n        absl::InvalidArgumentError(absl::StrCat(\"num_samples should be a scalar, got shape \",\n                                num_samples_t.shape().DebugString())));\n\n    const int num_samples = num_samples_t.scalar<int>()();\n    OP_REQUIRES(ctx, num_samples >= 0,\n                absl::InvalidArgumentError(absl::StrCat(\n                    \"num_samples should be non-negative, got \", num_samples)));\n\n    const int batch_size = static_cast<int>(logits_t.dim_size(0));\n    const int num_classes = static_cast<int>(logits_t.dim_size(1));\n\n    OP_REQUIRES(ctx, batch_size == logits_t.dim_size(0),\n                absl::InvalidArgumentError(\"batch_size cannot exceed max int\"));\n\n    OP_REQUIRES(ctx, num_classes == logits_t.dim_size(1),\n                absl::InvalidArgumentError(\"num_classes cannot exceed max int\"));\n\n    OP_REQUIRES(ctx, num_classes > 0,\n                absl::InvalidArgumentError(absl::StrCat(\"num_classes should be positive, got \",\n                                        num_classes)));\n\n    Tensor* samples_t;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(0, TensorShape({batch_size, num_samples}),\n                                  &samples_t));\n\n    // Execute kernel only for nonempty output; otherwise Eigen crashes on GPU.\n    if (samples_t->NumElements() > 0) {\n      Tensor noises, scores, scratch;  // Scratch space only used for GPU.\n      if (std::is_same<Device, GPUDevice>::value) {\n        OP_REQUIRES_OK(\n            ctx,\n            ctx->allocate_temp(\n                DT_FLOAT, TensorShape({batch_size, num_samples, num_classes}),\n                &noises));\n        OP_REQUIRES_OK(\n            ctx,\n            ctx->allocate_temp(\n                DT_FLOAT, TensorShape({batch_size, num_samples, num_classes}),\n                &scores));\n        OP_REQUIRES_OK(\n            ctx,\n            ctx->allocate_temp(DT_FLOAT, TensorShape({batch_size, num_samples}),\n                               &scratch));\n      }\n\n      int num_samples_ceil_4 = (num_samples + 3) / 4 * 4;\n      // CPU generates doubles = 2 samples per number.\n      if (std::is_same<Device, CPUDevice>::value) num_samples_ceil_4 *= 2;\n      auto rng =\n          generator->ReserveRandomOutputs(batch_size * num_samples_ceil_4, 256);\n      functor::MultinomialFunctor<Device, T, OutputType>()(\n          ctx, ctx->eigen_device<Device>(), logits_t.matrix<T>(),\n          noises.flat<float>(), scores.flat<float>(), scratch.flat<float>(),\n          batch_size, num_classes, num_samples, rng,\n          samples_t->matrix<OutputType>());\n    }\n  }", "source_start_line": 153, "tokens": ["void", "DoCompute", "(", "OpKernelContext", "*", "ctx", ",", "const", "Tensor", "&", "logits_t", ",", "const", "Tensor", "&", "num_samples_t", ",", "GuardedPhiloxRandom", "*", "generator", ")", "{", "OP_REQUIRES", "(", "ctx", ",", "TensorShapeUtils", "::", "IsMatrix", "(", "logits_t", ".", "shape", "(", ")", ")", ",", "absl", "::", "InvalidArgumentError", "(", "absl", "::", "StrCat", "(", "\"", "\"", ",", "logits_t", ".", "shape", "(", ")", ".", "DebugString", "(", ")", ")", ")", ")", ";", "OP_REQUIRES", "(", "ctx", ",", "TensorShapeUtils", "::", "IsScalar", "(", "num_samples_t", ".", "shape", "(", ")", ")", ",", "absl", "::", "InvalidArgumentError", "(", "absl", "::", "StrCat", "(", "\"", "\"", ",", "num_samples_t", ".", "shape", "(", ")", ".", "DebugString", "(", ")", ")", ")", ")", ";", "const", "int", "num_samples", "=", "num_samples_t", ".", "scalar", "<", "int", ">", "(", ")", "(", ")", ";", "OP_REQUIRES", "(", "ctx", ",", "num_samples", ">=", "0", ",", "absl", "::", "InvalidArgumentError", "(", "absl", "::", "StrCat", "(", "\"", "\"", ",", "num_samples", ")", ")", ")", ";", "const", "int", "batch_size", "=", "static_cast", "<", "int", ">", "(", "logits_t", ".", "dim_size", "(", "0", ")", ")", ";", "const", "int", "num_classes", "=", "static_cast", "<", "int", ">", "(", "logits_t", ".", "dim_size", "(", "1", ")", ")", ";", "OP_REQUIRES", "(", "ctx", ",", "batch_size", "==", "logits_t", ".", "dim_size", "(", "0", ")", ",", "absl", "::", "InvalidArgumentError", "(", "\"", "\"", ")", ")", ";", "OP_REQUIRES", "(", "ctx", ",", "num_classes", "==", "logits_t", ".", "dim_size", "(", "1", ")", ",", "absl", "::", "InvalidArgumentError", "(", "\"", "\"", ")", ")", ";", "OP_REQUIRES", "(", "ctx", ",", "num_classes", ">", "0", ",", "absl", "::", "InvalidArgumentError", "(", "absl", "::", "StrCat", "(", "\"", "\"", ",", "num_classes", ")", ")", ")", ";", "Tensor", "*", "samples_t", ";", "OP_REQUIRES_OK", "(", "ctx", ",", "ctx", "->", "allocate_output", "(", "0", ",", "TensorShape", "(", "{", "batch_size", ",", "num_samples", "}", ")", ",", "&", "samples_t", ")", ")", ";", "if", "(", "samples_t", "->", "NumElements", "(", ")", ">", "0", ")", "{", "Tensor", "noises", ",", "scores", ",", "scratch", ";", "if", "(", "std", "::", "is_same", "<", "Device", ",", "GPUDevice", ">", "::", "value", ")", "{", "OP_REQUIRES_OK", "(", "ctx", ",", "ctx", "->", "allocate_temp", "(", "DT_FLOAT", ",", "TensorShape", "(", "{", "batch_size", ",", "num_samples", ",", "num_classes", "}", ")", ",", "&", "noises", ")", ")", ";", "OP_REQUIRES_OK", "(", "ctx", ",", "ctx", "->", "allocate_temp", "(", "DT_FLOAT", ",", "TensorShape", "(", "{", "batch_size", ",", "num_samples", ",", "num_classes", "}", ")", ",", "&", "scores", ")", ")", ";", "OP_REQUIRES_OK", "(", "ctx", ",", "ctx", "->", "allocate_temp", "(", "DT_FLOAT", ",", "TensorShape", "(", "{", "batch_size", ",", "num_samples", "}", ")", ",", "&", "scratch", ")", ")", ";", "}", "int", "num_samples_ceil_4", "=", "(", "num_samples", "+", "3", ")", "/", "4", "*", "4", ";", "if", "(", "std", "::", "is_same", "<", "Device", ",", "CPUDevice", ">", "::", "value", ")", "num_samples_ceil_4", "*=", "2", ";", "auto", "rng", "=", "generator", "->", "ReserveRandomOutputs", "(", "batch_size", "*", "num_samples_ceil_4", ",", "256", ")", ";", "functor", "::", "MultinomialFunctor", "<", "Device", ",", "T", ",", "OutputType", ">", "(", ")", "(", "ctx", ",", "ctx", "->", "eigen_device", "<", "Device", ">", "(", ")", ",", "logits_t", ".", "matrix", "<", "T", ">", "(", ")", ",", "noises", ".", "flat", "<", "float", ">", "(", ")", ",", "scores", ".", "flat", "<", "float", ">", "(", ")", ",", "scratch", ".", "flat", "<", "float", ">", "(", ")", ",", "batch_size", ",", "num_classes", ",", "num_samples", ",", "rng", ",", "samples_t", "->", "matrix", "<", "OutputType", ">", "(", ")", ")", ";", "}", "}"], "to_mask": {}, "attention_idx_tokens": [37, 47], "patch": "@@ -153,30 +153,30 @@\n   void DoCompute(OpKernelContext* ctx, const Tensor& logits_t,\n                  const Tensor& num_samples_t, GuardedPhiloxRandom* generator) {\n     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(logits_t.shape()),\n-                errors::InvalidArgument(\"logits should be a matrix, got shape \",\n-                                        logits_t.shape().DebugString()));\n+                absl::InvalidArgumentError(absl::StrCat(\"logits should be a matrix, got shape \",", "ext_attention_idx_tokens": [37, 240], "uid": "db09d309", "question": "Why did you change this?", "code": "void DoCompute OpKernelContext* ctx const Tensor& logits t const Tensor& num samples t GuardedPhiloxRandom* generator { OP REQUIRES ctx TensorShapeUtils IsMatrix logits t shape absl InvalidArgumentError absl StrCat \"logits should be a matrix got shape \" logits t shape DebugString ; OP REQUIRES ctx TensorShapeUtils IsScalar num samples t shape absl InvalidArgumentError absl StrCat \"num samples should be a scalar got shape \" num samples t shape DebugString ; const int num samples num samples t scalar<int> ; OP REQUIRES ctx num samples > 0 absl InvalidArgumentError absl StrCat \"num samples should be non-negative got \" num samples ; const int batch size static cast<int> logits t dim size 0 ; const int num classes static cast<int> logits t dim size 1 ; OP REQUIRES ctx batch size logits t dim size 0 absl InvalidArgumentError \"batch size cannot exceed max int\" ; OP REQUIRES ctx num classes logits t dim size 1 absl InvalidArgumentError \"num classes cannot exceed max int\" ; OP REQUIRES ctx num classes > 0 absl InvalidArgumentError absl StrCat \"num classes should be positive got \" num classes ; Tensor* samples t; OP REQUIRES OK ctx ctx->allocate output 0 TensorShape {batch size num samples} &samples t ; Execute kernel only for nonempty output; otherwise Eigen crashes on GPU if samples t->NumElements > 0 { Tensor noises scores scratch; Scratch space only used for GPU if std is same<Device GPUDevice> value { OP REQUIRES OK ctx ctx->allocate temp DT FLOAT TensorShape {batch size num samples num classes} &noises ; OP REQUIRES OK ctx ctx->allocate temp DT FLOAT TensorShape {batch size num samples num classes} &scores ; OP REQUIRES OK ctx ctx->allocate temp DT FLOAT TensorShape {batch size num samples} &scratch ; } int num samples ceil 4 num samples + 3 4 * 4; CPU generates doubles 2 samples per number if std is same<Device CPUDevice> value num samples ceil 4 * 2; auto rng generator->ReserveRandomOutputs batch size * num samples ceil 4 256 ; functor MultinomialFunctor<Device T OutputType> ctx ctx->eigen device<Device> logits t matrix<T> noises flat<float> scores flat<float> scratch flat<float> batch size num classes num samples rng samples t->matrix<OutputType> ; } }"}
{"message": "Can you also remove the future import? That is only in Python 2.", "timestamp": "2024-12-09T08:10:17Z", "file_name": "tensorflow/python/ops/math_ops.py", "range": {"start_line": 1487, "end_line": 1487, "start_character": 0, "end_character": 0}, "project": "tensorflow/tensorflow", "api_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/1875539982", "html_url": "https://github.com/tensorflow/tensorflow/pull/82466#discussion_r1875539982", "attention_area": "  `x / y` division with `from __future__ import division`.  If you want integer", "file_path": "files/38/01/00000138.py", "old_file_path": "files/40/01/00000140.py", "filters": {"comment_message": true, "patchset": true, "first_in_thread": true, "valid_patch": false}, "language": "python", "replies": {}, "diff_hunk": "@@ -1484,9 +1484,8 @@ def truediv(x, y, name=None):\n \n   This function forces Python 3 division operator semantics where all integer\n   arguments are cast to floating types first.   This op is generated by normal\n-  `x / y` division in Python 3 and in Python 2.7 with\n-  `from __future__ import division`.  If you want integer division that rounds\n-  down, use `x // y` or `tf.math.floordiv`.\n+  `x / y` division with `from __future__ import division`.  If you want integer", "source": "def truediv(x, y, name=None):\n  \"\"\"Divides x / y elementwise (using Python 3 division operator semantics).\n\n  NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n  division operator semantics.\n\n  This function forces Python 3 division operator semantics where all integer\n  arguments are cast to floating types first.   This op is generated by normal\n  `x / y` division with `from __future__ import division`.  If you want integer\n  division that rounds down, use `x // y` or `tf.math.floordiv`.\n\n  `x` and `y` must have the same numeric type.  If the inputs are floating\n  point, the output will have the same type.  If the inputs are integral, the\n  inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n  and `int64` (matching the behavior of Numpy).\n\n  Example:\n\n  >>> # Division with integer tensors (returns float)\n  >>> x1 = tf.constant([10, 20, 30], dtype=tf.int32)\n  >>> y1 = tf.constant([2, 4, 5], dtype=tf.int32)\n  >>> result1 = tf.math.truediv(x1, y1)\n  \n  <tf.Tensor: shape=(3,), dtype=float64, numpy=array([5., 5., 6.])>\n\n  >>> # Division with different shaped tensors (broadcasting)\n  >>> x2 = tf.constant([[10, 20], [30, 40]], dtype=tf.float64)\n  >>> y2 = tf.constant([2, 5], dtype=tf.float64)\n  >>> result2 = tf.math.truediv(x2, y2)\n\n  <tf.Tensor: shape=(2, 2),dtype=float64,numpy= array([[ 5.,  4.],[15.,  8.]])>\n\n  # Handling potential division by zero (returns inf)\n  >>> x3 = tf.constant(5, dtype=tf.float32)\n  >>> y3 = tf.constant(0, dtype=tf.float32)\n  >>> result3 = tf.math.truediv(x3, y3)\n\n  <tf.Tensor: shape=(), dtype=float32, numpy=inf>\n\n  Args:\n    x: `Tensor` numerator of numeric type.\n    y: `Tensor` denominator of numeric type.\n    name: A name for the operation (optional).\n\n  Returns:\n    `x / y` evaluated in floating point.\n\n  Raises:\n    TypeError: If `x` and `y` have different dtypes.\n  \"\"\"\n  return _truediv_python3(x, y, name)", "source_start_line": 1479, "tokens": ["def", "truediv", "(", "x", ",", "y", ",", "name", "=", "None", ")", ":", "\"\"\"Divides x / y elementwise (using Python 3 division operator semantics).  NOTE: Prefer using the Tensor operator or tf.divide which obey Python  division operator semantics.  This function forces Python 3 division operator semantics where all integer  arguments are cast to floating types first.   This op is generated by normal  `x / y` division with `from __future__ import division`.  If you want integer  division that rounds down, use `x // y` or `tf.math.floordiv`.  `x` and `y` must have the same numeric type.  If the inputs are floating  point, the output will have the same type.  If the inputs are integral, the  inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`  and `int64` (matching the behavior of Numpy).  Example:  >>> # Division with integer tensors (returns float)  >>> x1 = tf.constant([10, 20, 30], dtype=tf.int32)  >>> y1 = tf.constant([2, 4, 5], dtype=tf.int32)  >>> result1 = tf.math.truediv(x1, y1)    <tf.Tensor: shape=(3,), dtype=float64, numpy=array([5., 5., 6.])>  >>> # Division with different shaped tensors (broadcasting)  >>> x2 = tf.constant([[10, 20], [30, 40]], dtype=tf.float64)  >>> y2 = tf.constant([2, 5], dtype=tf.float64)  >>> result2 = tf.math.truediv(x2, y2)  <tf.Tensor: shape=(2, 2),dtype=float64,numpy= array([[ 5.,  4.],[15.,  8.]])>  # Handling potential division by zero (returns inf)  >>> x3 = tf.constant(5, dtype=tf.float32)  >>> y3 = tf.constant(0, dtype=tf.float32)  >>> result3 = tf.math.truediv(x3, y3)  <tf.Tensor: shape=(), dtype=float32, numpy=inf>  Args:    x: `Tensor` numerator of numeric type.    y: `Tensor` denominator of numeric type.    name: A name for the operation (optional).  Returns:    `x / y` evaluated in floating point.  Raises:    TypeError: If `x` and `y` have different dtypes.  \"\"\"", "return", "_truediv_python3", "(", "x", ",", "y", ",", "name", ")"], "to_mask": {"VAR": ["name", "x", "y"], "METHOD": ["_truediv_python3"]}, "attention_idx_tokens": [null, null], "patch": "@@ -1484,9 +1484,8 @@\n \n   This function forces Python 3 division operator semantics where all integer\n   arguments are cast to floating types first.   This op is generated by normal\n-  `x / y` division in Python 3 and in Python 2.7 with\n-  `from __future__ import division`.  If you want integer division that rounds\n-  down, use `x // y` or `tf.math.floordiv`.\n+  `x / y` division with `from __future__ import division`.  If you want integer", "ext_attention_idx_tokens": [null, null], "uid": "af3df02e", "question": "Can you also remove the future import? That is only in Python 2.", "code": "def truediv x y name None \"\"\"Divides x y elementwise using Python 3 division operator semantics NOTE Prefer using the Tensor operator or tf divide which obey Python division operator semantics This function forces Python 3 division operator semantics where all integer arguments are cast to floating types first This op is generated by normal `x y` division with `from future import division` If you want integer division that rounds down use `x y` or `tf math floordiv` `x` and `y` must have the same numeric type If the inputs are floating point the output will have the same type If the inputs are integral the inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32` and `int64` matching the behavior of Numpy Example >>> # Division with integer tensors returns float >>> x1 tf constant [10 20 30] dtype tf int32 >>> y1 tf constant [2 4 5] dtype tf int32 >>> result1 tf math truediv x1 y1 <tf Tensor shape 3 dtype float64 numpy array [5 5 6 ] > >>> # Division with different shaped tensors broadcasting >>> x2 tf constant [[10 20] [30 40]] dtype tf float64 >>> y2 tf constant [2 5] dtype tf float64 >>> result2 tf math truediv x2 y2 <tf Tensor shape 2 2 dtype float64 numpy array [[ 5 4 ] [15 8 ]] > # Handling potential division by zero returns inf >>> x3 tf constant 5 dtype tf float32 >>> y3 tf constant 0 dtype tf float32 >>> result3 tf math truediv x3 y3 <tf Tensor shape dtype float32 numpy inf> Args x `Tensor` numerator of numeric type y `Tensor` denominator of numeric type name A name for the operation optional Returns `x y` evaluated in floating point Raises TypeError If `x` and `y` have different dtypes \"\"\" return truediv python3 x y name"}
